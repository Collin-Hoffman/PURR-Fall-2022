,text,Section Title,Subsection Titles,Class Labels
0,"There is an urgent need to improve our understanding of the global carbon cycle, in which anthropogenic carbon dioxide (CO2) emissions into the atmosphere are the dominant factor driving climate change. Terrestrial ecosystems play a crucial role in the mitigation of climate warming [1]. Global forests are responsible for the sequestration of approximately 29% of the emitted CO2 [2], but forest areas are also an important source of CO2 emissions to the atmosphere through deforestation and forest degradation. Despite the importance of forests in the global carbon cycle, the spatial distribution of forest carbon stocks and related fluxes is not yet well-quantified [3,4]. Above-ground biomass (AGB) in forests, which contains about 50% of carbon [5], is a central factor in the carbon budget, but in many parts of the planet AGB is poorly quantified due to the difficulty in collecting sufficient field measurements.Measurements of AGB from spaceborne sensors have relied on sensors of opportunity so far, since no mission was designed for this specific purpose [6]. Several studies deal with either the combination of forest height (FH) estimates from laser altimeters with other Earth observation (EO) measurements (e.g., [7]) or with time series of Synthetic Aperture Radar (SAR) data to estimate AGB and its change over time (e.g., [8]). Limitations of these studies mainly come from the very coarse scale at which reliable estimation is possible or the availability of a limited amount of data both in time and space due to the lack of systematic acquisition strategies over forested areas. Moreover, as regards SAR sensors, the higher frequencies at which some in-orbit platforms operate (e.g., Sentinel-1, Tandem-X) are only sensitive to the uppermost layer of the forest canopy (mainly leaves) and thus have only limited retrieval capabilities, while the sensitivity to AGB of L-band sensors (ALOS-PALSAR, SAOCOM) tends to saturate at higher levels of AGB [3,4].The European Space Agency (ESA) Earth Explorer missions focus on the most challenging issues identified by the scientific community regarding the study of our planet using innovative satellite technologies. In this framework the BIOMASS mission was selected as the seventh Earth Explorer in May 2013 [3,4]. The scientific goal of BIOMASS is to provide frequent global maps of AGB, FH and forest disturbance (FD) at a resolution and accuracy compatible with the needs of international reporting on carbon stocks [9] and terrestrial carbon modeling [1,6]. BIOMASS will carry the first P-band radar in space (435 MHz) with multi-baseline interferometric and fully-polarimetric capabilities. This configuration will provide unprecedented sensitivity to forest AGB and penetration capability down to the underlying terrain [4,10].The mission preparatory activities include the definition and implementation of the main algorithms of the Prototype Processor for generating global biophysical mission products [11]. In this paper, the scientific basis and the outline and operational flow of the level 2 prototype processor are presented. Section 2 contains a summary of BIOMASS mission and product characteristics. Section 3 presents the scientific concepts and rationale behind the AGB inversion implemented in the processor, as well as for the other mission products. In Section 4 the processor outline and operational flow are presented, with a focus on global AGB estimation. In Section 5 experimental results from level 2 product generation obtained with campaign data are discussed, highlighting the current status and open issues in Section 6.", 1. Introduction,None,1.
1,"The data products to be retrieved in order to accomplish the primary mission objectives are defined in the BIOMASS Mission Requirements Document [12] and are defined as:AGB, defined as dry weight of woody matter per unit area, expressed in t/ha = Mg/ha. AGB is defined as the mass of live organic matter above the soil including stem, stump, branches, bark, seeds and foliage, it does not include dead mass, litter and below-ground biomass [13].FH, defined as upper canopy height according to the H100 standard used in forestry expressed in m. H100 is defined as the average height of the 100 tallest trees/ha [14].FD, defined as an area where an intact patch of forest has been cleared, expressed as a binary classification of intact versus deforested or logged areas.The accuracy and spatial resolution of these products are defined in Table 1. The higher resolution of the FD product with respect to the AGB and FH products is due to two facts: (a) logging and disturbance activities often occur at small scale requiring higher resolution to detect them; (b) deforestation is expected to cause large changes in the radar return which is expected to be detectable with a much smaller number of looks (i.e., independent samples in a spatial estimation window and hence finer spatial resolution) than is needed to estimate AGB. The temporal sampling of products is one map every global observation cycle, where the length of the global observation cycle depends on the specific mission phase. The latency of the data products will be shorter than 1 month. The products are intended to be global, covering forested land areas between 75°N and 56°S but subject to United States Department of Defense Space Object Tracking Radar (SOTR) restrictions [15]. These restrictions exclude coverage of North America and Europe.", 2. BIOMASS Mission and Products Summary, 2.1. BIOMASS Products,2
2,"The spatial resolution of the BIOMASS level 1 single-look complex images will be about 8.3 m in azimuth and 59 m in-ground range (25 m in slant range), where the range resolution is limited by the 6 MHz bandwidth of the system considering an incidence angle of 25°. The 50 × 50 m2 product will hence be based on six equivalent numbers of looks (ENL) [4].The system will observe during both ascending and descending passes, thus providing for each point within the observation mask at least two stacks of level 1 data within one global coverage cycle. BIOMASS will be in a sun-synchronous orbit with a near dawn-dusk equator crossing time (Local Time of the Ascending Node of 06:00 ± 15 min), chosen to minimize scintillation effects that occur in the post-sunset equatorial ionosphere [16]. The system will be left-looking and the orbit inclination will be 98°, with the highest latitude in the northern hemisphere attained on the night-side.The BIOMASS orbital pattern will be organized into three phases. The three month Commissioning Phase (CP) is designed to allow 21 passes over a transponder at different incidence angles in order to measure the 2-D antenna pattern and test the polarimetric calibration [17]. The subsequent Tomographic Phase (TOM) will provide 3D tomographic mapping of all forest areas (in fact, all continental areas) outside the SOTR zone. A TOM stack will be composed of seven acquisitions, each one separated by three days and a baseline of 15% of the critical baseline (approximately 0.823 km at the Equator [4]) which will be achieved through orbital drift [18]. This mission phase will require 425 days or approximately 14 months in order to cover the globe. The temporal and spatial separation of the tracks was designed in order to preserve coherence at P-band with a repeat pass system [19]. The TOM phase will also provide the mission’s first global maps of AGB and FH. The remainder of the five-year mission will be taken up by the Interferometric Phase (INT). During the INT phase each interferometric stack will consist of three acquisitions, thus allowing for faster global coverage of 228 days (approximately seven months). Similar to the TOM phase, each acquisition will be separated by three days and a baseline of 15% of the critical baseline.Both ascending and descending data will be used to provide more independent samples in the estimation, to reduce topographic effects and to acquire data with large enough ENL to meet the strict accuracy requirements. This means that the time to produce a final product at any given location within the TOM phase and each cycle of the INT phase will depend on the interval between the ascending and descending acquisitions at that point.A peculiar feature of BIOMASS is the way the global coverage is obtained, as it is built up systematically by a sequence of roll and repositioning maneuvers. This is due to the relatively small swath width of approximately 50 km that can be achieved at P-band while maintaining the performance requirements and a requirement for a three-day repeat cycle to maintain high coherence. Roll maneuvers will allow the satellite to successively generate three sub-swaths of width 54.32, 54.41 and 46.06 km, giving a range of incidence angles across the combined swath from 23° to 34°. After acquiring the three subswaths, the satellite will conduct an orbit maneuver to move to the next swath and start again to acquire a sequence of three subswaths. This strategy implies that adjacent swaths used to build up the global coverage are gathered at different times. Consequently, the algorithms retrieving the biophysical parameters will encounter differences in the environmental conditions between adjacent swaths acquired during one global coverage cycle. It is thus of paramount importance that the proposed algorithms are robust to or can compensate for these variations to avoid introducing systematic biases in the final global products.", 2. BIOMASS Mission and Products Summary, 2.2. BIOMASS Mission Characteristics,2
3,"The relationship between P-band SAR backscatter intensity of forests and forest AGB is governed by a large number of factors related to both forest characteristics (3D structure, species, growth stage, leaf and wood water content, etc.) and the environment (topography, soil moisture and surface roughness). An inversion taking into account all these parameters is ill-posed, as mentioned in the following. Existing studies are usually based on data obtained on a limited number of test sites and for one point in time. For these, extensive reference data available within the same scene were used in the training process of some inversion scheme. The extension from reference plots to the entire scene was performed using statistical methods (e.g., Random Forest), or using simplified physical models [20,21,22,23,24]. In those models effort was made to reduce or take into account the various effects disturbing the relation between vegetation AGB and backscatter (including system effects, such as radiometric accuracy and incidence angle, and environmental effects, such as soil and vegetation moisture, surface roughness and ground topography).The following approaches to retrieve AGB from P-Band SAR data have been identified:in the tropics, regression of VH tomographic intensity from a height around 30 m above the ground against reference data using a log-linear regression relation [20];in the tropics, regression of a VH polarimetric power index of some form (σ0, γ0 or t0) against reference data using a power law [21];in the boreal zone, regression of a polarimetric relation involving all three polarimetric terms (HH, VV and VH) [25] against reference data [22];a physics-based approach based on a semi-empirical scattering model [23];conversion of height estimates into AGB using allometric relations [24], which does not rely on regression or reference data for its primary height estimate, but thereafter is dependent on the accuracy of the height-to-AGB allometric relationships used.However, these approaches are subject to severe limitations. The data on which tropical inversion schemes were based covered a very limited range of conditions: almost all the reference plots had high AGB and the environmental conditions during the acquisitions of the airborne data used to develop the algorithms showed little variation. Topography was the major disturbing factor and methods were developed to minimize its impact [21], even though significant sensitivity to AGB could mostly be demonstrated using tomographic techniques [20]. Boreal campaigns were specifically designed to include substantial environmental changes, and the study areas included significant topographic variation. This allowed the development of relations that mitigated both moisture and slope effects by the use of the HH/VV ratio [22]. However, establishing the regressions or parametrizing the models relied (both for tropics and boreal) on substantial amounts of reference data, so the generality of these relations was of great concern. Boreal studies [22] indicated that the regression could be successfully transferred between sites to some extent. However, satisfactory accuracy across all boreal datasets could only be achieved by increasing the number of regression parameters, and extra parameters are to be handled with care for a global algorithm, especially when they have no clear physical meaning.The model presented in [23] is more grounded in scattering physics but its initial assessment suggested that it involved too many parameters, required too much reference data and was algorithmically unstable. Regarding AGB estimation from height, particularly in the tropics, the allometric relations between height and AGB are not mature enough to yield accurate AGB estimates, especially when the uncertainty in the height estimate from Pol-InSAR is taken into account. Moreover, the application of allometric equations without precisely knowing the diameter causes errors as, in many tree species, the variation of diameter and tree height is not correlated after a certain point [26]. To overcome this issue, it would be useful to add optical-based variables (e.g., multispectral data [27]) or structural-related variables (e.g., heterogeneity from LiDAR [28]), but this would add more requirements on external/training data to the algorithm, weakening the desired self-containedness.Circumventing these limitations and making full use of the BIOMASS interferometric observation capabilities requires a fundamentally new conceptual design of the retrieval. This revision is based on three research results of the mission preparatory activities:The observational and modeling evidence that 30−40% of the total AGB in a dense tropical forest is contained in the canopy region 25–35 m above the ground [20], and that the biomass in this region is highly correlated with the total AGB [29];The development of signal processing techniques (i.e., ground cancellation) to cancel out the backscatter signal from the ground layer using interferometric stacks of P-band data to isolate the volume scattering element of the forest canopy;The development of an optimization approach to solve the model [23] that minimizes the need for reference data.Studies comparing tomographic SAR data to in situ observations of AGB show that the backscatter of a layer located at 30 m above ground shows higher sensitivity to and correlation with AGB than the total backscatter of the whole canopy [20]. The explanation for this observation is twofold. First, the effectiveness of SAR tomography in achieving good sensitivity to AGB is due to the fact that by reconstructing the full 3D image of the forest it is possible to single out the canopy layer, which is hardly contaminated by any contribution from the ground layer as long as the vertical resolution is sufficient. Second, recent ecological studies in dense tropical forests reveal that the correlation between AGB and the area occupied at different heights by large trees (as derived from terrestrial LiDAR measurements) is maximal at a height of about 30 m [29], and about one-third of the total volume tends to be concentrated at the same height above the ground [30]. These findings provide a sound basis for the very good results obtained with tomographic regression [20]. These results are further confirmed by the prediction obtained with the TROLL ecological model that for dense tropical forests the fraction of biomass contained between 20 and 40 m accounts for about 35% to 40% of the total AGB. This relation is stable over a large range of AGB values. It has to be noted however that the relevance of the layer of vegetation around 30 m was demonstrated for dense tropical forests [31], in other types of forests with different structures the most representative layer height may be different. These results, along with the evidence that the ground mostly acts as a noise source to the AGB retrieval (being influenced mainly by soil moisture, the micro-relief of the surface and tree-ground interaction) [32] and the limited availability of baselines during the INT mission phase compared to the TOM phase, motivated the development of ground cancellation techniques. Finally, from [23] the backscattering coefficient in each polarimetric channel can be expressed as the incoherent summation of three main contributions: volume (related to the forest canopy), surface, and double-bounce scattering (related to the ground). With ground cancellation the volume component can be isolated which, as noted above, is well correlated with AGB.Volume separation can be obtained through model-based ground and volume decomposition techniques [33,34], although the decomposition does not have a unique solution and the preferred solution is obtained by imposing physical constraints on the model [35,36]. Interferometric ground cancellation [37] instead relies purely on geometry. Consider two acquisitions separated by an interferometric baseline that has been previously phase-calibrated [38,39] and phase-steered, so that the sensor-terrain distance is compensated, and the ground level corresponds to zero. By subtracting these two acquisitions, cancellation of the ground, as well as the emphasis of a certain height layer, is automatically achieved with a vertical impulse response function (IRF) that weights backscatter within the resolution cell depending on the interferometric baseline:



I
R
F

(
z
)

=
2
j
exp

j


k
z

2

z

sin



k
z

2

z





(1)


where z is the elevation and 

k
z

 is the phase-to-height conversion factor. As 

I
R
F
(
z
=
0
)
=
0

, terrain scattering is canceled out. The value of 

k
z

 determines the position of the peak of the vertical IRF, that is 


z

p
e
a
k


=
π
/

k
z

=

z

a
m
b


/
2

, with 

z

a
m
b


 being the height of ambiguity [40]. With more than two acquisitions a specific elevation can be emphasized in the processing, while at the same time removing the ground echo. A synthetic SLC image emphasizing the desired 

z
0

 can be produced by linearly interpolating the stack to the position 


k
z

=

k
z


(

z
0

)


. Ground cancellation for each polarization is then obtained as 


I

G
N


=

I

m
a
s
t
e
r


−

I


k
z


(

z
0

)




. It must be noted that unlike extracting a tomographic layer at a specific height, ground cancellation emphasizes an interval of heights and it is thus less sensitive to change of the average canopy height depending on the specific type of forest.The effectiveness of ground cancellation is shown in Figure 1. The two top panels show ground-canceled data produced by using image pairs which correspond to a short and long interferometric baseline, respectively. As a reference, we show in the two bottom panels the HH-VV phase difference obtained using the original SLC data (bottom left) and the tomographic section corresponding to the ground elevation (bottom right). Double bounce scattering from ground-trunk interactions is associated with a value of the HH-VV phase approaching 180°. This phenomenon is significant at Paracou, a tropical forest site in French Guiana, and strongly connected to local ground topography [32]. It is immediate to see that the HH-VV phase of both ground-canceled images is nearly zero everywhere on forested areas, while the presence of double bounce scattering is clearly observable in the phase of original SLC data and (especially) in tomographic data.The effectiveness of ground cancellation in enhancing the backscatter-AGB correlation is highlighted in Figure 2. Ground truth AGB plots are represented against σ0 [41] for the same area in three cases: the VH channel power from SLC (left plot), the tomographic power at 30 m layer (center plot) and the power of the volume-only component as obtained through ground cancellation. It is evident that while from a single acquisition we get no sensitivity to AGB, ground cancellation greatly improves correlation and sensitivity, with tomography giving the best results.A critical point regarding the application of ground cancellation is the availability of a precise Digital Terrain Model (DTM). Equation (1) shows that if data are steered in phase with an incorrect DTM, the elevation canceled out will not correspond to the true terrain, thus resulting in errors. Since commonly available global Digital Elevation Models (DEM) are estimated from sensors operating at higher frequencies than P-band (e.g., Tandem-X or SRTM [42]), the elevation model may not correspond to the real terrain level, due to the limited penetration capabilities of higher frequencies into natural media. Thus, a suitable DTM will be produced from BIOMASS data themselves by using the full 3D information achievable from multi-baseline tomographic data [43] in the TOM phase.Once the backscattering terms related to the ground (surface scattering and double bounce) are removed from the model formulation [23], the volume only scattering term related to the canopy can be expressed in simplified form (both for low and high attenuation vegetation [4]) as:




σ

p
q


V
O
L


=

C

p
q



W

α

p
q




cos

n

p
q



θ
,




(2)


where 

p
q

 is the polarization combination, 

C

p
q


 is a scaling coefficient, W is the AGB, 

α

p
q


 is a coefficient determined by forest structure, and 
θ
 is the local incidence angle accounting for topography [21]. 

n

p
q


 is a coefficient accounting for the volumetric scattering within the resolution cell [20]. Modeling the 

σ

p
q


V
O
L


 in this way is consistent with previous literature, which states that the most appropriate backscattering coefficient correction for uniform volumetric scattering is 


γ
0

=

σ
0

/
cos
θ

 [20,21,22]. The difference of n from 1 is an empirical correction which allows for more flexibility when accounting for multiple volumetric effects [21].The model presented in Equation (2) contains many fewer parameters than the original formulation in [23]. It can be solved from ground-cancelled data by constraining the dimensionality of the unknown parameters. AGB is not polarization-dependent and we assume that 

C

p
q


, 

α

p
q


, and 

n

p
q


 are slowly varying in time and space. All model parameters can be simultaneously estimated by a non-linear iterative minimization scheme without model training [44]. However, there is a scaling ambiguity since the same prediction is obtained if the model parameters 

C

p
q


, 

α

p
q


 are scaled versions of the true parameters. The parameters are also sensitive to canopy moisture changes although this effect is ignored in [23]. Therefore, it is not possible to obtain an unambiguous estimate of the true AGB value 

W
0

 without calibration. Reference data are needed, but these data do not need to cover a wide range of backscatter, slope and incidence angle conditions, as would be required if any of the models such as [23], were to be trained directly. Several options exist for reference data, e.g., in situ data and LiDAR AGB estimates, though a systematic network of calibration super-sites with suitable characteristics for AGB is yet to be established (this is mainly due to the limited number of sites available, mostly in the tropics, and the different spatial scale of the measurements with respect to that of AGB). Among the pre-launch activities, the Forest Observation System [45] database is being developed with that aim and possible benefits will come also from the cooperation between ESA BIOMASS and the NASA GEDI [46] and NISAR initiatives [47].", 3. Scientific Background, 3.1. AGB Retrieval,3
4,"The FH product is generated in both the TOM and INT phases. The baseline methodology for the INT phase is implemented by means of Pol-InSAR which in recent years has evolved into a well-established method [33].Polarimetric-interferometric correlations estimated from data are linked to forest structural parameters such as FH, terrain height, ground-to-volume ratio, canopy extinction and scalar temporal decorrelation used to model environmental changes through the Random Volume over Ground (RVoG) model. This model assumes that forest scattering comes from an extended layer of height equal to the canopy height above an opaque ground layer. The vertical distribution of scatterers is weighted by an extinction function, accounting for electromagnetic attenuation through the vegetation. The propagation through the volume is assumed to be independent of polarization. Two approaches are possible for ground and volume separation in order to fit the volume-only correlations: the classic coherence region-based approach, performing the separation for each interferometric pair independently [33] and the algebraic decomposition-based approach [34], performing the separation for all interferometric pairs simultaneously. While the former provides the flexibility of accounting for the temporal decorrelation between each interferometric pair, the latter estimates the average polarimetric-interferometric properties of the volumetric scattering mechanism within the timespan needed to acquire the stack.Pros and cons of Pol-InSAR are well known from the literature, thanks to extensive studies and validation. The main challenges for BIOMASS are the presence of ground scattering in all polarizations due to the limited extinction at P-band [34], the limited ENL available at 6 MHz and temporal decorrelation due to the three-day repeat cycle. Thus, the design of the inversion scheme accounts for scalar temporal decorrelation and three-dimensional polarimetric ground scattering. Another critical point is that an accurate DTM is required for the height estimation algorithm to be unbiased. To minimize the impact of this uncertainty the algorithm is expected to use the terrain elevation of the DTM derived during the tomographic phase [43], similarly to the ground cancellation described in Section 3.1.During the TOM phase FH will be estimated from the upper envelope of the tomographic voxel intensity, as is done for instance in [35] for boreal forests. This is done by employing ground/volume separation to isolate volume-only contributions from data and computing tomographic voxels from them [34].", 3. Scientific Background, 3.2. FH Product,3
5,"The disturbance product generation is based on level 1 instead of level 2 products: the restriction to severe disturbance allows the spatial resolution to be much finer than the other products since the associated changes in backscatter are expected to be several dBs in each intensity channel. As numerous other sensors are used to detect severe disturbance with higher temporal revisit and spatial resolution (Sentinel-1, optical [48]), the BIOMASS disturbance product will be a complement to their capabilities that allows for the detection of selective logging.The detection of changes in the polarimetric time series is based on hypothesis testing, where the null hypothesis is that in a time series of polarimetric data no change has occurred (at a given position and up to a given time). If this hypothesis fails at a given level of significance (assuming a Wishart distribution for the complex covariance data), then we assume a change has occurred [49]. Note that this approach does not specify the detection probability, which depends on the form of the multi-variate probability distribution function associated with disturbed forest. Unlike the distribution for the unchanged forest, this distribution cannot be specified a priori because change may affect the covariance matrix in many different ways. Instead, the approach provides a statistically well-defined way to determine how sure we are that change has occurred. Note that it is closely related to the constant false alarm rate approach to target detection, in which the probability that an undisturbed pixel is incorrectly classified as disturbed is fixed. The estimates are updated each time a new acquisition is added to the stack, and significance levels can be attached to the test statistics.An open issue in generating the BIOMASS disturbance product in this way is that changes in the signal caused by disturbance occur against a general background of non-forest and environmental changes. Further work is required to quantify how much these nuisance changes will increase the false detection rate. An important requirement is also to have an initial forest mask, derived from the BIOMASS data themselves or from some other source, in order to mask out detections in the non-forest areas.", 3. Scientific Background, 3.3. FD Product,3
6,"The processing chain for the AGB product generation is outlined in Figure 3. 4.1.1. Data Pre-ProcessingThe starting point is a full-polarimetric stack of multi-baseline SLC data(reciprocity can be assumed so that HV = VH), coregistered to a common master geometry, and calibrated both radiometrically and in-phase (which will be denoted by level 1c). This will correspond to three acquisitions with a different baseline in the INT phase and seven acquisitions during the TOM phase for a given cycle and ascending or descending pass. The data stack is phase-calibrated, which means that all the noise related to atmospheric effects (mainly ionosphere) and orbital inaccuracies are compensated for and the phase of the complex data is related directly to the geometric sensor-to-target distance [38,39]. Moreover, the data are DTM flattened, i.e., the sensor-to-ground distance has been compensated so that the ground level corresponds to zero elevation. As already mentioned in Section 3.1 this implies having a precise DTM available, which will be generated using the full 3D information of the TOM phase.The first processing step applied to data is ground cancellation [37]. As explained in Section 3.1, ground cancellation is a way to combine two or more images in order to attenuate the ground return from interferometric data and at the same time enhance a vegetation layer well correlated with the AGB, depending on the baseline. This can be done by simply subtracting two calibrated and ground steered acquisitions in the case of a single baseline or by subtracting from the master an acquisition synthesized at a desired interferometric vertical wavenumber 

k
z
0

 by interpolation from multi-baseline data, 

k
z
0

 corresponding to the height of interest 

z
0

. In this way a set of three polarimetric images representative of the forest canopy will be obtained.Subsequently, compensation of the radiometric variations due to the variation of the incidence angle over the swath is carried out in order to go from backscattering coefficient 

β
0

 to 

σ
0

 [51], using precise local incidence angle estimation from the tomographic DTM. The 

σ
0

 polarimetric data are then geocoded to map coordinates. A fixed grid reference system is chosen in order to ease merging of subsequent ascending and descending products and AGB calibration (e.g., [52]).An up to date forest/non-forest map (from the disturbance product presented in Section 3.3) is computed during the INT phase by change detection between the current stack and historical time series, in order to aid the AGB estimation algorithm. For the TOM phase an initial map will be available from the BIOMASS data themselves or from some other source, to be updated during the INT phase. 4.1.2. Global AGB EstimationAfter geocoding to a fixed global grid, AGB estimation is performed. The model described in Equation (2) is inverted by iteratively minimizing a cost function of the form:






J
(

W

R
O
I


,
p
;

σ
̲

,

W

C
A
L


,

θ
̲

)





=

|
|
l
g


(
f

(

W

R
O
I


,

p

R
O
I


;


θ
̲


R
O
I


)

)

−
l
g

(


σ
̲


R
O
I


)



|
|

2

+











|
|
l
g


(
f

(

p

C
A
L


;

W

C
A
L


,


θ
̲


C
A
L


)

)

−
l
g

(


σ
̲


C
A
L


)



|
|

2

.







(3)

In Equation (3), 

l
g

 is the base 10 logarithm, 
W
 is the vector collecting the AGB values, known for at least two calibration (CAL) points, to be estimated for a grid of regions-of-interest (ROIs); 
p
 is the model parameter vector (

C

p
q


, 

α

p
q


, 

n

p
q


) to be estimated for all the points; 

σ
̲

 is the vector of observables, i.e., 

σ
0

 for all the three polarizations after ground cancellation; 

θ
̲

 is the vector of local incidence angle values accounting for local topography; 

f
(
·
)

 is the model of Equation (2).The dimensionality of the inversion problem is reduced considering that:AGB, i.e., W, varies in space, but not with polarization or between ascending and descending passes (as long as no disturbance occurred between the acquisition times);the local incidence angle varies only in space and between ascending and descending passes;model parameters (

C

p
q


, 

α

p
q


, 

n

p
q


) vary with polarization, but slowly in space, so that they can be assumed constant within a grid region (see below for more details). Generally, they can also vary between ascending and descending passes due to, e.g., vegetation moisture variability and residual 

k
z

-dependent ground contributions. Since the differences between ascending and descending passes and between repeat swaths gathered in different cycles are uncertain, the algorithm has the flexibility to alter whether these parameters should vary or be constant across swaths. One approach to this is to first assume that both 

C

p
q


 and 

α

p
q


 are constant. The inversion is then run and AGB is estimated for both swaths. If AGB estimates over unchanged areas are similar, without any visible trends or biases, then the assumption is taken to be correct. Otherwise, the assumptions may need to be reviewed and the inversion has to be performed using different assumptions about the variability of model parameters across swaths. If an ascending-descending pair is used, then 

n

p
q


 is assumed to be constant between these two swaths and can be estimated with better confidence. If only a single heading is available, 

n

p
q


 should be fixed to an empirical value to reduce the dimensionality of the inversion and avoid ambiguity [53,54].The provided ROIs must represent the diversity of AGB, backscatter and incidence angle conditions across the scene. These ROIs can be stands, plots or even individual pixels. Larger ROIs are preferred because they give a larger number of looks and less speckle. A large number of ROIs is preferred because this represents a larger number of backscatter-AGB combinations, at the price of a larger computational load. A regular sampling of ROIs is preferred because this gives a better representation of incidence angle scenarios.To obtain low bias, the estimation algorithm requires at least two calibration areas with known AGB. For this reason, global estimation begins over areas with existing reference AGB data, e.g., well-known test sites. Subsequently, AGB is estimated using regions in overlap zones without significant forest disturbance and associated AGB estimates obtained in the previous steps, but now used as calibration references. For this, a global regular ROI grid is set up, from which ROIs in overlap regions are selected as calibration areas for adjacent acquisitions. The BIOMASS disturbance detection is carried out prior to calibration area selection from the ROIs to discard deforested and severely changed areas. Accordingly, a global grid of model parameters (

C

p
q


, 

α

p
q


, 

n

p
q


) is established and subsequently filled. It will have a coarser spatial sampling than the ROI grid, as model parameters are assumed to vary more slowly in space than AGB. The best model parameter grid size will be dealt with in a separate study, as further understanding is required to shed light on the variability of model parameters from area to area and from forest to forest [54] (the reader is also referred to Section 5.3 and Section 6.2). The procedure is repeated until global coverage is achieved and both grids are filled. This process results in the global level-2 AGB product, which can be further refined by combining ascending and descending tracks in the estimation step. The processor is able to deal with data both from individual and combined acquisitions.", 4. Processor Architecture and Current Implementation, 4.1. AGB Product Generation,4
7,"The starting point is a full-polarimetric stack of multi-baseline SLC data(reciprocity can be assumed so that HV = VH), coregistered to a common master geometry, and calibrated both radiometrically and in-phase (which will be denoted by level 1c). This will correspond to three acquisitions with a different baseline in the INT phase and seven acquisitions during the TOM phase for a given cycle and ascending or descending pass. The data stack is phase-calibrated, which means that all the noise related to atmospheric effects (mainly ionosphere) and orbital inaccuracies are compensated for and the phase of the complex data is related directly to the geometric sensor-to-target distance [38,39]. Moreover, the data are DTM flattened, i.e., the sensor-to-ground distance has been compensated so that the ground level corresponds to zero elevation. As already mentioned in Section 3.1 this implies having a precise DTM available, which will be generated using the full 3D information of the TOM phase.The first processing step applied to data is ground cancellation [37]. As explained in Section 3.1, ground cancellation is a way to combine two or more images in order to attenuate the ground return from interferometric data and at the same time enhance a vegetation layer well correlated with the AGB, depending on the baseline. This can be done by simply subtracting two calibrated and ground steered acquisitions in the case of a single baseline or by subtracting from the master an acquisition synthesized at a desired interferometric vertical wavenumber 

k
z
0

 by interpolation from multi-baseline data, 

k
z
0

 corresponding to the height of interest 

z
0

. In this way a set of three polarimetric images representative of the forest canopy will be obtained.Subsequently, compensation of the radiometric variations due to the variation of the incidence angle over the swath is carried out in order to go from backscattering coefficient 

β
0

 to 

σ
0

 [51], using precise local incidence angle estimation from the tomographic DTM. The 

σ
0

 polarimetric data are then geocoded to map coordinates. A fixed grid reference system is chosen in order to ease merging of subsequent ascending and descending products and AGB calibration (e.g., [52]).An up to date forest/non-forest map (from the disturbance product presented in Section 3.3) is computed during the INT phase by change detection between the current stack and historical time series, in order to aid the AGB estimation algorithm. For the TOM phase an initial map will be available from the BIOMASS data themselves or from some other source, to be updated during the INT phase.", 4. Processor Architecture and Current Implementation, 4.1.1. Data Pre-Processing,4
8,"After geocoding to a fixed global grid, AGB estimation is performed. The model described in Equation (2) is inverted by iteratively minimizing a cost function of the form:






J
(

W

R
O
I


,
p
;

σ
̲

,

W

C
A
L


,

θ
̲

)





=

|
|
l
g


(
f

(

W

R
O
I


,

p

R
O
I


;


θ
̲


R
O
I


)

)

−
l
g

(


σ
̲


R
O
I


)



|
|

2

+











|
|
l
g


(
f

(

p

C
A
L


;

W

C
A
L


,


θ
̲


C
A
L


)

)

−
l
g

(


σ
̲


C
A
L


)



|
|

2

.







(3)

In Equation (3), 

l
g

 is the base 10 logarithm, 
W
 is the vector collecting the AGB values, known for at least two calibration (CAL) points, to be estimated for a grid of regions-of-interest (ROIs); 
p
 is the model parameter vector (

C

p
q


, 

α

p
q


, 

n

p
q


) to be estimated for all the points; 

σ
̲

 is the vector of observables, i.e., 

σ
0

 for all the three polarizations after ground cancellation; 

θ
̲

 is the vector of local incidence angle values accounting for local topography; 

f
(
·
)

 is the model of Equation (2).The dimensionality of the inversion problem is reduced considering that:AGB, i.e., W, varies in space, but not with polarization or between ascending and descending passes (as long as no disturbance occurred between the acquisition times);the local incidence angle varies only in space and between ascending and descending passes;model parameters (

C

p
q


, 

α

p
q


, 

n

p
q


) vary with polarization, but slowly in space, so that they can be assumed constant within a grid region (see below for more details). Generally, they can also vary between ascending and descending passes due to, e.g., vegetation moisture variability and residual 

k
z

-dependent ground contributions. Since the differences between ascending and descending passes and between repeat swaths gathered in different cycles are uncertain, the algorithm has the flexibility to alter whether these parameters should vary or be constant across swaths. One approach to this is to first assume that both 

C

p
q


 and 

α

p
q


 are constant. The inversion is then run and AGB is estimated for both swaths. If AGB estimates over unchanged areas are similar, without any visible trends or biases, then the assumption is taken to be correct. Otherwise, the assumptions may need to be reviewed and the inversion has to be performed using different assumptions about the variability of model parameters across swaths. If an ascending-descending pair is used, then 

n

p
q


 is assumed to be constant between these two swaths and can be estimated with better confidence. If only a single heading is available, 

n

p
q


 should be fixed to an empirical value to reduce the dimensionality of the inversion and avoid ambiguity [53,54].The provided ROIs must represent the diversity of AGB, backscatter and incidence angle conditions across the scene. These ROIs can be stands, plots or even individual pixels. Larger ROIs are preferred because they give a larger number of looks and less speckle. A large number of ROIs is preferred because this represents a larger number of backscatter-AGB combinations, at the price of a larger computational load. A regular sampling of ROIs is preferred because this gives a better representation of incidence angle scenarios.To obtain low bias, the estimation algorithm requires at least two calibration areas with known AGB. For this reason, global estimation begins over areas with existing reference AGB data, e.g., well-known test sites. Subsequently, AGB is estimated using regions in overlap zones without significant forest disturbance and associated AGB estimates obtained in the previous steps, but now used as calibration references. For this, a global regular ROI grid is set up, from which ROIs in overlap regions are selected as calibration areas for adjacent acquisitions. The BIOMASS disturbance detection is carried out prior to calibration area selection from the ROIs to discard deforested and severely changed areas. Accordingly, a global grid of model parameters (

C

p
q


, 

α

p
q


, 

n

p
q


) is established and subsequently filled. It will have a coarser spatial sampling than the ROI grid, as model parameters are assumed to vary more slowly in space than AGB. The best model parameter grid size will be dealt with in a separate study, as further understanding is required to shed light on the variability of model parameters from area to area and from forest to forest [54] (the reader is also referred to Section 5.3 and Section 6.2). The procedure is repeated until global coverage is achieved and both grids are filled. This process results in the global level-2 AGB product, which can be further refined by combining ascending and descending tracks in the estimation step. The processor is able to deal with data both from individual and combined acquisitions.", 4. Processor Architecture and Current Implementation, 4.1.2. Global AGB Estimation,4
9,"The FH product generation in the INT phase is depicted in Figure 4. The level 1c stack is fed into the RVoG inversion, after computing precise incidence angles from the DTM. Again an up to date forest/non-forest map provides additional input in order to mask out non-valid points.The RVoG module computes the complex polarimetric correlation between each acquisition pair (i.e., the three possible pairs in each triplet), perform ground and volume separation and fits the model to volume-only correlation as a function of FH, extinction, ground-to-volume ratio and temporal decorrelation for each baseline. The inversion includes correction of topographic effects [55] that affect both 

k
z

 and the estimated FH. In particular, terrain slopes tilted in range towards the radar decrease the local incidence angle and increase the vertical wavenumber. Slopes tilted away from the radar have the opposite effect. Accordingly, for the same volume height, on positive slopes the interferometric correlation decreases and FH (if estimated without terrain correction) is overestimated while on negative slopes the interferometric coherence increases and FH is underestimated. Hence for unbiased FH inversion, the dependence of 

k
z

 on range terrain slopes has to be accounted for. After inversion, the estimated volume heights have to be transformed into FH, as the terrain slope correction by means of the local incidence angle also tilts the reference ground level [55].The output FH map is then geocoded to map coordinates. If available, ascending and descending passes are processed separately for the same area and then merged at the map level. Merging is done on the basis of the accuracy requirements outlined in Section 2. For each geometry (ascending or descending) the areas associated with vertical wavenumbers 

k
z

 lower than a minimum threshold or higher than a maximum threshold are masked out. The maximum threshold is defined by the minimum number of looks (assumed as 20) required to meet the performance and is set at 60% of the critical wavenumber [56,57]. The minimum threshold is defined by the lower FH that has to fulfill the performance specifications (set at 10 m). Three cases are possible: one of the two solutions is masked out (combined FH will be given by the single solution); both solutions are available (combined FH will be given by the mean or alternatively by a weighted combination of the two FHs); both solutions are masked out, in which case we either do not provide any solution, or use only one solution and flag a warning. The final strategy is still to be decided based on further investigations.In the TOM phase, FH is retrieved from tomographic voxels. Volume-only contributions are computed using algebraic decomposition [34]. Then volume-only data are focused in 3D and FH is estimated from the upper envelope of tomographic voxel intensity by setting a threshold to the power decay at each range-azimuth bin.", 4. Processor Architecture and Current Implementation, 4.2. FH Product Generation,4
10,"The generation of the FD product is summarised in Figure 5. The process takes as input a stack of polarimetric data, which are averaged to 6 looks in azimuth to reach the target resolution of 50 m (see Table 1) and to allow the calculation of scattering statistics expressed by the covariance matrix [25]. This process is only run for pixels within a forest mask at a given time N. For the initial run, the forest mask generated during the TOM phase will be used (see Section 4.1.1). Assuming a Wishart distribution for the complex covariance data, hypothesis testing [49] is then applied to determine whether the new matrix is different from the previous n matrices at that pixel at a given significance level. If the null hypothesis (no change occurred) is rejected, we assume that the given pixel is disturbed. The pixel is then removed from the forest mask at time 

N
+
1

, i.e., the currently completed global cycle.", 4. Processor Architecture and Current Implementation, 4.3. FD Product Generation,4
11,"All three forest products (AGB, FH and FD) are intended to be provided with an additional layer. This contains information about the quality of the estimates obtained from the error budget of the overall end-to-end processing chain for each pixel. The definition of the best quality metrics for each product is still being investigated, but some general consideration about the main sources of error is already possible.For AGB and FH, in particular, the focus is on determining the impact of errors mainly in the DTM and covariance/multi-look statistics. Both systematic and random DTM errors must be precisely quantified, as both ground notching employed in AGB estimation and RVoG inversion for height estimation relies on a precise estimate of the height level of the terrain, as explained in Section 3.1 and Section 3.2. A dedicated study is ongoing to determine the quality of the DTM estimate from tomography [58]. Concerning the estimation of covariance/multi-look statistics, classical bounds from the interferometric literature already provide consistent metrics [40]. For AGB, a further point is represented by the errors on the ground plots used to calibrate AGB estimation, thus confidence intervals on the AGB estimates from ground plots through allometric equations have to be accounted for in the error budget [45]. The impact of the spatial distribution (or better the representativeness of geometric and environmental conditions) and size of the calibration plots and propagation of the errors when propagating the estimates through overlaps is a particularly delicate point, that will be assessed in a dedicated study [54]. For FD, the error budget is based on the statistics of multi-look estimated covariance matrices.The end-to-end error budget to form the quality indicators is derived through sensitivity analysis of the end-to-end error model, in order to transfer the uncertainties in the inputs to the outputs. Wherever the complexity of the model is too demanding, an alternative would be to use statistical procedures such as bootstrapping [59], where confidence intervals on the estimates are built by random sampling with replacement of the inputs based on their errors. A comprehensive reference on uncertainty estimation for biomass retrieval can be found in [60].", 4. Processor Architecture and Current Implementation, 4.4. Product Quality Considerations,4
12,"The accuracy of AGB estimation with respect to the target requirements is tested at the Paracou site in French Guiana from TropiSAR data. Paracou is characterized by hilly topography and high AGB range with a mean value of 345 t/ha (with a dispersion of 73 t/ha). In situ surveys provided 16 ground plots, one of which has size 25 ha, the rest being 6.25 ha, all measured in the same year as the SAR campaign.AGB inversion is run on calibrated ground-cancelled data geocoded to a UTM grid. The AGB estimation ROIs are 200 m × 200 m wide and with 250 m × 250 m spacing. The height emphasized by ground cancellation corresponds to 30 m above ground level [20]. Results are shown in Figure 6. Two of the ground plots were chosen as calibration points for the algorithm, as representative of the higher and lower AGB regions. Since only one heading is available, the model parameter 

n

p
q


 is fixed to 0.5 (see Section 4.1.2) as this configuration proved to produce the best results in the framework of this initial performance assessment.In plot (a) the estimated AGB map is represented in UTM, with the ground plot locations superimposed in grey boxes. In near range, corresponding to the right side of the plot, the estimation saturates, possibly due to residual uncompensated incidence angle effects. In plot (b), zoom of the area corresponding to the ground plot location is represented, highlighting also the two plots used for calibration. In (c) the estimated AGB is plotted against reference AGB. The RMSD is 82 t/ha, corresponding to about 23% for this range of AGB values, close to target requirements, while the Pearson correlation coefficient is 0.7. By comparing the blue line corresponding to the fit with the black one-to-one line, a bias is evident, amounting to about 55 t/ha for the entire range of AGB values. The bias could be introduced by the two calibration areas being at very similar range and incidence angles, thus not representing the whole range of scenarios.", 5. Experimental Results, 5.1. AGB Estimation Accuracy,5
13,"This test used the dataset acquired at the La Lope site in Gabon from four different headings by DLR in the framework of the AfriSAR campaign (see Table 2). The terrain at La Lope has topographic variations from moderately flat to steep slopes, and the AGB range follows a bimodal distribution around low AGB values (50 t/ha) and high AGB values (450 t/ha), with mean value 298 t/ha (dispersion 172 t/ha). Ground plots were collected, but found to be not fully representative of the full range of forest conditions. Hence, LiDAR-derived AGB maps are used as the main data source for reference data.AGB inversion was run on calibrated ground-cancelled data geocoded to the UTM grid. The AGB estimation ROIs are 200 m × 200 m wide and spaced at 250 m × 250 m. The height emphasized by ground cancellation corresponds to 50 m above ground level, as taller trees are found in La Lope than Paracou. Two areas from the LiDAR AGB maps are chosen as calibration points for the algorithm, as representative of the higher and lower AGB regions, shown in Figure 7a. As for the Paracou scenario, the model parameter 

n

p
q


 is fixed to 0.5.AGB was estimated for two headings separately and then both headings were combined. We selected two headings with contrasting look-angles in order to simulate an ascending/descending combination representing an operational BIOMASS scenario. The effects of further combinations of headings are studied in [54]. Note that when combining data from two or more headings, the algorithm still produces one AGB map for each backscatter dataset with parameters estimated from the joint inversion. For this test, the maps are then averaged to provide one output product. In Figure 7b–d the estimated AGB maps are represented for the two individual headings as well as for the combination of headings. Note that the AGB estimation for the combined headings has a smaller extent due to the limited overlap of the opposing acquisitions. It can be seen that while all three estimated AGB maps reproduce the general patterns of the reference map, the estimation based on two headings shows the most homogeneous result and the best agreement with the reference LiDAR-based AGB map. The patterns of AGB estimates from single headings show some local differences whose explanation can be twofold: sensitivity to AGB may depend in part on the acquisition geometry heading (thus on incidence angle and local slopes) and incidence angle variation for the considered area may be attributed to AGB variation by the model. This is further analyzed in [54], where plots of bias and RMSE against incidence angle are presented.Figure 8 compares the AGB estimates for two individual headings (a) and (b) as well as for the combined headings (c), with the LiDAR- and ground-based reference data. The red circles indicate the results for the estimation ROIs with a size of 200 m × 200 m; here the LiDAR-based map is used to extract reference AGB values. Reference values and estimation results for the ground plots are indicated by blue crosses. For the individual headings, dispersion in the high AGB region leads to RMSD values of 25.4% to 32.8% (LiDAR-based) and 32.5% to 47.5% (ground-based). The combination of headings substantially reduces the RMSD to 18.9% (LiDAR-based) and 14.2% (ground-based). A small bias relative to LiDAR ROIs can be seen in the high AGB region of plot (b), which is significantly mitigated in the combined headings case (c).To study the influence of topography, the dependence of MD and RMSD on the terrain slope (calculated using the LiDAR AGB map) is visualized in Figure 9. Since azimuth slopes have only a secondary impact on estimation performance by moderately increasing the dispersion, only range slopes are considered in this test. It is clear in Figure 9a,b that increasing slopes degrade AGB estimation, especially for slopes facing away from the sensor (indicated as negative slopes). Note that using a combination of headings for model parameter estimation still produces one AGB map for each of the input headings. Hence, Figure 9c,d show the results of AGB estimation based on combined headings for headings 124° and 275° respectively. In these cases, the impact of slopes is much less severe as the RMSD values remain stable across different slope values, although a small bias (expressed by the MD) is introduced. Nevertheless, the combination of headings clearly leads to improved AGB estimation.To estimate the expected impact of slopes under operational BIOMASS conditions, the global distribution of slopes in the tropics is evaluated from available datasets. A slope map covering the tropical land surface is generated from the SRTM 3-arc second (approximately 100 m) V3 void-filled DEM according to the methods described in [63]. To define a forest mask, both the GLC-SHARE global tree cover map (pixel size about 1 km2) [64] and a global forest canopy height map derived from data from the Geoscience Laser Altimeter System (GLAS) onboard the ICESat mission (pixel size about 1 km2) [65] are used. Both forest parameter maps are resampled to match the higher DEM resolution to avoid the smoothing of the slopes. Following the forest definition of the Food and Agriculture Organization of the United Nations (FAO), slope statistics are calculated for areas with a canopy cover of more than 10% and a tree height of more than 5 m [66]. Note that the X and C band radar acquisition frequency of SRTM is likely to lead to overestimation of slopes at forest edges, as in these areas the DEM represents the transition from canopy to ground layer. From Figure 10 it can be seen that 74% of the tropical forest areas have less than 5° slope and more than 85% have less than 10° slope, representing favourable conditions for AGB estimation.", 5. Experimental Results, 5.2. Effects of Topography and Multi-Pass Combination on AGB Estimation,5
14,"The transferability of model parameters for AGB estimation is tested for three sites from the AfriSAR campaign. Transferability is tested as an alternative to model parameter estimation through overlap propagation. Model parameters estimated at the La Lope site are transferred to backscatter data from Mabounie and Rabi. The Mabounie site lies 130 km southwest of La Lope and is characterized by swampy tropical rainforest with high AGB values, with a unimodal distribution around 332 t/ha, a mean of 328 t/ha and dispersion of 93 t/ha. Rabi is located 270 km southwest of La Lope, rainforest AGB is distributed unimodally around 280 t/ha with a mean of 275 t/ha and a dispersion of 78 t/ha. LiDAR-based AGB maps, as well as ground measurements, are available as a reference for both campaign sites. Note that the LiDAR acquisition at Mabounie was carried out in 2007, while for La Lope and Rabi it was 2015 [62]. Hence, forest changes may have occurred at Mabounie between the LiDAR and radar acquisitions, possibly causing mismatches between reference and estimated values.For this test, model parameters are estimated for data from four individual headings at La Lope (see Section 5.2), using the same calibration areas (see Figure 7) and fixing 

n

p
q


 to 0.5. They are then applied to the ground-canceled backscatter data from Mabounie and Rabi to generate AGB maps.Figure 11 shows scatterplots of the resulting AGB maps against reference data. Note that differences between the plots (a) to (d) are caused entirely by varying model parameters. The transfer results in good agreement with the LiDAR-based reference data for cases (b) and (c), where model parameters are estimated based on La Lope headings 230° and 275°. However a large bias is visible in case (a), and a smaller bias in case (d), corresponding to parameter estimation at La Lope headings 124° and 320°. The comparison to the ground measurements shows a good agreement in cases (b) and (c), with RMSD values below 20%. Larger differences due to biases are visible in the other two cases. Similar patterns occur in Figure 12, where the results of the model parameter transfer to Rabi are shown. A good general agreement based on LiDAR reference data can be stated, but biases are present for test cases (a) and (d). Comparison to ground data shows a large dispersion with RMSD values between 24.1% and 35.7%. Furthermore, the sensitivity of backscatter to ground-measured AGB is very low. Similar tests were carried out transferring model parameters the other way around from Rabi and Mabounie to La Lope, resulting in larger biases than reported in Figure 11 and Figure 12, especially in low AGB regions. This can be explained by the fact that Rabi and Mabounie only cover a limited AGB range in the high AGB region and the model parameters are therefore also optimized for this scenario. The La Lope site, however, covers both low and high AGB values. Hence, it is assumed that model parameter transfer is performed under more representative conditions using La Lope data as the initial set for parameter estimation.This test indicates that model parameters are generally transferable to sites with similar forest types and comparable terrain conditions. Biases may be introduced, especially if AGB is estimated based on one heading only, as is the case for this test. However, general conclusions on the spatial variation of model parameters cannot be drawn from this preliminary assessment, and further research is required on this issue.", 5. Experimental Results, 5.3. Transfer of Model Parameters for AGB Estimation,5
15,"FH estimation is preliminarily tested on the La Lope multi-heading dataset presented in Section 5.2. To simulate an ascending/descending scenario, FH is estimated individually for two different headings and the average of both products is calculated (see Section 4.2). Figure 13 reports the RMSD depending on the LiDAR-based reference FH for two individual different headings as well as for their combination.For heights from about 10 m to 40 m RMSD is about 8-15 m when only one heading is used for estimation. This is slightly larger than target requirements but the performance improves, especially at high FH values, with the merging of ascending and descending acquisitions. A comparable effect is found for the MD, as a strong bias for high FH values is visible in case (b), which is neutralized by the combination of headings. Further analysis shows that similarly to AGB estimation, higher errors (in terms of both bias and RMSD) are found for steeper slopes, with RMSD around 10 m and 40% bias for gentle slopes and RMSD around 20 m and bias 60% for steep slopes. This confirms that sloping terrain represents a challenge for FH estimation, but based on the tests in Section 5.2, the impact is mitigated by merging of ascending and descending data.", 5. Experimental Results, 5.4. FH Estimation,5
16,"In this section, we compare the methodology chosen for AGB estimation implemented in the processor with other popular AGB estimation methodologies found in the literature. The discussion again focuses on AGB, due to its relevance and the novelty of the approach. Forest height estimation and forest disturbance detection rely on more consolidated techniques and their main innovations are related to the tailoring of the chosen algorithms to the BIOMASS case.Since comparison with AGB inversion techniques tailored to particular scenarios is already done in Section 3.1 when explaining where the current approach originated from, the purpose of this section is to put the AGB estimation proposed within the L2 processor in a broader context of global AGB estimation methodologies. The discussion here considers only general methodologies for AGB estimation, without going into the details of any particular approach.Following [67,68], the techniques for AGB estimation commonly found in the literature can be divided roughly into:Parametric empirical regression models: the backscatter-AGB relationship is modeled by some simple mathematical law (linear, power-law) as a function of a few regression parameters and is then inverted. This simple approach is effective when the chosen mathematical law corresponds to the relationship observed in the data. Drawbacks include that it requires a lot of training data and when the estimation procedure is applied to regions too far from the training area or which include a substantial amount of environmental variation (not accounted for in the training data), the estimates become questionable. As a last point, the inversion parameters cannot generally be transferred as they usually do not have physical meaning. Rodríguez-Veiga et al. [67], in particular, discusses how problems of overestimation of low AGB and underestimation of high AGB very often occur in practice, due to the simplicity of the chosen mathematical law (often linear or with too few parameters) describing the AGB-backscatter relationship or to unaccounted environmental variation in training data. Techniques 1-3 described at the beginning of Section 3.1 belong to this class.Parametric semi-empirical physically-based model: the backscatter-AGB relationship is modeled with some physical law as a function of a few parameters that have a clear physical meaning. In this case the model is more adaptable than empirical regression models, due to the physical meaning of the parameters. Parameters can moreover be transferred between sites (at least in principle) and there is less need for training data. Parameters can be tuned in order to control the inversion, but direct inversion can be hindered by the complexity of the model. Moreover, the model may not be able to fully capture the complexity of the scattering mechanisms. Techniques 4-5 described at the beginning of Section 3.1 belong to this class.Non-parametric techniques (e.g., Neural Networks, Random Forest): these do not require any data model, can ingest multiple predictors and adapt much better than model-based approaches. However, it is much more difficult to control their behavior and they require a substantial amount of reference data to account for all the possible conditions.The discussion presented in this paper makes clear that the global algorithm proposed for implementation in the BIOMASS L2 prototype processor belongs to the second class, i.e., it is based on a semi-empirical physically-based model. This choice is motivated, as explained in Section 3.1, by the necessity to keep the complexity at a reasonable level, limit the amount of training data required and at the same time preserve the physical meaning of the parameters in order to allow transferability and to control the model behavior. Significant effort has been made to reduce the parametrization of the scattering model through ground cancellation techniques, which are of major benefit to the model inversion, though further investigations are required to determine both the impact of ground cancellation errors (due to for instance a non-precise DTM knowledge) and whether the simple model Equation (2) is sufficient to describe all the environmental conditions to be met by BIOMASS. Moreover, significant efforts are being made to design an effective global estimation scheme that relies on propagating the estimates through overlapping regions, starting from calibration points (as described briefly in Section 4.1.2). This requires further investigations to determine the impact of both the initial calibration points and the propagation of errors through overlaps as discussed in [54]. Further investigation of model parameter transferability is also required as the results reported in Section 5.3 are mixed.Regarding the non-parametric class of biomass estimation methods, it is worth mentioning that besides the official L2 product delivery, BIOMASS P-band L1 data will be available for use in the broader context of multi-sensor data fusion. This kind of approach is not self-contained and is less intuitive than the approach proposed for BIOMASS. However, it may be able to exploit the varying sensitivity of other radar frequencies (as well as that of optical and LiDAR sensors) to different forest properties (including forest horizontal structural information provided by LiDAR and optical data), potentially improving the accuracy of and reducing the uncertainties in AGB estimation.", 6. Discussion, 6.1. Comparison with Other Forest Biomass Retrieval Approaches,6
17,"The experimental results suggest that AGB accuracy is close to the target requirement when good calibration data are available and terrain slopes are moderate (as for example is the case for Paracou). They further imply that AGB estimation is significantly improved by combining acquisitions from multiple headings, as will be the case when combining data from ascending and descending orbits. Similar results apply also for height estimation. However, these results do not represent an exhaustive validation, because tests are carried out only for a few scenarios and not the full range of available campaign data and their combinations. A dedicated study is currently tackling this issue [54]. Furthermore, no effort is committed to evaluating the performance of the individual modules of the processor, as only the accuracy of the final level 2 products is assessed. Validation of interferometric ground cancellation is carried out in [61]. Nevertheless, several open issues can be identified from the experimental results in Section 5 that are required to improve the robustness of the algorithms, especially in a global perspective.The first concerns the limited AGB range and range of weather conditions within the campaign data available for testing, which are only partially representative of the range of AGB and environmental conditions that will be met by BIOMASS. In this context, it is important to note that other technology, such as L-band [47], can be effective in measuring AGB. Campaign data used for testing mainly contains variation across high AGB values which is the range for which the BIOMASS mission is particularly designed. In addition, the environmental conditions did not vary much across the tropical campaigns as they were collected at a limited number of sites and times. This limited the testing of the AGB inversion and meant that testing of the disturbance product relied on simulation, as no data representative of a BIOMASS-like case was available. Efforts to provide more thorough testing of the disturbance product are now focused on using additional datasets, such as multi-temporal L-band airborne polarimetric data collected by DLR at the Traunstein site [69] or polarimetric time series data collected during tower experiments to study seasonal effects [70,71] (however the latter are collected in a slightly different geometry than airborne and spaceborne systems and the coverage is much more limited in space).Connected to the use of campaign data is also the fact that the suggested approach to area extension using grid region overlaps could not be tested, as the test scenarios available are localized in different areas separated by hundreds of kilometers, even in the best case (AfriSAR). Splitting a scenario in smaller blocks is not a viable option, as the scales would not be representative for BIOMASS. A dedicated study is currently being performed to address this issue. The strategy foreseen is to study the variability of model parameters, AGB and environmental conditions across AfriSAR sites, simulate data in between and test the propagation through overlaps from one scene to another. This will help also in assessing how to extend the solution away from regions with calibration data without causing excessive error propagation. The study of model parameters should also shed more light on model parameter transferability, see Section 5.3.The implementation of a fixed grid will support the merging of ascending and descending data and simplify model calibration. Here a UTM grid was used to process campaign data, but the Equi7 grid [52] represents a valid alternative that minimizes projection distortions for each continent.The AGB estimation algorithm relies on some calibration data, but these have not yet properly defined for BIOMASS and further work is required to define proper calibration strategies (e.g., supersites with stratification, etc.).The framework and algorithms for height estimation are well-defined and understood. More effort should be devoted to comparing the performance of different proposed algorithms with respect to the effects of temporal decorrelation, and optimizing the spatial baseline ratios to maximize the FH range over which the inversion performance meets BIOMASS requirements.The impact of the tomographic DTM on error propagation of level 2 estimates will be assessed in a dedicated study [58].More effort is needed to investigate AGB estimation in boreal and temperate forests. These forests are not as tall as in the tropics and the tomographic resolution of BIOMASS is unlikely to allow clear separation of the ground and canopy. In addition, double-bounce scattering is much more relevant for these types of forests, so ground cancellation may remove pertinent information. Preliminary results from the level 2 study do not give any clear indication that AGB estimation is improved by ground-cancellation [4].Finally, consistency between the estimated FH and AGB will be addressed. This implies converting the FH estimates into AGB through an allometric equation and then comparing the derived AGB map with that estimated from the BIOMASS algorithm.", 6. Discussion, 6.2. Open Points,6
18,"In this paper, we present the theoretical basis, implementation design and global coverage strategy for the level 2 products created in the framework of ESA’s P-Band SAR mission BIOMASS. The generation of global above-ground biomass (AGB) maps relies on fundamental findings from the level 2 prototype processor development. For tropical forests, tomographic analysis and biophysical evidence show that biomass in the 25 m to 35 m canopy layer is highly correlated with total AGB and that backscatter attributed to the ground represents an obstacle for AGB retrieval. This is exploited in the level 2 prototype processor by applying interferometric ground cancellation, a novel technique developed in the course of the level 2 activities, that strongly attenuates the signal contribution from the ground by combining two or more acquisitions separated by an interferometric baseline. The resulting signal can be attributed to the vegetation layer. Because of this, the semi-empirical model used to establish a relationship between AGB and backscatter [23] can be simplified to describe only the volume scattering terms. In this way the number of model parameters and hence the dimensionality of the inversion problem is greatly reduced, thus permitting a stable numerical inversion procedure.Furthermore, we present the implementation of the FH product generation. While the data acquired in the TOM phase allows the estimation of FH through a tomographic voxel dataset, Pol-InSAR methods are applied together with the RVoG-model in the INT phase. It is envisaged to merge FH maps generated from ascending and descending orbits to improve accuracy and mitigate negative effects of slopes.We test AGB and FH retrieval using airborne P-Band data from the AfriSAR and TropiSAR campaigns together with reference data from LiDAR-based AGB maps and plot-based ground measurements. For AGB estimation based on data from a single heading, comparison with reference data yields relative RMSD values mostly between 20% and 30%. Combining different headings in the estimation process, as will be possible with the ascending/descending pattern of the BIOMASS satellite, significantly improves performance and relative RMSD values of less than 20% are achieved. RMSDs of 8–15 m are achieved for FH retrieval which improve to 3–11 m when combining data from different headings.The experiments suggest that the implemented retrieval scheme provides robust results that are within target requirements. However, testing was carried out only for a very limited number of reference sites and further research is currently dedicated to algorithm validation. On top of this, ongoing preparatory research activities include simulation-based analyses on the spatial variation of model parameters as well as the development of a validation strategy for the FD product.", 7. Conclusions,None,7
19,"Wildland fires play an important role in the dynamics of terrestrial ecosystems. Although they have positive effects on biodiversity and plant succession [1], wildland fires are also a critical disturbance factor in forests, affecting the structure, function [2], adaptation, and distribution [3] of ecosystems, as well as degradation of water quality, erosion, and land cover change [4,5]. In addition, wildland fires constitute a serious threat to the environment and society when they are not well managed [6,7,8]. It is estimated that 4–4.5 million km2 is burnt annually in the world [9,10], but this estimation is most likely conservative. These areas include agricultural and pasture burns, and wildland fires, which have a strong impact on societal and economic value. This is particularly clear in Southern Europe (Spain, Portugal, Greece, Southern France), where most European fires occur, but these patterns may be extended to Northern Europe as a result of global warming [11,12]. In fact, Europe’s wildland fire vulnerability has recently increased due to the effects of climate change [13,14,15].The origin of wildland fires can be natural (mainly lightning) or human. For fires to spread, continuity of living or dead vegetation is required to maintain the fire, as well as oxygen and heat transfer for ignition. Moreover, suitable environmental, meteorological, and topographic conditions must be met [16]. Fuel types, which refer to vegetation categories with similar behaviour in fire propagation [17], are a primary factor in the behaviour of wildland fires and their prevention [18,19]. Consequently, mapping fuel types is critical to characterize risk conditions and plays an important role in wildland fire risk prevention, where it is essential to have quality maps that are easily and regularly updated. Fuel parameterization is performed throughout fuel models, which are numerical descriptions of the physical parameters of each fuel type. Fuel models involve parameterizing fuel types to estimate their fire behaviour. They are widely used in fire risk assessment and behaviour programmes [20,21]. Many efforts have been made to develop methodologies to generate and map fuel types. The methods used to obtain fuel types and their parameters strongly depend on their input data, final use, and the detail of the work scale [16,20].Mapping the updated distribution of fuels and describing their properties improves decision-making, evaluation, and risk management of wildland fires because it considers vegetation changes due to previous fires and the dynamic nature of forest fuels [16,22,23]. Currently, the problem is the development of cost-efficient methods for updating fuel maps and their parameters, which will be used in fire behaviour modelling [16,24]. Therefore, it is essential to improve the current fuel mapping methodologies to amend wildland fire assessment, by providing an optimal allocation of resources [25,26,27,28] to mitigate the adverse effects of wildland fires through early response and strategic planning [16].The vegetation characteristics that are usually considered when describing fuel types are crown height, crown base height, percentage of vegetation covered area, forest canopy density (proportion of the ground covered by the projection of the crown of the trees to the ground), apparent crown density, canopy bulk density (mass of available canopy fuel per canopy volume unit), number of trees by area, vertical and horizontal continuity, moisture content, live and dead fuel load, and biomass [16,20]. Standardized fuel classification systems based on vegetation characteristics have been proposed in recent decades for several world regions: Southeast Asia [26], United States [21,29], Canada [30], and the Mediterranean region [24,31]. One of the most used is the Fire Behaviour Fuel Types (FBFT) [21], prepared by the United States Forest Service Rocky Mountain Research Station for the United States. It uses field measures and photo series to describe 40 fuel types based on the 13 types of the Northern Forest Fire Laboratory (NFFL) system [29], widely used for fire propagation modelling [19,24]. FBFT [21] improves the accuracy of fire behaviour predictions for surface fires outside the fire season (June–October). It also considers the humidity of the climate in which the fuel is included. Some works have adapted the FBFT fuel types to European islands [32,33].The original 40 FBFT fuel types are divided into seven large groups: grass (GR), grass-shrub (GS), shrub (SH), timber-understory (TU), timber-litter (TL), slash-blowdown (SB), and non-burnable (NB). For each fuel type, the parameters to be used in fuel and fire propagation models are defined, except for the NB category. For each fuel type, the system provides an estimation of the fuel load, fire spread rate, and flame length based on generic climatic conditions [21]. The fuel load refers to the amount of fuel potentially available for combustion [20]. The fire spread rate is the rate of the fire head advance [34]. The flame length is the distance between the midpoint of the flame depth at the base of the flame and the flame tip [35].Traditionally, field samples, photointerpretation of aerial images, and remote sensing methods have been used to perform mapping of fuel types and their parameterization. Recent bibliographic reviews [36,37] show a growing utilization of remote sensing for fire risk assessment, using passive optical sensors, Radio Detection And Ranging (RADAR), and Laser Imaging Detection And Ranging (LiDAR) (including ground, airborne, and satellite systems [38]). Remote sensing presents the advantages of global systematic coverage (easily updateable) and information on non-visible regions of the spectrum [16,20]. Remote sensing has mainly contributed to characterizing the conditions of fuel types—moisture content, biomass, canopy coverage, and vertical and horizontal continuity—evidencing the considerable capabilities of this technique in evaluating the multiple variables involved in fire risk assessment. A common approach to fuel mapping using remote sensing is to firstly map the vegetation types and secondly generate the fuel types using auxiliary information to refine the vegetation types [36]. Second-order variables, such as fire spread rate and flame length, have also been mapped [39].At the local-regional scale, the input data to classify fuel types have usually been generated using optical remote sensing images. Their high temporal resolution facilitates the updating of the derived cartography, although they require calibration and validation efforts. The most used sensors have been Landsat Thematic Mapper (TM) [31,40,41] and Sentinel-2 MultiSpectral Instrument (MSI) [42,43,44]. High spatial resolution sensors, such as those onboard the QuickBird [39,45,46] and WorldView-2 [47,48] satellites, have also been used. Visible, NIR, and SWIR bands, spectral indexes [32,39,41,42,45,49,50], and multi-temporal analysis [31,43] have also been used, which have provided classification improvements [51]. Different classification algorithms have been used: maximum likelihood [31,46], decision trees [39], random forest [42], Support Vector Machine (SVM) [42], and Object Based Image Analysis (OBIA) [43,44,45].At the continental-global scale, cartography of fuel types has usually been generated from the integration of land use databases and pre-existing maps as input data. However, using databases does not consider phenological changes. There are examples of continental-scale works (South America [52] and Africa [53]) that generate fuel maps from the integration of databases and pre-existing products. With a similar approach, a global fuel type map was recently proposed [54] by combining land cover and biogeographic region databases with optical remote sensing-derived products for tree vegetation, such as vegetation continuous field collection 5 from Terra MODIS (Moderate Resolution Imaging Spectroradiometer).The main objective of this work is to develop a methodology to map fuel types at a regional scale for modelling fire propagation behaviour. We selected the FBFT system [21] because it provides a standard set of parameters for fire behaviour estimation. This work is focused on the Iberian Peninsula and the Balearic Islands but aims to extend similar methods to other European regions. We first describe the methods used to generate the vegetation map. Then, we describe the methods used to generate the map of fuel types and the parameters for the different fuel types. Since validation of the fuel map was not feasible, we present a first assessment of the result by comparing the fuel parameters with those derived from a European fuel map produced under the European Forest Fire Information System (EFFIS) programme [55] and a global product derived from [54]. This work is part of the European project FirEUrisk, which aims to generate a European integrated strategy for fire risk assessment, reduction, and adaptation.", 1. Introduction,None,1.
20,"The study area is the Iberian Peninsula and the Balearic Islands, with 587,198.93 km2 (Figure 1). Other archipelagos belonging to Spain and Portugal were not considered to focus the work on the European Mediterranean region. Wildland fires in European Union countries for the 2000–2017 period have affected 480,000 ha/year, 34 people/year, and have implied costs of 3 billion euros/year [56]. The Mediterranean European countries are the most affected by wildland fires, with an annual average of about 45,000 wildland fires and 478,900 burnt hectares. Spain and Portugal have been for decades the two countries in Europe most affected by wildland fires, especially in the fire season (June–October). For 2009–2018, the average annual statistics were 12,182 fires and 99,083 burnt hectares for Spain, and 18,345 fires and 138,841 hectares for Portugal [15,57,58,59].A relationship between fires in the Iberian Peninsula and its long-term climatic conditions has been observed [62]. The study area has three biogeographic regions, which are stable over time (Figure 1): (1) Alpine, with a high mountain climate, (2) Atlantic, with mild temperatures and humid summers, and (3) Mediterranean, characterized by hot and dry summers. Their different climatic conditions favour different degrees of vegetation development [63], and therefore different fuel types.", 2. Materials and Methods, 2.1. Study Case: Spatial Delimitation,2
21,"The development of the cartography and characterization of fuel types was based on the integration of multi-seasonal images (spring, summer, autumn) of the Sentinel-3 Synergy product, MODIS vegetation continuous field collection 6 maps, a map of biogeographic regions, and a biomass map. Two main steps were followed: (1) the generation of the basic vegetation cartography, and (2) the generation of the cartography of fuel types (Figure 2). 2.2.1. Generation of the Basic Vegetation CartographyTo avoid relying on external land cover maps as in [52,53,54] and to base our approach on updated data, a vegetation map was generated from Sentinel-3 Synergy product images. Sentinel-3 is part of the European Space Agency’s (ESA) Copernicus programme [64] and was conceived for land monitoring and security applications, and climate change detection [65]. It is composed of a pair of optical satellites, Sentinel-3A and 3B, in orbit since 2016 and 2017, respectively. It includes two main instruments: OLCI (Ocean and Land Colour Instrument, 21 channels, 300 m spatial resolution) and SLSTR (Sea and Land Surface Temperature Radiometer, 9 channels, 500 m resolution). Sentinel-3 images have already been used for wildland fire detection and mapping. Works exist that analyse the capabilities of the Sentinel-3 SLSTR sensor for active fire detection [66,67,68,69], especially for forest biomass burning events [66].In this, work, the Sentinel-3 Synergy product [65] was used, as it combines OLCI and SLSTR data. This product offers geometrically, atmospherically, and Top of Canopy (TOC) reflectivity corrected daily images at 300 m resolution for 26 spectral bands. The Sentinel-3 Synergy product has already been used, in combination with other Sentinel-3 products, for the generation of a moderate spatial resolution global burnt area product under the ESA’s Fire Climate Change Initiative (CCI) project [70]. However, the potential of this product to contribute to fuel modelling and mapping has not been exploited yet. In this work, we aim to use the relatively recent product of Sentinel-3 Synergy in the context of fuel modelling, especially for the generation of updated vegetation maps, which are expected to be useful for fuel mapping.Sentinel-3 Synergy images were downloaded from the Copernicus Open Access Hub [71] for the study area: 20 images for summer 2020, 27 images for autumn 2020, and 20 images for spring 2021. For each season, cloud-free mosaics were performed at 300 m resolution in SNAP 7.0 (Sentinel Application Platform), which uses the nearest neighbour (Figure 3). The mosaics were projected from WGS84 Geographic latitude/longitude coordinates to ETRS89 Albers equal-area conic projection with central meridian in 3° W, which preserves the area measure, and is appropriate to represent the study area.We selected the following categories to create the vegetation map: conifers, evergreen broadleaves, deciduous broadleaves, shrubs, grasses, and other uses. In the study area, the conifers only refer to evergreen conifers because deciduous conifers only grow in boreal climates. However, broadleaves can be evergreen or deciduous [63]. Conifers, evergreen broadleaves, and deciduous broadleaves have different moisture content and amount of leaves in summer and winter, and therefore different responses to fire [72]. The other uses category refers to non-natural vegetation surfaces, including crops. This classification was selected for an easy adaptation to the FBFT system [21].(A)Classification training sampleFirst, a total of 403 pure training pixels were visually selected with the help of Google Earth for 14 initial categories: conifers, evergreen broadleaves, Atlantic deciduous broadleaves, Mediterranean deciduous broadleaves, landa (Atlantic shrubs), thermophilic Mediterranean shrubs, grasses, water, burnt areas, urban areas, bare soil, rainfed crops, irrigated crops, and floodplains. These categories consider the variability of land use and vegetation due to the biogeographic regions of the study area.(B)Input bandsA total of 21 bands were used as classification input. For each season, 5 nadir observation bands (which minimize geometric distortions) were used: 555 nm (green), 659 nm (red), 865 nm (NIR), 1610 nm (SWIR 1), 2250 nm (SWIR 2). These spectral regions have been widely used in previous studies [32,41,42,49,50,51] as they have shown the potential to discriminate vegetation types. To improve the classification performance, the NDWI index ((NIR band − SWIR 2 band)/(NIR band + SWIR 2 band)) and the SAVI index (((NIR band − Red band)/(NIR band + Red band + L)) * (1 + L)) were also calculated for each season and used as input bands. We used the standard soil brightness correction parameter L = 0.5 [73,74,75].(C)Classification algorithmThe classification was performed using Support Vector Machine (SVM), a supervised non-parametric statistical machine learning algorithm, for the 403 pure training pixels and the 21 input bands. It finds the optimal hyperplane to separate the input dataset into the categories defined by the training sample [76]. The classification was performed in Orfeo ToolBox of QGIS 3.10 assigning the most similar category to each pixel. We used SVM kernel RBF (Radial Base Function), which offers optimal results for classifying vegetation with remote sensing [76], and cost parameter 100 [42]. The classification was also performed using random forest. As in [42], 100 trees and 3 as the minimum number of samples per node were used. Then, some classified categories were merged to fit the final target categories (Table 1).(D)ValidationThe vegetation map was validated using as the reference a mosaic of TOC reflectivity images from the Sentinel-2 MSI sensor (resolution 20 m) for the same period as the Sentinel-3 images. A validation dataset was generated for 500 independent validation points, which were selected by stratified random sampling (this compensates for differences in surface area covered by each category). A vector net of the dimensions of the classified image (300 m × 300 m) was generated, and each point was visually assigned to the category with the largest extension of the Sentinel-2 reference mosaic in the square of the net in which it is included (Figure 4). Visual qualitative analysis was also performed, comparing with (1) the Sentinel-2 reference mosaic and (2) vegetation maps for the study area [63,77]. 2.2.2. Generation of the Cartography of Fuel TypesTo facilitate the integration of the raster vegetation map with the auxiliary maps, the vegetation map was vectorized to obtain vegetation polygons. Non-vegetation categories (other uses: water, burnt areas, urban areas, bare soil, rainfed crops, irrigated crops, and floodplains) were not considered. The vegetation map was integrated with data of vegetation horizontal continuity [78] and biogeographic regions [60]. The resulting fuel map was reclassified to obtain the target FBFT categories [21].(A)Horizontal fuel continuityHorizontal fuel continuity is considered an important factor influencing fire behaviour [16] and therefore is commonly considered in the classifications of fuel types [54]. We used 2019 global MODIS vegetation continuous field collection 6 version 1 [78]. This dataset indicates the percentage of tree and non-tree vegetation cover (0–100%) at 250 m resolution with 7.87–9.40% mean absolute error [79]. A mosaic of the study area was performed and projected to ETRS89 Albers equal-area conic projection with central meridian in 3° W.The 5 vegetation categories of the vegetation map were split into tree (conifers, evergreen broadleaves, deciduous broadleaves) and non-tree (shrubs, grasses) categories. For each vegetation polygon, zonal statistics (mean and standard deviation) were calculated for (1) the percentage of tree vegetation cover for the tree categories and (2) the percentage of non-tree vegetation cover for the non-tree categories. Afterwards, the horizontal continuity percentage was used to divide each vegetation type into categories according to their fire spread occurrence possibility: (1) 0–40%, (2) 40–70%, and (3) 70–100%. The 0–40% category refers to sparse vegetation cover density. The 40% threshold was assigned because it is the percentage used in the Fire Characteristic Classification System (FCCS) to decide if canopy fire spread can occur. To divide the rest of the cover percentage, the 70% threshold was assigned. The 40–70% category refers to dense cover density, while the 70–100% category refers to very dense cover density [43,54].(B)Biogeographic regionsEnvironmental and climatic conditions affect fire spread [16], as a relationship between fires in the study area and its long-term climatic conditions has been observed [62]. Moreover, differences in species richness [80,81], total fuel biomass [82,83,84,85], and fire behaviour [86,87] within biogeographic regions have also been shown. To account for the biomass variations of fuels in our study area, we used the 2016 dataset of Europe’s biogeographic regions generated by the European Environment Agency (EEA) [60]. The study area was divided into Alpine, Atlantic, and Mediterranean regions (Figure 1). Through overlapping, each polygon with a given vegetation type and horizontal continuity percentage was assigned the biogeographic region in which it was included. If a polygon belonged to more than one biogeographic region, it was split into as many polygons as biogeographic regions it belonged to.(C)Generation of the customized Iberian fuel typesPolygons with the same vegetation type, percentage of horizontal vegetation cover group, and biogeographic region were merged to generate the customized Iberian fuel types. Therefore, the description of each Iberian fuel type is based on its vegetation type, horizontal continuity percentage, and biogeographic region. The Iberian fuel types were mapped to create the Iberian fuel map. The fuel types’ area, and their horizontal continuity mean and standard deviation were calculated.(D)Adaptation of the Iberian fuel types to the FBFT systemThe Iberian fuel types were adapted to the fuel categories of the FBFT system [21]. We based this translation on the different fuel types’ definitions, using the variables of vegetation type, climatic conditions, and horizontal fuel continuity. The vegetation type is both defined in the Iberian and standard FBFT fuel types. For the Iberian fuel types, we derived this information from the SVM classification of the Sentinel-3 Synergy mosaics, while for the FBFT system, this information is derived from field work and photo series. The climatic conditions are defined by the biogeographic regions for the Iberian fuel types (distinguishing 3 regions for the study area from [60]), while the FBFT system only distinguishes between fuel types from sub-humid/humid climates (adequate rainfall in all seasons) and arid/semi-arid climates (rainfall deficit in summer). Because the FBFT system only distinguishes between sub-humid/humid and arid/semi-arid climates, we assigned the study area’s Alpine and Atlantic fuels to the sub-humid/humid group and the Mediterranean to the arid/semi-arid group. The horizontal fuel continuity information is derived from the dataset of [78], and for the FBFT system, information on fuel density and load is based on field measures and photo series. We also visually analysed the United States FBFT map [88], extracting similar covers to those existing in the study area. The input data caused some Iberian fuel types to be assigned to various FBFT fuels. However, not all original FBFT fuels were found in the study area. The FBFT-adapted fuel mapping generated the FBFT fuel map. To improve this map’s readability, the non-burnable categories were not mapped (not considered fuel).Then, the parameters from the original FBFT fuel types were translated to the FBFT-adapted fuel types for the study area. For each fuel type, mean biomass load, spread rate, and flame length values (Table A1 in the Appendix A) were extracted from the original FBFT fuel descriptions. These values refer to the mean fuel conditions and serve to predict fire behaviour inside and outside the fire season (June–October). Local and short-term variations in fire risk caused by changes in the weather conditions and the amount of fuel moisture, among other variables, are expected to be considered in posterior analysis for fire behaviour modelling. FBFT describes the total surface biomass for non-tree fuels and only timber litter and understory biomass for tree fuels [21]. Fire potential spread rate and flame length were mapped. The FBFT fuel types were characterized by their FBFT category, area, biomass, potential spread ratio, and potential flame length. 2.2.3. Fuel Parameters: BiomassFor tree-vegetation fuels, original FBFT biomass load descriptions only refer to timber litter and understory [21], which affect surface fires. Thus, further analysis was performed to obtain the biomass load that would affect crown fires. We completed biomass load values from the original FBFT descriptions with the 2018 global CCI (Climate Change Initiative) Biomass dataset [89], recently made available. This product was derived from observations from the Copernicus Sentinel-1, Envisat’s ASAR (Advanced Synthetic Aperture RADAR), and the Japanese Advanced Land Observing Satellite (ALOS-1 and ALOS-2) missions. It estimates tree-cover Above Ground Biomass (AGB) in Mg/ha, not including small-medium shrubs and grasslands, with 100 m resolution and a relative error of less than 20% for AGB > 50 Mg/ha and an error of 10 Mg/ha when AGB < 50 Mg/ha [90]. A mosaic of the study area was performed and projected to ETRS89 Albers equal-area conic projection with central meridian in 3° W. For the tree-vegetation categories, for which FBFT only describes timber litter and understory biomass, zonal statistics (mean and standard deviation) were calculated from CCI Biomass. For the other parameters of the different fuels, we relied on the FBFT standard values, but they could be easily updated if field measurements of local analysis were available. 2.2.4. Intercomparison of the FBFT Fuel MapStrict validation of the final FBFT fuel map was not feasible because of the lack of fuel reference data and the practical difficulties of performing alternative field work. Thus, as a first assessment of the final product, we compared our FBFT fuel map with two fuel maps covering the same region: (1) the 2015 global map of Pettinari and Chuvieco [54,91] classified with the Fuel Characteristic Classification System (FCCS), and (2) the European Forest Fire Information System (EFFIS) fuel map classified with NFFL [55]. To enable the comparison of different fuel classification systems, we compared fuel biomass, which is parameterized for each fuel type in FBFT, FCCS, and NFFL. We also compared our results with CCI Biomass values. We performed a statistical analysis: (1) mean and standard deviation of the biomass values for every FBFT-adapted fuel type polygon for the study area, (2) Spearman’s rank correlation, a non-parametric measure to compare the monotonical relation of two variables even if they have a non-linear relationship [92], and (3) box plots. We compared biomass for every fuel type polygon of our FBFT fuel map for the following groups: grass, shrub, and tree fuels.", 2. Materials and Methods," 2.2. Materials, Data, and Analysis Techniques",2
22,"To avoid relying on external land cover maps as in [52,53,54] and to base our approach on updated data, a vegetation map was generated from Sentinel-3 Synergy product images. Sentinel-3 is part of the European Space Agency’s (ESA) Copernicus programme [64] and was conceived for land monitoring and security applications, and climate change detection [65]. It is composed of a pair of optical satellites, Sentinel-3A and 3B, in orbit since 2016 and 2017, respectively. It includes two main instruments: OLCI (Ocean and Land Colour Instrument, 21 channels, 300 m spatial resolution) and SLSTR (Sea and Land Surface Temperature Radiometer, 9 channels, 500 m resolution). Sentinel-3 images have already been used for wildland fire detection and mapping. Works exist that analyse the capabilities of the Sentinel-3 SLSTR sensor for active fire detection [66,67,68,69], especially for forest biomass burning events [66].In this, work, the Sentinel-3 Synergy product [65] was used, as it combines OLCI and SLSTR data. This product offers geometrically, atmospherically, and Top of Canopy (TOC) reflectivity corrected daily images at 300 m resolution for 26 spectral bands. The Sentinel-3 Synergy product has already been used, in combination with other Sentinel-3 products, for the generation of a moderate spatial resolution global burnt area product under the ESA’s Fire Climate Change Initiative (CCI) project [70]. However, the potential of this product to contribute to fuel modelling and mapping has not been exploited yet. In this work, we aim to use the relatively recent product of Sentinel-3 Synergy in the context of fuel modelling, especially for the generation of updated vegetation maps, which are expected to be useful for fuel mapping.Sentinel-3 Synergy images were downloaded from the Copernicus Open Access Hub [71] for the study area: 20 images for summer 2020, 27 images for autumn 2020, and 20 images for spring 2021. For each season, cloud-free mosaics were performed at 300 m resolution in SNAP 7.0 (Sentinel Application Platform), which uses the nearest neighbour (Figure 3). The mosaics were projected from WGS84 Geographic latitude/longitude coordinates to ETRS89 Albers equal-area conic projection with central meridian in 3° W, which preserves the area measure, and is appropriate to represent the study area.We selected the following categories to create the vegetation map: conifers, evergreen broadleaves, deciduous broadleaves, shrubs, grasses, and other uses. In the study area, the conifers only refer to evergreen conifers because deciduous conifers only grow in boreal climates. However, broadleaves can be evergreen or deciduous [63]. Conifers, evergreen broadleaves, and deciduous broadleaves have different moisture content and amount of leaves in summer and winter, and therefore different responses to fire [72]. The other uses category refers to non-natural vegetation surfaces, including crops. This classification was selected for an easy adaptation to the FBFT system [21].(A)Classification training sampleFirst, a total of 403 pure training pixels were visually selected with the help of Google Earth for 14 initial categories: conifers, evergreen broadleaves, Atlantic deciduous broadleaves, Mediterranean deciduous broadleaves, landa (Atlantic shrubs), thermophilic Mediterranean shrubs, grasses, water, burnt areas, urban areas, bare soil, rainfed crops, irrigated crops, and floodplains. These categories consider the variability of land use and vegetation due to the biogeographic regions of the study area.(B)Input bandsA total of 21 bands were used as classification input. For each season, 5 nadir observation bands (which minimize geometric distortions) were used: 555 nm (green), 659 nm (red), 865 nm (NIR), 1610 nm (SWIR 1), 2250 nm (SWIR 2). These spectral regions have been widely used in previous studies [32,41,42,49,50,51] as they have shown the potential to discriminate vegetation types. To improve the classification performance, the NDWI index ((NIR band − SWIR 2 band)/(NIR band + SWIR 2 band)) and the SAVI index (((NIR band − Red band)/(NIR band + Red band + L)) * (1 + L)) were also calculated for each season and used as input bands. We used the standard soil brightness correction parameter L = 0.5 [73,74,75].(C)Classification algorithmThe classification was performed using Support Vector Machine (SVM), a supervised non-parametric statistical machine learning algorithm, for the 403 pure training pixels and the 21 input bands. It finds the optimal hyperplane to separate the input dataset into the categories defined by the training sample [76]. The classification was performed in Orfeo ToolBox of QGIS 3.10 assigning the most similar category to each pixel. We used SVM kernel RBF (Radial Base Function), which offers optimal results for classifying vegetation with remote sensing [76], and cost parameter 100 [42]. The classification was also performed using random forest. As in [42], 100 trees and 3 as the minimum number of samples per node were used. Then, some classified categories were merged to fit the final target categories (Table 1).(D)ValidationThe vegetation map was validated using as the reference a mosaic of TOC reflectivity images from the Sentinel-2 MSI sensor (resolution 20 m) for the same period as the Sentinel-3 images. A validation dataset was generated for 500 independent validation points, which were selected by stratified random sampling (this compensates for differences in surface area covered by each category). A vector net of the dimensions of the classified image (300 m × 300 m) was generated, and each point was visually assigned to the category with the largest extension of the Sentinel-2 reference mosaic in the square of the net in which it is included (Figure 4). Visual qualitative analysis was also performed, comparing with (1) the Sentinel-2 reference mosaic and (2) vegetation maps for the study area [63,77].", 2. Materials and Methods, 2.2.1. Generation of the Basic Vegetation Cartography,2
23,"To facilitate the integration of the raster vegetation map with the auxiliary maps, the vegetation map was vectorized to obtain vegetation polygons. Non-vegetation categories (other uses: water, burnt areas, urban areas, bare soil, rainfed crops, irrigated crops, and floodplains) were not considered. The vegetation map was integrated with data of vegetation horizontal continuity [78] and biogeographic regions [60]. The resulting fuel map was reclassified to obtain the target FBFT categories [21].(A)Horizontal fuel continuityHorizontal fuel continuity is considered an important factor influencing fire behaviour [16] and therefore is commonly considered in the classifications of fuel types [54]. We used 2019 global MODIS vegetation continuous field collection 6 version 1 [78]. This dataset indicates the percentage of tree and non-tree vegetation cover (0–100%) at 250 m resolution with 7.87–9.40% mean absolute error [79]. A mosaic of the study area was performed and projected to ETRS89 Albers equal-area conic projection with central meridian in 3° W.The 5 vegetation categories of the vegetation map were split into tree (conifers, evergreen broadleaves, deciduous broadleaves) and non-tree (shrubs, grasses) categories. For each vegetation polygon, zonal statistics (mean and standard deviation) were calculated for (1) the percentage of tree vegetation cover for the tree categories and (2) the percentage of non-tree vegetation cover for the non-tree categories. Afterwards, the horizontal continuity percentage was used to divide each vegetation type into categories according to their fire spread occurrence possibility: (1) 0–40%, (2) 40–70%, and (3) 70–100%. The 0–40% category refers to sparse vegetation cover density. The 40% threshold was assigned because it is the percentage used in the Fire Characteristic Classification System (FCCS) to decide if canopy fire spread can occur. To divide the rest of the cover percentage, the 70% threshold was assigned. The 40–70% category refers to dense cover density, while the 70–100% category refers to very dense cover density [43,54].(B)Biogeographic regionsEnvironmental and climatic conditions affect fire spread [16], as a relationship between fires in the study area and its long-term climatic conditions has been observed [62]. Moreover, differences in species richness [80,81], total fuel biomass [82,83,84,85], and fire behaviour [86,87] within biogeographic regions have also been shown. To account for the biomass variations of fuels in our study area, we used the 2016 dataset of Europe’s biogeographic regions generated by the European Environment Agency (EEA) [60]. The study area was divided into Alpine, Atlantic, and Mediterranean regions (Figure 1). Through overlapping, each polygon with a given vegetation type and horizontal continuity percentage was assigned the biogeographic region in which it was included. If a polygon belonged to more than one biogeographic region, it was split into as many polygons as biogeographic regions it belonged to.(C)Generation of the customized Iberian fuel typesPolygons with the same vegetation type, percentage of horizontal vegetation cover group, and biogeographic region were merged to generate the customized Iberian fuel types. Therefore, the description of each Iberian fuel type is based on its vegetation type, horizontal continuity percentage, and biogeographic region. The Iberian fuel types were mapped to create the Iberian fuel map. The fuel types’ area, and their horizontal continuity mean and standard deviation were calculated.(D)Adaptation of the Iberian fuel types to the FBFT systemThe Iberian fuel types were adapted to the fuel categories of the FBFT system [21]. We based this translation on the different fuel types’ definitions, using the variables of vegetation type, climatic conditions, and horizontal fuel continuity. The vegetation type is both defined in the Iberian and standard FBFT fuel types. For the Iberian fuel types, we derived this information from the SVM classification of the Sentinel-3 Synergy mosaics, while for the FBFT system, this information is derived from field work and photo series. The climatic conditions are defined by the biogeographic regions for the Iberian fuel types (distinguishing 3 regions for the study area from [60]), while the FBFT system only distinguishes between fuel types from sub-humid/humid climates (adequate rainfall in all seasons) and arid/semi-arid climates (rainfall deficit in summer). Because the FBFT system only distinguishes between sub-humid/humid and arid/semi-arid climates, we assigned the study area’s Alpine and Atlantic fuels to the sub-humid/humid group and the Mediterranean to the arid/semi-arid group. The horizontal fuel continuity information is derived from the dataset of [78], and for the FBFT system, information on fuel density and load is based on field measures and photo series. We also visually analysed the United States FBFT map [88], extracting similar covers to those existing in the study area. The input data caused some Iberian fuel types to be assigned to various FBFT fuels. However, not all original FBFT fuels were found in the study area. The FBFT-adapted fuel mapping generated the FBFT fuel map. To improve this map’s readability, the non-burnable categories were not mapped (not considered fuel).Then, the parameters from the original FBFT fuel types were translated to the FBFT-adapted fuel types for the study area. For each fuel type, mean biomass load, spread rate, and flame length values (Table A1 in the Appendix A) were extracted from the original FBFT fuel descriptions. These values refer to the mean fuel conditions and serve to predict fire behaviour inside and outside the fire season (June–October). Local and short-term variations in fire risk caused by changes in the weather conditions and the amount of fuel moisture, among other variables, are expected to be considered in posterior analysis for fire behaviour modelling. FBFT describes the total surface biomass for non-tree fuels and only timber litter and understory biomass for tree fuels [21]. Fire potential spread rate and flame length were mapped. The FBFT fuel types were characterized by their FBFT category, area, biomass, potential spread ratio, and potential flame length.", 2. Materials and Methods, 2.2.2. Generation of the Cartography of Fuel Types,2
24,"For tree-vegetation fuels, original FBFT biomass load descriptions only refer to timber litter and understory [21], which affect surface fires. Thus, further analysis was performed to obtain the biomass load that would affect crown fires. We completed biomass load values from the original FBFT descriptions with the 2018 global CCI (Climate Change Initiative) Biomass dataset [89], recently made available. This product was derived from observations from the Copernicus Sentinel-1, Envisat’s ASAR (Advanced Synthetic Aperture RADAR), and the Japanese Advanced Land Observing Satellite (ALOS-1 and ALOS-2) missions. It estimates tree-cover Above Ground Biomass (AGB) in Mg/ha, not including small-medium shrubs and grasslands, with 100 m resolution and a relative error of less than 20% for AGB > 50 Mg/ha and an error of 10 Mg/ha when AGB < 50 Mg/ha [90]. A mosaic of the study area was performed and projected to ETRS89 Albers equal-area conic projection with central meridian in 3° W. For the tree-vegetation categories, for which FBFT only describes timber litter and understory biomass, zonal statistics (mean and standard deviation) were calculated from CCI Biomass. For the other parameters of the different fuels, we relied on the FBFT standard values, but they could be easily updated if field measurements of local analysis were available.", 2. Materials and Methods, 2.2.3. Fuel Parameters: Biomass,2
25,"Strict validation of the final FBFT fuel map was not feasible because of the lack of fuel reference data and the practical difficulties of performing alternative field work. Thus, as a first assessment of the final product, we compared our FBFT fuel map with two fuel maps covering the same region: (1) the 2015 global map of Pettinari and Chuvieco [54,91] classified with the Fuel Characteristic Classification System (FCCS), and (2) the European Forest Fire Information System (EFFIS) fuel map classified with NFFL [55]. To enable the comparison of different fuel classification systems, we compared fuel biomass, which is parameterized for each fuel type in FBFT, FCCS, and NFFL. We also compared our results with CCI Biomass values. We performed a statistical analysis: (1) mean and standard deviation of the biomass values for every FBFT-adapted fuel type polygon for the study area, (2) Spearman’s rank correlation, a non-parametric measure to compare the monotonical relation of two variables even if they have a non-linear relationship [92], and (3) box plots. We compared biomass for every fuel type polygon of our FBFT fuel map for the following groups: grass, shrub, and tree fuels.", 2. Materials and Methods, 2.2.4. Intercomparison of the FBFT Fuel Map,2
26,"The Support Vector Machine (SVM) vegetation map (Figure 5) shows the study area’s general spatial distribution of vegetation. It shows a wide presence of coniferous species in the northern and eastern mountainous regions of the study area. Evergreen deciduous species dominate in the central and southern regions. Deciduous species predominate in the northern and western regions. Shrubs are represented almost all over the study area, standing out in the eastern region. Grasses have a wide presence in the central and western Iberian Peninsula, mostly associated with agroforestry (dehesa) ecosystems.The SVM vegetation classification provided an overall accuracy of 85% and kappa 0.81 (Table A2 in the Appendix A), much higher than the random forest, with an overall accuracy of 56% and kappa 0.44. Thus, we chose the SVM map as the vegetation cartography on which to base the fuel type mapping. The qualitative validation confirms the adjustment of the SVM map to the vegetation patterns observed in the Sentinel-2 images used as reference data. Quantitative validation indicates high agreement between the reference data and the classification.", 3. Results, 3.1. Vegetation Map,3
27,"The customized Iberian fuel map has 45 fuel types adapted to the study area and input data (Figure 6). Each fuel type is identified by its vegetation type, vegetation horizontal continuity percentage, and biogeographic region.The five Iberian fuel types with the largest area belong to the Mediterranean region. The largest area belongs to Mediterranean shrubs with 40–70% continuity (83,831 km2), followed by Mediterranean grasses with 70–100% continuity (55,696 km2). These fuel types relate to the arid/semi-arid steppe and the dehesa ecosystems, respectively. No significant differences were observed in means and standard deviations of the vegetation horizontal continuity between biogeographic regions or vegetation types (Table A3 in the Appendix A). Fuel types with 0–40% vegetation horizontal continuity presented greater internal variability (highest standard deviation) and therefore greater heterogeneity. Fuel types with 70–100% vegetation horizontal continuity showed less internal variability (lowest standard deviation) and therefore are more homogeneous.Next, the Iberian fuel types were converted to the FBFT fuel types (see Table A4 in the Appendix A). The FBFT fuel map was generated (Figure 7) with 19 fuel types, and the fuel types were characterized and parameterized (Table 2, Table 3 and Table 4). The FBFT fuels’ spatial distribution is similar to that of the customized Iberian fuel map (Figure 6). The fuel types with the largest area Table 2, Table 3 and Table 4) are related to the largest Iberian fuel types (Table A3 and Table A4 in the Appendix A). The fuel type with the largest area (83,831 km2) is SH2, corresponding to Mediterranean shrubs with 40–70% horizontal continuity. The second fuel type with the largest area (55,696 km2) is GR4/GR7, corresponding to Mediterranean grasses with 70–100% horizontal continuity.The mean biomass of the FBFT-adapted fuel types for the study area (Table 2, Table 3 and Table 4) varies between 1 and 136 Mg/ha, with differences of up to two orders of magnitude between the FBFT-adapted [21] values and the CCI Biomass [89] values. The fuel type with the highest FBFT-adapted mean biomass is SH6/SH8/SH9 (19.56 Mg/ha) followed by GR5/GR8/GR9 (17.05 Mg/ha), corresponding to dense shrubs and grasses from sub-humid/humid climates, respectively. The FBFT-adapted fuel types with the highest mean biomass values extracted from CCI Biomass are TL9 or very high broadleaf litter (136 Mg/ha), and TL5 or high load conifer litter (152 Mg/ha). The more heterogeneous FBFT-adapted fuel types (greater internal variability) are TU5/TL3/TL8 or moderate-high conifer load litter with/without shrub (standard deviation = 66.55), and TL5 or high load conifer litter (standard deviation = 65.12). Non-tree vegetation biomass values could not be extracted from CCI Biomass because this product only indicates tree-vegetation biomass.The fire potential spread rate and flame length intensity values for surface fires vary between very low and extreme (Table 2, Table 3 and Table 4, Figure 8). A strong visual correlation exists for the spatial distribution of both variables, especially for the arid/semi-arid climate (Mediterranean biogeographic region). The more flammable fuels are moderate-heavy grasses and shrubs (high-extreme fire potential spread ratio and flame length). The highest fire potential spread rates and flame length intensities predominate in the central and western Iberian Peninsula, while the lowest intensity values dominate in the northern and eastern regions of the study area. The GR5/GR8/GR9 fuel type or Alpine and Atlantic highly continuous (70–100%) grasses (56 km2) has the highest values for both variables (very high-extreme).Finally, grass, shrub, and tree fuels’ biomass was compared with other fuel products (Table 5, Figure 9). This work’s FBFT grass biomass mean is 27% higher compared with the global map [54] and 42% lower compared with the European map [55]. This work’s FBFT shrub biomass mean is 41% and 34% higher compared with the global and European maps, respectively. This work’s FBFT tree biomass mean is 542%, 8%, and 39% lower compared with the CCI Biomass [89] values, the understory biomass of the global map, and the European map, respectively. The derived CCI Biomass tree biomass mean is 56% lower compared with the tree Above Ground Biomass (AGB) of the global map, and 295% higher compared with the European map. The Spearman’s rank correlation values show the highest correlation between this work’s non-tree fuels and the European map (0.11 for grass, and 0.13 for shrub fuels), and between the CCI Biomass values and the tree AGB values of the global map (correlation of 0.45) for the tree fuels. The large differences between biomass values and their distribution for the compared products is due to (1) the different methods used to estimate the biomass values and (2) the dissimilar vegetation parts considered in the biomass estimation.", 3. Results, 3.2. Fuel Type Map,3
28,"The quantitative assessment of the vegetation map presented an overall accuracy of 85% (category errors between 3% and 28%), which is aligned with the goal of 85% global accuracy and no category less than 70% accuracy when classifying land cover with remote sensing [93]. As in [42], the best vegetation map was obtained with SVM versus random forest, possibly due to the small size of our training sample.The Sentinel-3 Synergy 300 m resolution required some generalization of the vegetation map, ignoring the complexity of the real ecosystems. Thus, mixed pixels were not considered. The vegetation map’s accuracy results could be improved with the optimal search for SVM parameters. The classification was not also performed with Object Based Image Analysis (OBIA), for which other authors obtained similar results to QuickBird and Sentinel-2 (global accuracy 75–90%, categories 50–100%) [43,45] as compared with this work’s Support Vector Machine (SVM) results. Thus, the computational and time costs of OBIA did not seem worth it for the purposes of this work.The main errors shown in the validation of the vegetation map were caused by Sentinel-3 mixed validation pixels, in which the reflectivity of the different covers was combined. The omission of conifers was mainly related to the confusion with shrubs, mostly in low-density forest areas. Evergreen broadleaves offered commission errors mostly confused with areas of low-density conifers and tall shrubs in agroforestry (dehesas) and mountainous areas. Deciduous broadleaves were confused with conifers in mixed forest areas in the northern and western forests. The shrubs’ commission errors were mainly related to confusion with permanent crops (vineyards, fruit trees). The shrubs’ omission errors were associated with their confusion with annual crops and mixed pixels of shrubs and grasses. Omission and commission errors for grasses were mainly related to patchy grass areas.Regarding the conversion from the customized Iberian fuel map to the FBFT fuel map, several problems were found. For instance, this work assumes an equivalence between the United States FBFT sub-humid/humid climate and the Atlantic and Alpine European biogeographic regions, as well as between the United States FBFT arid/semi-arid climate and the Mediterranean European biogeographic region. Moreover, the Atlantic and Alpine fuel types were impossible to separate in the FBFT system [21]. This issue could be improved for the European FBFT fuel map by complementing the information of the FBFT fuel types with the biogeographic region in which they are included. For this, every European-adapted FBFT fuel type could be split into as many fuel types as European biogeographic regions it belongs to.Some difficulties were also found concerning the broadleaves because the FBFT system does not distinguish between evergreen and deciduous broadleaves. Thus, we adapted the broadleaves based on the biogeographic region, horizontal continuity, and fuel load. Therefore, caution should be taken when using the FBFT fuel map for these vegetation categories. The Iberian and FBFT fuel maps have a similar general spatial distribution of fuels because one is based on the other. The fuel types with the largest area are the Mediterranean types because this is the largest biogeographic region in the study area.Moreover, in this work we have used the original FBFT descriptions and visual analysis of the United States FBFT fuel map [88] to convert from the Iberian fuel types to the standard FBFT fuel types (Table A4 in the Appendix A). A way to improve this in future works would be to compare the quantitative environmental specifications (such as rainfall, temperature, evapotranspiration, available water, and drought index) for the United States FBFT fuel types and the Iberian fuel types. This could be done by comparing these metrics for the United States, Spain, and Portugal.Concerning the fuel type parameters, the tree fuels’ biomass values derived from CCI Biomass [89] presented great differences (up to two orders of magnitude) from those extracted from the FBFT system [21]. The reason for this is that for the tree fuel types, the CCI Biomass values refer to total AGB and the FBFT values to timber litter and understory biomass. Moreover, CCI Biomass values offer pixel-disaggregated information compared with the FBFT values, for which the mean biomass values of the fuel types are assigned to all the extension occupied by an FBFT fuel type. Biomass data are expected to improve with the upcoming ESA Biomass mission in 2022 [16].Dense grasslands and shrubs are the most flammable fuel types [94]. This agrees with the obtained results, which show that the GR5/GR8/GR9 fuel type or Alpine and Atlantic highly continuous (70–100%) grasses entails the highest fire risk and danger: very high-extreme fire potential spread rate and flame length. Also, grasses and shrubs occupy much of the surface of the study area. Thus, the biggest economic and human fire prevention efforts should be focused here.In terms of intercomparison with existing vegetation and fuel maps of the study area, a strict validation was not possible, since the scales, methods, and classification schemes change between products. Still, the vegetation map’s distribution agrees with that detailed for the study area [63,77], and its classification scheme is similar to that defined on larger scales with Sentinel-2 [43,50]. Also, the global [54,91] and the European [55] fuel maps have, respectively, 41 and 10 fuel types for the study area, while here we mapped 45 (Iberian fuel map) and 19 (FBFT fuel map) types. This difference may be caused by the use of the vegetation horizontal continuity to develop fuel types in this work, while in [54] it is only used to parameterize and the FBFT system uses field measures and photo series.Furthermore, this work’s comparison with the global [54] and European [55] fuel maps shows some similarities for the mean biomass values but does not show very strong associations for the distribution of values, probably caused by the dissimilar biomass estimation methods. FBFT is based on field measures and photo series, and for tree fuels describes timber litter and understory [21]; CCI Biomass is derived from RADAR images and indicates tree AGB [90]; FCCS (global map) infers vegetation parts’ biomass from expert opinion, scientific literature, photo series, and pre-existing databases [95]; NFFL (European map) is based on observations and for tree fuels describes only timber litter [35]. Thus, the biomass values differ between products. This may explain the high tree mean biomass differences when compared with other mean biomass values. However, it is important to note that there is no reason why the global and European fuel maps should be considered more accurate than this work’s result. A homogeneous field sampling for the fuel parameters in the study area would be useful for a strict validation of this work’s fuel maps. Moreover, CCI Biomass indicates AGB while FBFT, FCCS (except for the tree Above Ground Biomass parameter), and NFFL describe surface fuel biomass affecting surface fires. Hence, the fuel parameterization methods and assumptions, usually determined by the fuel categories of the standard fuel classification systems, stand out as a key aspect to homogenize fire risk assessment, evidencing the importance of an integrated fuel mapping strategy across regions.The final fuel descriptions and maps are influenced by the errors of their inputs. For the FBFT fuel map, adaptation-derived errors also had an effect. In addition, the original FBFT system uses field measures and photo series to describe the fuel types, which results in dissimilar fuel descriptions and difficult adaptation. Thus, the main limitations of this work are (1) the selected inputs, which limit the disaggregation of fuel types, (2) the errors of the inputs and the generated vegetation map, which influence the final map’s accuracy, and (3) the FBFT adaptation difficulties. These aspects limit the utility of the final fuel map for local studies. It is also limiting not to consider mixed categories and pixels.The main contribution of our methodology was to derive an easily upgradeable and reproducible method to map fuel types and estimate fire propagation potential to improve fire risk assessment. It is expected to be applicable to regional, continental, or global scales, adapting the methods and data if necessary. Sentinel-3 Synergy images offer an advantage over higher resolution sensors, which would require a greater computational effort for regional-continental fuel mapping. The standard FBFT fuel types facilitate the homogenization of fuel maps across regions. Our methodology is expected to be useful for fuel mapping that can be updated for short time periods (semi-annual or annual), usable in fire simulation models to consider the fuels’ high temporal variability in fire risk assessment. It serves to optimize the prevention, resource allocation, and management of wildland fires. This work is relevant because it generates the framework for an updated large-scale (European) fuel mapping.Future works should focus on refining the fuel type maps by subdividing categories, searching for optimal SVM parameters for the vegetation classification, considering mixed vegetation categories and vegetation vertical characteristics (using LiDAR data), and comparing with classifiers such as OBIA. Future works should also make efforts to compare the results with fieldwork or local products. Regarding this, it would be useful to develop a European database with homogeneous field sampling to help validation and selection of remote sensing products in future works concerning vegetation and fuel mapping, and fuel parameterization.", 4. Discussion,None,4
29,"This work generated an FBFT [21] fuel map for the Iberian Peninsula and the Balearic Islands with 19 fuel types, which were also parameterized. Estimated fire behaviour (potential spread rate and flame length) was also mapped. The input data were Sentinel-3 Synergy images, MODIS vegetation continuous field collection 6 maps, a map of biogeographic regions, and the CCI Biomass map. Intercomparison of the final FBFT fuel map with other fuel products showed some agreement for mean biomass values but did not present a strong correlation between products in the distribution of values. As intermediate results, this work generated a vegetation map and a map of 45 customized fuel types, and proposed an adaptation to the FBFT system [21] for the study area.Up-to-date mapping of fuel types is essential for wildland fire prevention. This work has wide applicability because it proposes a methodology to develop an easily upgradeable fuel cartography on a regional-continental scale for wildland fire risk assessment. This is a priority future line of research because it will facilitate, speed up, and optimize wise decision-making. The proposed methodology can be used to classify fuel types in other regions, adapting the fuel categories if necessary. The next step should be to apply this methodology to homogenize fuel maps in the European Union, a vital point to derive an integrated fire risk strategy adapted to European conditions, which is a key objective of the FirEUrisk project, in which our present research fits.", 5. Conclusions,None,5
30,"Remote sensing, with Landsat in particular, has long been used to detect forest disturbance at a wide variety of scales [1,2,3,4]. Since the Landsat archive was made freely available, numerous change detection algorithms have been developed which use up to decades-long time series of observations to signal, quantify, and attribute forest disturbance [5,6,7,8,9,10,11]. These time series algorithms improve on more traditional bi-temporal, or image-to-image, approaches.Disturbances that occur abruptly in the temporal domain such as clearcut harvests, fires and land-use conversions tend to be easier to detect than more subtle changes brought on by thinning, drought, insects and other within-class changes [12,13,14,15]. These subtle changes are harder to detect but may still contribute significantly to the overall forest carbon budget [16,17,18]. For example, Cohen et al. [13] found evidence of a more general forest decline, defined there as canopy loss not associated with or attributable to other common classes (in the case of that study: fire, harvest, wind, water, land use conversion, or debris), that has a wide extent and an increasingly sizable impact on forest productivity and carbon flow. Given that these subtle changes can affect the structure and functioning of forests over large areas, there is a great need to identify them and other such within-class changes (e.g., a thinned or drought-stressed forest) using remote sensing.Exponentially Weighted Moving Average Change Detection (EWMACD) [5] is a freely available, open-source [19] pixel-level time series change detection algorithm originally designed to detect a wide variety of persistent changes to forested pixels. EWMACD uses exponentially weighted moving average (EWMA) control charts to analyze residual values resulting from fitting the input time series to harmonic (e.g., Fourier) curves to account for seasonal patterns. The result is a time series of signals which convey not only the presence of a disturbance but also the magnitude and timing, up to the temporal resolution of the input data. Part of the class of memory control charts, EWMA charts are specifically designed to detect subtle shifts from the in-control state, the state in which a process (in this case, forest status) continues to behave according to its historically observed or intended characteristics (e.g., stable forest) [20,21,22]. This makes them ideally suited to detect not only acute changes, such as harvests and fires, but also longer, slower periods of gradual forest decline.EWMACD trains its harmonic curves on an initialization period, the training period, then compares all subsequent data against this initial training. This results in it being a time series-based change detection method that can be interpreted in a bi-temporal manner. Used this way, EWAMCD has previously been shown to detect subtle forest disturbance, in particular thinning, at a sub-pixel spatial scale using Landsat data [5].However, EWMACD continues to measure departures from the initial curve even after signaling a disturbance. While this can be helpful in comparing a pixel’s status from one time to the next, it does not effectively monitor the pixel’s trajectory in a continuous fashion [5]. For analyses spanning decades, a single training period is often insufficient to effectively capture forest change. Figure 1 offers an example of this problem. In this example, the pixel covers a pine forest plantation in North Carolina, USA, which exhibits a typical growth and harvest pattern. EWMACD is initialized during a condition of forest maturity, and it correctly signals the disturbance in 1991. However, it continues to treat the mature forest as the baseline for comparison, resulting in a consistent loss signal even when the forest clearly recovers; the pattern repeats for the disturbance in 2003–2004. While this example is not of a subtle disturbance, it does illustrate the problem associated with using a fixed reference curve.Other contemporary change detection algorithms incorporate methods for long-term trend analysis. LandTrendr [7], ITRA (Image Trends from Regression Analysis) [8], VCT (Vegetation Change Tracker) [6], and VeRDET (Vegetation Regeneration and Disturbance Estimates through Time) [11] automatically target multi-year disturbances, but they do not directly use all available data and are constrained to an annual time step, which can reduce their ability to precisely identify disturbance timing. The Continuous Change Detection and Classification algorithm (CCDC) [9], an algorithm based on harmonic regression principles similar to those underlying EWMACD, has built-in methods for retraining curves and does use the full time series. However, CCDC is specifically focused on between-class changes and has difficulty signaling for “partially changed” pixels [9], the area in which EWMACD specializes.Thus, what is needed is a dynamic update to EWMACD: an algorithm which can detect subtle forest disturbances in a long-term, flexible fashion. Accordingly, our objective is to present and assess Edyn (dynamic EWMACD), an EWMACD-based change detection algorithm that retrains its harmonic reference curves after a disturbance is registered. In this study we describe the differences between Edyn and EWMACD, then compare the two algorithms in an agreement assessment on over 3500 forested pixels from across the contiguous United States (CONUS) using decades-long time spans.", 1. Introduction,None,1.
31,"For reference data in our assessment, we used a collection of pixels interpreted by users of the TimeSync software [23], a web application hosted by Oregon State University. (TimeSync version 2.0 was used for generating the reference data.) These pixels were randomly sampled from a collection of 179 Landsat scenes covering a diverse subset of the CONUS ([13], Figure 1), with each scene hosting different forest types and disturbance regimes. Figure 2 shows the same pixel from Figure 1, when processed by TimeSync. All available Landsat images within the growing season (approximately May through October) were acquired for a 200 × 200-pixel area around each sample pixel. Each pixel’s time series was input into TimeSync and visually interpreted by a pair of expert analysts, with disagreements adjudicated by a third interpreter. For further information about the TimeSync process the reader is referred to [23]; for more on the reference dataset used in this study, please refer to [13].For our study, we selected a subset of these reference data which corresponded to time series representing forested pixels. Typical timeframes ranged from 1985 to 2012, covering multiple Landsat sensors and platforms. Spectral data for each pixel were provided, as were data regarding the TimeSync disturbance interpretations. The dataset used in this study comprised 3751 pixels in total. We excluded all data marked by the associated Fmask codes [24] as non-clear, then computed NDVI (Normalized Difference Vegetation Index) values [25] for all remaining data to use as inputs to EWMACD and Edyn.", 2. Materials and Methods, 2.1. Reference Data and Spectral Data,2
32,"While developing Edyn, we also updated EWMACD to improve general performance. A brief summary of the algorithm (Figure 3) and a description of these key modifications follows. For a full description of the original version of EWMACD, please refer to [5]. Vectors and matrices are in bold typeface; scalars are not.Given an image time series of length 

n

, 


t
=

{


t
1

,

t
2

,
…
,
 

t
n


}



, and a corresponding Julian date time series 


d
=

{


d
1

,

d
2

,
…
,
 

d
n


}



, we first estimate harmonic coefficients for the first 



n

t
r
a
i
n


<
n


 elements by ordinary least squares estimation using 



k
s



 sine harmonics and 



k
c



 cosine harmonics:






β
^

=



(


X

t
r
a
i
n

′


X

t
r
a
i
n



)



−
1



X

t
r
a
i
n

′


t


n

t
r
a
i
n




,





(1)

where 



X

t
r
a
i
n




 is the 



n

t
r
a
i
n


×

(

1
+

k
s

+

k
c


)



 design matrix consisting of a ones column and each harmonic adjustment to 

d

. In practice, we recompute 


β
^


 after screening out all elements that have standardized residual values greater than a global, user-specifiable threshold. We then compute residuals for the full time series,





r
=
t
−
X

β
^

,





(2)


where 

X

 is the full 


n
×

(

1
+

k
s

+

k
c


)



 design matrix computed similarly. We then estimate the training period variance,






s
2

=



r


n

t
r
a
i
n





r


n

t
r
a
i
n



′




n

t
r
a
i
n


−
1


.





(3)

Next, we compute EWMA values for the full time series by setting 


E
W
M

A
1

=
0


 and recursively calculating:




E
W
M

A
i

=

(

1
−
λ

)

E
W
M

A

i
−
1


+
λ

r
i

,
 
i
∈

{

2
,
 
3
,
 
…
,
 
n

}

,





(4)

where 


λ
∈

(

0
,
 
1

]



 is the smoothing parameter which indicates the weight of the current observation against the exponentially decayed weight of all prior observations. Note that we assume the mean of the in-control residuals (based on stable, undisturbed forest) to be 0, since OLS is an unbiased estimation technique.At the same time, we compute signaling thresholds:





C

L
i

=
±
L
s



(


λ

2
−
λ



)


[

1
−



(

1
−
λ

)



2
i



]



,
 


i
∈

{

2
,
 
3
,
 
…
,
 
n

}

,






(5)


where 

L

 (the control limit) determines how many standard deviations away from the in-control mean of 0 are required to signal. Then, we record the EWMACD outputs in relative form by dividing the EWMA values by the control limits and taking the floor of the absolute values multiplied by the original signs:




E
W
M
A
C
D
=
sign

(

E
W
M
A

)

⌊



|

E
W
M
A

|



C
L


⌋
.





(6)

When the EWMA values extend beyond the signaling thresholds, EWMACD signals a disturbance; otherwise a value of 0 indicates no signaled disturbance. (The user can instead obtain an output of the raw EWMA chart values, if desired). Note that using this rule, EWMACD signals for both negative (e.g., removal) and positive (e.g., growth) deviations from the curve; EWMACD can be made to ignore positive deviations by setting the positive value of 




CL

i



 to infinity. EWMACD outputs correspond to each element of the input time series; thus they may be post-processed and summarized to give annual or similar summaries. Parameter UpdatesMany of the pre- and post-processing subroutines in EWMACD rely on a measure of persistence, defined here as a quantification of the number of consecutive elements in the time series that must occur before some decision is made (e.g., recording a signal as opposed to treating it as anomalous). This persistence was previously a global, user-specified parameter. However, due to inherently variable conditions and differences in image availability as functions of both time and location, the density of data for any given pixel or timeframe varies considerably. We therefore modified the persistence parameter into a persistence per year parameter, 



p

y
e
a
r




, allowing a user to specify what proportion of a year (or possibly multiple years) is considered to be “long enough” for the algorithm to act. Given this value, EWMACD now takes the mean number of elements per year in the time series, then modifies this value accordingly to obtain a per-pixel value for persistence. This value is thus data-driven yet more consistent with user expectations.The quality of fit for the initial harmonic curve has a strong impact on EWMACD’s accuracy in general, making it important to have enough data to accurately and robustly fit this curve. Taking too little data into the training period risks overfitting and allowing the otherwise-unconstrained curves to deviate nonsensically [9,26,27], which can result in many false alarm signals when real data are compared to the extrapolations. On the other hand, taking too much data into the training period reduces the algorithm’s effectiveness by rendering a substantial portion of the time series unavailable for change detection, and doing so also increases the likelihood that the algorithm will attempt to train a curve on a disturbance. Thus, in an ideal situation EWMACD will take only the minimum amount of data required for an accurate curve-fitting. We achieve this by first determining a minimum training length of at least 


3

(

1
+

k
s

+

k
c


)



, where 



k
s



 and 



k
c



 are the number of harmonics for the sine and cosine terms being used in the Fourier expansion. Then, using a moving window starting at the beginning of the time series, the algorithm fits successive harmonic curves until it either achieves a minimum fit 



R
2



, denoted 



q

f
i
t




, or reaches the maximum training date (by default the point in the time series twice as large as the endpoint of the minimum training length), at which point it accepts the final curve. This process reduces the likelihood of training on a disturbance while ensuring that a well-fitted curve is found relatively early in the time series. Between specifying 



p

y
e
a
r




 and 



q

f
i
t




, the user now has more flexible control over how likely EWMACD is to inadvertently train on a disturbance.", 2. Materials and Methods, 2.2. Review and Updates to EWMACD,2
33,"Many of the pre- and post-processing subroutines in EWMACD rely on a measure of persistence, defined here as a quantification of the number of consecutive elements in the time series that must occur before some decision is made (e.g., recording a signal as opposed to treating it as anomalous). This persistence was previously a global, user-specified parameter. However, due to inherently variable conditions and differences in image availability as functions of both time and location, the density of data for any given pixel or timeframe varies considerably. We therefore modified the persistence parameter into a persistence per year parameter, 



p

y
e
a
r




, allowing a user to specify what proportion of a year (or possibly multiple years) is considered to be “long enough” for the algorithm to act. Given this value, EWMACD now takes the mean number of elements per year in the time series, then modifies this value accordingly to obtain a per-pixel value for persistence. This value is thus data-driven yet more consistent with user expectations.The quality of fit for the initial harmonic curve has a strong impact on EWMACD’s accuracy in general, making it important to have enough data to accurately and robustly fit this curve. Taking too little data into the training period risks overfitting and allowing the otherwise-unconstrained curves to deviate nonsensically [9,26,27], which can result in many false alarm signals when real data are compared to the extrapolations. On the other hand, taking too much data into the training period reduces the algorithm’s effectiveness by rendering a substantial portion of the time series unavailable for change detection, and doing so also increases the likelihood that the algorithm will attempt to train a curve on a disturbance. Thus, in an ideal situation EWMACD will take only the minimum amount of data required for an accurate curve-fitting. We achieve this by first determining a minimum training length of at least 


3

(

1
+

k
s

+

k
c


)



, where 



k
s



 and 



k
c



 are the number of harmonics for the sine and cosine terms being used in the Fourier expansion. Then, using a moving window starting at the beginning of the time series, the algorithm fits successive harmonic curves until it either achieves a minimum fit 



R
2



, denoted 



q

f
i
t




, or reaches the maximum training date (by default the point in the time series twice as large as the endpoint of the minimum training length), at which point it accepts the final curve. This process reduces the likelihood of training on a disturbance while ensuring that a well-fitted curve is found relatively early in the time series. Between specifying 



p

y
e
a
r




 and 



q

f
i
t




, the user now has more flexible control over how likely EWMACD is to inadvertently train on a disturbance.", 2. Materials and Methods, Parameter Updates,2
34,"When only a single disturbance occurs over a time series, EWMACD generally signals it and tracks the magnitude as it varies over time. This magnitude is valuable in its own right, as it is derived from the pixel’s trajectory and variability during the training period and in some sense incorporates that pixel’s unique characteristics as a result. Additionally, EWMACD is tuned to detect low-magnitude disturbances, as described in Section 2.2. Therefore, when determining when and how to retrain the harmonic curve after a signaled disturbance, we wanted to utilize this information and preserve the subtle change detection as much as possible.The workflow of the Edyn algorithm is given in Figure 4. Edyn initializes just as EWMACD does, with a harmonic curve fitted and EWMA values calculated to produce an output time series of signal values. However, when a disturbance is signaled, Edyn reinitializes on a subset of the original time series, restarting after the disturbance is presumed stabilized and recording the original outputs from the period before the new starting point. It then repeats the core EWMACD algorithm on the subset, reinitializing on further signals and repeating until either no disturbances are signaled or insufficient data remain. The resulting output is a spliced collection of EWMACD signal outputs, yielding a dynamic disturbance trajectory based on last-known-stable conditions.The crux of Edyn’s performance lies in accurately determining when a disturbance has stabilized. To do this, we make use of the previous EWMACD output as well as the persistence parameter and the training period demarcation, denoted here as 



t

t
r
a
i
n




, as follows. Given a time series of EWMACD outputs that signals a disturbance after the training period, we note that the outputs for the training period are assumed to be 0 (no change). Then, the first signaled disturbance represents a vertex in the output. However, simply reinitializing at this point would (1) most likely cause training on the continued disturbance or recovery thereof; or (2) cause the disturbance record to be overwritten as “retraining”. Therefore, we make the simplifying assumption that the second vertex in the signal time series represents the point at which the original disturbance has stabilized and the pixel has reached a new equilibrium, and we choose this point to reinitialize. Figure 5 illustrates this approach, using the same forested pixel shown in Figure 1 and Figure 2. Note that like EWMACD, Edyn signals for both negative and positive deviations from the curve by default.We determine vertices in a manner similar to the methods used in LandTrendr [7], a segmentation-based change detection algorithm which inputs a time series (typically annual steps) and uses a sequence of linear interpolations to identify vertices. The segments defined by these vertices are then classified into disturbance, stable, and growth trends according to their slopes. In the case of Edyn, we find the line between the endpoints of a given segment, then find the point in the time series with the highest squared deviation from the line and designate it a vertex. We use this new vertex to partition the time series into two smaller ones and repeat, finding additional vertices. Candidate vertices are only considered if they are far enough away from previously identified vertices, using half the persistence value as the distance threshold (making a persistence-sized interval around a given vertex). The process is repeated until no more viable candidates can be found, at which point we identify the second vertex. Because EWMACD signals directly indicate observed changes, choosing this point generally ensures that the initial disturbance event is no longer active when retraining begins. Because EWMACD signals can capture subtle disturbances, they potentially offer more information than raw spectral or vegetation index values.Figure 6 shows sample Edyn and EWMACD outputs for part of the study area of [5], a region of Alabama, USA that is dense in industrial pine plantations. In both cases, there is spatial coherence, indicating that both algorithms are likely capturing real change processes on the landscape, but note the stand in the north-central area, indicated by the arrow. Both algorithms signal a disturbance beginning in 2007. However, Edyn “resets” after a given time (the persistence: in this case, approximately one year’s worth of images) and ultimately signals growth in 2010–2011. EWMACD consistently signals the patch as a disturbance, although the degree does lessen from 2008 to 2011, as evidenced by the color shifting from reds to yellows. In both cases, the algorithms observe the disturbance, but they differ in how they quantify it.", 2. Materials and Methods, 2.3. Edyn,2
35,"Like any change detection algorithm, EWAMCD and Edyn have both strengths and limitations that result from the underlying assumptions and model structure. Although it has not yet been employed across wide spatial extents, Edyn is based on the same core algorithm and thus shares many of the strengths and limitations of EWMACD, with the obvious exception being the ability to retrain its harmonic curves in support of long-term monitoring.The most apparent strength of the two algorithms is their ability to detect subtle changes. EWMACD was shown to accurately detect forest thinning harvests in an industrial pine setting, including canopy reductions of as low as 25% based on visual inspection of aerial photographs [5]. EWMACD also detected stand-replacing disturbances with high accuracy, and the use of signal strength relative to pixel-specific control limits yielded maps which indicated both disturbance occurrence and relative magnitude, as well as direction (e.g., growth or removal). Furthermore, by using all available images instead of composites or annualized summaries, EWMACD signaled detected changes with good temporal precision, often signaling only one or two images after the disturbance occurred [5]. Finally, because the algorithms are defined generally, they can be employed on any remotely sensed time series regardless of land cover, sensor platform, or image frequency—provided sufficient data exist to train harmonic curves (two or three periods’ worth, as a rule of thumb).However, this generality also underlies many of the algorithms’ limitations. EWMACD and Edyn are intended to detect and monitor change, but they are not in themselves designed to attribute such changes to particular causes (though their outputs could be used in an algorithm that does, such as that of [10] or [28]). The algorithms also rely on the harmonic curves for both the residual time series and the in-control statistics, so any pixel that normally exhibits non-harmonic patterns through time (e.g., vegetation in very arid climates) could confound the algorithms’ outputs. Similarly, a sparse time series for some pixels (e.g., from a cloud-covered rainforest) can lead to model overspecification, causing the in-control standard deviation estimate to be so small that the algorithms subsequently signal at the slightest fluctuation. In general, the algorithms’ focus on detecting subtle disturbances results in their being prone to larger commission error rates, as was seen in [14]. Finally, EWMACD/Edyn currently input a single spectral band or index at a time. While this may be sufficient for detecting typical changes in forests [29], in general the availability of multiple spectral bands represents a wealth of information that in many cases is already preprocessed and should be utilized. While rigorously adapting EWMACD/Edyn to a multiband input is outside the scope of the current study, we have already begun to do so.", 2. Materials and Methods, 2.4. Strengths and Limitations of EWMACD/Edyn,2
36,"We used a simplified classification of disturbance to compare both EWMACD and Edyn against the TimeSync reference dataset. In particular, we computed EWMACD and Edyn outputs for NDVI time series derived from each of the 3751 forested pixels, using the full time series in each case and using the same default parameters given in Table 1. Note that our choice of the control limit, L, is slightly higher than the conventional value of 


L
=
3


 [21]. We did this to better reflect the choice of parameters used in [14], as that study used similar reference data.We summarized the Edyn/EWMACD outputs to an annual time step using a simple mean value per year approach. We then reclassified the annualized outputs into −1 (removal/decline) for negative values or 0 (no change/growth) for nonnegative values. Accordingly, any year in which a negative signal was generated for a given date would be a year in which the signal value was automatically −1. Similarly, we reclassified TimeSync segments into −1 and 0 and converted the TimeSync trajectories to annual timesteps and assigned the status from the corresponding segment to each year. For example, the pixel shown in Figure 2 had “Harvest” for 1990, “Growth/Recovery” for 1991–2003, and “Fire” for 2004, based on the corresponding TimeSync segment designations. We also preserved a simplified listing of disturbance agents as designated by TimeSync: Fire (4.4% of all annualized disturbances), Harvest (39.8%, including mechanical clearing), Stress (33.8%), and Other (21.9%, including wind, debris, water, and other agents which could not be attributed to another cause).In general, disturbance of any type is a rare event [30]: across all forested TimeSync pixels and years, approximately 4% of the recorded values were disturbances, with 56% being no change and 40% being growth of some kind. This led us to use metrics which emphasize the algorithms’ ability to detect disturbances’ occurrence and timing within the general time series. In particular, we wanted to compare the overall disturbance record on a per-pixel basis, assessing whether the Edyn or EWMACD outputs successfully mimicked the TimeSync data in pattern as well as signal amounts. Thus, for each pixel we generated an error matrix for Edyn against the TimeSync data by treating each available year as a data point, then computed commission on disturbance (total false positive Edyn signals over all Edyn positive signals) and omission on disturbance (total false negative Edyn signals over all TimeSync positive signals). To assess general agreement between the time series, we also computed overall error (the false positive and false negative Edyn signals over all years). We performed the same process for EWMACD against TimeSync, generating in each case a collection of 3751 matched commission error, omission error, and overall error rates: one set per forested pixel.To illustrate the error-generation process, some example pixels are given in Figure 7. For the case of low omission and high commission (Figure 7a), the NDVI series begins a decline circa 1990, with a minimum circa 1992 followed by a rise through the remainder of the 1990s. Edyn signals the initial decrease in 1990, one year ahead of TimeSync, but it continues to signal the disturbance through 2000 because the recovering NDVI trajectory does not level off sufficiently until that time. This results in a high commission error (82%) and a 0% omission error (since TimeSync never signals disturbance when Edyn does not). The failure of Edyn to retrain sooner in this example suggests a persistence value that was too high to capture the dynamic; it is notable that this occurred in the pre-Landsat 7 era, when the data density was lower. In Figure 7b, the NDVI time series is relatively stable to visual inspection, with a slight decrease over 2000–2006. TimeSync signals the beginning of this decrease but not the end; Edyn signals the end (including 2007) but not the beginning, yielding a 100% commission error and a 100% omission error. In the case of Figure 7c, both Edyn and TimeSync signal a single-year disturbance in 2004 corresponding to a clear drop in the NDVI time series, resulting in 0% commission and 0% omission errors for Edyn. Finally, in the case of high omission and low commission (Figure 7d), the original training data from 1984 to 1986 are noisy. Due to its burn-in period, Edyn has no chance to signal the disturbance registered by TimeSync in those years but fits a curve around the stable portion of the data. However, the resultant high in-control SD dulls the algorithm’s sensitivity for the remainder of the time series, causing it to also miss the slight decreases to NDVI in 1996 and 2001–2002. These four examples, while by no means exhaustive, do illustrate possible causes of disagreement between Edyn and the TimeSync data and highlight the need for caution when interpreting the results.This approach to calculating error did not allow for timing disagreements; however, it was not uncommon to have pixels for which both Edyn and TimeSync were signaling the same disturbance but disagreed on the exact timing and duration. Figure 8 provides an example of this case: under the strict year-by-year method, the resultant 100% commission and omission error rates do not offer any numerical evidence that the two time series were clearly signaling the same basic disturbance in 1995–1996. As such disagreements could be explained by noting that Edyn could begin signaling at any date within the year (and thus a single-year signal could be stretched over two years, as seems to be the case in mid-1995 through mid-1996), we additionally generated a set of more flexible signal time series by allowing a potential one-year offset on signaled disturbances to improve matching. Using this rule, the signal time series in Figure 8 would be adjusted so that the TimeSync signal in 1995 would count as an agreed disturbance with Edyn by virtue of the Edyn signal in 1996, while the Edyn signal in 1997 would still count as commission error because there was no TimeSync signal recorded in 1996–1998. Similarly, the TimeSync signal in 2008 still generates an omission error for Edyn, as there were no Edyn signals in 2007–2009. Using these “blurred” time series, we computed per-pixel error matrices as before and generated collections of commission, omission, and overall error rates, noting that such error rates may be biased to smaller values by virtue of “double-counting” overlapped years of agreement.We made the error comparison for all 3751 forested pixels in the reference data, but we were also interested in particular subsets relating to Edyn’s ability to detect various types of disturbances. In particular, we assessed agreement for pixels which included at least one TimeSync disturbance (1620 pixels). We also partitioned this into the subset of forested pixels for which the disturbing agent was not stress (1408 pixels) as well as considering the case where the disturbing agent was stress (212 pixels), as Edyn and EWMACD are specifically designed to detect subtle, persistent changes.In all cases, we considered the distributions of the errors of commission and omission on disturbance, as well as overall error against the TimeSync data. To complement the commission, omission and overall error rates, we also computed the F1 score (or balanced F score):





F
1

=
2

(



p
r
e
c
i
s
i
o
n
×
r
e
c
a
l
l


p
r
e
c
i
s
i
o
n
+
r
e
c
a
l
l



)

,





(7)

where precision is the complement of commission error and recall is the complement of omission error. This score is a single-number summary of accuracy that treats omission and commission as being equally important. Finally, in each case we compared the error rates from Edyn and EWMACD using paired t-tests to assess whether the difference in algorithm performance was statistically significant. Results are presented separately for the no-offset and one-year temporal offset groups.", 2. Materials and Methods, 2.5. Agreement Assessment,2
37,"The main results of the agreement assessment are shown in Table 2. Differences in the mean error rates between Edyn and EWMACD were generally significant, with the only exceptions being the commission and overall error rates for the stress-only subset, most likely due to a small relative difference and a relatively small sample size.In general, Edyn had lower per-pixel rates of commission error than EWMACD, and in general Edyn had higher per-pixel rates of omission error. Since Edyn retrains the harmonic curves after a disturbance, it might reasonably be expected to have a lower commission error than EWMACD, as it will no longer signal “outdated” disturbances (as in Figure 1). Similarly, because it removes data to achieve retraining, it is reasonable to expect Edyn to also have a higher omission error rate, as years during such retraining are treated as non-disturbed. Edyn also exhibited lower overall error rates than EWMACD in every case (albeit less so for stressed forested pixels), which suggests that it is more faithfully mimicking the TimeSync data by virtue of its retraining. Allowing for a one-year offset in disturbance timing decreased the error rates in all cases and all subsets, but the overall pattern remained the same.Because disturbance-based error rates depend greatly on the number of disturbance signals in a given time series, we also considered the distribution of the error rates, in this case the commission on disturbance, omission on disturbance, and overall disagreement between the algorithm and TimeSync data. Figure 9 shows such distributions in the form of violin plots, in this case for disturbed forests pixels excluding stress and stressed forested pixels with no timing offset (Figure 9a,b) and the same when allowing a one-year timing offset (Figure 9c,d). From the figures it is clear that the commission and omission error rates are generally bimodally distributed, with distinct subsets of pixels for which there were either very high or very low error rates. Given that a commission (or omission) error of 100% can easily be achieved by mismatching a single year in an otherwise stable trajectory, the plots illustrate the importance of interpreting the error rates carefully. It is interesting to note that allowing the one-year offset reduced the non-stress commission and omission errors more than for the stressed forested pixels subset; this is most likely due to the acute nature of many such disturbances (e.g., harvest or fire) and justifies the use of the offset to compensate for algorithmic differences in disturbance timing. Finally, the overall error rate in each plot is generally clustered around small values, suggesting that per-time-series agreement between both Edyn and EWMACD, as compared to the TimeSync data, was relatively good.Since Edyn and EWMACD offer signals for both disturbance timing and severity, we also further analyzed the distribution of their disagreements with TimeSync by binning them into severity classes (Severe, Moderate, Subtle, No Signal and Growth) based on the observed relative magnitude of NDVI change (in signal thresholds) signaled by the algorithms (Table 3). We did this on an annualized basis, not on a per-pixel basis, so there was no offset to consider here. We found that for both algorithms, omission errors were higher in the Stress category than for all other types of disturbance, while the magnitudes for correctly signaled stress were generally in the Subtle category, both of which are to be expected given the low magnitude of change and general detection difficulty associated with stress [12,13,14,15]. However, EWMACD misclassifies almost twice as many stressed years as being growth years compared to Edyn (13.6% versus 7.8%), suggesting that the Edyn signals, when available, are generally better at detecting stress than the EWMACD signals. Importantly, when excluding the no-signal bin, Edyn had a general omission error rate of 19.2%, less than the omission error rate of 26.9% for EWMACD. While we did not explicitly filter out the exact years in which Edyn retrained, this reversal of the usual omission rate pattern in Table 2 strongly suggests that when these retraining periods are excluded, Edyn agrees with TimeSync more than EWMACD does.Based on the consistency of the results, we conclude that Edyn generally performed better than EWMACD in terms of overall agreement and lower commission error for forested pixels. EWMACD still outperformed Edyn in terms of omission error rates, but this appears to be largely a reflection of the opportunity costs of retraining the harmonic curves for Edyn. This cost may be compensated by the generally higher accuracy Edyn exhibited in detecting disturbances while not retraining.", 3. Results,None,3
38,"Several questions and caveats arise from the study presented here, some of which may prove fruitful avenues for future work. A brief discussion of these points follows.There are fundamental differences in the way TimeSync and Edyn handle spectral data. Most importantly, the analysts developing the TimeSync reference data utilized all spectral bands and numerous indices for the images. As currently designed, Edyn inputs one band or index. This increases processing speed but fails to take full advantage of all available data. For example, in Figure 7d we observed TimeSync signaling a disturbance where Edyn did not. Visual inspection of the NDVI time series offers only vague intuition that a disturbance has occurred, but further inspection of the short-wave infrared band time series revealed distinct vertices at the associated year. Without using these other bands there is no way for Edyn to detect this disturbance, short of training a curve so tightly that even the slightest deviation would trigger a signal. Thus, there is certainly incentive to develop a multi-band approach based on the assumptions underlying Edyn; EWMACD could similarly be modified.Conversely, we must note that while the TimeSync data were used here as a reference, they are also subject to error. Sun et al. [31] found that while mutual visual interpretation can produce consistent results among the interpreters, that in itself is no guarantee of accuracy. In general, the relative unavailability of ground truth data (which also contains errors, even discounting the differences due to top-down and bottom-up perspectives), particularly historical ground truth data, continues to impact the community’s ability to assess the accuracy of time series-based approaches. This can be alleviated for more recent historical periods as the era of big data and frequent measurements begins, but the issue will continue to remain a challenge for long-term studies.Another important potential issue arises from the nature of the data set and the persistence-per-year parameter, 



p

y
e
a
r




. In computing it as the mean number of data points (available images) per year for a given pixel, we are assuming a certain regularity in data frequency. However, the data frequency doubled in 1999 with the establishment of Landsat 7. Thus, Edyn/EWMACD may have treated the 1983–1999 period differently from the 1999–2012 period. We saw an example of this in Figure 7a. It is possible that establishing two persistence parameters, or dividing a 1999-present value by 2, could mitigate this if a user finds problems as a result of the divide.The error rates reported in the agreement assessment are generally lower than those reported in [14], which made a general comparison between seven change detection algorithms—CCDC [9], LandTrendr [7], ITRA [8], MIICA (Multi-Index Integrated Change Analysis) [32], VCT [6], VeRDET [11], and the then-current version of EWMACD—across a sample of 1800 pixels drawn from six Landsat scenes across the CONUS. There, EWMACD was seen to have commission and omission rates of approximately 80% and 70%, respectively. The difference lies in part in the methods for computing error. In [14], a generalized error matrix was created, summing all yearly agreements/disagreements over all pixels before computing the error rates. In this study, we summed yearly disagreements for each pixel independently and computed error on a per-pixel basis because we were also interested in the algorithms’ ability to mimic the overall time series patterns observed in the TimeSync data, including non-disturbance pattern and timing. Thus we also performed an agreement assessment using such a generalized error matrix, finding that for all forested pixels Edyn had commission and omission error rates of 86.1% and 77.0%, respectively, while EWMACD had error rates of 89.5% (commission) and 71.9% (omission) when using no offset allowance. When a one-year offset was allowed, Edyn had error rates of 72.0% commission and 57.6% omission, while EWMACD had 78.0% commission and 50.8% omission. This suggests again that a considerable number of omission errors were in actuality one-year timing disagreements between Edyn/EWMACD and TimeSync. In any case, the pattern of results—Edyn having fewer commission errors and better overall agreement with TimeSync while having more omission errors than EWMACD—remained the same. Finally, we also made a direct comparison with the algorithms in [14] by implementing Edyn and EWMACD using the same data and methods from that study, where possible using the same input parameters as were used for EWMACD there. Compared to the other algorithms, Edyn had the fourth lowest general commission rate and the fourth lowest general omission rate; EWMACD had the fifth lowest commission rate and the second lowest omission rate. Partitioning agreement by the disturbance agents used in [14] (Table 4), we found that for the subset of forested pixels in decline, both Edyn and EWMACD had lower rates of omission error than almost every other algorithm [14] (Table 3), with the exceptions of the previous version of EWMACD and LandTrendr. The discrepancy in EWMACD results can be explained by new parameters such as 



p

y
e
a
r




; LandTrendr had the advantage of being similar in nature to the TimeSync reference data with which it was being compared, as both rely on temporal segmentation of annual time series [7,23].A natural question that arises from this study is whether there is a condition or circumstance in which a user might prefer EWMACD over Edyn—or more generally, when an algorithm that uses a fixed reference might be preferable to one that updates such references. To answer this, we note that while Edyn had better overall agreement with TimeSync than EWMACD did, this agreement reflects the time series-based approach to error calculation. This in turn places assumed value on the algorithms’ ability to mirror the full time series, including time steps with no disturbance. Reconsidering Figure 1 and Figure 5, if the question of interest relied on comparing status between two points in time, EWMACD might be the more appropriate choice between the two because it maintains the initial baseline. A user could simply initialize EWMACD at the “before” time and run until the “after” time, as in [5]. In fact, based on the observed high omission error rates, using Edyn may cause the user to completely miss changes of interest if it happens to be retraining during the second timeframe.Ultimately, when discussing change detection and accuracy, one must be careful to precisely define what “change” is. Current state-of-the-art change detection algorithms are tested according to their creators’ and users’ needs, and a great many are specialized to particular use cases. These algorithms can often be used on general image stacks, but it is essential to understand their intended uses and keep their underlying assumptions in mind when doing so. For example, despite their generality in accepting input data, Edyn and EWMACD were designed for use on vegetated pixels assumed to exhibit some degree of harmonic variation throughout the year. The algorithms will yield results for other types of pixels, but those results may be unintuitive or easily misinterpreted.Given the sheer number of change detection algorithms available today, there is incentive and potential benefit to designing algorithms to fill certain niches, not only to help distinguish them for the end user but also to aid ensemble efforts that seek to leverage algorithm differences to improve results, as in [33,34]. As an example, while the high omission error rates for stress in the agreement assessment indicate ample remaining room for improvement, both Edyn and EWMACD returned lower omission error rates for decline than all but one other algorithm from [14] in direct comparison. Thus, while they by no means captured the subtle, persistent disturbances in the reference data as hoped for, they at least were relatively good at doing so among contemporary change detection algorithms.", 4. Discussion,None,4
39,"In this study we found that Edyn agreed better with the TimeSync reference data than EWMACD did, with a mean disagreement rate of 13.7% (Table 2) when considering a binary disturbance/non-disturbance case for disturbed forested pixels, compared to 19.9% for EWMACD. When allowing a one-year offset for timing discrepancies on this subset, Edyn had a mean overall disagreement rate of 8.2%, still smaller than 14.0% for EWMACD. We also found that Edyn generally yielded lower rates of commission error on disturbances, while it yielded higher rates of omission error.Edyn and EWMACD will continue to be freely available and open-source [19], and they will be usable for any remotely sensed time series with sufficient temporal data. The results of this study show that Edyn represents a small improvement over its parent algorithm, EWMACD, in terms of long-term subtle disturbance detection, though we note that the relatively small sample size of 212 pixels is insufficient to make a robust claim. Nevertheless, it is our hope that as end users continue to monitor the landscape for long-term changes, they now have an additional tool to utilize.", 5. Conclusions,None,5
40,"Wetlands play key roles in regional and global environments and are critically linked to major issues such as climate change, wildlife habitat health, and biodiversity. More specifically, wetlands play important roles in flood mitigation, water quality protection, and global carbon and methane cycles. In addition, nearly one-half of plant and animal species listed as endangered by the U.S. Fish and Wildlife Service are wetland dependent [1], and wetland loss is arguably the largest factor for the cause of global amphibian declines [2]. North American and global wetland losses are estimated to be on the order of 50% since the early 1700s [3,4]. The importance of the wetland conservation is well-established as a matter of national and international public policy. In this vein, accurately mapping and monitoring wetlands and their changes in a timely and repeatable manner are of utmost importance. Remotely sensed imagery provides researchers with a means to achieve these goals. In previous studies, maps of wetlands were created with some levels of success through medium resolution (10 –30 m), high resolution, and very high resolution remotely sensed imagery [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]. Some of the most widely used maps have been created by expert photo-interpreters using high spatial resolution imagery [1,10]. The main disadvantages to these maps are their limited coverage and their large time and resource demands. The turnaround times for these products can last years [1,11]. Wetland mapping using Landsat Thermatic Mapper (TM) imagery is common and considered a standard approach. It is found to have good class separation when one class dominated the classification area (>30 m2), but not when mixtures of wetlands types were of the same order as the sensor resolution [13]. Additionally, for these Landsat derived maps, accuracy levels varied between 30 and 82%, depending on the techniques used [13,14,15,16,17,18,19,20,21]. Generally, for all studies with finer class definitions, lower classification accuracies are observed, and in some cases, aggregation of similar wetland classes are necessary in order to produce a product with desirable accuracies [15,22]. For some studies, the classification process with TM imagery is aided through the incorporation of ancillary data such as elevation maps and field samples [13,18,22,23,24]. It should be noted that surface temperature, while a readily available Landsat product, is not commonly used in the classification of wetlands, mainly due to its relatively low spatial resolution. Due to its relatively low spatial resolution (compared with optical satellite imagery), surface temperature is utilized to differentiate surface cover types with a large difference in temperature, such as separating roads and buildings from vegetation. However, given the recent advances in machine learning, we contend that a smaller difference in surface temperature may be able to aid in the classification process of surface cover types. As a result, surface temperature was exploited in this study. Since many wetland species have overlapping spectral reflectance at peak biomass [25], researchers have employed multitemporal imagery in the classification process of TM imagery [13,15,17,26,27]. Other studies have approached this problem by incorporating Radio Detection and Ranging (RADAR) or Light Detection and Ranging (LiDAR) based measurements with Landsat TM imagery to aid in their classification methodologies. Resulting classification accuracies range from ~63% to 92%, again, depending on the methodologies and class definitions used [15,15,21,27,28,29,30,31].It is also worth noting that in many studies [15,16,17,21,27,28,29,30,31,32,33,34], there is relatively little justification for choice in features used in classification, with trial and error being a common approach. It is also still common practice to test all possible features or parameters in order to determine the most optimal set of inputs. This is not a desirable strategy as this is both crude and time consuming. Furthermore, the performances of machine learning algorithms depend strongly on inputs used for classification, which could explain, partially, why there is no clear consensus on their relative performance of different algorithms to one another. However, the use of a set of features that are significant among the land covers of concern undoubtedly aid in the pursuit of superior classification accuracy. This is especially important given that the advances in remote sensing technology make an enormous amount of data readily available. A key remaining challenge in land cover classification lies in how to extract the best or most relevant information from a huge amount of data in an efficient and logical way. Considering all of these factors, there is a strong need to determine which image features are best suited for identifying wetlands. Furthermore, quantifying the quality of these features can help provide a better understanding of how accuracy and error propagates through different types of analysis. In support of this, the purpose of this study was to investigate the significance of different combinations of features and feature types through various feature analysis and classification methodologies, with the intent of determining which features were the most significant in the classification process of wetlands for our study area, and which approaches are best suited in determining those features. This was accomplished through evaluating a wetland study area in Northern Ontario, using various statistical analysis and classification and imagery sources. Data inputs were primarily drawn from Landsat-5, RADARSAT-2, and Sentinel-1 imagery, with ancillary data such as digital elevation data, also being used. Feature analysis was conducted using Log-normal distance measurements and Random Forest predictor improvement values. The classification techniques investigated were Naïve Bayes, K-Nearest Neighbor (K-NN), Support Vector Machine (SVM), and Random Forest (RF). ", 1. Introduction,None,1.
41,"The study area, located at approximately 49°31′.34N, 80°43′37.04W, was chosen because of the availability of satellite and other geo-spatial data. Figure 1 illustrates the study area from a geographic perspective, and a Landsat-5 and aerial imagery perspective.Landsat-5, RADARSAT-2, and Sentinel-1 imagery were the primary image sources used in this study. The Landsat-5 series of sensors collect multispectral optical imagery with a spatial resolution of 30 m by 30 m and thermal imagery at 120 m by 120 m [35]. As a point to note, when creating layer stacks of these images for analysis, the lower resolution (120 m by 120 m) temperature-based images were resampled to 30 m by 30 m. The RADARSAT-2 imagery product used was a C-band, Wide Fine, SLC (Single Look Complex), quad-polarization image with a spatial resolution of 5.2 m by 7.7 m [36]. However, the features (such as entropy and alpha) derived from the original RADARSAT-2 imagery had a spatial resolution of 12.5 m by 12.5 m. The final step with preparing the RADARSAT-2 imagery was to resample it to 30 m by 30 m to match the resolution of the Landsat-5 imagery. For Sentinel-1 imagery (C-band), the product used was the duel-polarization imagery, and had a resolution of 5 m by 20 m [37]. As with the RADARSAT-2 imagery, the Sentinel-1 imagery was resampled to 30 m by 30 m in order to facilitate ease of analysis with the other imagery products. The final imagery product used in this study was the aerial imagery with four channels ((590–675 nm, 500–650 nm, 400–580 nm, 675–850 nm) and with a very high resolution (0.4 m by 0.4 m) [38]. It was used for closer examinations of training and validation sites as identified by Ministry of Natural Resources surveys of the area. Finally, a digital elevation map (DEM) of the study area taken from the Canadian Digital Surface Model [39] at the spatial resolution of 30 m by 30 m and an associated DEM derived slope were used. In total, five different Landsat-5 images, two different RADARSAT-2, and three Sentinel-1 images were collected. Table 1 summarizes the dates and types of imagery that were collected for this study.During covariance analysis of our datasets, it was discovered that inter-season Landsat-5 images were strongly correlated with one another. In an effort to promote better data independence, only a single Landsat-5 image for a particular season was chosen; the Landsat-5 image that produced the highest classification accuracy was selected. The selected Landsat-5 images for testing were Spring-1, Summer-2, and Fall-1, with the Summer-1 and Fall-1 images being selected from the Sentinel-1 images.Eight different land covers were classified in this study. These land covers were Open Fen, Treed Fen, Open Bog, Treed Bog, Dense Coniferous Forest, Swamps, Grassy Areas, and Cleared Areas. Open Fens are non-treed Grassy areas, with open pools of water. Fens are peat-covered sloping plains or channels with very high water tables and with surface carpets of brown mosses and associated Sphagnum. The average depth to the water table, even in a dry season, is usually less than 20 cm [40]. Treed Fens are fens, as described above, with dense shrubs and tamarack trees. In Northern Ontario, Treed Fens are usually dominated by Black Spruce (Picea mariana). Treed Fens occur generally throughout the province but most extensively in the Hudson Bay-James Bay Lowlands [40]. Bogs are peat-covered plains or peat-filled depressions with a high water table and a surface carpet of mosses dominated by Sphagnum. In flat or level Bogs, the water may remain at the surface throughout the spring and summer months. Open Bogs that may have a partial cover of stunted trees occur generally throughout the province of Ontario, Canada, but also exist very extensively in the Hudson Bay-James Bay area in Northern Ontario [40]. Treed Bogs are bogs with a low to high density of tree cover. It was expected for there to be some degree of overlap between densely Treed Bog and Sparse Conifer Forest. Treed Bogs are typically dominated by Black Spruce trees. Treed Bogs exist in many parts of the province of Ontario, Canada, but extensively in the Hudson Bay-James Bay Lowlands area in Northern Ontario [40]. Dense Coniferous Forests are large continuous forested areas, composed of at least 80 percent of coniferous species. Dense Coniferous Forest exists throughout the province of Ontario, Canada [40]. Coniferous and deciduous Swamps occur along rivers, and lakes and are characterized by a range of moisture conditions and plant species such as cattails, grasses, and shrubs. The Swamps in Northern Ontario can also have a sparse presence of trees, both coniferous and deciduous [40]. Grassy areas are flat open areas covered almost entirely of grass, colloquially known as meadows or fields. Some of these areas are older cleared areas that are regenerated and are almost entirely covered by tall grasses [41]. Cleared areas are forested areas that are harvested, and are undergoing regeneration. Characterized by very young trees, open areas, low to medium height grasses, shrubs, and bare soil. These areas are generally dry and the soil is of poor nutrient content [41].", 2. Study Area and Data Used,None,2
42,"Training and evaluation areas were identified using ground survey data collected during the summers of 2011–2014 by the Ministry of Natural Resources in support of forest inventory resource management [38] and aerial imagery also collected for the Ministry of Natural Resources, as part of its internal inventory and records. Oftentimes, areas were cross referenced with one another for added verification. For the ground survey data, survey areas were defined by 100–200 m square areas where generally 3–4 GPS points are taken to define the extents of those areas. Surveying of those areas followed the Ontario Forest Resource Inventory Calibration Plot Specifications guide [38]. Table 2 summarizes the sizes of the training areas (in pixels), and their corresponding evaluation sets. The evaluation and training were sets taken from separate areas to eliminate spatial correlation, which was observed in initial testing, illustrated in Figure 2.The number of pixels for each study area was determined by the size of land cover plots identified through the ground survey data. We attempted to have approximately 60% of the identified pixels be part of the training set, with the remaining 40% be part of the validation set. Based on the boundaries of these land cover plots, a set of contiguous pixels were selected for that individual land cover.", 3. Methodology, 3.1. Defining Training and Evaluation Areas,3
43,"For this study, six different image indices or metrics were used: NDVI (The Normalized Difference Vegetation Index), NDWI (The Normalized Difference Water Index), Albedo, Surface Temperature, Alpha, and Entropy. These image metrics were selected due to the fact that they are all popularly used metrics in the analysis of multi-spectral and radar imagery, with the addition of Surface Temperature due to our intuition that it might prove to be useful when incorporated into the correct classification strategy. Additionally, the DEM, and DEM derived slope were also incorporated into the classification of imagery. DEM and DEM derived slope were selected to determine the role geographic features play in the classification process. For instance, it is known that some species of Fens prefer to grow in slopes. All Landsat-5 imagery used was Level 1G, which are both radiometrically and geometrically corrected. NDVI, NDWI, Albedo, and Surface Temperature were calculated using Landsat-5 based imagery, which, through its multispectral measurements, provides a spectral representation of a surface, for multiple wavelength ranges.NDVI is a popular vegetation index sensitive to leaf area index, coverage, and pigment content of vegetation canopies vegetative activity photoactivity [42,43]. NDVI is defined as:



NDVI
=



ρ

N
I
R


−

ρ

r
e
d





ρ

N
I
R


+

ρ

R
E
D








(1)


where 


ρ

N
I
R



 and 


ρ

R
E
D



 are the reflectances in the near infrared and red band, respectively. NDWI works on a similar principle to NDVI, but is designed to be sensitive to water content rather than to photosynthetic activity. NDWI is defined as:



NDWI
=



ρ

G
R
E
E
N


−

ρ

M
I
R





ρ

G
R
E
E
N


+

ρ

M
I
R








(2)


where 


ρ

G
R
E
E
N



 and 


ρ

M
I
R



 are the reflectance in the green and middle infrared band (MIR), respectively. In his paper describing NDWI, [44] mentions that the green and MIR bands are located in the high reflectance plateau of vegetation canopies; the absorption by vegetation liquid water near the green band is negligible, but weak liquid absorption at MIR is present. Canopy scattering enhances the water absorption and as a result NDWI is sensitive to changes in liquid water content of vegetation canopies. Gao [44] also argues that the effect of atmospheric aerosol scatter effects in the MIR region are weak; NDWI is less sensitive to atmospheric-optical depth compared with NDVI. Due to its success in many applications, NDWI is a standard layer product for the Moderate Resolution Imaging Spectroradiometer (MODIS) sensor [45].Surface albedo is a measure of reflectivity from a surface, which takes on a value from 0 (absorption) to 1 (complete reflectance). A standard approach in determining the surface albedo using Landsat-5 imagery is through a numerically determined relationship described by Liang et al. [46,47]. Liang describes albedo 
α
 using Landsat-5 TM imagery through the following equation:



α
=
0.356

α
1

+
0.130

α
3

+
0.373

α
4

+
0.085

α
5

+
0.072

α
7

−
0.0018




(3)


where in (3) the subscript on each α represents a band number in a Landsat-5 TM image. Note that band 6 and the panchromatic band are not present in (3).The first step in determining the surface temperature for an individual pixel from the Landsat-5 imagery was to calculate the surface radiance from Band 6 (Thermal Infrared). The following equation was used to convert the digital number (DN) of Band 6 into spectral radiance [35]: 




L
λ

=
0.0370588
 
×
D
N
+
3.2




(4)

The next step was to convert the spectral radiance to the brightness temperature (i.e., blackbody temperature) under the assumption of uniform emissivity as shown in (5) [35]:




T
B

=



K
2



l
n

(




K
1



C

V

R
2




+
1

)







(5)


where 


T
B


T_B is the blackbody temperature in kelvin, 

C

V

R
2



 is the radiance 


(

W

m

−
2


s

r

−
1


u

m

−
1



)

 

at
 
the
 
surface


; and K1 = 607.76

 
W

m

−
2


s

r

−
1


u

m

−
1



 and K2 = 1260.56 K, which are numerically determined constants [35].During initial examinations of the test imagery, it was noted that surface temperature when plotted against NDVI via a scatter plot, produced several well-defined clusters. These clusters could then be used to quickly classify the source image into two separate classes (Figure 3). This helped motivate the exploration of the role that temperature could play in the wetland classification process. Surface temperature is generally not used in the classification of land covers due to its low resolution. However, we contend that with advanced classification methodologies and the needs of specific land cover types, such as wetlands, surface temperature could play a role in improving classification accuracies for this application.Alpha and Entropy were calculated from RADARSAT-2 imagery. The RADARSAT-2 imagery used in the study was the Level 1-Single Look Complex (SLC) imagery product. For the RADARSAT-2 images, the Alpha and Entropy values were determined through the European Space Agency software called PolSARpro v4.0 [48]. PolSARPro also provided the means to initially process the raw RADARSAT-2 images into georeferenced images which could be inputted into other software suites such as ENVI 5.0 [49] and Matlab r2016b [50]. Given a quad polarized radar image, the backscattered and polarized signal can be decomposed into roll invariant parameters. Two of which are used frequently in the analysis of RADAR imagery, and are used in the analysis of the RADARSAT-2 imagery here are Alpha (


α
¯

)

) and Entropy (H). 

α
¯

 is a measure of the reflected angle of the radar signal, which physically is determined by the angle of incident, surface roughness, and dielectric constant of the reflecting surface [51]. From a physical standpoint, Entropy can be thought of as a measure of the degree of disorder from the measured reflected quad-polarization radar signal [51]. From a physical standpoint, 

α
¯

 provides the nature or the type of dominate scattering mechanism for a given scatter [51,52]. The scattering nature of a given target can vary among three different categories: isotropic odd bounce (


α
¯

 

= 0°), dipole or volume bounce (α = 45°), or isotropic even bounce (α = 90°) [51]. Figure 4 illustrates a physical interpretation of the alpha scattering mechanism. Scattering from a flat surface will result in α ≃ 0°, scattering from a surface dominated by random scattering medium with cylindrical geometry (such as branches or needles) will result in α ≃ 45°, surfaces which result in double or ‘even’ bounce scattering events, such as those provided by isolated dielectric and metallic dihedral scatters result in α values closer to 90°.For the Sentinel-1 imagery, it was put through a similar georeferencing process as the RADARSAT-2 imagery. In total, each land cover had a data set corresponding to 48 individual layers, with each layer representing a unique feature: either a spectral band value, an image metric, radar metric or value, digital elevation point, or a slope derived from the digital elevation. These individual features are summarized in Table 3. This parsed data will be known as the Master Data Set from hereon.", 3. Methodology, 3.2. Image Preprocessing and Feature Selection,3
44,"The objective of feature significance analysis was to quantify the statistical differences and similarities between land covers for a given feature. The intent of doing this analysis was to aid in determining which features and feature combinations would be desirable when classifying our selected land covers. To accomplish this, two strategies were used. They were the log-normal distance and RF predictor importance value. The log-normal distance is a purely statistically determined value, while the predictor importance value is determined through an iterative exploration of the dataset with an RF classification scheme. By using these two different approaches, it provides us with contrasting statistical perspectives on our dataset and features, which in turn should affect classification results. The first strategy, given a single feature with multiple land covers, was to measure the log-normal distance between land covers for that feature [53]. The log-normal distance, in this case, measures the statistical similarity between two sets of data for a given measure where larger values imply dissimilarity between sets, when compared to smaller values. This is defined by:




D

L
N



(

p
,
q

)

=

1
4

l
n

(


1
4


(




σ
p
2




σ
q
2



+



σ
q
2




σ
p
2



+
2

)


)

+

1
4


(






(


μ
p

−

μ
q


)


2




σ
p
2

+

σ
q
2




)





(6)


where 


D

L
N



 is the log-normal distance between the two classes, 


σ
p
2


 is the variance of the p-th distribution, 


μ
p


 is the mean of the p-th distribution and p, q are two different class distributions. As an example, given two land covers, measured by features A, and B, if the log-normal distance between land covers as measured by A was larger than B, it would imply that A is of a higher quality, compared to B. In other words, A would be a better feature to classify those land covers from one another. Given the eight land covers classified in this study, this corresponded to 28 unique combinations of land cover pairs to have their log-normal distance calculated for a given input feature. When those results were averaged together, an overall quality factor was produced for that feature. This strategy was executed on all input features.The second strategy was based on the performance of features when utilized in an RF classification scheme. During the classification process with RF, a predictor importance value can be calculated for each feature input, for that given classification scheme. The predictor importance value was computed by summing changes in MSE due to splits on every predictor and dividing the sum by the number of branch nodes for that tree, averaged over all trees. These calculations are done on all input features, with larger values implying a feature is more important based on its impact on changes to the mean squared error. The objective here is to estimate a single features importance compared to the rest of the input features, using this metric. To accomplish this we ran a series of 48 classification tests where, for each test, a given feature was excluded for that test. In that way, for a given feature, when averaged over its 47 tests, a metric for how important that feature was when compared to its peers can be computed. The use of predictor importance with the RF classification methodology is a standard approach to evaluate the performance of individual input from a classification result. ", 3. Methodology, 3.3. Feature Significance Analysis,3
45,"The core of this project was the analysis of the master data set utilizing advanced data regression and classification techniques. These techniques have been applied and adapted to multiple fields such as remote sensing, finance, and spam filtering. For our purposes, we trained a classifier using data drawn from our study area, for a given set of features, which then classified a separate set of data, again drawn from the study area, using the same set of features, and then evaluated that classification result and based its producer accuracy and kappa value, which provides an assessment of the resulting accuracy when compared to chance. A higher kappa value implies a higher quality result. For this project, four popular techniques were selected. They are Naïve Bayes, K-NN, SVM, and RF. These techniques are described in more detail below.The Naïve Bayes classifier assigns observations to the most probable class by estimating the probability densities of the training classes. Classification of an observation is completed by estimating the probability for each class, and then assigning the observation to the class yielding the maximum posterior probability. Unless a probability threshold is incorporated, all inputs are classified [54].The K-NN classification algorithm operates by finding a group of k objects in a training set that are closest, in feature space, to a provided test object, and bases the assignment of a classification label on the predominance of a particular class in this neighborhood [54,55]. To classify an unlabeled object, the distance, in feature space, of this object to each labeled object is computed. The K nearest neighbors of the unlabeled object are identified and the class labels of these K nearest neighbors are then used to predict the class label of the object. SVM is a binary classification methodology that separates classes by fitting a hyperplane between two sets of data. The optimization of this fitting is determined by “maximum-margin hyperplane” that divides a group of points such that each point distance from the hyperplane is maximized [56,57]. Even though this methodology is binary in nature, it can be used in to classify multiple classes through an adoption of a one versus one (OvO) classification strategy. We adopted this strategy in this study. In an SVM-OvO classification strategy, n classes are parsed into n(n-1)/2 binary classifiers—essentially an ensemble classification method. The RF classifier is an ensemble learning method and operates by constructing a multitude of decision trees with the ultimate class of a given input determined by the mode of the classes from those decision trees [58,59,60]. With RF, the diversity of the decision trees is accomplished by making them grow from different training data subsets created through bagging or bootstrap aggregating [58]. RF lends itself well to parallelization and investigating the nuances of large datasets. As a result, RF has become one of the most successful and widely implemented data mining methodologies to date [59,61]. For this reason, it was chosen as the main classification methodology for this project. Finally, the two main input parameters needed to run the RF classifier were the number of trees and the depth or complexity of those trees. Choosing too few trees results in lower accuracies, while choosing too many trees results in no accuracy gain for extra computations. Additionally, choosing a tree depth that is too shallow tends to produce trees that underfit, while choosing trees that are too deep will overfit the data. In order to determine the right settings for our data, we utilized a built-in Matlab function that will optimize these features given an RF input, as a function. From these experiments, we determined to choose 150 trees to “grow” and have a p-value of 0.05 as the minimum value for the curvature test, which is utilized with the RF classifier to determine when to terminate a split. Using this type of technique to determine RF input parameters is considered to be a standard approach [60]. The training data was analyzed and classified using the previously mentioned classification schemes using the feature inputs listed in Supplementary Materials. These features inputs were determined and assembled through a number of different methods. The first method was to select groups of feature inputs with a “holistic” approach. This involved selecting groups of features based on similarities or contrast in type (bands or metrics), similarities or contrasts in time (the same or different seasons) and combinations thereof. Additionally, combinations of features were selected from a physical or structural standpoint in order to take into account seasonal variability in vegetation and structural differences in land covers which could be parsed by the classification schemes through the incorporation of features like Radar and DEM derived values. Using this holistic approach, 180 different sets of input features were created. The next set of input features was selected by examining the results from the feature significance analysis. Based on the overall ranking of those features, the top 10 to 90 percent of features were selected, in 10 percent increments as feature inputs. Additionally a hybrid combination of the top 10 to 60 percent of features were selected based on selecting a combination of surface reflectances from bands, image indices, Radar, and DEM derived features, in order to emulate the holistic approach but with a more quantitative background. In order to execute this, for instance, for the top 10 percent of features with the hybrid approach, the top three surface reflectances from bands, the top image indices and the top Radar or DEM or DEM Slope features was selected, for a total of 5 or 10 percent of available features. This approach was repeated until we had created six different hybrid combinations reflecting the top 10 to 60 percent of features. Finally, the bottom ranked 25 percent of features were grouped together from the bottom 16 to the bottom four features in two feature, decreasing, increments in order to examine the performance of those features, when used in combination. The aforementioned feature selection strategies were executed for both the Log-normal distance and RF determined feature importance values. In total, 225 unique tests were devised. ", 3. Methodology, 3.4. Classification and Feature Selection,3
46,"Once the features were selected based on the training data sets, they were used in the classification for the test set drawn from our study area for visualization purposes and to explore the functionality of the classifier. Given that RF classifies an unknown pixel via a majority voting criteria, in addition to the class category, a confidence value was also calculated for each pixel. The confidence value represented the percentage of the votes the chosen class represented with a higher value representing a higher confidence for result. ", 3. Methodology, 3.5. Classification and Evaluation,3
47,"Given a feature and eight land cover classes, 28 unique combinations of land cover pairs were created with an associated log-normal distance. By averaging these results together, an average log-normal distance for that feature was obtained. A larger value implied that feature could play a more significant role in the classification of those land covers compared with features which had lower log-normal values. Additionally, given the 48 features and eight land cover classes, using the RF computed predictor importance values, executed with the strategy described in Section 3.3, the importance of a given feature could be determined. Like the log-normal values, larger importance values implied that a given feature was more valuable in the classification process, and when utilized, would produce more accurate results. The results of the feature importance computations are summarized in Table 4. From the results in Table 4, it is noted that the features calculated from multispectral imagery, on average, were of the highest quality and importance, with traditional metrics such as NDVI performing well, when measured by both the log-normal and RF determined predictor importance values. In addition, the features calculated from data acquired in the spring and summer, was of a higher quality compared to the fall according to the log-normal results. However, according to the RF determined predictor importance values, there was no clear preference among the data acquired in different seasons; the metrics associated with fall, summer, and spring all ranked highly. It is also noted that surface temperature, traditionally a feature not associated with wetland land cover classification, was ranked fairly high by both feature analysis methodologies. These results also implied that the collected surface temperature data, despite its low resolution, was of a high enough quality that it could be useful for land cover classification. This was an unexpected result but also was in line with some of our early classification experiments, which showed that temperature could be useful in some circumstances. Finally, the features derived from Radar data and DEM were of a significantly lower quality compared with those derived from optical and thermal data based on the log-normal method. Similar results were obtained using the RF method. However, the difference (in magnitude) was not as large. Among the features from the Radar data and DEM, several of them, namely, DEM, slope, the entropy in the fall season, and the alpha in the summer season, were ranked similar by both methods.", 4. Results, 4.1. Feature Significance,4
48,"The classification results from the four classification methods and the 225 feature tests were computed on a desktop computer equipped with an AMD Ryzen 5 26000 Six-Core Processor with 32 gigabytes of RAM, analyzed, and ranked. From these 225 tests, the top 20 and bottom 20 results were extracted, and overall statistics for these tests, for each classification technique was calculated. These results are presented and summarized in Table 5 and the table in Supplementary Materials.From Table 5, RF on average produced the most accurate results given all inputs scenarios, followed by SVM, K-NN and Naïve Bayes. It is also worth noting that the highest ranked test, one produced by RF was some 7 percent higher than its closest rival. Additionally, average Kappa values are consistent and are of a magnitude which imply that classification results are of a good agreement between producer and user accuracy. According to the results in Supplementary Materials, the effects of input features on the classification accuracies varied among classification techniques and there were no clear set of metrics which consistently outperformed others. However, for individual classification techniques, it would appear that there was a performance preference for certain feature inputs. Parsing this further, we can generalize for each classification methodology the preferred input features which produced the highest classification results. These results are summarized in Table 6.A common theme from Supplementary Materials and Table 6 was a preference for incorporating all seasons, surface temperature, and radar-based images into the analysis for the best performing classification methodologies (RF and SVM). Table 6 also shows that for all classification methodologies image reflectance data from all seasons, used in combination, is a high performer. Furthermore, among the image metrics, NDVI performs well, for three of the four classifiers. It is also noteworthy that NDWI only performed well with one classifier and surface albedo was not found to be a significant feature. It is also noted that there was a correlation between the number of features and the overall classification accuracy. More features generally resulted in higher classification accuracy; however, the highest ranked tests for all classification methodologies did not contain the most features. Additionally, one may note some other interesting peculiarities with the results presented in Supplementary Materials and Table 6. An expected result was to see that feature inputs, selected due to their high quality or importance, would result in higher classification accuracies compared to results from inputs selected by a holistic approach. However, this was found to not always be true. With the exception of the K-NN Classifier, of remaining classifiers, the vast majority top ranked tests were tests determined through a holistic approach. This is counter intuitive, and expanded on further in the discussion section. For the bottom ranks results, we summarize the common features and themes in Table 7.From Table 7, it is noted that the worst performing results were from image metrics taken from falls scenes. This was common among all classification methodologies and classification structures. This was not unexpected given that during the fall scenes vegetation activity and temperature variations would be at a minimum, making it difficult to discern one land cover from another. Additionally, it is noted that the classification tests with the poorest accuracy were all tests from the worst performing features as measured from our feature analysis. In fact, the lowest quality or the least important feature combinations were consistently in the bottom 30 percent of all tests—the expected result. However, it was noted that for the K-NN tests the bottom 50 percent of tests were all tests determined through feature analysis, rather than the holistic approach, which was not always true for the other classification methodologies.Regarding the best overall classification performance, the RF classification methodology using image bands, radar, slope, and surface temperature from multiple seasons, produced the best classification result (87.51%). Intuitively this was in line with the operation of the RF classifier which exceled when using large datasets, and when provided with similar inputs, RF generally outperformed other classification methodologies. However, it is worth mentioning that the OvO application of SVM produced results which also outperformed the other classification methodologies by a margin between 3-6% for averaged results. We explore these results further in the discussion section.Additionally, to better examine our best performing classification result we present its corresponding confusion matrix in Table 8.When examining Table 8, we note that Cleared Areas and Open Fens have the biggest discrepancy. In fact, its producer accuracy is 58.2%. If this result could be improved to be more comparable with the other classification results, it could produce an even stronger classification result. Additionally, as a comparison, we examine the confusion matrix of the worst performing result in Table 9.When examining Table 9, we can immediately see the contrast in classified results compared to Table 8. For all land covers, there is a great deal of misclassification, with some results producing an almost even distribution across all land covers (no better than guesswork). We note that the best classified land covers are Swamps, with a producer classification accuracy of ~60%. The worst performing land cover (Treed Fen) has a producer accuracy of ~8.7%. We also note that five of the land covers have a producer accuracy below 30% As a final examination of the classification results, we examined the average rank of a given test input averaged over the four classification methodologies. The objective was to determine a given classification inputs overall performance across all of the given classification methodologies. We also calculated the standard deviation for that given classification test across the different classification methodologies, in order to gain a sense of the spread of the distribution of those classification ranking results. A scatter plot of these results is presented in Figure 5.Given that the highest ranking a test could achieve would be 1 and the lowest ranking a test could achieve would be 225 (the total number of tests conducted), we can interpret Figure 5 by noting that the highest quality results would be at the origin and the lowest quality results would be further down the x-axis and up the y-axis. When examining Figure 5, we note that results with the highest accuracy had lower spreads compared to results which were of lower quality; however, results of the lowest quality had similarly tight spreads with their distributions. These results imply that tests which produced the highest accuracies would tend to be similarly accurate across classification strategies, and alternatively, classification tests which were of lower accuracy would be of similarly lower accuracy across different classification strategies. Moreover, for tests that were of average accuracy, have large variations in accuracies across classification methods. Finally, according to Figure 5 feature inputs selected by their performance from feature significance analysis were generally of a higher accuracy and lower deviation when compared to results selected by a holistic approach, and alternatively, feature inputs indicated to be of lower quality and significance produce consistently lower accuracy results across all classification strategies.As a test to explore the functionality of a classification scheme produced from this study, the most accurate classification scheme, produced through an RF classifier (test #77), was adapted to classify a test area from our study area. This test area was chosen such that it did not contain any data drawn from the training or validation data and appeared to contain wetlands of varying types (identified through visual interpretation). The classification inputs were image bands, Temp, Radar (Alpha), and slope from all seasons, with open water, such as rivers, lakes, etc. masked out of the test image. Figure 6 contains three images, which are typical of the output from this classification scheme. Figure 6A), is a true color Landsat-5 image of a test area, Figure 6B) is the actual classification result. Figure 6C) is a ‘confidence map’ of the classification result, where 0 indicates low confidence and 1 high confidence. When examining Figure 6C) it should be noted that cleared areas, roads, shrubs and grass, were of low confidence, while wet areas or dense wooded areas were of high confidence.", 4. Results, 4.2. Classification,4
49,"From the feature importance analysis, we generally found that features which were ranked highly from this analysis correlated to higher ranked classification results. However, we noted that this performance varied among classifiers. The K-NN classifier benefited the most from selecting input features from feature analysis—more than half of the top 20 ranked classification results were all from tests derived from feature analysis. Alternatively, most of the worst ranked tests as produced from the K-NN classifier were from the lowest ranked features. Delving further into these results, we note that K-NN operates by finding a group of k-objects that were closest to a provided test object—in essence, its distance in some defined feature space. In that way, this algorithm would both benefit and be disadvantaged more by numerical similarities or differences in its inputs, compared to the other classification methodologies used, which, arguably, use a more gross statistical examination of the datasets or negates these issues through a more thorough examination of the datasets.RF, the closest to K-NN’s from a mathematical and algorithmic standpoint, had only three out of 20 of its top ranked tests coming from tests created from selected inputs from feature analysis, as opposed to 11 for K-NN. However, we do note that for the top 25 percent of tests classified by RF close to half of these tests were tests determined by feature selection analysis. This implies that while the highest ranked tests for RF might be selected through a holistic methodology, overall, selecting inputs from feature analysis is beneficial but not as beneficial when compared to the K-NN classifier. We reason that these differences could be accounted for by several factors which broadly differentiate how RF classifies a dataset from K-NN. Given that the log-normal feature analysis methodology provides a somewhat gross statistical interpretation of the inputs, and assumes that the data is not bi-modally distributed, it would not explore these subsets within the data, if present, which could otherwise be helpful in the classification process when inputted into an RF classifier. Furthermore, even with the RF determined feature importance values, this style of analysis, while it utilized the RF classifier, our implementation of it still provided a somewhat gross perspective on the performance of these features. It means that the higher performance of a given feature when used in conjunction with other features was not examined from our testing. This could explain why, for RF, the highest accuracy tests were holistically determined tests rather than tests determined through feature analysis. However, the top quartile of tests were still highly represented by tests determined through feature analysis, implying that feature selection, overall, did provide value in the selection of sets of features for an RF based classifier, but in this context also did not provide the most accurate results. Furthermore, like the K-NN classifier, for the RF classifier, the poorest quality or least significant features all performed poorly, as expected. For the SVM produced results, we note that out of the top 20 tests, only one was from features selected through feature significance analysis. This test was a hybrid test of the top 20 features and was 5 percent less accurate than the top result. However, we also note that for the top-quartile of tests some 26% of those tests were represented by tests selected by feature significance analysis, implying that tests determined by feature significance analysis could produce higher quality results for SVM. Additionally, we note that the tests created through the selection of features via RF feature importance produced, overall, better results compared to results determined by Log-normal distance analysis. This is an unexpected result, given that SVM operates by fitting a hyper-plane between inputs. By this measure, inputs which were further statistically separated should be of more significance, and thus higher accuracy. We speculate that the higher sensitivity to RF importance determined inputs was related to the fact that the SVM was executed via an OvO approach. In this way, the SVM classifier was being executed in an ensemble fashion, not unlike the RF classifier, where it was likely that some of the ‘trees’ being grown in the RF classifier would be very similar to the ensemble results produced by the SVM. In other words, features and feature combinations which were significant to RF would also be significant to execution of SVM. From the Naive-Bayes classification results, we note that from the top 20 ranked feature tests only three were from tests derived by feature significance analysis. Examining these results further, we note that the distribution of feature analysis derived tests were more even compared to the other three classification methodologies with higher quality or significant feature tests ranked in the top half of tests and lower quality or less significant feature tests ranked in the bottom half of tests. Given that Naïve-Bayes classifies through a Gaussian based probabilistic methodology, it would be expected that feature combinations determined through Log-normal analysis would produce the most accurate results, which was not the case. However, we note that the difference between the top ranked classification result and the 25th percentile test was only ~5 percent, and the difference between the top ranked result and the bottom 50th percentile result was only ~9 percent. This implies that the Naïve-Bayes results were closer in distribution and less sensitive to feature inputs but still benefited from the application of feature analysis, just not as dramatically as the other classification methodologies. When examining all of these classification results from a more gross perspective in the form of Figure 5, we note that feature analysis both aided in determining which features can benefit and can be detrimental to classification. When examining both ends of the scatter plot, we note that it trends towards a decrease in distribution of standard deviation. This implies that for high and low ranked tests, the features used in those tests, generally perform the same across all classification methodologies. Further to that, feature combinations that were predicted to do poorly, did perform poorly across all classification methodologies. Furthermore, feature combinations that were predicted to perform well generally produced higher accuracies, with consistency across all classification methodologies. It is also worth noting that high quality and low-quality feature selections were all ranked in either the top half or bottom half of the distribution, respectively, which implies that our selection methodology is working as designed. Finally, feature combinations that produce mediocre classification results also had large variability between classification methods, which implies that this style of analysis and selection does not have the same level of impact on average results compared to high or low performing results. As an overall take-away from Figure 5, we assert that feature significance analysis could aid in identifying which features can both aid and be detrimental to classification, with the identification of lower quality features and feature combinations showing the strongest relationship across all classification methodologies. Exploring the most successful features in more detail, we note that the addition of surface temperature, RADAR features, and DEM derived attributes, to the features derived from optical images, overall, increased classification accuracy. The most accurate classification results were generated from using optical data from more than one season and the addition of surface temperature and RADAR features. For individual seasons, classification using the data from the spring and summer season generally outperformed that using the fall season. When considering only individual seasons, classification using the data from the spring season usually produced better classification results than the summer and fall season. We speculate that this was due in part to the increase in vegetative driven spectral overlap seen during the summer months, and the slowing and decay of vegetative activity during the fall. It should also be noted that the 2010 spring season, for the study area, was abnormally warm. Temperature records from the area indicated that the air temperature for that particular image, at collection time, was over 300 K, 5-8 degrees higher than historical seasonal averages [62] and the recorded surface temperatures, in some cases, was well over 300 K, about 8-10 degrees warmer than temperatures recorded from the 2009 Landsat-5 image from a similar time of the year. We speculate that these higher temperatures and the incomplete seasonal growth aided in classification by further separating class differences for the spring scene. To explore the temperature results further, we produce Figure 7. From Figure 7 for the spring scene, we note that Grassy and Cleared areas had some of the lowest temperatures recorded, which was counter intuitive. The expected result would be that Grassy and Cleared areas would be higher in temperature compared to wetlands due to lower moisture content, and thermal inertia. However, if we consider that the vegetation was still developing and the land was still warming from the winter months, this could account for some of these observed differences in the distributions of land cover temperature. Furthermore, for the summer season we noted that temperatures for coniferous forests and Swamps had the lowest temperatures. For coniferous forests, the lower temperature could be attributed to the evapotranspiration effect produced in the needles of trees and leaves of other vegetation in that area. Similarly, Swamps, would have an equally profound evapotranspiration effect from their aquatic plant life, and the very high water content of the land cover which would cause the areas to be naturally cooler than dry land. Grassy and cleared areas measured the highest temperatures. These higher temperatures could be contributed by the relatively low water content compared to the aforementioned land covers, which resulted in lower evapotranspiration, and thermal inertia. The lower evapotranspiration produced lower latent cooling of the surface and the lower thermal inertia resulted in the land cover warming more quickly compared to the relatively moister wetland land covers. Fen and bog land covers were ranked in the mid-range of summer temperatures, which might be driven by the relatively higher water content compared to the Grassy and Cleared areas which resulted in higher thermal inertia and slower heating and lower comparable temperatures.Overall, despite its low resolution, temperature showed itself to be a feature which could be used to increase classification accuracy when used in conjunction with other features, with temperature based class differences found to be both physical and logical.Regarding the addition of Radar features to the classification process, addition of RADARSAT-2, and/or Sentinel-1 imagery to Landsat-5 imagery was shown to improve overall classification accuracies by 2-6%, when compared to an input lacking those measurements, when using an RF classifier. Furthermore, using a combination of different seasons and features produced the higher accuracies across all classification methodologies and schemes. For instance, given only the spring Landsat-5 data, when classified in an RF classifier, produced an accuracy of ~72%. When spring data was used in conduction with data from the summer and fall, in an RF classifier, the classification accuracy jumped ~81%—a 9% increase. Examining these results from a more physical standpoint, it was noted that since the intensity and scatter of the Radar signal is dependent on structural features of the measured surface, treed areas would have different scattering profiles compared to wetland types which do not have large and tall vegetative structures. The addition of these measurements would enhance the depth of the input dataset and thus the overall accuracy of the classification result. Moreover, it was found that DEM and DEM derived slope were significant features in the separation of wetlands from non-wetland classes. We speculate that this was driven by the fact that wetlands were generally flatter, due to the collection of water, when compared to other land cover types where terrain could vary significantly. Examining the classification results from an overall perspective, we would like to note that during preliminary testing, training and validation sites were chosen randomly, from a pixel standpoint, from a base set and it was found that classification accuracies were, in some cases, over 98 percent as produced from some RF Classification tests. It was suspected that this extremely high accuracy was caused by the random sampling masking spatially driven differences from the training and evaluation sets, in effect the methodology was “over fitting” the dataset. This phenomenon of overfitting is a common and well known within the data science field. Furthermore, we suspect that this phenomenon was responsible for the very high classification accuracies presented in some papers utilizing these styles of algorithms to classify remotely-sensed imagery [21,63,64]. With classification methodologies such as RF, the training sets are “learned” thoroughly. If the training and validation sets both have similar spatial representation, it is possible to achieve very high accuracies which may not necessarily be representative of true accuracies if given inputs from similar but spatially different areas. This has motivated us to use spatially separated training and evaluation data sets, which has reduced the overall accuracy of our results, but we believe is now producing results which are more representative of results which would be produced when these classifiers are applied to other study areas—the ultimate goal of this research. However, it should be noted that results produced by Naïve Bayes were not significantly affected by these spatial correlations. This represents how Naïve Bayes uses a more gross statistical representation of the training data compared to RF, SVM–OvO, and K-NN methods.From an overall performance standpoint, the RF Classification methodology outperformed all other classification methodologies. RF classification, while more computationally intense compared to the other classification methods used in this study, outperformed its closest competitor by 8 percent. Additionally, upon closer examination of the best performing classification result (RF test #77—Table 8), it was noted that the classification of cleared areas did rather poorly (producer accuracy of 58.2%). This also resulted in a poor user accuracy of Open Fens (58.0%) as illustrated in Table 8. Despite this the classification of the rest of the land covers performed very well. We speculate that the misclassification between Cleared Areas and Open Fens lays within the image reflectance and spectral overlap between the two land covers. Upon further examination, it would appear that both Cleared Areas and Open Fens are very similar, spectrally, for both the Spring and Summer season. In particular, bands 2-4 tightly match one another. We suspect that this is likely the cause of the misclassification. Improving the classification of Cleared Areas from Open Fens would further improve the classification accuracy and this could be accomplished through examining other classification schemes where cleared areas were classified more successfully. By comparing and contrasting the feature inputs used, we may be able to identify an even more superior set of inputs. When examining the worst performing classification tests (Naïve Bayes test #225 - Table 9), we note that the most accurately classified land cover only had a producer classification accuracy of ~60%. The worst performing land cover (Treed Fen) has a producer accuracy of some ~8.7%. We also note that five of the land covers (Treed Bog, Cleared Areas, Treed Fen, Open Fen, and Coniferous Forests) have producer accuracies below 30%—essentially guesswork. Similar results are reflected in the corresponding user accuracy. For this test we note that the features used are as the worst performing features as defined by the RF predictor importance analysis—3 of the 4 features are relatively noisy Sentinel-1 images and the other is a fall Band 3 image. Upon closer examination the statistical overlap between all land covers, for these features, is substantial, which indicates that this is the possible cause for this low level of classification accuracy across all land covers. In this case, there is not much which can be done to improve these results. However, what can be gleaned from this test is that these features truly are of poor quality. When ranking the classification methods, overall, from most to least accurate, among all input features, it yielded (1) RF, (2) SVM, (3) K-Nearest Neighbours, (4) Naïve Bayes. Moreover, from an overall standpoint, RF classification results consistently outperformed all other classification methods, for all feature inputs. However, it is worth noting that in many cases the SVM and K-NN classification strategy produced results that were much closer in accuracy to the RF methodology when compared to Naïve-Bayes. As mentioned previously, one distinction between the RF, SVM, and the K-NN classification strategies compared to the Naïve-Bayes strategy, was that they more thoroughly investigate subsets within the input training set, and are ensemble learning methods which do not operate on calculating gross statistics on the input datasets, at the cost of computation time. It is also worth mentioning, again, that from a mathematical perspective, RF regression and K-NN could be viewed as being part of similar mathematical families [65], which implies that they would interpret a given dataset in a similar fashion.When considering how our work can be expanded upon, we note that this project would benefit from the addition of images from other years, and from other image sources. As a general principle, all of the classification methodologies used would benefit from additional data and data sources. To further develop our work, the addition of Lansat-8 and Sentinel-2 data (both now readily available) would be beneficial. However, it is worth noting that some of the best classification tests produced during this study already have very high accuracies and will probably not show vast improvement by the addition of more data. We speculate that the addition of more images in the form of Landsat-8 and Sentinel-2 images would provide more certainly with our variable significance analysis results, and possibly improve the accuracies of the worse performing tests. However, the addition of large time-series of SAR data would be interesting. We speculate that through a large addition of SAR data more seasonal and structural features would become evident through our classification results. Furthermore, when considering how this work can be adapted to other study areas, we note that northern hemisphere temperate forests are all very similar in structure and vegetation distribution. The work done with this project should be sufficiently general with only minor local considerations from the study site. The methodologies and results produced in this study should be able to be applied without much difficulty to other northern hemisphere temperate study areas, in Canada or other parts of the world. Applying this work to tropical environments would likely be less compatible given the difference in vegetation density, vegetation types, and the lack of large seasonal variations with that vegetation. However, if given the appropriate datasets, the study methodology used here should be able to produce similar variable analysis and classification results, which would be an interesting contrast to our work.", 5. Discussion,None,5
50,"A large focus of this study was the analysis and selection of features in order to facilitate the successful classification of the selected land covers from the test area. It was found that analysis of features using gross statistical analysis in the form of the Log-normal distance and an iterative regression approach in the form of the RF predictor importance value were an effective means of identifying which features were of high quality and should be used in classification and also which features were of low quality and should be either ignored or removed from classification. However, it was noted that while this style of analysis was effective across all classification methodologies in identifying low quality features, when it came to identifying the highest quality features it was not as consistent. We suspect that these performance differences are driven by fundamental differences in how the log-normal distance is calculated (gross statistical measure, with no provisions for identifying multi-modal features) compared to the RF predictor importance value, which is iterative and explores subsets within a given dataset. Give these differences in feature analysis and the differences in how each classification technique analyzes a given dataset, the likely cause of this is discrepancy. It was also found that this analysis aided K-NN the most in identifying features, with its best performing tests being mostly represented by tests determined through this analysis (17 of its top 20 tests were determined by feature selection). For the other classification methodologies, results generally showed that the features determined by this analysis produced high accuracies but they did not produce the best results. Those results were produced by the input features determined through a holistic approach, with the best performing tests (RF test #77) produced an overall accuracy of % 85.71. The exact reason why holistically determined tests have performed so much better than quantitatively determined tests is unknown but should be further explored in future work. However, as a general trend we contend that applying this methodology to RF, SVM, and Naïve-Bayes especially provided value in determining lower quality features (features common in the bottom performing 20 tests), which could then be excluded from analysis to both speed up analysis time and ensure that results are more likely to be of a higher quality and accuracy. Moreover, we contend that with further development and study, this feature selection methodology could be refined such that it could produce selections of features, which would result in the highest classification accuracies. When considering the classification results from a feature standpoint, our work has shown that the use of surface temperature, despite its low resolution, could be used to better classify wetlands in our study area in Northern Ontario, in particular if the temperature measurement was from an abnormally warm, spring season. Additionally, the addition of RADARSAT-2, and or Sentinel-1 imagery to Landsat-5 imagery was shown to improve overall classification accuracies. It was also found that the data acquired in the fall season, if used solely as the classification input, consistently produced the poorest classification results.Finally, from this study our analysis showed that the data used allowed for broad class separations (wetland-non versus wetland, treed wetland versus non-treed wetland), which implied that a hierarchical classification strategy could be an effective and efficient approach to the classification of wetlands. In order to explore this, further testing and development of these models should be undertaken. Additionally, further examinations of our results which would explore, and assign more quantifiable physical explanations to these results, and features should be carried out. Furthermore, optimum classification conditions for wetlands, and the ultimate limits that this style of analysis can produce should be explored. This is a challenging proposition but one that is worthwhile. This will not only provide a framework for wetland classification which can be used as a product but will also provide a level of expectation when it comes to the ultimate accuracy that this style of analysis can produce. This in turn will aid in determining the next steps required to achieve the next level of accuracy or detail.", 6. Conclusions,None,6
51,"Sustainable forest management demands accurate information that can be obtained efficiently and rapidly [1] in order to describe forest structure and quantify forest resources [2]. However, although accurate, traditional forest inventory is resource- and time-consuming, indicating the need for either alternative or complementary methods that may overcome the drawbacks of field data acquisition [3]. In addition, although field-measured data are commonly assumed to be ground truth values for remote sensing estimations, the associated errors tend to be large [3,4,5,6].A number of alternatives to traditional field-based measurement of morphological parameters for characterizing three-dimensional (3D) structure of trees and canopies have emerged [4,7]. Airborne Laser Scanning (ALS), Digital Aerial Photogrammetry (DAP) and Terrestrial Laser Scanning (TLS) have become widely established as forest mapping and monitoring methods [8,9,10,11]. In the last two decades, DAP, ALS (e.g., [12,13,14]) or a combination of these methods (e.g., [15,16,17]) have been increasingly used to support forest inventories at different scales.ALS has been the primary source of 3D data on forest vertical structure since the 1990s [18,19]. There has been an abundance of research demonstrating the utility of ALS for predicting forest biophysical variables to support forest inventories at individual tree- and stand-level [20,21]. Since the late 2000s DAP has provided a promising alternative, as the accuracy of stand-based estimates has been found to be similar to that achieved through ALS, at much lower cost [17,22,23].Baltsavias [12] provided a comprehensive comparison of DAP and ALS data, highlighting the advantages and disadvantages of both technologies with regards to acquisition, accuracy, maturity and costs. Although ALS data have many advantages (e.g., direct measurement of height, higher penetration through the vegetation), DAP still represents an essential source of data for the forest inventory analyses. In fact, photogrammetric software has developed rapidly in the past 15–20 years. Since the first studies [24], advances in computer vision, image matching algorithms and computing power have promoted the use of aerial images for generating high-resolution 3D data by image matching [25]. Many photogrammetric software packages (proprietary and open-source) have been developed, offering unparalleled opportunities to produce 3D data from 2D image collections with high overlap.Recent advances in sensors and in image processing –particularly Structure from Motion (SfM) technology– have also enabled the extraction of dense point clouds obtained by DAP [16,24,26,27,28,29]. In this sense, DAP derived from SfM is an emerging source of 3D data, reaching quality standards close to those provided by ALS [25,30]. works by [26,31,32,33] pointed out the potential of DAP for forest applications. During the past five years in particular, there has been an increasing interest in the use of DAP to generate 3D data analogous to ALS data, in order to support forest inventories [17,22,25,34,35,36,37,38,39]. This interest can be attributed to the need to optimize costs while improving the temporal resolution.Unmanned Aerial Vehicles (UAVs), also known as drones or Unmanned Aerial Systems (UAS), have emerged as a cost-effective alternative to conventional methods based on manned fixed-wing aircraft or helicopters for DAP imagery and ALS data collection [40,41,42,43]. Since the first studies in which UAV-derived data was used for forest inventory purposes [44,45], UAV-based forestry applications of both ALS and DAP have increased substantially [40,46,47,48,49,50,51,52]. Indeed, ALS and Red-Green-Blue (RGB) sensors mounted on UAV platforms are becoming cost-effective tools for monitoring forest structure because of their high spatial and temporal resolution, achieved by the low flight height, operational flexibility and relatively low cost of the flight surveys, which meet most of forest managers requirements [53]. In particular, light UAVs equipped with inexpensive consumer grade cameras have recently appeared as a feasible option for monitoring 3D forest structure [54]. In addition, multi-temporal UAV-acquired data can also be used for rapid, accurate and cost-effective tree growth assessment, providing up-to-date information to support decision-making in forest management [48,54,55,56,57,58].Two main strategies have been adopted for DAP and ALS-based analysis in forestry inventories: (i) the Area-Based Approach (ABA), a distribution-based technique which typically provides data at stand level, and (ii) the individual tree crown (ITC) delineation, in which individual tree crowns, heights and positions are the basic units of assessment. ABA has been used with ALS and DAP to estimate forest attributes over a wide range of forest types including Temperate (e.g., [59]), Boreal (e.g., [13,14,17,34,60]), Atlantic (e.g., [61,62]), Tropical (e.g., [37]), Alpine (e.g., [63,64]), Mediterranean forests (e.g., [65,66,67,68,69]) and plantations [70]. At the stand level, results from recent research on small- to medium-sized boreal and tropical forests have demonstrated the potential use of UAV-based DAP data for estimating forest biomass [53,71]. On the other hand, ITC has also been applied to DAP point clouds [72] and to ALS clouds [73,74]. ITC presents several advantages over ABA for estimation of above-ground biomass because it can be used to derive biomass when an allometric model is available at individual tree level [75]. At the same time, it is particularly well suited for precision forestry, which usually requires information about individual trees.Finally, ALS and SfM approaches to tree height estimation tend to underestimate tree height [73,74,76,77]. Recent studies [77] have presented a model that explains the observed bias using probability theory, developing methods for correcting several ALS metrics used for ABA prediction of stand structure. However, few studies have evaluated the influence of this bias at individual-tree level. In this respect, further research is needed in order to analyze the influence of this bias in the individual-tree biomass and volume models for both technologies.The objectives of this study were as follows: (i) to investigate the combined use of ALS- and SfM-derived individual-tree measurements (height and crown area) with non-linear regression models to estimate individual tree diameter and volume; and (ii) to compare the estimation of ALS- and SfM-derived individual-tree volume models to estimate growing stock volume in relation to field data.", 1. Introduction,None,1.
52,"The study area is located in the municipality of Valongo (41.213° N, −8.496° W) in the district of Porto, Portugal (Figure 1). The site consists of a seven year old plantation of Eucalyptus spp. clonal material (G74), covering an area of 26 ha. Tree spacing was 3.70 × 2.5 m, yielding a density of one tree per 9.25 m−2. The elevation ranges from 163 to 294 m above the WGS84 reference ellipsoid. The terrain is topographically complex, with steep slopes (mean slope = 24.2%), and of elevation up to 131 m. The mean annual rainfall is 1568 mm, and 42.1% of the precipitation occurs between November and January. The mean annual temperature is 14.2 °C, ranging from 8.6 °C in the coldest months (December to February) to 20.1 °C in the warmest months (July to September). The study site is characterized by evenly planted trees of superior genetic material with a low mortality rate.", 2. Materials and Methods , 2.1. Study Area,2
53,"The field data were collected in December 2016 (to correspond to the date of acquisition of ALS data) from 6 square plots, each of approximately 400 m2 (Table 1). A total of 323 reference trees were measured and located in 6 square plots (400 m2). The height of each tree (h, m) within the plots was measured with a Haglof Vertex IV hypsometer equipped with a T3 transponder. The diameter at breast height (1.30 m above the ground – d, cm) was measured with a steel diameter measuring tape. Field plots were remeasured using the same methods in September 2017 (matching with UAV-based DAP acquisition).In order to obtain accurate positions of the trees, topographic surveys were conducted to determine the position of the center of each tree within the plots. A Trimble® TSC3 GPS controller with Trimble® R8s Integrate GNSS System Antenna (Trimble, Sunnyvale, CA, USA) (dual-frequency real-time kinematic receiver –RTK) was used to determine the coordinates of a densified geodetic network for the study area by applying real time kinematic (RTK). Based on the network established with GPS, a topographic survey of the plots was conducted using a Trimble® M3 Robotic Total Station (Trimble, Sunnyvale, CA, USA). Observations on the position of each tree within the plot were made during the survey.Field-derived volumes were estimated using the Equation (1), provided by [78].




v
^

 
=
0.2105
 



(


d

100



)



1.8191


 

h

1.0703






(1)


where 

v
^

 is the estimated volume (m3), d is the diameter (cm) at the breast height (1.30 m) and h is the tree height (m).", 2. Materials and Methods , 2.2. Field Measurements and Field Volume Estimation,2
54,"The airborne surveys were conducted on 17 December 2016, covering an area of 100 ha. The data were captured with Leica ALS80-HP laser scanner operating at pulse rate of 704 kHz, field of view of 6.5° and scan rate of 73.5 Hz, which was mounted on a Cessna airplane that flew the area at an approximately flight altitude of 2750 m.a.s.l and an average speed of 250 km.h−1. The overlap between sweeps was 30%, achieving an average laser pulse density of 43.33 pulses m−2.", 2. Materials and Methods , 2.3. ALS Acquisition,2
55,"The airborne surveys were conducted on 6 September 2017. An RGB S.O.D.A. 10.2 (20 MP) camera (senseFly Co, Cheseaux-Lausanne, Switzerland) was mounted, with nadir view, on a fixed-wing UAV (SenseFly eBee) (Figure 2). The camera, which was equipped with a 12.75 × 8.5 mm sensor and 5472 × 3648 pixels detector, was used in manual mode. Exposure settings (ISO 150 and shutter speed of 1/1000 s) were set before each take-off according to the light conditions. This provided ~6 cm pixel−1 resolution for a variable altitude above ground level, which is especially useful in areas of diverse elevation range such as mountainous regions. Atmospheric conditions during the airborne surveys were characterized by calm winds, clear lighting at the flight time (between 11.30 am and 12.15 pm) to minimize the effect of shadowing. Flight parameters were determined using eMotion V. 3.2.4 flight planning and monitoring software. The flight plan covered the entire study area with longitudinal and lateral overlaps of 85% in both cases. The flight line spacing was 25 m (Figure 2). In total, 744 images were used to generate orthomosaics and Digital Surface Models (DSMs) by the SfM image reconstruction process. Two-block flights were required to capture the entire forest study area (the orthomosaic covered an area 103.70 ha with average Ground Sample Distance (GSD) of 5.95 cm).", 2. Materials and Methods , 2.4. UAV Data Acquisition and Use,2
56,"The absolute orientation of the aerial photos was determined using aerotriangulation techniques implemented in pix4D 3.3.29 (pix4D®, Ecublens, Switzerland). A set of 10 ground control points (GCPs) measured in the field with topographic methods was used to georeference the SfM mosaics to a projected coordinate system for both datasets. The ground control photogrammetric points (GCPs) were captured with a Trimble TSC3 controller and a Trimble R8s GNSS antenna (RTK precision 8 mm + 1 ppm Horizontal/15 mm + 0.5 ppm Vertical) mounted on a pole. The GCPs markers comprised a set of 1 × 1 m cross-shaped white painted timber planks with some black and white 50 × 50 cm painted checkerboards. For reliable accuracy of GPS measurement, all GCPs were located in open areas with no canopy cover. At each point, GPS signals were logged in RTK–global navigation satellite system (GNSS) mode. The recordings were processed with real-time correction data retrieved from the fixed base station in Gaia (Porto) (latitude: 41°06′21.67048″ N, longitude: 8°35′20.73434″ W, and ellipsoidal elevation: 287.63 m above the WGS84 reference ellipsoid).Photogrammetric point clouds were computed using SfM techniques, implemented in Pix4D 3.3.29. The matching parameters for point cloud densification were set as follows: multiscale, image scale = 1/2 (half image size) and point density = ‘optimal’. The minimum number of matched images was also set to 3. DEMSfM was generated from the ground points by using a natural neighbor interpolation technique implemented in Pix4D (additional details of the algorithms are proprietary and were not disclosed by Pix4D).The ALS and SfM point clouds preprocessed using FUSION/LDV 3.60 software [79] and LasTools [80]. For more details of point cloud processing see details in [74]. Finally, two CHMs (CHMSfM and CHMALS) were obtained by subtracting the DEMs (DEMALS and DEMSfM) from the DSMs (DSMALS and DSMSfM) in the FUSION LiDAR Toolkit [79].", 2. Materials and Methods , 2.5. 3D Model Generation and Preprocessing Point Clouds,2
57,"Individual tree position (X and Y coordinates), height (hSfM, hALS) and crown area (caSfM, caALS) were retrieved from the respective CHMSfM and CHMALS (Figure 2). Resampling of the CHMs to 20 cm resolution and subsequent smoothing with mean filter (5 × 5 window) in the case of ALS and median filters (3 × 3 window) for SfM were conducted using the FUSION LiDAR Toolkit [79]. Crown delineation followed the procedure detailed in [81]. The process is divided into three main phases: segmentation, classification and iterative watershed segmentation The Chessboard Segmentation algorithm was used to split the image into square image objects. In the second phase, a Classification algorithm was used to classify image objects from the smoothed CHM. Objects with an elevation value of less than 5 m were classified as gaps. The threshold was established empirically from field observations and by trial-and-error tests. The remaining objects were assigned to the ‘temporary canopy’ class. These objects were used to locate tree tops and delineate tree crowns in the following iterative watershed segmentation processes. In the iteration, the Find Local Extrema algorithm was used to classify the image objects of the ‘temporary canopy’ class, which fulfills a local extreme condition according to image object features within a search domain in their neighborhoods. However, because of the forest stand and tree species characteristics, the initial maximum search domain used in the iterative process (see Figure 3 in [81]) to detect top trees was changed from 5 to 3, and 4 interactions were applied. A search with a variable square window enables detection of apices of trees with a large variety of crown sizes. Objects less than 3 m away from any detected tree top were retained in the ‘temporary canopy’ class (candidates for watershed) and any other objects were disregarded. This distance was the maximum observed crown width in the plots, which was considered the limit for crown growing in the next step. Then, the crown delineation results (Figure 3) and tree top positions were exported in ESRITM shapefiles as vector polygons and points respectively, for subsequent analysis.", 2. Materials and Methods , 2.6. ITC Process to Derive ALS- and SfM-Variables,2
58,"Volume equation (Equation (1)) requires the measurement of tree diameter or circumference, which is not available from UAV imagery. We therefore tested two approaches for estimating ALS- and SfM-derived individual-tree volumes (vSfM and vALS) (Figure 4). In the first approach, the multiplicative (power function) model in Equation (2) was fitted using d (from field data) as the dependent variable and the pairs of explanatory variables hSfM, caSfM for SfM, or hALS, caALS for ALS. The predicted diameter obtained by each method (dSfM and dALS) and their respective height estimates (hSfM and hALS) were then included as independent variables in Equation (1) to predict the individual volumes for the subset of 192 trees for ALS and 199 for SfM (vSfM and vALS, respectively). In the second approach, the multiplicative (power function) model in Equation (3) was also fitted to predict vSfM and vALS for the 192 and 199 trees respectively, but v was considered a dependent variable (estimated using the field-measured d and h in Equation (1)), and the pairs hSfM, caSfM (from SfM) or hALS, caALS (from ALS) were considered explanatory variables, without the need to estimate the diameters.




d
^

=

h


β
0



c

a


β
1



+
ε




(2)






v
^

=
 

h


β
0



c

a


β
1



+
ε




(3)


where 

v
^

 is the estimated volume (m3), 

 

d
^


 is the estimated tree diameter (cm), h is the tree height (m), ca is the canopy area (m), generated from ALS or SfM, β0, β1, are the exponential parameters to be estimated by non-linear regression analysis; and ε is the additive random error. The models were fitted using the Non-linear Least Squares nls function implemented in the BASE package of R software (R Core Team, 2018).Finally, the Model Efficiency (Mef, Equation (4)), the overall root mean square error (RMSE, Equation (5)), the relative root mean square error (rRMSE, Equation (6)) and the Bias (Equation (7)) were computed in order to determine the accuracy of ALS and SfM models for estimating diameter and volume with the second approach. Mef compares predictions directly with observed data using a statistic analogous to R2 [82]. This statistic provides a simple index of performance on a relative scale, where 1 indicates a ‘perfect’ fit, 0 reveals that the model is no better than a simple average, and negative values indicate a poor model.



M
e
f
=
1
−

(




(

n
−
1

)



∑


i
=
1

n




(


y
i

−


y
^

i


)


2




(

n
−
p

)



∑


i
=
1

n




(


y
i

−


y
¯




)


2




)





(4)





R
M
S
E
=






∑


i
=
1

n




(


y
i

−


y
^

i


)


2


n







(5)





r
R
M
S
E
=


R
M
S
E


y
¯


*
100




(6)





B
i
a
s
=




∑


i
=
1

n

(


y
^

i

−
 

y
i

)

n





(7)


where n is the number of trees; yi is the field-measured tree diameter i; 

y
¯

 is the the mean observed value for the field-measured diameters; 



y
^

i


 is the estimated value of diameter derived from the non-linear regression model and 
p
 is the number of parameters in the models.Finally, using the correctly detected and delineated trees, d was compared with dSfM, dALS and v with vSfM, vALS in the subsample of 192 trees for SfM and 199 for ALS, respectively. Estimated and observed values were plotted and visually examined. A paired t-test was conducted to compare ALS- and SfM-predicted variables (dSfM, dALS, vSfM, and vALS) to verify the significance of the deviations between the observed and estimated values. However, these deviations were previously checked using the Shapiro-Wilk test [83], which indicated that the distributions meet the assumption of normality. The tests were conducted at a 5%significance level.", 2. Materials and Methods , 2.7. Individual Tree Volume Estimation,2
59,"Table 2 shows the parameter estimates and goodness-of-fit statistics for the models used to predict d (cm) in the first approach, and v directly estimated by SfM- and ALS-variables in the second approach.In the first approach, non-linear regression yielded an Mef value of 0.45 for the SfM-estimated diameter and 0.47 for ALS-estimated diameter (RMSE = 1.17 and 1.12 cm, rRMSE of 8.49 % and 8.31%, respectively). Although the UAV-based DAP method tends to underestimate tree height relative to field measurements (hypsometers), there was no appreciable bias throughout the observed diameter (Figure 5a,b). The bias values (0.38 and 0.35 cm) indicated a slight tendency to overestimate the initial diameter values from field data (Figure 5a,b). On the other hand, although d was not directly measured in CHMs derived from UAV and ALS, hSfM and hALS were, and these variables were significant in the SfM and ALS equations. For dSfM and dALS modelling, the crown area (caSfM and caALS) was also statistically significant (p < 0.05 and p < 0.001, respectively). In the case of vALS modelling, the second approach yielded an Mef value of 0.56. The mean rRMSE of v estimation was 20.31% (0.030 m3) when calculated on the basis of the SfM cloud, and 19.97% (0.026 m3) when based on the ALS cloud. There were no appreciable biases from the models throughout the observed volume range using both approaches (Figure 5c–f). However, the tendency of ALS and SfM to underestimate h may be the main reason for the slight underestimation of v in the first approach (Figure 5c,d). In the case of the second approach, a slightly positive bias (0.0004 and 0.0016 m3) indicated slight overestimation when volume was modeled directly form ALS- and SfM-variables (Figure 5e,f).The t-test (Table 3) showed that there were no evidence of significant differences between observed and estimated values of diameter (p-values of 0.98 for both approaches in the subsample of 192 trees for SfM and 199 for ALS, respectively) and volume using the second approach (p-values of 0.99 for ALS and 0.98 for SfM, Figure 6b). However, there were significant differences using the 1st approach between the observed values and estimated value at the tree level (Table 3, Figure 6b). It is important to note that the mean values of field data for diameter and volume computed for ALS and SfM in the subsample were similar that the values considering the 6 field plots for the total of 323 reference trees, except for the mean volume values for volume in 2017 (Table 3).", 3. Results," Field, ALS and SfM Volume Estimation",3
60,"Both vSfM and vALS were accurately estimated from UAV photograph and ALS-based 3-D point clouds using SfM- and ALS-variables extracted automatically from their respective CHMs. Although ALS-based methods and UAV-based DAP methods tend to underestimate tree height [73,74,77], relative to field measurements (hypsometers), no appreciable biases in the observed diameter and volume range estimations occurred with either technologies in the 2nd approach.Variables derived from the automated processing of ALS and UAV-based DAP with ITC delineation (hSfM, hALS, caSfM, and caALS) were found to be significant explanatory variables for predicting d and v in both approaches; however, the Mef and RMSE values for diameter models indicate poorer fits than reported in some recent studies in P. pinea plantations [57] (Mef = 0.79, rRMSE = 4.99%, n = 50 trees) and Japanese Cypress (Chamaecyparis obtusa) [84] (R2 = 0.79, n = 51 individual trees where d ranged from 11 to 58 cm) using UAV-based DAP point clouds.In the case of ALS-based diameter models, our results were similar in terms of R2 to those reported by Chisholm et al. [85], who extracted forest below-canopy information using UAV-based LiDAR and developed post-processing software to detect trees and to estimate their diameters (R2 = 0.45, rRMSE = 25.1%). Finally, the results were also similar in terms of rRMSE to those reported by Cosenza et al. [86] in a eucalyptus plantation in Brazil (rRMSE = 9%), for an exponential equation with h as explanatory variable. Cosenza et al. [86] also observed a slight tendency to overestimate the initial diameter values (bias = 0.12 cm).Studies conducted in Picea abies (L.) H. Karst. and Pinus sylvestris L. stands in Sweden and in Pinus taeda L. stands in the SE United States found that ALS-derived h and crown diameter (cd) explained up to 87% and 91% of the variance associated with the estimation of d, with RMSE of 3.8 and 4.9 cm, respectively [87,88]. Zhao et al. [89] reported an R2 value of 0.87 and a RMSE value of 5.2 cm for ALS-derived tree dimension variables including h, cd and crown base height in P. taeda stands. In this study, the diameter equation based on ALS-derived variables performed well, although the values of Mef were slightly lower than some of those reported for other species [87,88].Regarding volume modelling, the performance of the vALS and vSfM estimates for predicting tree volume directly from ALS- and SfM-derived variables (the second approach, R2 = 0.46, R2 = 0.43; RMSE = 0.026 m3, RMSE = 0.030 m3; respectively) was lower than that obtained in different conifer species (R2 = 0.88) [88], as well as in P. taeda (R2 = 0.80) [89] and P. pinea (Mef = 0.84 − 0.85) [57]. The mean differences between the deviations of field volume and the ALS- or SfM-derived volume were statistically significant using the 1st approach. The tendency of ALS and UAV-based DAP technologies to underestimate h may be the main reason for the underestimation of v with 1st approach. It should be also borne in mind that the ALS and UAV-based DAP, as a tree height estimation technique, tends to underestimate tree height (e.g., DAP [39,90,91], UAV-based DAP [47,74,76,92] and ALS [73,77,93,94,95] point cloud data). However, our volume modelling results suggest that this bias may not influence in volume estimations using the 2nd approach, leaving open the question as to when and where specific models should be developed for correcting the bias at tree level depending on particular species or forest structure [77]. The results of this study are consistent with the approaches used by other authors [57,73], in which the use of linear regression improved the accuracy of tree height estimations from DAP-ALS data in terms of RMSE and bias, instead of using tree height extracted directly from the CHM to calculate the RMSEs and bias [74], as also occurred with modelling volume in the present study.There are three possible reasons for the differences in performance for diameter models using SfM- and ALS-variables relative to other species: (i) First, broadleaved trees trees in particular are more challenging for both local maxima detection and delineation compared to conifer trees. (ii) Second, crown delineation remains difficult because the crowns of neighboring trees often overlap due to the high density of trees per unit area. (iii) Third, the low density of leaves in the crowns and the small size of the crowns of mature trees prevent a considerable number of laser pulses from hitting the crown (thus hampering crown delineation). As expected, the ALS cloud contributed to yielding slightly better results for diameter and volume estimation, but we did not observe differences in terms of volume estimations. As with previous studies using DAP, ITC delineation is more affected than ALS crown delineation as UAV-based DAP has several limitations: (i) ALS is insensitive to shadows made by clouds [15], (ii) the images are strongly influenced by atmospheric conditions (e.g., wind swaying can cause problems building point clouds), solar illumination and view angles (sun, surface and sensor geometry), occlusions caused by shadows are particular problematic for generation of image-based point clouds in dense forest canopies [45,96,97,98]. In addition, seasonality (timing) influences underestimation of tree heights but can improve detection accuracy [99]. The allometric relationship between volume and ALS or SfM crown-derived variables could be also refined through improvements in UAV imagery acquisition and processing.Finally, a more comprehensive examination of the effects of varying the conditions of UAV-based DAP acquisition and their implications for estimating forest inventory variables in different types of forest should be carried out using these techniques [100,101,102]. Many facets have not been explored with current state-of-the-art techniques. Several effects related to flight configuration (i.e., flight speed, wind effect, illumination effect), post-processing pipelines (i.e., comparing different SfM algorithms), field data collection (i.e., number of field plots) and environmental variables (i.e., effect of aspect or slope when using different DEM approaches or the DEM-independent approach) must be analyzed. Future research must also explore how the type of platform (fixed-wing versus multirotor), sensors or the type of forest (e.g., temperate, deciduous, evergreen needleleaf, and tropical forest) influence the ability of UAV-based DAP methods to accurately characterize biometric tree variables at the tree level.", 4. Discussion,None,4
61,"The study findings showed that UAV-based DAP methods are useful and comparable to ALS for forest inventory and sustainable forest management in planted forests, by providing accurate estimations of forest structural attributes at the tree level. The results suggested that object-based image analysis (OBIA) provides more accurate predictive models for individual volumes of Eucalyptus trees based on ALS-derived and SfM-derived variables from the 3D point clouds than those obtained using indirect approaches to estimate diameter.", 5. Conclusions,None,5
62,"Aboveground biomass (‘AGB’ or ‘biomass’ hereafter) is a strong indicator of ecosystem structure, function, and productivity. In dryland ecosystems, AGB is important for estimating fuel loads, measuring carbon storage, assessing habitat quality, and monitoring changes in native species [1,2,3]. Although AGB per unit area in drylands is relatively low compared to other ecosystems, drylands cover one fifth of the earth’s land area and thus play a significant role as a carbon sink and provider of essential ecosystem services [4,5].In western North America, semiarid sagebrush communities once extended across >500,000 km2, but the ecosystem is now one of the most imperiled on the continent [6,7]. An increase in invasive species, fire frequency, and other disturbances has resulted in a decrease in the extent of native shrub-steppe communities [7,8,9,10]. Indeed, the risk of permanent habitat loss from fire is so great, especially in the Great Basin, that in 2015, the secretary of the U.S. Department of Interior (DOI) released a secretarial order (SO3336; https://www.forestsandrangelands.gov/rangeland/index.shtml) that directed wildland fire prevention, suppression, and restoration in sagebrush-steppe ecosystems to protect the greater sage-grouse and other sagebrush-associated species. However, one limitation to the effective implementation of SO3336 is a lack of accurate and timely estimates of the distribution of AGB in sagebrush-steppe ecosystems, information that is critical for fuel management and fire risk planning at regional to landscape scales [11].Various direct and indirect methods are available for in-situ measurements of AGB of shrubs and herbaceous (forb and grass) species [12,13,14]. Some of the most common methods include harvesting [12]), clip-and-weigh [14], visual estimations [15], and point-intercept sampling [13]. These methods are labor intensive [13,14], which limits their scale of application. Although these field-based methods perform reasonably well (i.e., acceptable accuracy, precision, and reproducibility) at small spatial extents, at larger extents, such as landscapes greater than about 1 ha, performance declines because of the natural heterogeneity of dryland soils and vegetation. Hence, field-based measurements may misrepresent actual AGB values (as well as vegetation structure and composition) and are certainly inefficient and expensive when applied across entire landscapes. Techniques to improve the accuracy, precision, repeatability, and efficiency of AGB estimates over large areas (10 s of km) are needed, particularly in sagebrush-steppe and similar ecosystems that are experiencing landscape-level changes associated with invasive species, fire, and climate change.Remote sensing has the potential to meet this need by providing multi-scale contiguous estimates of AGB, which are ideally suited for modeling over broad spatial [16,17] and temporal scales [18]. For more than a decade, light detection and ranging (Lidar) has been successfully used to measure forest volume, height and AGB [19,20,21,22,23], and the vegetation characteristics of shrubs (e.g., shrub height, canopy cover, leaf area index) in rangelands [24,25,26]. In some shrub species, there is a strong link between shrub height and other biophysical characteristics (e.g., cover, AGB, canopy volume [27]), thus making Lidar advantageous for vegetation structure measurements.Metrics derived from Lidar (e.g., mean height, variance of height, canopy relief ratio) can be correlated with biophysical vegetation characteristics in the field using statistical methods such as Classical Multiple Linear Regression (CMLR) [28], Partial Least Square Regression [29], Hierarchical Bayesian [30], Random Forests [31], and Artificial Neural Networks [32]. The machine learning algorithm Random Forests (RF) assembles the analysis of Classification and Regression Trees (CART) by bootstrapping samples to iteratively construct a large number of decision trees, each grown with a randomized subset of predictors [33]. RF has been widely used in non-linear relational models and high dimensional data sets [34,35]. Recently, RF has gained attention in the field of remote sensing due to the classification and computational accuracy, the potential to capture complex and non-linear relationships between predictors, the ability to support small sizes of training data relative to a large number of predictors, and because it provides a measure of variable importance [36,37]. RF has been demonstrated to be more accurate than simple regression techniques for forest biomass estimations [18,38] and a number of studies have demonstrated that RF provides low prediction variance and bias, and strong model performance, e.g., [39,40,41].Statistical and machine learning methods for Lidar remote sensing studies are typically implemented on raster-based datasets instead of point cloud data. Raster-based models of Lidar data are relatively easy to process and store in comparison to point clouds [42]. A raster dataset is created by the aggregation of irregularly distributed points, typically starting with the upper-left points of the grid cell. Interpolation is performed for cells that contain no points. Therefore, vegetation metrics derived from rasterized imagery over a specific plot will differ from those calculated directly from the point cloud due to the likely mismatch between the field plot and grid cell boundaries. As an example of these effects. El-Ashmawy and Shaker [43] found that the overall accuracy of land cover classification in British Columbia was slightly higher using point clouds than raster-based classifications.The research objectives of this study were to model AGB in the sagebrush-steppe by linking field-measured biomass with 35 airborne Lidar-derived vegetation metrics using RF and Stepwise Multiple Regression (SMR), explore the uncertainty associated with Lidar-derived metrics and the models tested, and ultimately develop a spatially-explicit estimate of biomass across the xeric study site in the Great Basin. To accomplish these objectives, we compared the vegetation metrics from both Lidar point clouds and rasterized Lidar images as a proxy for the estimation of AGB to determine which processing method introduced a lower uncertainty and produced better results. We also compared different Lidar-derived metrics at a range of spatial scales to identify the best model for biomass prediction across a regional area. In addition, the RF and SMR models were compared to explore their relative strengths for predicting total and shrub biomass. All our analyses were performed to estimate biomass at the 1-ha plot scale since the in-situ biomass was measured across 1-ha plots.", 1. Introduction,None,1.
63,"The 75,164 ha study area is located within the 243,000 ha U.S. DOI Morley Nelson Snake River Birds of Prey National Conservation Area (NCA) in the Snake River Plain ecoregion of southwestern Idaho, USA (Figure 1). The NCA receives approximately 20 cm of precipitation annually, and has an average annual maximum and minimum temperature of 20 °C and 6 °C, respectively [44]. Native vegetation is generally composed of an open canopy of shrubs dominated by big sagebrush (A. tridentata) of up to 1.5 m tall [45], with a generally sparse cover of native bunchgrass (e.g., P. secunda, Festuca idahoensis) and forbs. Other native shrub species include shadscale (Altriplex confertifolia), winterfat (Ceratoides lanata), budsage (Artemisia spinescen), and rabbitbrush (Chrysothamnus visciflorus). Since 1980, about half of the NCA has burned, resulting in a mosaic of plant communities, with compositions spanning a gradient between intact native shrublands, shrublands degraded by biological invasion and wildfire, and grasslands where native perennial plants have been fully replaced by nonnative annuals, including cheatgrass (Bromus tectorum), medusahead (Taeniatherum caput-medusae), and various forbs (e.g., tall tumblemustard, Sisymbrium altissimum). Nonnative annuals have likely increased the amount of litter, fine fuel loads, and fuel continuity on the NCA compared with historical conditions. Likewise, the amount of bare mineral soil and biological soil crusts have likely diminished. Currently 37% or less of the NCA retains an intact native shrubland community; the remainder is predominantly a mixture of nonnative annual grasslands (i.e., Bromus tectorum) or a mosaic of native perennial (i.e., Poa secunda) and nonnative annual grasslands with occasional forbs and shrubs [46].", 2. Study Area and Data, 2.1. Study Area,2
64,"In the summers of 2012 and 2013, we established forty-six (n = 46) 100-m by 100-m (1 ha) field plots at locations throughout the northwestern NCA. We used a stratified random sampling approach within unburned, burned-treated, and burned-untreated areas over the Lidar coverage to capture invasion and successional gradients as part of a related study [47]. We located the corners of each plot using a survey-grade GNSS (Global Navigation Satellite System). We tested a point-quarter sampling design and deemed it suitable to quantify the cover of sparse plants such as shrubs in early successional habitats [48]. Each 1-ha plot included a three by three grid of nine subplots of 1 m2 each, with 25 m spacing between subplots (Figure 2). The subplots were sampled to represent the 1-ha plot. Vegetation within each subplot was classified as either herbaceous or shrub, then clipped at ground level, bagged, and labeled. We oven-dried and weighed the harvested vegetation. If shrubs were too large to be harvested, a portion was collected for reference and the number of equivalent portions remaining in the quadrat was estimated. We calculated the biomass across each 1-ha plot as the average of the nine subplots for the herbaceous and shrub classes. We combined the data collected in 2012 and 2013 into one dataset (n = 46 plots) to compare with Lidar collected in the same years. We assumed negligible differences in shrub biomass between years due to the slow growth of shrubs in our study area (e.g., [16]). We estimated the herbaceous and shrub cover and biomass across the 46 field plots. Herbaceous and shrub cover ranged from 0 to 100% and 0 to 87%, respectively. The herbaceous class had a mean biomass of ~144 g/m2 and the shrub class had a mean biomass of ~208 g/m2 (Table 1).", 2. Study Area and Data, 2.2. Field Sampling,2
65,"The Lidar data were collected over 65,194 ha in 2012 and 9970 ha in 2013, with an ALS60 system (Leica Geosystems, Heerbrugg, Switzerland) operated by Watershed Sciences (Corvallis/Portland, Oregon), with a small-footprint Lidar of an 18 cm diameter at nadir and a point density of approximately eight points per m2. The Lidar system was ≥148 kHz and was flown at 1500 m above ground level, with a scan angle of 48° (±12°) from nadir (field of view). An opposing flight line side-lap of ≥50% (i.e., 100% overlap) was maintained to increase the point density. The absolute vertical accuracy was ~0.03 m and the relative accuracy was ~0.024 m. The vertical accuracy was primarily assessed from ground check points on open, bare earth surfaces with level slope (<20°) by the vendor.", 2. Study Area and Data, 2.3. Airborne Lidar Data Acquisitions,2
66,"We buffered and height filtered the Lidar point cloud data using the BCAL Lidar Tools developed for vegetation analysis (http://bcal.boisestate.edu/tools/Lidar; [24]). The height filtering classifies Lidar points into ground and vegetation points. The height filtering was performed using a 5-m canopy spacing, which has previously been shown to perform well in the semi-arid sagebrush-steppe environment [24], a 5-cm ground threshold, nearest neighbor interpolation, and 40 iterations. Two groups of metrics were calculated from resulting Lidar vegetation points: metrics based on numerical values (e.g., canopy height) and metrics based on the density of points (e.g., canopy density). We calculated 35 metrics using the BCAL Lidar Tools (Table 2). We conducted two separate analyses of the 35 metrics to explore the effect of rasterization of the point cloud on the ability of the vegetation metrics to predict biomass. The first averaged the metrics derived from the rasterized vegetation products (created at a range of scales) of the plot and the second averaged the metrics directly from the point cloud of the same plot, with no rasterization. We used 1-m, 7-m, 30-m, and 1-ha resolutions to test the appropriate scale to represent biomass and to explore the differences between deriving metrics with the Lidar point cloud and rasterized data. The 1-m and 1-ha resolutions were chosen as they matched the field subplot and plot sizes, respectively. The 7-m resolution was chosen because a related study used RapidEye 7-m resolution data [49] and the 30-m resolution was chosen as a potential to compare and fuse with Landsat imagery in future studies (also see [50]). In addition, testing the input metrics at coarser scales (e.g., 7 m, 30 m, and 100 m spatial resolutions) for the biomass modeling will provide a possible strategy for using several of NASA’s previous and future space-based Lidar missions with large footprint sizes. For example, ICESAT-1’s GLAS had a footprint size of ~70 m; whereas ICESAT-2’s ATLAS and GEDI will have ~12 and ~25 m footprint sizes, respectively. While our study does not simulate the full waveform or photon counting lasers of these instruments, we can provide a measure of the uncertainty of vegetation biomass estimates at these coarser scales. In addition, earth system models are now beginning to use Lidar data, but at coarser scales (e.g., the iSNOBAL snow model used with airborne Lidar data from NASA’s Airborne Snow Observatory uses 50 m grid cells of Lidar derived information [51]).In the point cloud processing approach, the metrics were derived from the point cloud data at 1 m, 7 m, 30 m, and 100 m. We then used the average of these metrics at the different scales to represent the 1-ha plots (e.g., an average of the 1-m metrics across the 1-ha plot). In the raster processing approach, the Lidar point cloud data were rasterized at the same resolutions (1 m, 7 m, 30 m, and 100 m) and we then averaged the rasterized metrics to represent the 1-ha plot. The resulting 1-ha scale metrics, derived from different scales using either the point cloud or rasterization approach, were then compared to the field-based biomass average at the 1-ha plot level.", 3. Methodology, 3.1. Data Processing,3
67," 3.2.1. RF Regression ModelThe non-parametric machine learning approach, Random Forests (RF), was used to assess the relationship between field-level biomass with vegetation metrics developed from Lidar. We used SPM Suite (Salford Predictive Modeler Software Suite version 7, Salford Systems, San Diego, CA, USA) for the implementation of the RF algorithm. Each RF regression run generated 2000 trees and the maximum number of variables considered per node was kept equal to the square root of the number of variables for the run [33]. All 35 predictor variables (Table 2) were used to perform the initial RF run and ranked based on their predictive power. The predictive power of the variable or variable ranking was performed by a ‘Standard Method’: testing the variable stepwise and retaining it only if the error gain exceeds a certain threshold. This means that if a variable substituted with incorrect values can predict the target accurately, then the variable has no relevance for predicting the outcome and hence is assigned a low score (SPM user guide, 2013). For the best variable selection, we used the backward feature elimination method where the lowest performing variables were iteratively removed until the best model was obtained. The best models for total AGB, shrub AGB, and herbaceous AGB were determined based on the highest coefficient of determination (R2) (referred to as pseudo R2 in RF) and lowest root-mean-square error (RMSE) estimated using “out-of-bag” (OOB) testing. The OOB error provided an internal leave-one-out cross-validation using the ‘boot’ package in R statistical software (R Development Core Team 2013) and has previously been used as an unbiased estimate of error [39,52,53]. The number of predictor variables in the models was kept as low as possible to maintain model parsimony. The variable selection was performed to reduce the number of predictor variables and to understand which predictor variables are most suitable to estimate biomass [54]. The analyses were performed for all four resolutions (i.e., 1 m, 7 m, 30 m, 100 m) for both raster and point cloud derived metrics. 3.2.2. SMR ModelIn stepwise regression, predictor variables are entered into the regression equation one at a time based on given statistical criteria. At each step in the analysis, the predictor variable with the highest correlation to the dependent variable is entered into the regression equation first [55]. When the additional variables do not statistically improve the regression equation and increase R2, the process ends. Based on results from the RF, the SMR model was used to model the relationship between the 35 Lidar derived metrics at a 1 m raster resolution and field AGB at the plot level (1 ha). A common problem with linear regression and its use in biomass estimation is multicollinearity between the independent variables, possibly leading to the violation of basic assumptions [55]. Hence, we used the SMR approach adopted by Lefsky et al. [56], which selects the two most important independent variables that were not collinear using the Pearson’s correlation coefficient.", 3. Methodology, 3.2. Moldeing Plot-Scale Biomass,3
68,"The non-parametric machine learning approach, Random Forests (RF), was used to assess the relationship between field-level biomass with vegetation metrics developed from Lidar. We used SPM Suite (Salford Predictive Modeler Software Suite version 7, Salford Systems, San Diego, CA, USA) for the implementation of the RF algorithm. Each RF regression run generated 2000 trees and the maximum number of variables considered per node was kept equal to the square root of the number of variables for the run [33]. All 35 predictor variables (Table 2) were used to perform the initial RF run and ranked based on their predictive power. The predictive power of the variable or variable ranking was performed by a ‘Standard Method’: testing the variable stepwise and retaining it only if the error gain exceeds a certain threshold. This means that if a variable substituted with incorrect values can predict the target accurately, then the variable has no relevance for predicting the outcome and hence is assigned a low score (SPM user guide, 2013). For the best variable selection, we used the backward feature elimination method where the lowest performing variables were iteratively removed until the best model was obtained. The best models for total AGB, shrub AGB, and herbaceous AGB were determined based on the highest coefficient of determination (R2) (referred to as pseudo R2 in RF) and lowest root-mean-square error (RMSE) estimated using “out-of-bag” (OOB) testing. The OOB error provided an internal leave-one-out cross-validation using the ‘boot’ package in R statistical software (R Development Core Team 2013) and has previously been used as an unbiased estimate of error [39,52,53]. The number of predictor variables in the models was kept as low as possible to maintain model parsimony. The variable selection was performed to reduce the number of predictor variables and to understand which predictor variables are most suitable to estimate biomass [54]. The analyses were performed for all four resolutions (i.e., 1 m, 7 m, 30 m, 100 m) for both raster and point cloud derived metrics.", 3. Methodology, 3.2.1. RF Regression Model,3
69,"In stepwise regression, predictor variables are entered into the regression equation one at a time based on given statistical criteria. At each step in the analysis, the predictor variable with the highest correlation to the dependent variable is entered into the regression equation first [55]. When the additional variables do not statistically improve the regression equation and increase R2, the process ends. Based on results from the RF, the SMR model was used to model the relationship between the 35 Lidar derived metrics at a 1 m raster resolution and field AGB at the plot level (1 ha). A common problem with linear regression and its use in biomass estimation is multicollinearity between the independent variables, possibly leading to the violation of basic assumptions [55]. Hence, we used the SMR approach adopted by Lefsky et al. [56], which selects the two most important independent variables that were not collinear using the Pearson’s correlation coefficient.", 3. Methodology, 3.2.2. SMR Model,3
70,"A Nearest Neighbor (NN) imputation technique developed in the R statistical computing environment (R Development Core Team 2013) was used to apply the optimal RF model to scale biomass estimates to the larger study area. In the NN imputation, the best predictor variables selected by the optimal RF model form an attribution space. Missing data are then computed using biomass estimates produced as weighted averages of the neighbors, which are determined by the similarity (distance) [35,57]. Nearest Neighbor imputation methods can use different distance metrics to determine the similarity between target and reference records, including Euclidean, Mahalanobis, Minkowski, and fuzzy in the attribution space [58]. We used the R imputation package, yaimpute, with the available Lidar coverage to obtain a contiguous map of predicted biomass. The yaimpute package has a built-in function to calculate NN distances based on the RF proximity matrix [31,59]. A detailed explanation of imputation, its types, and its fundamental difference with interpolation can be found in Hudak et al. [31]. Our RF biomass model was trained and developed at the 1-ha plot scale, hence a spatially-explicit plot-scale average biomass map was developed at this scale. We also developed a spatially-explicit map of the coefficient of variation (CV, equal to the value of the standard deviation divided by the mean) for shrub and total AGB estimates in RF [17]. The imputed AGB for a given pixel was estimated by averaging all estimates produced by all regression trees for that pixel and the standard deviation of each pixel estimate across all trees was calculated by retaining the individual pixel estimates from all trees.", 3. Methodology, 3.3. Imputation of Regional Biomass and Uncertainty,3
71,"Lidar-derived metrics using rasterization were found to have a strong relationship with total AGB and shrub biomass using RF regression models. Lidar metrics, including HAAD and Hstd from the 1-m raster image, predicted total biomass with an R2 of 0.74 and RMSE of 141 g/m2, whereas shrub biomass was predicted with an R2 of 0.76 and RMSE of 152 g/m2 (Table 3).As the raster resolution decreased, the prediction capability of the Lidar metrics also decreased with an R2 of 0.70, 0.58, and 0.52 at 7 m, 30 m, and 100 m, respectively, for total AGB. Similarly, the RMSE increased as the resolution decreased. We observed a similar trend for the shrub biomass.", 4. Results, 4.1. Plot-Scale Biomass from Raster-Derived Vegetation Metrics,4
72,"Unlike the raster processing, the coarsening of the pixel size had a smaller effect on the total and shrub AGB prediction capability of the point cloud-derived metrics. Whereas the AGB estimation ability of the RF model from point clouds was not statistically different from raster processing at the 1-m resolution, the predictions at 7-m, 30-m, and 100-m resolutions improved using the point cloud data (Table 4). Notably, the RMSE of the shrub AGB estimates was lower in the point cloud processing at the 7-m, 30-m, and 100-m scales in comparison to the raster processing.In contrast to shrub and total biomass, herbaceous biomass was poorly predicted by Lidar metrics. This result fitted our expectations as herbaceous vegetation types are short in stature and differentiating ground from herbaceous returns in Lidar is difficult. The results were consistent across all scales and all processing approaches and hence only the results from the 1-m raster and point cloud datasets are listed in Table 5.", 4. Results, 4.2. Plot-Scale Biomass from Point Cloud-Derived Vegetation Metrics,4
73,"The Pearson’s correlation analysis identified the metric Hstd as the variable with the highest correlation with total AGB (Pearson’s correlation r = 0.85) and shrub biomass (Pearson’s correlation r = 0.84). A regression analysis of total AGB with Hstd provided us with the following equation, with an R2 of 0.72 and p-values < 0.001.


Total AGB = 12,374.67 × Hstd − 142.058


(1)

An analysis of the residuals obtained from the above equation was correlated with the remaining 34 metrics and Hskew was found to have the highest correlation (Pearson’s correlation r = 0.39). Hence Hskew was added to the equation, resulting in an R2 of 0.79, RMSE of 129 g/m2, and p-value < 0.001 (Figure 3).


Total AGB = 10,230 × Hstd + 386 × Hskew − 226.416


(2)

Applying the same methodology to the shrub biomass, provided the following model with an R2 of 0.77, RMSE of 120 g/m2, and p-value < 0.001 (Figure 3).


Shrub AGB = 25,655.23 × Hstd − 19,052.4 × HMAD − 169.62627


(3)

Comparing the pseudo R2 using OOB testing with the R2 from the linear regression model, we found the RF results to be slightly worse than the SMR models for both total and shrub AGB. We then used the optimal RF model (1 m raster scale) to estimate the predicted biomass for each observed (field) biomass. This resulted in the RF predicted total AGB of R2 = 0.80 and shrub AGB of R2 = 0.84 with RMSE values of 124 g/m2 and 102 g/m2, respectively (Figure 4).", 4. Results, 4.3. Comparison of RF Model and SMR Model,4
74,"Using RF, total and shrub biomass were best modeled with 1-m Lidar-derived metrics (Table 3 and Table 4). For total AGB, raster processing and point cloud processing had an R2/RMSE of 0.74/141 g/m2 and 0.71/147 g/m2, respectively. For shrub AGB, raster processing and point cloud processing had an R2/RMSE of 0.76/125 g/m2 and 0.73/129 g/m2, respectively. There was no significant difference between the two data processing methods used (raster or point cloud). Based on these results and because raster processing is computationally more efficient, spatially-explicit, contiguous total and shrub aboveground biomass maps over the Lidar coverages were produced by imputation using predictors associated with the 1-m raster-derived metrics. Figure 5A,B and Figure 6A,B show that the shrub-dominant regions had higher biomass values in comparison to the sparse shrub and grass dominant areas. Note the crops depicted in the northeast corner of the 2013 Lidar were not masked as they had a small influence on the overall mean biomass values calculated for the study area. In this study area, the mean shrub biomass is 50–60 g/m2 and the mean total biomass is 210–263 g/m2 (Table 6). There are wide expanses of no shrub cover across the NCA (more discussion below) and in fact, the shrub biomass imputation represents large regions of 0–50 g/m2 of biomass. These areas are likely representative of regions where the herbaceous class was present; this is confirmed by the total biomass imputations where biomass pixels in the ~0–200 g/m2 are more abundant. The CV maps (Figure 5C,F and Figure 6C,F) illustrate the variation of the model estimates, represented as a percentage of the estimated biomass in each pixel. Larger biomass estimates had a higher standard deviation and lower CV (Figure 5, Figure 6 and Figure 7). Given the poor modeling results of the herbaceous cover class, and considering that the total biomass model includes both herbaceous and shrub components, the uncertainty in the total biomass imputation is higher than the shrub biomass imputation.", 4. Results, 4.4. Analysis of Imputed Regional Biomass,4
75," 5.1.1. UncertaintyProcessing of the point cloud data significantly improved the estimation of total and shrub AGB using coarser scales (7 m, 30 m and 100 m) in comparison to the raster image processing (based on R2 and RMSE, Table 3 and Table 4). However, 1-m scale point cloud and raster image processing provided nearly equivalent estimates of 1-ha plot average biomass. At the 1-m scale, the rasterization approach incorporates fewer points outside of the pixel boundary (and in close proximity). Furthermore, rasterization at 1 m had a greater probability of aligning with field plots and was less influenced by values from adjoining pixels in comparison to coarser pixel sizes. The similar RF regression model results indicate that the rasterization method preserves most of the 3D point cloud vegetation characteristics and thus is essentially equivalent to using point cloud data at the 1-m scale. At coarser raster scales, we attribute the declining results to boundary effects and alignment with field plots.In contrast, the pixel size in which point cloud processing was performed had negligible effects on the total and shrub AGB estimation. There is almost no loss of detail while extracting or averaging information from the original point cloud. Furthermore, the point cloud processing significantly reduced the RMSE at all scales in comparison to the rasterized approach. However, based on the R2 alone, at a 1-m resolution, the point cloud processing was not significantly different to raster data processing. The coarse-scale raster results may be more representative of expected results from large footprint Lidar than the point cloud analyses. This is because a large footprint Lidar is an integrated waveform (or photons in the case of ICESAT-2) of the canopy profile over the entire footprint.The bias in in-situ data also introduces uncertainty into the biomass models. As shown in Figure 2, averaging the biomass from the subplots to obtain the in-situ plot level biomass takes into account areas of no sampling in the outer 30-m buffer of the subplots. Because the predictors will adapt to the attribution space of the training samples [60], the RF imputation includes similar uncertainties as those in the training samples. This is likely the reason behind the appearance of the long linear features of a relatively high biomass in the resulting imputation map (Figure 5 and Figure 6). Although the average biomass over the nine 1-m subplots may represent herbaceous and small shrubs across a 1-ha plot (e.g., [48]), error in the field data may have been introduced because of relatively larger shrubs close to the subplot edge which were not fully accounted for in the field sampling. Moreover, estimating the biomass from Lidar without corresponding species level classification can be a disadvantage when different species have similar structural arrangements but substantially different AGB (e.g., in this landscape, low-AGB nonnative forbs, such as tumble mustard, can be incorrectly quantified as shrub, [39]). 5.1.2. RF Regression Model VariablesPrevious research in similar ecosystems has shown volume (e.g., [61,62,63]) or the approximation of volume (the product of basal area and height or the product of percent vegetation cover and height) (e.g., [16,64]) to be a strong proxy of shrub biomass. A related study by Li et al. [16] compared percent cover and height, but did not account for height variability metrics in their linear regression model to estimate biomass. Their results showed that the percent cover of shrubs was the best predictor for biomass. Yet in our sparse vegetation area, height variability-related metrics (including Hstd, HAAD, and HMAD) scored higher than other predictors for both total and shrub biomass in all RF models, with high R2 and low RMSE values. Considering the Lidar acquisition parameters in this study as equal to those in Li’s study [16], a higher number of Lidar returns from the vegetation canopy will occur in denser and larger shrubs (represented in the study in [16]) compared to the sparse canopies with smaller shrubs in our study. Vegetation Lidar returns are also more likely to be mixed with those of annual grasses, perennial bunchgrasses, litter, or bare ground in our study area. Hence, shrub height underestimation is likely more pronounced in this study due to constraints related to the laser pulse length [24,26,65,66]. Yet the variability of height may still be sufficiently captured by the Lidar to represent the spatial pattern of biomass with smaller shrub canopies in our study site.In this study, five predictors (Hstd, HAAD, HCV, Hrange, and FHDall) at the 1-m scale explained roughly 76% of the variability in shrub AGB (Table 3) in the optimal RF regression model. For the RF model for shrub biomass, the remaining 24% error may be credited to uncertainties associated with sparse vegetation distribution, the misclassification of canopy as ground, and the underestimation of the vegetation height [24,67]. Similar results were found by Estornell et al. [68] in a Mediterranean shrubland ecosystem. In their research, the median height, standard deviation of height, and percentile of height derived from airborne Lidar were the best predictors, explaining up to 78% and 84% of variability for biomass and volume, respectively. Greaves et al. [17] also reported a similar finding in an arctic shrubland, in which Lidar volume and canopy metrics coupled with vegetation indices from optical data explained roughly 71% of the variability of shrub biomass.Given the prominence of Hstd in the SMR and RF models, we further tested the ability of Hstd alone to estimate AGB biomass. Using univariate linear regression, we found that Hstd explained 73% and 71% of the variance of total and shrub AGB, respectively (Figure 8). While this relationship is likely oversimplified and the model fit is erroneous at low shrub biomass estimates, it is interesting to conceptualize that a vegetation roughness measure may coarsely approximate biomass. Notably, previous studies in this ecosystem have found vegetation roughness to be a proxy for classifying sagebrush [69] and sagebrush heights [24].In sum, most of the shrub biomass models were based on variables associated with vegetation structure (e.g., height and cover) and related metrics (e.g., standard deviation of height and percentile of height). In this study, the complexity of the RF model made interpreting the model challenging, but demonstrated the non-linearity of the relationship between biomass and its related driving variables, while also providing a variable importance to better understand the nature of the relationships.", 5. Discussion, 5.1. RF Biomass Regression Model,5
76,"Processing of the point cloud data significantly improved the estimation of total and shrub AGB using coarser scales (7 m, 30 m and 100 m) in comparison to the raster image processing (based on R2 and RMSE, Table 3 and Table 4). However, 1-m scale point cloud and raster image processing provided nearly equivalent estimates of 1-ha plot average biomass. At the 1-m scale, the rasterization approach incorporates fewer points outside of the pixel boundary (and in close proximity). Furthermore, rasterization at 1 m had a greater probability of aligning with field plots and was less influenced by values from adjoining pixels in comparison to coarser pixel sizes. The similar RF regression model results indicate that the rasterization method preserves most of the 3D point cloud vegetation characteristics and thus is essentially equivalent to using point cloud data at the 1-m scale. At coarser raster scales, we attribute the declining results to boundary effects and alignment with field plots.In contrast, the pixel size in which point cloud processing was performed had negligible effects on the total and shrub AGB estimation. There is almost no loss of detail while extracting or averaging information from the original point cloud. Furthermore, the point cloud processing significantly reduced the RMSE at all scales in comparison to the rasterized approach. However, based on the R2 alone, at a 1-m resolution, the point cloud processing was not significantly different to raster data processing. The coarse-scale raster results may be more representative of expected results from large footprint Lidar than the point cloud analyses. This is because a large footprint Lidar is an integrated waveform (or photons in the case of ICESAT-2) of the canopy profile over the entire footprint.The bias in in-situ data also introduces uncertainty into the biomass models. As shown in Figure 2, averaging the biomass from the subplots to obtain the in-situ plot level biomass takes into account areas of no sampling in the outer 30-m buffer of the subplots. Because the predictors will adapt to the attribution space of the training samples [60], the RF imputation includes similar uncertainties as those in the training samples. This is likely the reason behind the appearance of the long linear features of a relatively high biomass in the resulting imputation map (Figure 5 and Figure 6). Although the average biomass over the nine 1-m subplots may represent herbaceous and small shrubs across a 1-ha plot (e.g., [48]), error in the field data may have been introduced because of relatively larger shrubs close to the subplot edge which were not fully accounted for in the field sampling. Moreover, estimating the biomass from Lidar without corresponding species level classification can be a disadvantage when different species have similar structural arrangements but substantially different AGB (e.g., in this landscape, low-AGB nonnative forbs, such as tumble mustard, can be incorrectly quantified as shrub, [39]).", 5. Discussion, 5.1.1. Uncertainty,5
77,"Previous research in similar ecosystems has shown volume (e.g., [61,62,63]) or the approximation of volume (the product of basal area and height or the product of percent vegetation cover and height) (e.g., [16,64]) to be a strong proxy of shrub biomass. A related study by Li et al. [16] compared percent cover and height, but did not account for height variability metrics in their linear regression model to estimate biomass. Their results showed that the percent cover of shrubs was the best predictor for biomass. Yet in our sparse vegetation area, height variability-related metrics (including Hstd, HAAD, and HMAD) scored higher than other predictors for both total and shrub biomass in all RF models, with high R2 and low RMSE values. Considering the Lidar acquisition parameters in this study as equal to those in Li’s study [16], a higher number of Lidar returns from the vegetation canopy will occur in denser and larger shrubs (represented in the study in [16]) compared to the sparse canopies with smaller shrubs in our study. Vegetation Lidar returns are also more likely to be mixed with those of annual grasses, perennial bunchgrasses, litter, or bare ground in our study area. Hence, shrub height underestimation is likely more pronounced in this study due to constraints related to the laser pulse length [24,26,65,66]. Yet the variability of height may still be sufficiently captured by the Lidar to represent the spatial pattern of biomass with smaller shrub canopies in our study site.In this study, five predictors (Hstd, HAAD, HCV, Hrange, and FHDall) at the 1-m scale explained roughly 76% of the variability in shrub AGB (Table 3) in the optimal RF regression model. For the RF model for shrub biomass, the remaining 24% error may be credited to uncertainties associated with sparse vegetation distribution, the misclassification of canopy as ground, and the underestimation of the vegetation height [24,67]. Similar results were found by Estornell et al. [68] in a Mediterranean shrubland ecosystem. In their research, the median height, standard deviation of height, and percentile of height derived from airborne Lidar were the best predictors, explaining up to 78% and 84% of variability for biomass and volume, respectively. Greaves et al. [17] also reported a similar finding in an arctic shrubland, in which Lidar volume and canopy metrics coupled with vegetation indices from optical data explained roughly 71% of the variability of shrub biomass.Given the prominence of Hstd in the SMR and RF models, we further tested the ability of Hstd alone to estimate AGB biomass. Using univariate linear regression, we found that Hstd explained 73% and 71% of the variance of total and shrub AGB, respectively (Figure 8). While this relationship is likely oversimplified and the model fit is erroneous at low shrub biomass estimates, it is interesting to conceptualize that a vegetation roughness measure may coarsely approximate biomass. Notably, previous studies in this ecosystem have found vegetation roughness to be a proxy for classifying sagebrush [69] and sagebrush heights [24].In sum, most of the shrub biomass models were based on variables associated with vegetation structure (e.g., height and cover) and related metrics (e.g., standard deviation of height and percentile of height). In this study, the complexity of the RF model made interpreting the model challenging, but demonstrated the non-linearity of the relationship between biomass and its related driving variables, while also providing a variable importance to better understand the nature of the relationships.", 5. Discussion, 5.1.2. RF Regression Model Variables,5
78,"Both RF and SMR have been widely used in ecology [70,71] and remote sensing [40,50]. As a non-parametric machine learning method, RF has no formal distributional assumptions. It approaches the issue of non-linearity by using numerous trees and the “small observations large predictors” problem. However, when the trees become larger (e.g., due to a larger number of input variables), the resulting models are more difficult to interpret, resulting in a dynamic predictor set when the training data change a little. As shown in Table 3 and Table 4, the best RF model with metrics using point cloud processing has different important predictors from the best RF model with metrics using raster processing, even at a fine resolution. On the other hand, there are also limitations associated with SMR [70]. For example, SMR assumes a normal distribution of the error between observed and predicted values (i.e., the residuals of the regression) and that there is no multicollinearity in the predictor variables. Also, in linear regression, the constant value of predictor(s) will result in constant biomass values; yet different shrubs may have the same biomass but different 3D structures [17]. In addition, a common assumption is that a large number of predictors will require a large number of observations, otherwise the linear regression may fit the randomness that is inherent in most datasets. Interestingly, the best SMR model was more parsimonious (two predictors) than the best RF models (e.g., five predictors for shrub biomass) and had high model R2; and the two predictors in the best SMR model were included in the five important predictors in the best RF model. Yet, a high variable importance of an input variable (HAAD) in RF was not included in the SMR. This result may indicate that this variable represents interactions that are too complex to be captured by parametric regression models or simply because of correlation between the variables. If the former is true, RF’s non-linear model fit for biomass may be more appropriate as biomass is not controlled simply with one or two driving variables but a complex environment. Moreover, the RF model constrains predicted biomass within the range of the observed biomass (in comparison, SMR may represent invalid biomass values when the value of predictors is beyond the model range). Based on the results of this study, and understanding that advantages and disadvantages exist with most statistical representations, we recommend exploring a number of statistical approaches that may shed light on the behavior of the response variable, as well as the relative importance of predictor variables.", 5. Discussion, 5.2. Model Performances of RF and SMR,5
79,"Our imputation models estimated mean shrub biomass values of 51 ± 126 g/m2 and 60 ± 149 g/m2 with 2013 Lidar and 2012 Lidar, respectively. While there are not many studies in similar xeric sagebrush-steppe ecosystems to compare these results to, our estimates are similar to those by Uresk et al. [72]. They estimated the total phytomass of big sagebrush in Eastern Washington to be 69 g/m2 when they converted the individual sagebrush biomass to area based on density. As a comparison, Brown [73] estimated much higher shrub biomass values in Montana and Idaho, ranging from ~55 to 1490 g/m2, but their numbers are based on intact big sagebrush sites that included relatively mesic locations with mountain big sagebrush (A. t. vaseyana). Cleary et al. [74] estimated shrub biomass in Wyoming to be ~655 g/m2, also in mountain big sagebrush. They also converted their individual biomass estimates to mass per area based on density. It is important to note that our shrub biomass estimates (in a consistently arid landscape) included scattered shrub species other than big sagebrush.All things considered, there is a significant gap in baseline data on aboveground biomass across a range of growing conditions in sagebrush ecosystems, that can be used for fuel management and restoration. Our imputations provide the first spatially-explicit Lidar estimates of biomass across rangelands in the Great Basin and in more xeric conditions, in general. Considering that the areas of Lidar acquisition in this study are representative of the larger NCA, our estimates of shrub biomass of 51–60 g/m2 may be used as a baseline for the larger NCA. However, additional field and Lidar data are necessary to develop models across larger areas representing more diverse growing conditions.Biomass estimates of the herbaceous cover class were not well predicted at any scale in this study. The low predictive power was likely caused by the lack of signal (returns) in the Lidar from the short herbaceous community. Due to the complexity of the 3D structure in shrub-grass mixed compositions, Lidar-derived metrics may have more variability or even the same biomass values that were observed for some field plots. In the RF attribution space, the variability of metrics led to more variations of biomass predictions among the RF trees and led to more uncertainties (higher CV). A previous study in a similar environment demonstrated that spectral information can represent herbaceous communities well [41]. Therefore, the synergistic use of multispectral and hyperspectral data is likely to fill the deficiencies of herbaceous biomass estimates with Lidar data [50]. In addition, the total biomass estimates, which include the herbaceous class, are likely skewed by the high performance of the shrub biomass. Thus, to develop a strong model of total biomass, challenges associated with estimating herbaceous biomass will need to be overcome.", 5. Discussion, 5.3. Broader Application of the Imputed Shrub Biomass,5
80,"Lidar coupled with field training data explained more than 74% of the variance in shrub biomass in this shrub-steppe ecosystem. Further, the use of point cloud processing reduced uncertainties between 5% and 15% of the mean biomass at scales coarser than 1 m. Whereas rasterization is much easier to perform, we warn that it should only be used when the Lidar data can support fine scale pixel sizes (e.g., 1 m in studies similar to ours). Further development of analysis tools for Lidar point cloud processing, including efficient data processing (e.g., [42]), will encourage the use of point cloud processing over raster processing.Our results are sufficiently robust to support the contiguous mapping of biomass at the regional scale using Lidar-derived vegetation metrics coupled with machine learning RF. Further validation of the imputation maps can be conducted with additional data captured manually or with TLS (terrestrial Lidar) or UAS (unmanned aerial systems). As Lidar becomes more readily available through programs such as USGS 3DEP and from GEDI and ICESAT-2, future studies in the Great Basin and similar dryland ecosystems can implement our approach to estimate biomass. The use of height variability/roughness or percent vegetation cover in the RF models could be selected on the basis of the shrub structure (e.g., cover, height, density) observed in field plots. Lidar can also be used to map biomass in areas of pinyon-juniper (e.g., [75]), aspen (e.g., [76]), and coniferous communities (e.g., [35]), thus collectively providing biomass estimates across common community types in the Great Basin. These Lidar-derived biomass maps coupled with biomass estimates of herbaceous cover from optical data (e.g., [50]) will provide the necessary level of detail and accuracy to make effective management decisions relevant to SO 3336 and other directives. Quantification of biomass in this and similar rangelands can be applied to modeling vegetation dynamics, estimating pre-fire and post-fire fuel loads, measuring carbon storage, assessing habitat quality, and quantifying changes in native species. The next steps for this important region are to integrate multi-source and scale data (airborne Lidar, imaging spectroscopy, time-series multispectral imagery) to extend the biomass estimates across the wider Great Basin.", 6. Conclusions,None,6
81,"Boreal ecosystems of northwestern Canada store approximately 2.1% of the global terrestrial carbon (C) on 0.3% of the global land surface area [1]. Therefore, the global atmospheric climate-C cycle is tightly coupled to the changing C dynamics of northern boreal ecosystems [2]. For effective emissions targets and mitigation strategies, it is essential to reduce the high uncertainties of the C balance of unmanaged boreal ecosystems [2,3]. However, C accounting of unmanaged boreal ecosystems is challenging because these ecosystems are changing at unknown rates due to (1) the cumulative impacts of interacting climate-mediated and anthropogenic disturbances [4,5,6,7,8] and (2) the enhanced frequency, intensity, duration, and timing of these disturbances. For example, in boreal ecosystems of northwestern Canada the vegetation structure and composition has changed significantly towards increased abundance of shrubs [9,10] and short-stature low productive or juvenile trees. This is in particular the case where ecosystems were set back to an early successional stage post wildland fire disturbance [11] or in the rapidly changing transition zones between elevated forests and adjacent peatlands due to permafrost thaw [8]. This in turn has significant effects on ecosystem function and ecosystem-atmosphere interactions at local to regional scales [8,11] as well as at national to global scales [12,13]. For example, prominent shrub and broadleaf tree growth in, e.g., post-fire vegetation succession is likely the explaining factor for returning production levels to an annual net C uptake within 10 to 15 years post burn (e.g., [12,14,15]). However, boreal shrubs and short-stature trees are not integrated into C accounting strategies. This is because of a lack of available spatially explicit structural and quantitative information on boreal shrub and short-stature tree species, as discussed in our related study [16]. Therefore, aboveground biomass (AGB) allocation data for shrubs and short-stature trees are necessary to better understand the contributions of different plant components to the standing stocks of AGB and aboveground C in this region, while plant component AGB allometric equations for shrubs and short-stature trees provide a means to improve modeling of AGB and aboveground C pools.Consequently, the first objective of this paper was to describe and discuss the proportion of plant component AGB for boreal shrub and short-stature tree species. Plant components were separated into stems, branches, and leaves. The second objective was to provide allometric equations for estimating aboveground biomass of plant components of shrubs and short-stature trees. This paper is a follow-on study on shrub and short-stature tree total AGB allometric equations [16]. While in the previous study [16] we focused on total AGB allometric equations using 1D, 2D, and 3D predictor variables, in this study we analyze the AGB allocation to different plant components and provide plant component-specific allometric equations leveraging the same field data as described by Flade et al. [16]. The plant component data provided in this study is a crucial next step towards improved C pool partitioning required for improved C accounting strategies for unmanaged boreal ecosystems of northwestern Canada [3].", 1. Introduction,None,1.
82,"Plant component AGB was derived from shrubs and short-stature trees growing in the mid-boreal Taiga Plains and high-boreal Taiga Shield ecoregions of the Northwest Territories (Figure 1). The climate in this region is characterized by cold mean annual air temperatures, ranging from −2.5 °C near Fort Simpson (Taiga Plains) to −3/−4 °C near Yellowknife (Taiga Shield). The area receives between 360 mm (Yellowknife) and 390 mm (Fort Simpson) cumulative annual precipitation. The genera and species sampled are Alnus spp., Betula spp., Dasiphora fruticosa, Salix spp., and Shepherdia canadensis, which represent common boreal shrub genera/species in this study area. Common boreal tree genera/species sampled are Betula papyrifera, Picea glauca and mariana (combined to Picea spp.), Populus balsamifera, and Populus tremuloides [17,18].", 2. Materials and Methods, 2.1. Study Area,2
83,"A total of 206 shrub and 105 tree individuals were measured and destructively sampled at 65 different peatland and forest sites. In order to capture the various stages of boreal ecosystem succession in our field data, field sampling locations were situated in late successional sites and in sites disturbed by wildland fire within the last 50 years. For a detailed field sampling plan, we refer to our previous study [16]. Trees were sampled within the last two weeks in July 2019, while shrubs were harvested during the late July/early August period of 2018 and 2019. Therefore, shrub foliage might show higher variability compared to tree foliage due to the potential influences of changes in phenology. Shrubs and short-stature trees were destructively sampled from the understory and open areas across different height ranges determined in intervals of 0.5 m up to ≤4.5 m. A plant individual was selected for harvest when it was alive and mostly free of foliage disturbance/mortality and stem blemishes. Following measurements in situ [16], plants were clipped directly above the soil surface and stored in paper bags for further processing. Dead stems were not harvested. In the laboratory, harvested plants were air dried for up to 4 months and separated into stems, branches, and leaves. All plant components were oven dried at 60 °C for a minimum of 48 hrs. Constant mass was confirmed by weighing the largest plant individuals at multiple times post drying. Twigs and fruits were counted to the leaf component, while bark was included as part of the stem. For trees, branches were cut off directly at the stem. Shrubs did not develop distinctive branches and were separated into leave and stem components only. The total AGB for shrubs and trees was determined as dry weight (g) by weighing each plant component and summing the dry weight of all components per individual plant. In this study, we present measured plant component AGB as a percentage of the total AGB per plant genus/species. ", 2. Materials and Methods, 2.2. Plant Destructive Sampling,2
84,"We derived AGB allometric equations for each plant component per plant genus/species as well as all shrub genera/species (multi-species shrubs) and tree genera/species (multi-species trees) combined. The methods follow the same procedures used to determine total AGB in [16]. The in situ structural measurements of harvested shrubs and trees used to determine the most accurate AGB predictions were volume for shrubs and cross-sectional area for trees [16]. Volume was derived by measuring the extent of the upper-most foliage layer perpendicular to the transect (herein ‘width’ [m]) and parallel to the transect (herein ‘line-intercept cover’ [m]) using a tape measure. The 3D shrub volume [m3] was then calculated as


Volume [m3] = maximum height [m] × line-intercept cover [m] × width [m].


(1)

For short-stature trees, cross-sectional area [cm2] was derived from the measured stem diameters. Stem diameters were measured at 0.30 m along the stem length starting from the average ground surface surrounding the tree [16]. Highest model fits were derived using iterative non-linear least squares regression (herein ‘NLS’) via a power function:




y
=
β

x
α

+
ε





(2)


where 
y
 is the dependent variable, 
x
 is the independent in situ variable (volume for shrubs and cross-sectional area for trees), α and β are the regression coefficients, and 
ε
 is an additive error term, as discussed by Flade et al. [16]. Because our AGB data showed uniform variances on arithmetic scales for most species as well as on logarithmic scales for all species, we did not apply weights to our models. In order to address potential heteroscedasticity in shrub and short-stature AGB data, we also developed ABG allometric equations using linear logarithmic regression with correction (herein ‘LLRC’): 



l
n

(
y
)

=
l
n

(
β
)

+
α
×
l
n

(
x
)

+
l
n

(
ε
)





(3)





y
=
β

x
α

×
ε




(4)





ε
=

e


(



M
S
E

2


)







(5)


where 
ε
 represents a multiplicative correction factor (CF) of the back-transformed arithmetic values, derived with 

M
S
E

 as the mean square error of the regression [16,19,20]. The modeled biomass results were evaluated using root mean square error (RMSE), coefficient of determination (R2), and regression residual analysis. Residual analysis was performed using visual inspection of the relationships between dependent and independent variables. Regression coefficients are reported with standard errors. ", 2. Materials and Methods, 2.3. In Situ Measurements and Plant Component Aboveground Biomass Allometric Equations,2
85,"The amounts of harvested individual plants per genus/species and descriptive statistics of measured plant component AGB are provided in Table 1. The percentages of the measured AGB per plant component is provided in Figure 2. We found similar plant AGB for leaves and stems for all five shrub genera/species, ranging from 15% (Alnus spp.) to 19% (Betula spp.) for leaves, and from 81% (Betula spp.) to 85% (Alnus spp.) for stems, respectively (Figure 2a). Similarly uniform was the measured plant component AGB for deciduous tree species, ranging from 10% (Betula papyrifera) to 16% (Populus tremuloides) leaf biomass, 12% (Populus tremuloides) to 17% (Betula papyrifera) branch biomass, and 72% (Populus tremuloides) to 77% (Populus balsamifera) stem biomass (Figure 2b). The measured plant component AGB of the evergreen Picea genus had lower stem biomass (49%) and higher branch (27%) and leaf (25%) biomass compared to the deciduous tree and shrub genera/species. This finding can be explained by the thick and often longer branches of the sampled Picea plants in comparison to the branches of short-stature deciduous tree species. We further found that the biomass of leaves and branches combined (52%) was approximately equal to the stem biomass (49%) of the Picea genus. Although biomass allocation changes with tree size and age (e.g. [21,22]), Petersson et al. [22] reported approximately 45% combined leave and branch biomass and 40% stem biomass (including bark) for 11 to 20 year old Pinus sylvestris stands in Sweden, while Johansson [23] derived a mean stem biomass proportion of 56% for 17 to 54 year old Picea abies stands growing on abandoned farmland in Sweden. In addition, we found that all five shrub genera/species had similar AGB allocations comparable to the three deciduous tree species.The variability of measured plant component AGB per shrub and short-stature tree genus/species is depicted in Figure 3a–g, respectively. From the five shrub genera/species sampled, Alnus spp. and Betula spp. were similar and showed greater variation compared to Dasiphora fruticosa, Salix spp., and Shepherdia canadensis. This differs from the findings of, e.g. He et al. [24], who found greatest structural differences between Alnus spp. and Betula spp. However, in our study Betula spp. showed greater differences in leaf biomass compared to all other genera/species, which is similar to the reported differences in total AGB of the Betula genus by the same authors [24]. In addition, we found similar structural growth forms of Alnus spp. and Betula spp. as reported by Lantz et al. [25] and Moffat et al. [26] for Arctic environments. Alnus spp. had stems growing in an outward radiating form, while both Alnus spp. and Betula spp. developed long shoots. However, Salix spp. was the dominant species in our study area compared to Betula nana dominance on lichen plots found in the Tuktoyaktuk coastland tundra [26]. Our study results showed further that Salix spp. had a lower median of stem biomass and more outliers compared to the other four genera/species. This might not only be due to greater structural variability of this genus, but also due to the larger sample amount (n = 79, Table 1), which increases the sampling of a greater range of structural variation. However, Salix spp. was the dominant genus at our field locations, and therefore, the larger sample amount represents the naturally dominant occurrence of Salix spp. in our study area. For deciduous short-stature tree genera/species, stem, branch, and leaf biomass (Figure 3d–g) showed similar variation, while Picea spp. had greater ranges, outliers, and medians for stem, branch, and leaf biomass, as previously described (Figure 2b). In addition, it needs to be mentioned that influences of phenological changes could be the reason for slightly greater shrub foliage AGB variation compared to deciduous tree foliage AGB variation, due to the measuring period of shrubs extending into early August (Figure 3c,g).These findings suggest that short-stature deciduous tree genera/species may be combined with shrub genera/species as input into C allocation or terrestrial primary production models. However, model results might be improved when short-stature evergreen tree genera/species are analyzed separately, as already suggested by, e.g. Gower et al. [27], because these plant types differ in C budget processes, such as net primary production and C allocation [27,28,29], as well as percentage of plant component AGB. In addition, variations in plant traits, such as dry matter of leaves, adult plant height, leaf area, seed mass, leaf mass per area, and leaf nitrogen, vary among species as well as within species, in particular at local scales and in areas of low species richness (e.g., [30]). This suggests a need to additionally incorporate plant trait information in earth system models to improve understanding of the responses of plant communities, e.g., in ecosystem function and community assembly, to climate-mediated changes of environmental conditions [30]. The data used in this paper, does not provide the complete list of plant trait information, however, the plant component information might be useful as a first step towards improved earth system models in northern boreal environments. ", 3. Results and Discussion, 3.1. Measured Plant Component AGB,3
86,"Regression coefficients and error statistics for the modeling of plant component AGB are provided for each genus/species as well as for multi-species shrubs (Table 2) and short-stature trees (Table 3). Because we found different AGB allocation of Picea spp., we also provided one combined component model for all deciduous tree species excluding Picea spp. (herein ‘reduced hardwood tree model’) (Table 3). Modeled total AGB that was derived by the sum of the single component AGB models was on average 0.13 g ± 1.67 g standard deviation (0.03% of modeled mean total AGB) higher for shrubs, and 1.88 g ± 1.09 g standard deviation (0.67%) higher for tress respectively, compared to the total AGB model results.For shrub component AGB, we achieved better model fits for stem biomass (60.33 g ≤ RMSE ≤ 163.59 g; 0.651 ≤ R2 ≤ 0.885) compared to leaf biomass (12.62 g ≤ RMSE ≤ 35.04 g; 0.380 ≤ R2 ≤ 0.735) for each genus/species as well as for the general multi-species shrub model using the three-dimensional predictor variable volume. Higher prediction errors of leaf and branch biomass models vs. stem biomass models have been found as well by Lambert et al. [31]. However, except for Shepherdia canadensis, R2 are above 0.5 for all other genera/species and multi-species shrubs (Table 2). For short-stature trees, leaf biomass predictions using cross-sectional area as the independent variable resulted in similar model fits (18.21 g ≤ RMSE ≤ 70.0 g; 0.702 ≤ R2 ≤ 0.882) compared to branch biomass (6.88 g ≤ RMSE ≤ 45.08 g; 0.736 ≤ R2 ≤ 0.923) and only slightly better model fits for stem biomass (30.87 g ≤ RMSE ≤ 11.72 g; 0.887 ≤ R2 ≤ 0.960) for each genus/species as well as the general hardwood and multi-species tree models (Table 3). This suggests that leaf biomass can be predicted using cross-sectional area as an independent variable for short-stature trees, leading to better results as the prediction of leaf biomass of tall-stature trees (diameter at breast height (DBH) > 9 cm) using DBH as an independent variable (e.g., [31,32]). Due to the different AGB allocation of Picea spp., we derived a reduced hardwood tree model including only the remaining hardwood tree species, as explained above. For this reduced hardwood tree model however, we did not receive better overall model fits (0.760 ≤ R2 ≤ 0.887) compared to the full model that includes all tree genera/species (0.767 ≤ R2 ≤ 0.940). In fact, model fits for stem and branch biomass were better for the full multi-species tree model. However, model fits for leaf biomass improved using the reduced hardwood tree model (Table 3).The inspection of dependent vs. independent variable for the multi-species shrub and tree component models (Figure 4a,b) as well as the standardized residuals (Figure 4c,d) showed higher residuals of modeled leaf biomass compared to stem biomass for shrubs, while residuals were relatively homogeneous across all three modeled plant components for trees, as indicated by the goodness-of-fit metrics discussed above. For shrubs, the highest residuals were attributed to four shrub genera/species excluding Sheperdia canadensis, while the highest tree residuals corresponded to Picea glauca as well as mariana. Although this might imply that the multi-species tree component AGB models were mainly fit to Picea spp., we did not find higher residuals for smaller tree species in the multi-species component models. We achieved similar results with LLRC (not shown). This suggests that our multi-species models may have utility for using less invasive observation techniques (e.g., unmanned airborne vehicles or laser scanning) where vegetation species and type may be indeterminate. Furthermore, our genus/species-specific as well as multi-species models for predicting single plant component AGB may be well suited for scaling plant component and total AGB of shrubs and short-stature trees to the sporadic to discontinuous permafrost zones of the Taiga Plains and Taiga Shield ecozones of boreal northwestern Canada.", 3. Results and Discussion, 3.2. Modeled Plant Component AGB and Allometric Equations,3
87,"In this study we describe plant AGB allocation to leaf, branch, and stem components as well as plant component AGB allometric models for common boreal shrub and short-stature tree genera/species (<4.5 m height above ground) found in boreal northwestern Canada. We found similar AGB allocation to stems, branches, and leaves of shrubs and deciduous tree genera/species across our study region, while the sampled evergreen Picea genus differed in the AGB allocation to the aboveground plant components. Our plant component AGB allometric models showed better model fits for stem biomass compared to leaf biomass for shrubs. For short-stature trees, leaf biomass predictions resulted in similar model fits compared to branch biomass predictions with slightly better model fits for stem biomass predictions. In addition, our multi-species allometric models for shrubs and short-stature trees might be utilized for remote sensing techniques that do not allow to distinguish between plant functional types. This dataset and equations are a useful next step for integrating shrubs and short-stature tree AGB into C accounting strategies in order to improve our understanding of the rapidly changing boreal ecosystem function of forest and peatland ecosystems within the sporadic to discontinuous permafrost region. This provides an improved ability to develop full ecosystem models in the most climatically vulnerable and changing ecosystems found in the northern hemisphere.", 4. Conclusions,None,4
88,"Forest fires and carbon accounting are tightly interrelated areas of interest with critical importance for sustainable forest management [1,2]. Detailed spatial information about forest fuels and biomass accumulation in the forest are necessary to guide decision-making processes in these areas [3,4,5]. However, forested areas are typically large and remote, and obtaining this information using only field measurements is an expensive or inefficient option for many applications. For example, national forest inventories, such as the US Forest Inventory and Analysis (FIA) program [6], are able to provide accurate estimates of different forest attributes for large territories such as states or counties using only ground data [7]; however, that level of spatial detail is too coarse to be used in stand-level forest management problems or in fire-behavior simulations.Prediction of forest attributes using remotely sensed auxiliary information allows obtaining cartographic products with fine resolution with fine resolution, in the range of 10 to 30 m, that can be used in a wide array of forest-management scenarios. In particular, airborne laser scanning (ALS) or airborne LIDAR data provide auxiliary information that is highly correlated with a number of forest structural attributes such as above-ground biomass (AGB), total standing volume, basal area, dominant height, diameter distributions, tree-height distributions, and diversity indexes [8,9,10]. ALS auxiliary information has been shown not to suffer from saturation problems associated with optical datasets such as Landsat imagery when predicting AGB [11,12,13,14,15,16,17]. Furthermore, ALS data have also been used to reliably predict forest fuel attributes that can be used as inputs to fire-spread models [18,19,20].Besides forest-structure mapping, ALS data can be used for numerous applications such as deriving high-resolution digital terrain models and topographic indices [21,22], mapping human infrastructures [22,23] or improving information about hydrological networks [24,25]. Considering the large set of applications for ALS data, many countries and public agencies have coordinated efforts to obtain state- or country-wide coverage of ALS data. None of the western United States yet have complete ALS data coverage; however, they are continuously increasing their ALS data availability. New ALS data collections in these states cover areas of variable size, which results in a steadily increasing patchwork of areas with available ALS data that capture a broad range of forest conditions [26].Prediction of forest attributes using ALS data is typically performed using supervised methods that require matching ALS auxiliary information with observations of the target responses taken in field plots without a sizable temporal offset with respect to the ALS data acquisition. The data collected by the FIA program can be used to model forest structural attributes using available ALS data in this manner. However, the discontinuous nature in space and time of the ALS data acquisitions, in combination with the ten-year rotating panel design of FIA in the western US, causes challenges for an operational methodology to produce cartographic products that forest managers can use. Some ALS data acquisition projects are small, such that too few FIA plots are available to perform any modeling exercise. For larger areas, it is possible to develop acquisition-specific models once an ALS data collection is completed. However, modeling requires considerable time and hence delays for the delivery of maps of structural attributes to forest managers—e.g., for fire-related applications—and these delays can imply obtaining inputs for fire-spread simulators only after the fire season has finished. A potential solution to these problems is developing models that can either be: (1) directly transferred to new ALS data collections, or (2) calibrated for new ALS acquisition projects using a potentially small sample size.Directly transferring a model to a new ALS data collection is a very fast way to generate cartographic products for ALS data acquisitions. As long as the covariates needed for a model are available, generating new maps of forest structural attributes only involves generating predictions from a pre-fitted model. However, this direct transfer, oftentimes referred as synthetic prediction, may involve extrapolations or applying a model to conditions not included in the training dataset, which in turn, can result in significant bias problems. These potential bias problems have been investigated by [27,28,29]. In particular, [28] found bias issues for basal area and stand density when synthetic predictions were respectively used in 33% and 50% of the ALS acquisitions under analysis. A potential solution to these bias problems is localizing pre-existing models to the conditions of a new ALS acquisition through calibration [30]. Calibration is typically based on using mixed-effect models [31] with a fixed component that accounts for the general relationships in the population (i.e., a region) between auxiliary information and response, and a random-effects component that models the variability between subgroups of the population (e.g., particular ALS acquisitions within a region). Once models are fitted, calibrating them to the conditions of a new ALS data acquisition results in a significant reduction in modeling effort because it is only necessary to estimate the random effects for the new ALS acquisition under consideration, which can be done with small sample sizes and eliminates the need to fit new models.Linear and nonlinear mixed-effects models can be readily calibrated and appear as appealing modeling alternatives to reduce the time needed to obtain maps of forest attributes once a data collection is completed. Nonparametric modeling methods such as k-nearest neighbor imputation [32,33,34], gradient nearest neighbor imputation [35], and random forest [36,37,38] have been extensively used to predict forest attributes from remotely sensed auxiliary information in the last decade. However, the flexibility of these nonparametric methods, that impose no structure in the model errors, makes it impossible to calibrate pre-existing models to new data collections. Nonparametric models can be modified with parametric assumptions about the structure of the model errors [39,40]. These modifications result in semiparametric models that combine flexibility in modeling nonlinear patterns of the nonparametric techniques they are based on, with the possibility of calibrating predictions. Nothdurft et al. [40] proposed combining a k-NN model, fit to obtain population means conditional on a given set of covariates, with a mixed-effects model for the variability not explained by the k-NN model. This method allowed calibrating predictions from the k-NN model to subpopulations of stands. This approach can be applied to the problem of calibrating pre-trained models for new ALS data collections; however, to the best of our knowledge no previous studies exist on this topic.Finally, models to predict forest attributes from ALS data are typically developed using predictors or metrics derived from the point clouds enclosed in the areas where measurements were taken [41,42]. However, in some operational scenarios direct access to point-cloud data may not be available; i.e., when only gridded summaries of ALS predictors are readily available. Furthermore, sharing gridded products over the internet is more common and demands far fewer resources than sharing point-cloud data. If the accuracy and precision of models developed by extracting predictors for the field plots from pre-rasterized products are not substantially worse than the accuracy and precision of models developed with predictors computed for the point clouds enclosed in field plots, then a workflow entirely based on rasterized products can be a more tractable option for many applications. For example, when modelers do not have the knowledge or technical infrastructure to process point-cloud data, or when it is necessary to unify broad sets of ALS acquisitions. We are not aware of any existing research on this matter, despite the practical justification and need.This study is developed with the aim of obtaining insights for a regional strategy that allows using information from available ALS data acquisitions for rapid mapping of multiple attributes desired by forest and fuel managers in new ALS project areas. With that overarching objective, we focused our analysis on the state of Oregon and analyzed two sets of response variables. Based on their importance for carbon accounting purposes, the first set of variables consisted of AGB and downed wood biomass (DWB); i.e., the sum of coarse and fine woody debris. The second set of variables contained canopy bulk density (CBD), canopy height (CH), canopy base height (CBH), and canopy fuel load (CFL), chosen because they are inputs for fire-spread models such as Flammap [43,44,45,46] that are widely used by fire and fuel managers. For each response, we analyzed:Transferability and effect of calibration. Comparisons focused on analyzing differences in accuracy and precisions between synthetic predictions and predictions obtained using the same models but performing an additional calibration step with available ground and ALS data. We will refer to this factor in the following sections as “calibration”.Differences between modeling techniques. Comparisons focused on analyzing differences between parametric linear mixed-effects models and semiparametric models. We will refer to this factor in the following sections as “modeling technique”.Differences between models using a different source of ALS metrics. Comparisons focused on analyzing differences between models using ALS predictors computed from point-clouds clipped around the training plot footprints, i.e., point-cloud predictors, and models using predictors extracted from raster layers, i.e., rasterized predictors. We will refer to this factor in the following sections as “source of predictors”.", 1. Introduction,None,1.
89,"Eight ALS data acquisitions collected by different agencies in the state of Oregon during the period 2008–2016 were used in this study (Figure 1). These acquisitions covered the main forested areas in the state and included areas of temperate coastal coniferous forest, areas with Mediterranean influence in the south of the state, mountain areas on the Cascades range, and drier and more continental forest ecosystems east of the Cascades mountains. The area, completion year, flying altitude, sensor information, return density and number of field plots available for each ALS acquisition are indicated in Table 1.For all acquisitions, 30 m resolution rasters containing the ALS metrics indicated in Table 2 were available. The ALS predictors only included descriptors of the distribution of the ALS point cloud such as percentiles or moments and proportions of returns in height categories. For each FIA plot we obtained two sets of ALS predictors. The first set, “rasterized” predictors, was obtained by intersecting the FIA plot center location with the rasters containing the ALS metrics. The second set, “point-cloud” predictors, was obtained by first clipping the points inside the four macro-plots of each FIA plot. Then, for each FIA plot we normalized the point cloud with digital terrain models (DTMs) provided by the vendor of each ALS data acquisition using the R-package lidR [47]. Once normalized, metrics for each FIA plot were computed using FUSION [48]. An extended analysis for the factors: (1) transferability and effect of calibration, and (2) modeling technique, including 12 additional ALS acquisitions where only rasterized predictors were used is presented in Appendix A.In addition to the ALS predictors, we used topographic and climate predictors listed in Table 2 in the models for the selected responses. Topographic predictors were derived from a DTM derived from the Shuttle Radar Topography Mission and climate predictors were obtained from the Climate-FVS Ready Data Server [49]. Both topographic and climate indexes were rasterized at a 30 m resolution and a grid that aligned with the grids containing ALS metrics. For each FIA plot, topographic and climate predictors were obtained intersecting the FIA plot center with the corresponding raster layers.", 2. Materials and Methods," 2.1. ALS Data Acquisitions and ALS, Climate, and Topographic Metrics",2
90,"Ground data to train models was obtained from the FIA database [50]. Coordinates of FIA plots were obtained using mapping-grade GPS units. To the best of our knowledge no study has analyzed directly the reliability of the GPS coordinates of the FIA database in the study area, but based on previous experiences [51,52] the errors are expected to have accuracies in the range of a meter and maximum location errors are expected to be in the range of 5 to 10 m [53]. Following [26], only those FIA plots that were measured at most three years before or after each ALS data acquisition project was completed were used. In addition, any plots presenting any sign of disturbance between the plot visit date and the completion date of their corresponding ALS data acquisition were removed from the dataset. For each one of the remaining FIA plots, AGB per hectare were computed by aggregating tree-level AGB provided in the FIA database with their corresponding expansion factors [50] (Table 3). Estimates of DWB per hectare were obtained for each FIA plot condition class and weighed by the transect length of the appropriate condition class. Finally, values of CBD, CH, CBH and CFL were obtained for the FIA plots using the FireCalc program [54] and the tree-lists of the FIA plots as inputs (Table 3).", 2. Materials and Methods, 2.2. Ground Data and Response Variables,2
91,"Parametric models for AGB, DWB, CBD, CH, CBH, and CFL, were linear mixed-effects models with random intercepts and slopes for each ALS data acquisition. The general form of these models is





y

i
j


=

x

i
j

t


(

β
+

v
i


)

+

e

i
j


,




(1)


where 


x

i
j



 is a p-dimensional vector with the first element a 1 and the p-1 remaining elements being the values of p − 1 covariates for the 


j

t
h



 plot in the 


i

t
h



 ALS data acquisition, 
β
 is a p-dimensional fixed-effect parameter vector, 


v
i


 is a p-dimensional vector of random effects for the 


i

t
h



 ALS data acquisition, and 


e

i
j



 is an additive model error. The random effects 


v
i


 were assumed to be normally distributed with a variance–covariance matrix 

G

(


δ
v


)


 with 


δ
v


 a vector of variance–covariance parameters that is the same for all ALS data acquisitions; i.e., 


v
i

~
N

(

0
,
G

(


δ
v


)


)

 
∀
 
i
.

 Model errors were also assumed to be normally distributed, but we allowed for nonconstant error variances. The variance of the model errors was assumed to be proportional to a power 
α
 of the predictor most correlated with the response, 

m
c

p

i
j



. That is, 


e

i
j


~
N

(

0
,

σ
e
2

m
c

p

i
j


2
α



)

,

 where 


σ
e
2


 and 
α
 are model parameters that are the same for all ALS data acquisitions. For any pair of ALS data acquisitions, 
i
 and 
k
, random effects 


v
i


 and 


v
k


 were assumed to be independent so 

c
o
v

(


v
i

,

v
k


)

=

0

p
 
x
 
p



 and model errors 


e

i
j



 and 


e

k
l



 for any pair of FIA plots were also assumed to be independent.Hereafter we will use lower-case Greek letters to denote sets of FIA plots possibly distributed across several ALS data acquisitions. Four sets will be systematically considered in the following sections. The first one, 

τ
,

 will denote a set of FIA plots used to fit a model, the second one, 

ρ
,

 will be a set of FIA plots or prediction points in an ALS acquisition for which predictions are sought. The third and fourth sets that will be considered are 


ρ
s


 and 


ρ
u


. The set 


ρ
s


 is the subset of 
ρ
 that contains the sampled elements for which both ground and auxiliary information are available. Analogously, 


ρ
u


 is the subset of 
ρ
 for which only auxiliary data is known; i.e., the complement of 


ρ
s


. Letting 
ξ
 denote an arbitrary set containing 


n
ξ


 FIA plots, grouped by ALS acquisitions, the model in Equation (1) can be specified in matrix notation as





y
ξ

=

X
ξ

β
+

Z
ξ


v
ξ

+

e
ξ

,




(2)


where 


X
ξ

=



(


X
i


)






1
≤
i
≤
m


c
o
l



 is a matrix with 


n
ξ


 rows and 
p
 columns obtained by stacking the matrices 


X
i

=


(

x

i
1


,
 
…
,

x

i
j


,
…
,
 

x

i

n
i



)

t


 associated to the 


n
i


 elements from the ith ALS data acquisition in 
ξ
 and 


Z
ξ


 is a matrix with 


n
ξ


 rows and 

m
p

 columns formed by 

m
x
m

 blocks, where all elements in off diagonal blocks are zeros and blocks in the diagonal are the matrices 


X
i


. The vector of random effects is 


v
ξ

=


(

v
1
t

,
 
…
,

v
i
t

,
…
,
 

v
m
t

)

t


 with 


v
i

=



(


v

i
1


,
 
…
,

v
p


)


t


 and the vector of model errors is 


e
ξ

=


(

e
1
t

,
 
…
,

e
i
t

,
…
,
 

e
m
t

)

t


 with 


e
i

=



(


e

i
1


,
 
…
,

e


n
i




)


t


. The variance–covariance matrix of 


y
ξ


 is denoted as 


V
ξ


(


δ
v

,

σ
e
2

,
α

)

=

Z
ξ


G
ξ


(


δ
v


)


Z
ξ
t

+

R
ξ


(


σ
e
2

,
α

)


 where 


G
ξ


(


δ
v


)

=


d
i
a
g


1
≤
i
≤
m


G

(


δ
v


)


 is the variance–covariance matrix of 


v
ξ


 and 


R
ξ


(


σ
e
2

,
α

)


, the variance–covariance matrix of 


e
ξ


, a diagonal matrix where the elements in the diagonal equal 


σ
e
2

m
c

p

i
j


2
α



. Grouping all variance–covariance components into a single vector 

δ
=


(

δ
v
t

,
 

σ
e
2

,
α
)

t


, we will simplify the notation for 


V
ξ


(


δ
v

,

σ
e
2

,
α

)


 as 


V
ξ


(
δ
)


. 2.3.1. Model SelectionA model selection process consisting of four steps was run separately for every response and type of ALS metrics (i.e., point-cloud and rasterized predictors). In the first step we obtained the four linear fixed-effects models with highest R2 with one, two, three, and up to seven predictors using the R-package leaps [55]. For most models we observed that residuals tended to increase with the predicted value, thus, for each candidate we obtained a second fixed-effects model where the error variance was proportional to 

m
c

p

i
j


2
α



 and compared it to the first model using a likelihood ratio test. When the p-value of the likelihood ratio test was smaller than 0.05, the candidate model with constant error variance was replaced by its counterpart with error variance proportional to 

m
c

p

i
j


2
α



. Finally, for each candidate we obtained a mixed-effects model having the same fixed effects and error variance but incorporating random effects as indicated in Equation (1). The significance of the fixed-effect coefficients associated with each predictor was tested for each candidate and those coefficients that were not different from zero at a 0.05 significance level were sequentially removed from the model until all fixed effects were significantly different from zero at a 0.05 confidence level. The result was a list of 28 models from which we selected a final one for the response variable under consideration.To select the final model, we first removed from the list of 28 candidates all models where the maximum variance inflation factor, VIF, was larger than 5. To balance parsimony and predictive power, we observed at the increases of explained variance when increasing the number of predictors. We initially removed from the list all models where the R2 was 2.5% less than the maximum. Then, we only kept the models with the smallest number of predictors and selected the model with lowest root mean square error if more than one remained in the list. All models in this process were obtained using maximum likelihood and functions from the R package nlme [56]. 2.3.2. Prediction and Calibration with Parametric ModelsOnce models were fitted, we obtained synthetic predictions and calibrated predictions for each FIA plot. Letting 

δ
^

 be the estimated variance–covariance parameters of the model, we obtained the estimated fixed-effect parameters as





β
^

=



{


X
τ
t



V
^

τ




(


δ
^

 

)



−
1



X
τ


}



−
1





{


X
τ
t



V
^

τ




(


δ
^

 

)



−
1



X
τ


}



−
1



X
τ
t



V
^

τ




(


δ
^

 

)



−
1


.




(3)

Synthetic predictions for points in a new ALS acquisition, 
ρ
, were obtained by a direct extrapolation using the fixed-effects parameters obtained in the model fitting stage as






y
^

ρ

s
y
n


=

X
ρ


β
^

,




(4)

To emphasize that these are synthetic predictions, we will use the superscript 

s
y
n

. It is important to note that synthetic predictions do not perform any calibration to the local conditions of a new ALS data acquisition and can be obtained without any new ground information.If a set 


ρ
s


 of ground observations with their corresponding values of the auxiliary variables is available for the new ALS data acquisition, then, following p. 314 [57], it is possible to obtain calibrated predictions as






y
^

ρ

c
a
l


=

X
ρ


β
^

+

Z
ρ



v
^

ρ

,




(5)


where the superscript 

c
a
l

 is used to denote that these are calibrated predictions and






v
^

ρ

=

G


ρ
s




(



δ
^

v


)


Z


ρ
s


t


V


ρ
s






(

δ
^

)



−
1



{


y


ρ
s



−

X


ρ
s




β
^


}

.




(6)

", 2. Materials and Methods, 2.3. Parametric Models,2
92,"A model selection process consisting of four steps was run separately for every response and type of ALS metrics (i.e., point-cloud and rasterized predictors). In the first step we obtained the four linear fixed-effects models with highest R2 with one, two, three, and up to seven predictors using the R-package leaps [55]. For most models we observed that residuals tended to increase with the predicted value, thus, for each candidate we obtained a second fixed-effects model where the error variance was proportional to 

m
c

p

i
j


2
α



 and compared it to the first model using a likelihood ratio test. When the p-value of the likelihood ratio test was smaller than 0.05, the candidate model with constant error variance was replaced by its counterpart with error variance proportional to 

m
c

p

i
j


2
α



. Finally, for each candidate we obtained a mixed-effects model having the same fixed effects and error variance but incorporating random effects as indicated in Equation (1). The significance of the fixed-effect coefficients associated with each predictor was tested for each candidate and those coefficients that were not different from zero at a 0.05 significance level were sequentially removed from the model until all fixed effects were significantly different from zero at a 0.05 confidence level. The result was a list of 28 models from which we selected a final one for the response variable under consideration.To select the final model, we first removed from the list of 28 candidates all models where the maximum variance inflation factor, VIF, was larger than 5. To balance parsimony and predictive power, we observed at the increases of explained variance when increasing the number of predictors. We initially removed from the list all models where the R2 was 2.5% less than the maximum. Then, we only kept the models with the smallest number of predictors and selected the model with lowest root mean square error if more than one remained in the list. All models in this process were obtained using maximum likelihood and functions from the R package nlme [56].", 2. Materials and Methods, 2.3.1. Model Selection,2
93,"Once models were fitted, we obtained synthetic predictions and calibrated predictions for each FIA plot. Letting 

δ
^

 be the estimated variance–covariance parameters of the model, we obtained the estimated fixed-effect parameters as





β
^

=



{


X
τ
t



V
^

τ




(


δ
^

 

)



−
1



X
τ


}



−
1





{


X
τ
t



V
^

τ




(


δ
^

 

)



−
1



X
τ


}



−
1



X
τ
t



V
^

τ




(


δ
^

 

)



−
1


.




(3)

Synthetic predictions for points in a new ALS acquisition, 
ρ
, were obtained by a direct extrapolation using the fixed-effects parameters obtained in the model fitting stage as






y
^

ρ

s
y
n


=

X
ρ


β
^

,




(4)

To emphasize that these are synthetic predictions, we will use the superscript 

s
y
n

. It is important to note that synthetic predictions do not perform any calibration to the local conditions of a new ALS data acquisition and can be obtained without any new ground information.If a set 


ρ
s


 of ground observations with their corresponding values of the auxiliary variables is available for the new ALS data acquisition, then, following p. 314 [57], it is possible to obtain calibrated predictions as






y
^

ρ

c
a
l


=

X
ρ


β
^

+

Z
ρ



v
^

ρ

,




(5)


where the superscript 

c
a
l

 is used to denote that these are calibrated predictions and






v
^

ρ

=

G


ρ
s




(



δ
^

v


)


Z


ρ
s


t


V


ρ
s






(

δ
^

)



−
1



{


y


ρ
s



−

X


ρ
s




β
^


}

.




(6)

", 2. Materials and Methods, 2.3.2. Prediction and Calibration with Parametric Models,2
94,"For each response variable we obtained semiparametric random-forest models using point-cloud and rasterized predictors. We followed the approach proposed by [40] but included some modifications to accommodate nonconstant error variances because increasing error variances are commonly observed when modeling forest attributes with ALS auxiliary information (e.g., [58,59]).The form of the semiparametric models can be described as





y

i
j


=
f

(


x

i
j



)

+

θ

i
j


,




(7)


where 

f

(


x

i
j



)


 is a fixed and unknown function that will be approximated by the random forest algorithm and 


θ

i
j



 a random variable with zero mean that includes all the variation that is not explained by 

f

(


x

i
j



)


.We further assumed that the random component not explained by 

f

(


x

i
j



)


 was





θ

i
j


=
f

(


x

i
j



)


u
i

+

ε

i
j


,




(8)


where 


u
i


 is a random effect specific of the 


i

t
h



 ALS data acquisition and 


ε

i
j



 is an additive model error for the 


j

t
h



 plot in the 


i

t
h



 ALS acquisition. Random effects and model errors are assumed to be independent of each other and normally distributed with 


u
i

~
N

(

0
,

σ
u
2


)


, 


ε

i
j


~
N

(

0
,

σ
ε
2

f



(


x

i
j



)



2
κ



)


 where 


σ
u
2


, 


σ
ε
2


, and 
κ
 are model parameters. Finally, 


u
i


 was assumed to be independent of 


u
k


 for any pair of ALS data acquisitions and 


ε

i
j



 independent of 


ε

k
l



 for any pair of FIA plots.For an arbitrary set of units, model (8) can be expressed as





y
ξ

=


c
o
l


i
,
j
 
∈
ξ



[

f

(


x

i
j



)


]

+

U
ξ


u
ξ

+

ε
ξ

,




(9)


where 



c
o
l


i
,
j
 
∈
ξ



[

f

(


x

i
j



)


]


 is a 


n
ξ


 dimensional column vector obtained stacking the values 

f

(


x

i
j



)


 of all units in 
ξ
 and 


U
ξ


 is a matrix with 


n
ξ


 rows and 
m
 columns, where the row corresponding to the 


j

t
h



 element of the 


i

t
h



 acquisition has zeros everywhere except for the 


i

t
h



 position, which has a value of 

f

(


x

i
j



)


. The vector 


u
ξ

=


(

u
1

,
 
…
,

u
i

,
…
,
 

u
m

)

t


 groups the random effects for all ALS acquisitions in 
ξ
 and the vector 


ε
ξ


 is a vector of model errors obtained in the same way as 


e
ξ


. The variance–covariance matrix of 


u
ξ


 is 


J
ξ


(


σ
u
2


)

=

σ
u
2


I

m
x
m



 with 


I

m
x
m



 an identity matrix of dimension 
m
 and the variance–covariance matrix of 


ε
ξ


 is 


K
ξ


(


σ
ε
2

,
κ

)

=

σ
ε
2



d
i
a
g


i
,
j
 
∈
ξ



[

f



(


x

i
j



)



2
κ



]


. Letting 


L
ξ


 be the variance–covariance matrix of 


U
ξ


u
ξ

+

ε
ξ


, we have




c
o
v

(


U
ξ


u
ξ

+

ε
ξ

,

U
ξ


u
ξ

+

ε
ξ


)

=

L
ξ


(


σ
u
2

,

σ
ε
2

,
κ

)

=

U
ξ


J
ξ


(


σ
u
2


)


U
ξ
t

+
 

K
ξ


(


σ
ε
2

,
κ

)





(10)

Variance–covariance parameters 


σ
u
2


, 


σ
ε
2


, and 
κ
 were obtained after a random forest model was fitted to the training sample 
τ
. Then we assumed that the random forest provided a close approximation, 


f
^


(
.
)


, to the unknown function 

f

(
.
)


. Using 


f
^


(
.
)


 we obtained 



θ
^


i
j


=

y
ξ

−

f
^


(


x

i
j



)


, which were assumed to have a normal distribution with zero mean and variance covariance matrix as indicated in Equation (10). The estimated residuals from the random forest model, 



θ
^


i
j



, were finally used to estimate 


σ
u
2


, 


σ
ε
2

,

 and 
κ
 using maximum likelihood. 2.4.1. Model SelectionA model selection consisting of three steps was developed for every response variable and source of ALS metrics. In the first step we followed the approach described by [28] and eliminated correlated predictors using the QR decomposition implemented in the multi.collinear function of the rf.Utilities R package [60]. This step was run only once for each combination of response variable and source of ALS metrics. In the second step, we used the function rf.modelSel [60] to identify the best combination of variables selected in the final random-forest model for each response variable and source of ALS metrics. Once predictors were selected, random-forest models were fit using the randomForest R package [61]. These models provided the nonparametric component of the semiparametric models and were used to compute values for 



θ
^


i
j



. In the last step, we obtained the parametric part of the model that e×plains differences in 



θ
^


i
j



 due to ALS acquisition membership. Two models as indicated in Equation (10) were obtained for the variance–covariance of random effects and model errors using the R package nlme [56]. The first model had a fixed exponent 

κ
=
0

; i.e., homoscedastic errors, and the second model had an exponent 
κ
 that was free to vary during the model-fitting stage. Both models were compared using a likelihood ratio test. We selected the model with variable 
κ
 when the p-value of this test was smaller than 0.05; otherwise, we selected the model with 

κ
=
0

. 2.4.2. Prediction and Calibration with Semiparametric ModelsA direct application of the random forest model to a new ALS data acquisition provides synthetic predictions






y
^

ρ

s
y
n


=


c
o
l


i
,
j
 
∈
ρ



[


f
^


(


x

i
j



)


]

.




(11)

Following [41] (pp. 307, 353), calibrated predictions can be obtained as






y
^

ρ

c
a
l


=


c
o
l


i
,
j
 
∈
ρ



[


f
^


(


x

i
j



)


]

+

U
ρ



u
^

ρ

,




(12)


with






u
^

ρ

=

J


ρ
s




(



σ
^

u
2


)


U


ρ
s


t


L


ρ
s






(



σ
^

u
2

,
 


σ
^

ε
2

,

κ
^


)



−
1



{


y


ρ
s



−


c
o
l


i
,
j
 
∈
ξ



[


f
^


(


x

i
j



)


]


}





(13)

", 2. Materials and Methods, 2.4. Semiparametric Models,2
95,"A model selection consisting of three steps was developed for every response variable and source of ALS metrics. In the first step we followed the approach described by [28] and eliminated correlated predictors using the QR decomposition implemented in the multi.collinear function of the rf.Utilities R package [60]. This step was run only once for each combination of response variable and source of ALS metrics. In the second step, we used the function rf.modelSel [60] to identify the best combination of variables selected in the final random-forest model for each response variable and source of ALS metrics. Once predictors were selected, random-forest models were fit using the randomForest R package [61]. These models provided the nonparametric component of the semiparametric models and were used to compute values for 



θ
^


i
j



. In the last step, we obtained the parametric part of the model that e×plains differences in 



θ
^


i
j



 due to ALS acquisition membership. Two models as indicated in Equation (10) were obtained for the variance–covariance of random effects and model errors using the R package nlme [56]. The first model had a fixed exponent 

κ
=
0

; i.e., homoscedastic errors, and the second model had an exponent 
κ
 that was free to vary during the model-fitting stage. Both models were compared using a likelihood ratio test. We selected the model with variable 
κ
 when the p-value of this test was smaller than 0.05; otherwise, we selected the model with 

κ
=
0

.", 2. Materials and Methods, 2.4.1. Model Selection,2
96,"A direct application of the random forest model to a new ALS data acquisition provides synthetic predictions






y
^

ρ

s
y
n


=


c
o
l


i
,
j
 
∈
ρ



[


f
^


(


x

i
j



)


]

.




(11)

Following [41] (pp. 307, 353), calibrated predictions can be obtained as






y
^

ρ

c
a
l


=


c
o
l


i
,
j
 
∈
ρ



[


f
^


(


x

i
j



)


]

+

U
ρ



u
^

ρ

,




(12)


with






u
^

ρ

=

J


ρ
s




(



σ
^

u
2


)


U


ρ
s


t


L


ρ
s






(



σ
^

u
2

,
 


σ
^

ε
2

,

κ
^


)



−
1



{


y


ρ
s



−


c
o
l


i
,
j
 
∈
ξ



[


f
^


(


x

i
j



)


]


}





(13)

", 2. Materials and Methods, 2.4.2. Prediction and Calibration with Semiparametric Models,2
97," 2.5.1. Cross-Validation and Performance MetricsTo assess the effect of calibration for new ALS data acquisitions, we used the following procedure for each response variable and modeling technique (Figure 2). First, for each ALS data acquisition, we split the entire training dataset in two parts, 
τ
 and 
ρ
. The set 
τ
, the training subsample, contained all FIA plots not included in the selected ALS data acquisitions, and the set 
ρ
 contained the FIA plots within the ALS data acquisition under consideration. Models obtained in the model selection stage were re-fitted using only 
τ
 and synthetic predictions were obtained for all elements in 
ρ
. Finally, random effects and calibrated predictions for parametric and semiparametric models were obtained using Equations (5) and (6) and Equations (12) and (13), respectively. To consider that only FIA plots measured prior to the acquisition date will be available for the calibration of new ALS data collections, we performed the calibration using 


ρ
s


, the subset of 
ρ
 that contained the FIA plots that were measured the year the ALS data acquisition was finished or the three previous years. It is important to note that while models were selected including also plots measured up to three years after the ALS data collection was finished, we tested the effects of the calibration by excluding the plots that were measured after the ALS data collection was finished when computing the random effects using Equations (6) and (13). The potential use of the models developed in this study is to perform calibrations in new ALS data acquisitions. Thus, excluding the plots that were measured after the acquisitions were finished provides a closer approximation to the sample sizes that could be used for calibration in a real case. The result of this process was (1) a set of synthetic predictions from models developed with data from different acquisitions and (2) a set of calibrated predictions where only the field plot data available at the end of the ALS acquisition project was used to compute random effects.We used both sets of predictions to compute 



e
^


i
j


=


y
^


i
j


−

y

i
j



 and obtained the following performance metrics:



R
M
S
E
=






∑

i



∑

j



e
^


i
j

2





∑

i


n
i





,




(14)





B
I
A
S
=




∑

i



∑

j



e
^


i
j






∑

i


n
i



,




(15)


where 


n
i


 represents the number of elements in the 


i

t
h



 ALS data acquisition and 



y
^


i
j



 can represent synthetic or calibrated predictions. In addition to these metrics we also computed their values relative to the mean, 

 

y
¯


, of the response variable under consideration as:



R
R
M
S
E
=


R
M
S
E


 

y
¯







(16)





R
B
I
A
S
=


B
I
A
S


 

y
¯







(17)

And the coefficient of determination as:




R
2

=
1
−




∑

i



∑

j



e
^


i
j

2





∑

i



∑

j




(


y

i
j


−

 

y
¯



)


2







(18)

 2.5.2. Differences between Calibrated and Synthetic Predictions, Modeling Techniques, and Sources of ALS MetricsFor each response variable, we analyzed changes in performance due to each of the three factors under analysis (Figure 2) by computing changes in the relative root mean square error and relative bias. For a given factor, changes were computed as:



Δ
R
M
S

E
f

=
R
M
S

E
A

−
R
M
S

E
B

,




(19)


and:



Δ
R
B
I
A

S
f

=

|

R
B
I
A

S
A


|

−

|

R
B
I
A

S
B


|





(20)


where 
f
, 

A
,

 and 
B
 are generic superscripts that respectively indicate the factor under analysis and the two alternatives that are compared. For the transferability analysis we used the symbol 
t
 for 
f
, and 

A
=
c
a
l

 for calibrated predictions and 

B
=
s
y
n

 for synthetic predictions. To analyze differences due to the modeling technique we used error metrics computed after performing the corresponding calibration. We used the symbol 
m
 to indicate the factor “modeling technique”, and 

A
=
p
a
r

 for the parametric models and 

B
=
s
p
a
r

 for the semiparametric models. Finally, for the comparisons of models using rasterized and point-cloud ALS predictors, error metrics were also computed after performing the corresponding calibration. The letter 
s
 was used to indicate the factor “source of predictors”, and 

A
=
r

 for models using rasterized ALS metrics, and 

B
=
p
c

 for models using point-cloud predictors.To test differences in model performance due to: (1) the modeling technique and (2) the source of ALS metrics, we used a t-test on the differences 



e
^


i
j




A

−


e
^


i
j




B


 to test differences in accuracy and a t-test on the differences 




|



e
^


i
j



|


A

−



|



e
^


i
j



|


B


 to assess differences in precision. Finally, in addition to the global values of 

S
E
,

 

R
B
I
A
S

, 

Δ
R
M
S

E
f

,

 and 

Δ
R
B
I
A

S
f


, these metrics were also computed for each ALS acquisition separately.", 2. Materials and Methods, 2.5. Accuracy Assessment and Comparisons,2
98,"To assess the effect of calibration for new ALS data acquisitions, we used the following procedure for each response variable and modeling technique (Figure 2). First, for each ALS data acquisition, we split the entire training dataset in two parts, 
τ
 and 
ρ
. The set 
τ
, the training subsample, contained all FIA plots not included in the selected ALS data acquisitions, and the set 
ρ
 contained the FIA plots within the ALS data acquisition under consideration. Models obtained in the model selection stage were re-fitted using only 
τ
 and synthetic predictions were obtained for all elements in 
ρ
. Finally, random effects and calibrated predictions for parametric and semiparametric models were obtained using Equations (5) and (6) and Equations (12) and (13), respectively. To consider that only FIA plots measured prior to the acquisition date will be available for the calibration of new ALS data collections, we performed the calibration using 


ρ
s


, the subset of 
ρ
 that contained the FIA plots that were measured the year the ALS data acquisition was finished or the three previous years. It is important to note that while models were selected including also plots measured up to three years after the ALS data collection was finished, we tested the effects of the calibration by excluding the plots that were measured after the ALS data collection was finished when computing the random effects using Equations (6) and (13). The potential use of the models developed in this study is to perform calibrations in new ALS data acquisitions. Thus, excluding the plots that were measured after the acquisitions were finished provides a closer approximation to the sample sizes that could be used for calibration in a real case. The result of this process was (1) a set of synthetic predictions from models developed with data from different acquisitions and (2) a set of calibrated predictions where only the field plot data available at the end of the ALS acquisition project was used to compute random effects.We used both sets of predictions to compute 



e
^


i
j


=


y
^


i
j


−

y

i
j



 and obtained the following performance metrics:



R
M
S
E
=






∑

i



∑

j



e
^


i
j

2





∑

i


n
i





,




(14)





B
I
A
S
=




∑

i



∑

j



e
^


i
j






∑

i


n
i



,




(15)


where 


n
i


 represents the number of elements in the 


i

t
h



 ALS data acquisition and 



y
^


i
j



 can represent synthetic or calibrated predictions. In addition to these metrics we also computed their values relative to the mean, 

 

y
¯


, of the response variable under consideration as:



R
R
M
S
E
=


R
M
S
E


 

y
¯







(16)





R
B
I
A
S
=


B
I
A
S


 

y
¯







(17)

And the coefficient of determination as:




R
2

=
1
−




∑

i



∑

j



e
^


i
j

2





∑

i



∑

j




(


y

i
j


−

 

y
¯



)


2







(18)

", 2. Materials and Methods, 2.5.1. Cross-Validation and Performance Metrics,2
99,"For each response variable, we analyzed changes in performance due to each of the three factors under analysis (Figure 2) by computing changes in the relative root mean square error and relative bias. For a given factor, changes were computed as:



Δ
R
M
S

E
f

=
R
M
S

E
A

−
R
M
S

E
B

,




(19)


and:



Δ
R
B
I
A

S
f

=

|

R
B
I
A

S
A


|

−

|

R
B
I
A

S
B


|





(20)


where 
f
, 

A
,

 and 
B
 are generic superscripts that respectively indicate the factor under analysis and the two alternatives that are compared. For the transferability analysis we used the symbol 
t
 for 
f
, and 

A
=
c
a
l

 for calibrated predictions and 

B
=
s
y
n

 for synthetic predictions. To analyze differences due to the modeling technique we used error metrics computed after performing the corresponding calibration. We used the symbol 
m
 to indicate the factor “modeling technique”, and 

A
=
p
a
r

 for the parametric models and 

B
=
s
p
a
r

 for the semiparametric models. Finally, for the comparisons of models using rasterized and point-cloud ALS predictors, error metrics were also computed after performing the corresponding calibration. The letter 
s
 was used to indicate the factor “source of predictors”, and 

A
=
r

 for models using rasterized ALS metrics, and 

B
=
p
c

 for models using point-cloud predictors.To test differences in model performance due to: (1) the modeling technique and (2) the source of ALS metrics, we used a t-test on the differences 



e
^


i
j




A

−


e
^


i
j




B


 to test differences in accuracy and a t-test on the differences 




|



e
^


i
j



|


A

−



|



e
^


i
j



|


B


 to assess differences in precision. Finally, in addition to the global values of 

S
E
,

 

R
B
I
A
S

, 

Δ
R
M
S

E
f

,

 and 

Δ
R
B
I
A

S
f


, these metrics were also computed for each ALS acquisition separately.", 2. Materials and Methods," 2.5.2. Differences between Calibrated and Synthetic Predictions, Modeling Techniques, and Sources of ALS Metrics",2
100,"Regardless of the source of ALS metrics and modeling technique, several patterns were observed with respect to the predictive performance of the models for different response variables. The largest 


R
2


 values were obtained for CH, followed by AGB, with values ranging from 88.59% to 85.29% and from 80.03% to 76.45%, respectively. For the remaining variables the explanatory power of the models was largest for CFL with 


R
2


 values above 50%. This variable was followed by CBH and CBD, which tended to have 


R
2


 values around 30% and 25% respectively. Finally, the explanatory power of the models for DWB was very poor, and larger for the parametric models where 


R
2


 reached 13.79% for the model using point-cloud metrics and 13.49% for the model using rasterized predictors. Patterns observed for 

R
R
M
S

E

c
a
l



 were similar to those observed for 


R
2


 but in the opposite direction. Finally, 

R
B
I
A

S

c
a
l



 was positive for most models indicating a systematic overprediction with a magnitude that varied substantially between variables. For CH and AGB it was below 2.5% in absolute value. For CBD, CBH, and CFL, 

R
B
I
A

S

c
a
l



 was below 10% in absolute value and for DWB 

R
B
I
A

S

c
a
l



 exceeded 5% for the parametric models and 15% for the semiparametric models (Figure 3).All models included random effects; however, for the parametric models for DWB and CBH using point-cloud predictors, the inclusion of random effects did not improve the model fit significantly at a 0.05 confidence level. For CBH the model selection algorithm for the parametric models described in Section 2.3.1 provided models with up to six predictors, followed by models with three predictors but with an R2 3.2% points larger than the maximum R2. These simpler models were considered more appropriate and selected as final models for this variable because they allowed for a substantial model simplification without causing important performance losses. For most variables, sources of ALS metrics, and modeling techniques, models improved when including random effects for the ALS acquisitions and a parameter 

κ
≠
0

 to account for nonconstant error variances (Table A4, Table A5 and Table A7). The only exceptions to this trend were the parametric models for CFL and the parametric model for CH using rasterized ALS metrics.Important differences were observed between parametric and semiparametric models for the number of predictors included in the model. The median number of predictors for the semiparametric models was 33, and ALS, topographic, and climate metrics were present in all but the semiparametric model for DWB using rasterized predictors. The median numbers of ALS metrics, topographic, and climate metrics were 18, 10, and 4 variables respectively (Figure A5). Parametric models always had less than five predictors and in most cases these predictors were derived from the ALS data (Table A4 and Table A5).", 3. Results, 3.1. Parametric and Semiparametric Models,3
101,"All models included ALS acquisition random effects; however, the magnitude of these effects varied significantly between variables and modeling techniques. For semiparametric models, reductions in global 

R
M
S
E

 and 

R
B
I
A
S

 were negligible, which indicates that with these models using synthetic predictions and omitting the calibration step will not have consequences of practical importance in accuracy and precision. While semiparametric models seem to capture differences between ALS acquisitions directly, leaving little room for improvements to the calibration stage, parametric models operate differently, and their performance improves substantially with the calibration. Parametric models captured the main relationship with auxiliary information in their fixed-effect component, and a part of the variability between ALS acquisition was accounted for in the calibration stage (Figure 4). Focusing on the parametric models, for AGB, CBD, CBH, and CFL calibration resulted in consistent reductions of the global 

R
M
S

E

c
a
l



 and 

R
B
I
A

S

c
a
l



. For DWB and CH, three parametric models failed at reducing the global 

R
B
I
A

S

c
a
l



. We further inspected this issue by looking at ALS-acquisition-specific values of 

R
B
I
A

S

c
a
l



 for the parametric models.For all variables and source of ALS metrics the 


|

B
I
A
S

|


 decreased in the majority of the ALS acquisitions after the calibration was performed (Figure 5). These reductions in the ALS acquisition 

B
I
A
S

 also resulted in a reduction of 

R
M
S
E

. Similar patterns were observed for the e×tended dataset using only rasterized metrics (Figure A3). The effect of the calibration in DWB was very small and erratic, which, in conjunction with the poor performance of the models for this variable, indicate that the variability in DWB cannot be predicted well by the auxiliary information used in this study or by geographic factors such as membership in a particular ALS acquisition area. For the remaining variables the effect of the calibration varied in magnitude depending on the variable and source of predictors. Most important effects of calibration were observed for CH followed by CBH and AGB, and the smallest reductions of ALS-specific 

B
I
A
S

 were observed for CBD. Overall, the calibration step had positive impact in reducing the ALS acquisition biases and that is the main advantage of the mixed-effects parametric models developed in this study.", 3. Results, 3.2. Differences between Synthetic and Calibrated Predictions,3
102,"Parametric models provided lower values of the global 

R
B
I
A

S

c
a
l



 in 11 of the 12 possible combinations of response variables and sources of ALS metrics, while semiparametric models provided lower values of the global 

R
R
M
S

E

c
a
l



 in 8 of the 12 possible comparisons. With the exception of DWB, for which parametric models provided consistently better results in terms of 

R
B
I
A

S

c
a
l



 and 

R
R
M
S

E

c
a
l



, there was no modeling technique that can be considered as clearly superior than the other. For DWB, CBD, CH, CBH, and CFL, the 

R
B
I
A

S

c
a
l



 of parametric models was smaller than the bias of their semiparametric counterparts regardless of the source of ALS predictors (Table 4). For AGB there was no modeling technique better than the other in terms of 

R
B
I
A

S

c
a
l



. Semiparametric models provided better results in terms of global 

R
R
M
S

E

c
a
l



 for AGB, CBD, and CH, while for DWB the parametric models had consistently smaller values of 

R
R
M
S

E

c
a
l



. The magnitude of the differences in 

R
B
I
A

S

c
a
l



 and 

R
R
M
S

E

c
a
l



 between parametric and semiparametric models were of small magnitude for those responses with larger 


R
2


. For CH and AGB, differences between modeling techniques in 

R
B
I
A

S

c
a
l



 and in 

R
R
M
S

E

c
a
l



 were below 1.35% and 2.27% respectively, regardless of the source of ALS metrics. Excluding DWB, magnitude of the differences in 

R
B
I
A

S

c
a
l



 were most important for the models for CBH and CFL using rasterized predictors, while differences in 

R
R
M
S

E

c
a
l



 were below 4% for all variables (Table 4). Similar results were obtained when comparing parametric and semiparametric models with an extended dataset that included 12 additional ALS acquisitions (Table A3). The smaller 

R
B
I
A

S

c
a
l



 of the parametric models and smaller 

R
R
M
S

E

c
a
l



 in semiparametric models clearly indicates performance tradeoffs between modeling techniques; however, the magnitude of these tradeoffs is for most variables of very small magnitude.Except for CFL, where parametric models consistently had lower ALS-acquisition-specific values of 

B
I
A

S

c
a
l



, differences between parametric and semiparametric models did not show clear patterns of dominance of a modeling technique over the other in terms of 

B
I
A

S

c
a
l



 (Figure 6). In terms of 

R
M
S

E

c
a
l



, semiparametric models provided slightly lower acquisition specific values of 

R
M
S

E

c
a
l



 for CBD and CH and for the remaining variables no modeling technique consistently provided lower values of this performance metric. For both sources of ALS predictors, the magnitude of the differences between parametric and semiparametric models in 

R
M
S

E

c
a
l



 was, in general, orders of magnitude smaller than the values of 

R
M
S

E

c
a
l



 themselves. Similar results were obtained when comparing parametric and semiparametric models with the extended dataset that included 12 additional ALS acquisitions (Figure A4) and only used rasterized predictors. These results show that multiple exceptions to the trends observed for the global 

B
I
A

S

c
a
l



 and 

R
M
S

E

c
a
l



 can be observed when focusing on specific ALS acquisitions and confirmed that differences in performance due to the modeling technique are very minor.", 3. Results, 3.3. Differences between Parametric and Semiparametric Models,3
103,"For the parametric models, differences in global 

R
B
I
A

S

c
a
l



 between models based on point-cloud and rasterized ALS predictors were significant only for CBH, and the magnitude of these differences only reached 1.43%. For the semiparametric models, using point-cloud predictors resulted in significantly more accurate models for AGB, CH, CBH, and CFL, but the magnitude of these differences was below 2% for AGB and CH and below 4% and 6% for CBH and CFL respectively. Except for the semiparametric models for DWB, models using point-cloud predictors had lower values of global 

R
M
S

E

c
a
l



. However, the magnitude of these differences only reached a 5% for the semiparametric models for CBH, and for the remaining variables differences were always below 3.3% (Table 5).Finally, side by side comparison of ALS-acquisition-specific values of 

B
I
A

S

c
a
l



 and 

R
M
S

E

c
a
l



 for models using point-cloud and rasterized metrics showed that models using point-cloud predictors were not always better than the models using rasterized metrics (Figure 7). The only exceptions to this trend were the models for CH in which using point-cloud predictors resulted in 

R
M
S

E

c
a
l



 about 1 m smaller for most acquisitions. More important, the magnitude of the change in acquisition specific 

B
I
A

S

c
a
l



 and 

R
M
S

E

c
a
l



 was generally negligible compared to the values of these metrics. This suggests that using rasterized metrics instead of point-cloud metrics has a limited impact on accuracy.", 3. Results, 3.4. Differences between Sources of ALS Metrics,3
104,"We considered the prediction of a wide array of attributes of interest for forest managers and observed important differences between variables. Models for CH and AGB showed a high predictive performance, similar to that found in previous studies [20,26,62,63]. The percentages of explained variance for both parametric and semiparametric models for CBH and CFL were similar to those obtained by [20] for a single ALS acquisition. For CBD the percentage of explained variance of the semiparametric models was about 10% smaller than those reported by [20] for ALS acquisition-specific models. The low 


R
2


 values obtained for DWB were also about 10% smaller than those reported by [20] for local models, indicating that regional models developed using the auxiliary information considered in this study only provide a very crude approximation to reality for this variable.Important efforts have recently been made to analyze the potential transferability of ALS models to new acquisitions not considered in the training dataset [27,28,29] or to a new collection over the same study area [64]. These studies showed that the degradation in model performance due to temporal offsets, and differences in the configuration of the ALS data collection are small compared to the losses in performance due to (1) ecological differences between the regions where the models were fit and transferred, and (2) the effect of the modeling technique. In our study we focused on developing models that can be calibrated to new acquisitions as a way of developing maps of forest fuels and structural attributes in a rapid manner. Our results partially align with those obtained by [29] and for almost all response variables, synthetic predictions from semiparametric models had lower 

R
R
M
S
E

 than synthetic predictions from parametric models. The most important effect of the calibration in the parametric models was the reduction in the ALS-acquisition-specific 

B
I
A
S

. Such 

B
I
A
S

 reduction cannot be obtained transferring fixed-effect models to new ALS acquisition as fixed-effect models can only generate synthetic predictions. Once the parametric models were calibrated, few differences were observed between both modeling techniques. One factor that should be considered in future applications is that models developed with more ALS acquisitions will result in more reliable estimates of the variance parameters of the random effects [57]. For cases with fewer ALS acquisitions of large size or where the calibration is not an issue because no new ALS acquisitions are expected, other modeling techniques using only fixed-effects models would be more appropriate. We developed this study using eight ALS acquisitions, but main results were confirmed in the analysis of the extended dataset with 20 ALS acquisitions (Appendix A).The minor effect that calibration had in the semiparametric models can be explained by the ability of random forest to effectively use large numbers of predictors and model nonlinear patterns [37,38]. If the training dataset covers the main ecological gradients of the area under analysis, random forest captures the most important sources of variability that can be explained by the auxiliary information leaving little room for improvements in the calibration step. The linear mixed-effects models with random intercepts and slopes developed in this study operate in a very different manner. The fixed component of the model characterizes the main relationships between auxiliary information and response variables and complex effects, specific of a given ALS data collection, are accounted for in the calibration step.Results from our study support the idea that both techniques produce comparable results if calibration is a possibility and suggest the following recommendations for future applications. When calibration is a possibility, linear mixed-effects models do not provide consistently worse results than semiparametric models and have clear advantages in terms of simplicity, interpretability, and ease of use. Apart from the corresponding ground data and auxiliary information, only parameters reported in Table A4 and Table A5 are necessary to develop the calibrations of the parametric linear models. For random forest-based semiparametric models, external users need to have access to the original random forest data-structure developed by the modeler to obtain predictions in new areas. In addition, linear mixed-effects models allow mapping uncertainty of predictions using well-known methods [58,65], but reporting the same uncertainties for semiparametric models is still a field under development [38,66]. When calibration is not a possibility, or a fast and direct model transfer is necessary, semiparametric models are clearly a better option. For these models, synthetic predictions and calibrated predictions showed little differences for all variables, which indicates that omitting the calibration step should not imply significant losses in accuracy with respect to a scenario where calibration is possible.Regardless of the modelling technique and source of ALS predictors, for all responses analyzed in this study, ALS-acquisition-specific biases did not completely disappear after the calibration step indicating that global models should not be a replacement for ALS-acquisition-specific models, but instead a solution to enable a fast mapping of forest attributes. This result is consistent with [30,31] for nonparametric random forest models. The calibration approach used in this study relies on the assumption of having different error structures due to membership in a particular ALS acquisition. This assumption is reasonable because ALS acquisitions usually cover relatively homogeneous areas and the specifications in the ALS data collection can differ among ALS data-collection projects. The inclusion of ALS-acquisition-specific random effects allows accounting for these differences between ALS acquisitions in the calibration step. Nevertheless, other approaches to calibration should be investigated in the future. Of special interest is the approach proposed by [31] that develops calibrated predictions by considering the variability of geographic areas that do not have to match a specific ALS acquisition.Differences between models using point-cloud and rasterized metrics were negligible (Figure 7 and Figure A7). Differences of such a small magnitude were not expected; however, this result can be explained by: (1) the presence of GPS positioning errors that even if expected to be in the range of a meter introduce some noise in the ALS metrics [67], and (2) by the averaging that occurs when aggregating point-cloud metrics at the FIA plot level. FIA plots are composed of four 17.95 m radius subplots, with one subplot at the center and the other three subplots 36.58 m from the central plot. Point clouds for the subplots are combined when computing ALS predictors for an FIA plot, resulting in an aggregation effect similar to the one that occurs when computing rasterized metrics. While the use of pre-rasterized layers to e × tract ALS predictors implies a departure from traditional workflows using ALS data, this process is equivalent to that used in many applications using optical sensors such as Landsat images (e.g., [26]) and has been used in previous studies to combine ALS, optical, and topographic predictors [68]. Additionally, and more importantly: (1) ALS metrics are computed in a standardized and structured way that for every point of the territory assigns a unique support area [69] for the computation of ALS metrics, and (2) empirical results from our analysis showed that, by using rasterized ALS metrics instead of point-cloud metrics, the predictive performance of the models does not worsen substantially and allows generating cartographic products useful for multiple planning tasks, with accuracies and precisions similar to those obtained using point-cloud predictors.The small differences between models developed using point-clouds or rasterized predictors in combination with the fact that sharing rasterized products is far more operationally feasible than sharing large point-clouds, opens the possibility of developing models in a more efficient way. Future mapping applications that require rapid delivery could be developed extracting ALS metrics for the training units using interpolation over pre-rasterized products available from spatial data infrastructures serving raster layers with metrics derived using a standardized workflow. Operating in this way eliminates the need of intersecting ground measurements with large point clouds that are more difficult to share and manipulate, since a larger number of users will be more comfortable extracting auxiliary variables from raster files than clipping and normalizing point-cloud data. These two factors combined can reduce (1) the time needed to develop models and (2) the time that forest managers need to wait for maps of structural attributes once an ALS data are acquired and processed.", 4. Discussion,None,4
105,"The increasing availability of ALS data in the western US states raises questions about methodological aspects to derive cartographic products of forest attributes such as AGB, DWB, CBD, CH, CBH, and CFL. This study analyzes three factors of importance for development of a regional strategy to map forest structural attributes that allows using available ALS data acquisitions and incorporating new ALS project areas in a rapid manner. The main conclusion regarding these factors are:Transferability and calibration. For both modeling techniques, calibration reduced bias problems when predicting to ALS data acquisitions not included in the training dataset; however, the effect of calibration was much more important for parametric linear mixed-effects models than for semiparametric models using random forest. This indicates that linear models developed over such a large region only account for main trends with respect to the auxiliary information and need to (1) account for the variability between ALS data acquisitions and (2) be calibrated to local conditions to eliminate bias problems.Modeling technique. Once the calibration is performed, both modeling techniques have similar performance in terms of acquisition-specific 

R
B
I
A
S

 or 

R
R
M
S
E

. Interpretability of results and simplicity make the linear mixed-effects models more appealing for situations where performing a calibration for new acquisitions is feasible, and the small effect of calibration in semiparametric models makes them a better choice for cases where calibration is not possible.Source of ALS metrics. Differences in performance between models developed with predictors obtained by interpolation over rasterized ALS metrics and models developed using predictors computed by clipping the point clouds coincident with areas where field measurements were taken were minimal for the variables considered in this study. This clearly suggests that raster layers can be used to drive the entire modeling workflow with little loss in terms of performance, which can be important for time-sensitive applications because the pre-processing of the ALS data can be substantially simplified.", 5. Conclusions,None,5
106,"International emission reduction programs (especially Reducing Emissions from Deforestation and Degradation, Conservation of Forest Carbon Stocks, Sustainable Management of Forests and Enhancement of Forest Carbon Stocks (REDD+)) have principally focused on the reporting of deforestation activities, as robust and well-tested methods and data are available for monitoring such changes across forested landscapes. In contrast, although degradation of forests in developing countries is perceived to be important for global greenhouse gas emissions (GHG) [1], full inclusion of forest degradation accounting is very rare due to lack of methods and excessive costs of available approaches. Most REDD+ financing mechanisms and protocols require emissions from forest degradation to be accounted for when “significant”, defined by the World Bank under its Carbon Fund as more than 10% of all forest-related emissions [2] and some works have also been published that highlight a critical degradation threshold [3,4,5]. Identifying which activities cause “significant” forest degradation in any given country requires cost-effective measurement of their emissions, yet measuring and monitoring changes in carbon stocks (emissions and removals) due to forest degradation is decidedly more complex and costly than measuring and monitoring carbon emissions due to deforestation [1,6]. To develop a measurement, reporting, and verification (MRV) system for forest degradation, it is necessary that the causes of degradation be considered and the likely impact on carbon stocks be assessed. Examples of activities that commonly result in forest degradation include legal and illegal logging, human-set fires that escape into the forest, fuelwood collection, and persistent livestock grazing. Forest degradation refers to losses in forest cover that do not qualify as deforestation. Such degradation can be caused by many different drivers, but we argue that it consists of two different patterns of changes in forest cover. Forest degradation can occur on the edge of the forest, caused by drivers inadvertently or opportunistically taking advantage of access from deforested areas. Such degradation typically has a limited depth of penetration into the surrounding forest but is spread across an area with a variable and unpredictable density; examples include human and environmental impacts surrounding mining, livestock encroachment into forests, anthropogenically-set fires, and fuelwood collection. The second form of forest degradation occurs deep in the interior of the forest with the specific purpose (advertent or inadvertent) of an activity that lowers the forest carbon stock. This form of forest degradation impacts a defined area in a recognizable pattern and with a close relationship to a statistic that can provide activity data; examples include timber harvest (with activity data of timber volumes extracted), or low-grading for understory crop production (with activity data of plantation area). We term the second form of forest degradation “forest interior degradation” and the first form “forest edge degradation”. Here, we focus on how to account for greenhouse gas emissions from forest edge degradation as exemplified by forests adjacent to alluvial gold mines in Guyana. Mining for gold and other precious materials is a common cause of deforestation in many regions around the world [7], including many countries in South America [8,9], Southeast Asia [10,11] and parts of Africa [12,13,14]. As a result, many forested landscapes around the world have been severely altered [15]. The elevated rate of deforestation from gold-mining has been observed in the recent past due to multiple factors, including an increase in gold prices in the international market [16], an increase in accessibility to mines, lack of formalization of artisanal and small-scale mining [17], and the expectation of high short-term earnings from mining and selling gold [18]. Swenson et al. [19] and Asner et al. [9] showed mining activities in South America were both regulated and unregulated, primarily artisanal, and more often illegal than legal. It is highly likely that forests surrounding mining areas are degraded due to the nature of mining activity, including tree removal during pre-mining exploration and for timber for camp construction and fuel for cooking, as well as post-mining impacts such as toxic runoff and flooding as a result of mine tailings. Assessing deforestation from mining is relatively simple as remote sensing can be routinely used to record areas that previously had forest cover. However, the areas associated with forest degradation resulting from mining and the consequent GHG emissions are unknown. This paper is focused on identifying a viable approach to quantify the impact of forest edge degradation as exemplified by the degradation of forests surrounding mining sites. Here, mining can represent any forest edge degradation surrounding deforestation such as livestock encroachment or the penetration of desiccating climate on deforestation edges.Two basic elements are needed to estimate GHG emissions associated with forest degradation: activity data and emission factors. Activity data (AD) refer to the quantity of an activity that results in GHG emissions, such as the area of land degraded. Emission factors (EF) are the estimated amount of emissions of GHGs per unit of activity, such as megagrams of carbon emitted per hectare (Mg C ha−1) degraded [6,20]. EF combined with AD gives an estimate of total gross emissions from the activity. Available studies show how much uncertainty in the estimation of AD and EF is associated with forest degradation [6].A method for estimating gross emissions from forest interior degradation in the form of selective logging in tropical forests has been developed by Pearson et al. [21,22] using the Intergovernmental Panel on Climate Change (IPCC) gain–loss approach [23]. This approach focuses on the direct change in carbon stocks and therefore requires the measurement of tree mortality and damage rather than an estimation of the difference in carbon stocks before and after a degrading event. This method has been found to be more appropriate for estimating the impact of degrading activities, especially when carbon stocks are variable across the forest and the carbon loss is relatively small. In such situations, the gain–loss approach requires fewer measurements to reach a reasonable level of certainty than would be required by measuring carbon stocks before and after damage. However, this interior form of forest degradation is not directly associated with deforestation, and incorporates recognizable patches of cleared forest (in roads, log pile decks, temporary camps, and tree fall gaps), and has readily available activity data in extracted timber volumes. In contrast, degradation around mining results from limited and diffuse incidental tree mortality of predominantly small diameter trees. As such it is complex and difficult to capture accurately in remote sensing and the only reliable activity data are the length of the deforestation edge. Several studies have used remote sensing data for mapping and estimation of deforestation from mining and the majority of these studies were in South America [9,19,24,25,26,27]. A range of remote sensing data, both from active (LiDAR) [25] and passive (MODIS, Landsat, IRS LISS III, WorldView, Digital Globe) [16,24,26] sensors, have been used in these studies. These studies have demonstrated that areas of deforestation due to artisanal mining are visible from space and could easily be mapped at a regional or national-scale using a combination of remote sensing and limited ground-survey methods [9]. No studies have investigated the extent of forest degradation and associated GHG emissions from artisanal or small-scale mining. The purpose of our study was to analyze forest edge degradation, based on a case study in Guyana, where gold mining is the main cause of deforestation (more than 88% of total deforestation; [28]; Figure 1), and to arrive at a first estimation of carbon emissions, both in absolute terms and relative to deforestation and other forms of forest degradation. In this process, this paper seeks to develop and test methods for estimating gross carbon emissions caused by forest edge degradation surrounding areas of deforestation (as exemplified by mining). In this paper, we: (1) provide estimates of the total gross carbon emissions from forest edge degradation adjacent to mining areas, (2) compare the carbon emissions from forest degradation with carbon emissions from deforestation both associated with mining deforestation emissions and total forest emissions in Guyana, and (3) provide a sound method that can be used for estimating carbon emissions from forest edge degradation surrounding areas of deforestation. ", 1. Introduction,None,1.
107,"The study used remote sensing datasets spanning from 2010 to 2015, and field data collected between July and August 2015 (Table 1). ", 2. Materials and Methods, 2.1. Data Sets,2
108,"The remote sensing sampling design applied high resolution (5 m) RapidEye multispectral satellite imagery. The location of potential sampling sites was established from the multitemporal RapidEye imagery (2011–2014) that had been used to identify and map deforestation by driver. First, deforestation from mining activity was identified from RapidEye imagery as forest clearings with sharp boundaries, often in linear clusters in remote areas and near water [30]. All such areas that exceeded one hectare were mapped as deforestation from mining. The accuracy of the annual deforestation mapping products was independently assessed using an aerial multispectral imaging system that captures images across Guyana with resolution ranging from 25 to 60 cm [31]. The assessment shows high accuracy for deforestation (~99%). The 100 m wide buffers were established around identified mining deforestation. Field sites were pre-selected to ensure representation of mining practices and sizes of mining operations across the country. We identified five testing sites and installed transects at these sites all with the same dimensions of 20 m (width) × 100 m (length).Figure 2 shows the sampling approach. Transect locations were pre-established using forest change maps of three time periods: 2011–2012, 2012–2013, and 2013–2014 (Table 1), produced by the Guyana Forestry Commission. Areas of deforestation from mining during these time periods were identified with a representative distribution across the landscape using various information sources including an updated road map, a road layer from Google Earth Pro, and elevation data from Shuttle Radar Topography Mission (SRTM). The locations for an initial set of transects were randomly selected from the identified areas of mining deforestation, then 41 transect locations were randomly selected from this initial set of transects. For each selected deforestation polygon centroid, out of eight cardinal points, two were chosen at random (Figure 2). All potential transect locations were established on maps in advance of the ground surveys. ", 2. Materials and Methods, 2.2. Remote Sensing Sampling Design,2
109,"Using the gain–loss approach to identify carbon loss resulting from human activity, measurements focused on trees (or stumps) whose mortality was caused by human impact, such as harvesting to build a mining camp or a trail, or mortality that resulted from flooding or mine tailings.Across all transects, the diameter at breast height (DBH) of all trees ≥ 10 cm DBH was measured. For all damaged or killed trees (lying or standing), the following data were recorded: the species; DBH where ≥10 cm when available or basal diameter at 5 cm above ground, which was then converted to DBH using the taper factor shown in Equation 1; distance from start of transect to the damaged tree; whether damage was likely due to natural causes or was human-caused (e.g., cutting, snapped, broken, washed out roots, root burial by sediments, trail construction, flooding, or presence of toxic mining waste). In the tropical forests, measuring tree height is difficult and expensive [32]. In this study, tree height was not included due to the possibility of systematic measurement error, time and budget constraints, and inaccessible ground conditions resulting from mining. The systematic errors include measurement error due to dense canopy cover, measurement error due to the presence of tall trees, and irregular crown condition [33]. In each transect, evidence of degrading activities was also recorded with a description of the disturbance and measurement of distance from start of transect. The number of transects in each site established by plot type is given in Table 1. The number of transects varied for each year of deforestation due to availability. Available time and resources initially allowed for measurement of a total of 41 transects, and upon data analysis it was found that this number met the threshold of <20% uncertainty at a 95% confidence interval. Throughout data collection and data processing, independent checking and correction were conducted as integral parts of quality control and quality assurance.", 2. Materials and Methods, 2.3. Field Data Collection,2
110," 2.4.1. Estimation of Carbon Stocks in Aboveground BiomassTree data were converted to aboveground biomass using an equation from Chave et al. [34] that estimates biomass for moist forests using DBH and species-specific wood density (this equation has been tested and used for estimating aboveground biomass in Guyana’s REDD+ forest carbon monitoring system and is used here to remain in keeping with that system). Estimates of belowground biomass were not included in this analysis and comparisons were made to the aboveground biomass emissions from other sources only. Where the DBH was measured directly this was used in the Chave et al. [34] equation. However, if the tree was removed, the diameter of the stump at 5 cm above ground was measured and the DBH was estimated from the basal diameter using a taper factor (Ttaper) (see Equation (1)):




D

e
s
t
i
m
a
t
e
d


=
 

D

b
a
s
e


−

[


{

1.3
−

(




H

b
a
s
e




100



)


}

×

T

t
a
p
e
r



]





(1)


where:


D

e
s
t
i
m
a
t
e
d



 = estimated diameter at breast height, cm;


D

b
a
s
e



 = basal diameter, taken at 5 cm above the ground, cm;


H

b
a
s
e



 = height of the basal diameter measurement, 5 cm;


T

t
a
p
e
r



 = variation of unit of diameter over a unit of length, 0.79 cm m−1, as derived for and used in Guyana’s forest inventory.DBH was measured for 98% of the trees recorded and basal diameter was measured for 22%.Aboveground biomass was converted to megagrams per hectare using a scaling factor. This was multiplied by the carbon fraction 0.47 [35] to convert to Mg C ha−1. 2.4.2. Statistical AnalysisThe total carbon content in live trees across 41 transects showed a normal distribution, whereas the carbon loss values (Mg C ha−1) associated with mining-related tree mortality across 41 transects was skewed and non-normally distributed [36,37]. Further transformation of the carbon loss values using logarithmic, square root and reciprocal approaches did not satisfy the assumption of normality. Outliers in the values of carbon loss (Mg C ha−1) resulted in the median value serving as a better descriptor of the typical carbon emissions than the mean value. Therefore, non-parametric statistical analyses-median, the Wilcoxon rank-sum test [38], and Mann and Whitney’s U statistic [39] were applied to conduct statistical analysis using the values of carbon loss (Mg C ha−1) from 41 transects. Of note is that the field measurements represent cumulative damage between 2011 to 2015 with many of the deforestation sites first mapped in 2011. The Wilcoxon rank-sum test was run between the transects separated by year to investigate whether carbon emissions due to mining differ significantly between years.An evaluation of uncertainty (confidence interval—CI) associated with a sample-based point estimate using the percentile (p) method [40] is needed to relate to the corresponding population parameter. For the evaluation, we generated 10,000 bootstrap samples drawn within each of the 10,000 replications of a bootstrap simulation, which is ten times more replications than recommended by Efron and Tibshirane [41]. The 10,000 bootstrap samples were then used to derive three different CIs following three different nonparametric bootstrap resampling procedures: the bootstrap normal (BN) method, the bootstrap percentile (BP) method, and the bootstrap bias-corrected and accelerated (BCa) method [42]. Finally, the sample-based uncertainty (CI) estimate of carbon loss was evaluated against the uncertainty (CI) values derived from those three different nonparametric bootstrap resampling procedures. The standard error and bias were calculated using the bootstrap resampling method [43,44].", 2. Materials and Methods, 2.4. Data Analysis,2
111,"Tree data were converted to aboveground biomass using an equation from Chave et al. [34] that estimates biomass for moist forests using DBH and species-specific wood density (this equation has been tested and used for estimating aboveground biomass in Guyana’s REDD+ forest carbon monitoring system and is used here to remain in keeping with that system). Estimates of belowground biomass were not included in this analysis and comparisons were made to the aboveground biomass emissions from other sources only. Where the DBH was measured directly this was used in the Chave et al. [34] equation. However, if the tree was removed, the diameter of the stump at 5 cm above ground was measured and the DBH was estimated from the basal diameter using a taper factor (Ttaper) (see Equation (1)):




D

e
s
t
i
m
a
t
e
d


=
 

D

b
a
s
e


−

[


{

1.3
−

(




H

b
a
s
e




100



)


}

×

T

t
a
p
e
r



]





(1)


where:


D

e
s
t
i
m
a
t
e
d



 = estimated diameter at breast height, cm;


D

b
a
s
e



 = basal diameter, taken at 5 cm above the ground, cm;


H

b
a
s
e



 = height of the basal diameter measurement, 5 cm;


T

t
a
p
e
r



 = variation of unit of diameter over a unit of length, 0.79 cm m−1, as derived for and used in Guyana’s forest inventory.DBH was measured for 98% of the trees recorded and basal diameter was measured for 22%.Aboveground biomass was converted to megagrams per hectare using a scaling factor. This was multiplied by the carbon fraction 0.47 [35] to convert to Mg C ha−1.", 2. Materials and Methods, 2.4.1. Estimation of Carbon Stocks in Aboveground Biomass,2
112,"The total carbon content in live trees across 41 transects showed a normal distribution, whereas the carbon loss values (Mg C ha−1) associated with mining-related tree mortality across 41 transects was skewed and non-normally distributed [36,37]. Further transformation of the carbon loss values using logarithmic, square root and reciprocal approaches did not satisfy the assumption of normality. Outliers in the values of carbon loss (Mg C ha−1) resulted in the median value serving as a better descriptor of the typical carbon emissions than the mean value. Therefore, non-parametric statistical analyses-median, the Wilcoxon rank-sum test [38], and Mann and Whitney’s U statistic [39] were applied to conduct statistical analysis using the values of carbon loss (Mg C ha−1) from 41 transects. Of note is that the field measurements represent cumulative damage between 2011 to 2015 with many of the deforestation sites first mapped in 2011. The Wilcoxon rank-sum test was run between the transects separated by year to investigate whether carbon emissions due to mining differ significantly between years.An evaluation of uncertainty (confidence interval—CI) associated with a sample-based point estimate using the percentile (p) method [40] is needed to relate to the corresponding population parameter. For the evaluation, we generated 10,000 bootstrap samples drawn within each of the 10,000 replications of a bootstrap simulation, which is ten times more replications than recommended by Efron and Tibshirane [41]. The 10,000 bootstrap samples were then used to derive three different CIs following three different nonparametric bootstrap resampling procedures: the bootstrap normal (BN) method, the bootstrap percentile (BP) method, and the bootstrap bias-corrected and accelerated (BCa) method [42]. Finally, the sample-based uncertainty (CI) estimate of carbon loss was evaluated against the uncertainty (CI) values derived from those three different nonparametric bootstrap resampling procedures. The standard error and bias were calculated using the bootstrap resampling method [43,44].", 2. Materials and Methods, 2.4.2. Statistical Analysis,2
113,"The carbon loss due to mining-induced tree damage varied significantly, ranging from 0.0 to 96.7 Mg C ha−1 of the sampled transect (Table 2). The median loss in carbon stock across all years was 2.2 Mg C ha−1 (0.0–10.2 Mg C ha−1 at 95% CI based on the BCa method). This represents a mining degradation emission factor of 8.0 Mg CO2 ha−1 to be applied across the total calculated areas of buffer around mining deforestation.Despite the time span over which degradation had occurred (2 to 4 years), no significant differences were observed in the carbon loss values by year (Table 3). Approximately 61% of transects had 10 Mg C ha−1 or less of damage, with the highest frequency (46.3%) seen in the <1 Mg C ha−1 class (Figure 3).Carbon loss due to mining damage represented only 1.2% of live tree biomass and was estimated to be lower than damage due to natural causes (equivalent to 20% of the losses to natural causes; Table 4). The calculated annual rate of mortality was approximately 0.3% for mining damage and 1.6% for other causes (estimated as the amount of carbon emissions divided by the aboveground carbon stock, expressed as a percent, and assuming an average period of 4 years). To address the impact of the distance from the mining locus on forest degradation, we plotted the distribution of the number of mining damaged stems and the associated carbon loss at 10 m intervals as a percent of all mining damaged trees and total carbon loss along the transect length (Figure 4), starting from the edge of a deforestation polygon. The distribution of mining damaged stems shows an expected gradual decline with an increase in distance from the edge of the deforestation polygon (Figure 4). In the 41 transects, 70% of the mining damaged stems were located in the first half (0–50 m) of the transects with 60% of the carbon loss occurring in the same distance. Within 80 m from the deforestation edge, 88% of the damaged stems and carbon loss occurred. ", 3. Results, 3.1. Change in Carbon Stocks,3
114,"From 2011 through to 2014, an average of 10,663 ha was deforested annually across Guyana. The emission factor for deforestation in Guyana’s national forest monitoring system was 1104 t CO2 e ha−1, resulting in annual average emissions of 11.8 million Mg CO2 e. The average annual area of 100 m buffers around new mines between 2011 and 2014 was 40,250 ha. The average annual emissions applying the emission factor of 8 t CO2 ha−1 is 322 thousand t CO2. This accounts for only 2.7% of carbon emissions from deforestation. ", 3. Results, 3.2. Emissions from Mining Degradation Compared to Deforestation Emissions,3
115,"This study and approach are designed to cost effectively assess forest edge degradation. The very simple method presented here creates emission factors for buffer areas around deforestation and can be applied globally (adjusting only the buffer width and emission factor to the specific circumstance) to determine greenhouse gas emissions from forest edge degradation, defined here as forest carbon losses in remaining forest adjacent to deforestation and occurring without a clearly apparent predictable pattern. The method uses existing remote sensing data for deforestation and ground data gathered at one point in time in a manner consistent with IPCC guidelines. It can be applied at low cost to evaluate the significance of forest edge degradation and to provide GHG emission estimates. The method is as simple as running transects out from recorded deforestation and calculating an emission factor for a given buffer width. This is appropriate to forests surrounding mining as in the case studied here, but has the potential to be applied to other forms of forest edge degradation, such as livestock incursion into forests, the often overlooked degradation occurring at forest edges through microclimate changes, fuelwood collection, or localized entrance of anthropogenic fires into forests [45]. The specifics of the method, including the buffer width, the transect size, the measurements collected, and the allometric equations used should be adjusted for the specific geography and the driver of the forest degradation.A cost-assessment has not been conducted given that a comprehensive high resolution analysis of forest degradation has not been implemented in Guyana by the government in an ongoing and sustainable manner due to the prohibitive costs this would incur. However, the cost difference is fully self-evident. A comprehensive high resolution approach would require annual or biennial purchase of high resolution remote sensing imagery with analyst time to define all losses in canopy cover that can be recorded as forest degradation, which would then be paired with emission factors to be associated with such losses. The field measurements, such as those conducted in the simplified method, are also needed for a comprehensive assessment and in addition to this there is a requirement for high resolution data on a spatially and temporally significant level with commensurate analyst time. As described by Goslee et al. in this journal [46], a pragmatic approach to emissions accounting, as detailed here in the case of forest edge degradation, results in substantial cost savings for insignificant emission sources. Remote sensing techniques are commonly used to quantify forest degradation. Their calibration relies on the ground-based estimation of carbon emissions and removals [13,47,48] because quantification of forest degradation relies on the ability to relate degradation activities to disturbances in the canopy. Successful detection depends on the disturbance type, frequency, intensity, extent, and species composition [6]. Spatial and temporal resolutions of remotely sensed datasets are limiting factors to identifying disturbance on the ground. Even high spatial and temporal resolution imagery might not be able to capture minor forest structural disturbances [49]; thus, requiring ground-observations. Access to high-quality mapping, validation datasets, and ground measurements have been beneficial in estimating carbon emissions from forest degradation and in reducing uncertainty of estimates [50].Emissions from forest degradation due to large-scale mining in Ghana were estimated at 2.1 Mg C ha−1, including above and belowground carbon pools [51]. Using the IPCC default root:shoot ratio conversion factor (0.3), carbon emissions from aboveground biomass would be estimated at 1.5 Mg C ha−1. The study of Amoako et al. [51] was based on ground-survey data covering 60 ha of mining degraded forests, with emission estimates in the range of those from the current study (2.2 Mg C ha−1, at 95% CI 0.0–10.2 Mg C ha−1). It should be noted, however, that details on the sampling design and on the steps followed in data generation steps were missing from the Amoako et al. study. We are not aware of additional studies quantifying carbon emissions from mining degradation. The memorandum of understanding (MOU) between the governments of Norway and Guyana specified that the area of 500 m buffers around annual deforestation from mining be reported and that a 50% reduction in the carbon stock in these buffers would be taken due to degradation. Neither the area nor the stock reduction values were based on evidence. Remote sensing data, both from unpublished data and as reported here, show that there is clearly forest degradation associated with mining in Guyana, although the area impacted is much less than originally suggested in the MOU. Further underlining the invalidity of the 500 m transect, the number of stems damaged and the carbon loss in the damaged trees due to mining activities is higher within 0–50 m of mining deforestation than within 50–100 m. The field work and data analysis described here also indicate that the magnitude of loss in carbon stock due to mining activities in the 100 m buffers is considerably less than the 50% loss from the MOU—losses equal only around 1% of the aboveground tree pool. Historical estimates of CO2 emissions from deforestation, by all drivers, and from forest degradation by selective logging were made as part of Guyana’s national REDD+ program [28]. The average annual emission estimates for the period 2011–2014 are shown in Table 5. Here, we show that forest degradation emissions associated with mining represent only 2% of total recorded forest emissions.These estimates are likely an overestimate as the carbon impact of forest degradation presented here represents only the gross emissions and does not take into account how persistent the degradation might be or any regrowth and forest recovery—pioneer and small trees were observed in some of the year 2011 transects showing recovery of forest growth even while degradation was ongoing in other areas. The approach of establishing 100 m buffers around deforested areas to arrive at emission estimates from associated forest edge degradation requires no additional image interpretation and can be conducted efficiently and at low cost. Given the low magnitude of Guyana’s emissions resulting from mining forest degradation, this approach provides a sustainable and low-cost method for Guyana to conservatively include this source of emissions. In the absence of this new simplified approach, the likely only option would be to conduct an analysis with very high spatial resolution satellite or aerial imagery. Such an approach, although likely to provide a more accurate estimate of the area of forest degradation, is time and labor intensive, and our assessments have demonstrated that it is most often not possible to distinguish between natural tree mortality and that caused by mining-related activity. The buffer approach is conservative because even though the EFs estimated for the 100 m buffer are small, the buffer area will be large, and we have shown here that it encompasses a broad area with low risk of forest degradation. ", 4. Discussion,None,4
116,"It is clear that forest degradation surrounding mining represents a small source of emissions and a small percentage of emissions when scaled with other sources. As previously mentioned, the World Bank’s Carbon Fund requires emissions from forest degradation to be reported when they represent more than 10% of forest-related emissions. Under this condition, the carbon emissions from degradation due to mining in Guyana would be considered insignificant under all circumstances. This paper is expected to contribute in two ways to the global understanding and accounting of GHG emissions associated with forest degradation. First, this paper indicates that forest degradation associated with mining (and particularly alluvial mining excavation practices) is unlikely to be a globally significant source of GHG emissions that warrants fears of a major overlooked global emission. Second, the simplified methods in this paper can be used to derive country-specific estimates of carbon emissions from forest edge degradation including mining activities and other poorly understood forms of forest degradation to allow complete accounting at sufficiently low costs appropriate to the low net greenhouse gas emissions.", 5. Conclusions,None,5
117,"Higher temperatures and lower rainfall amounts may result in drought, is a common weather phenomenon and costly natural hazard. Drought is a recurrent climate process that occurs in association with temporally and spatially uneven rainfall over broad areas and extended periods [1]. The regional temperatures of Southern Mongolia have increased by 0.1–3.7 °C over the past 60 years, spring precipitation has decreased by 17%, and summer precipitation has increased by 11% [2]. These changes in temperature and precipitation are likely to intensify the occurrence of drought, especially during the onset of vegetation green-up. Moreover, the frequency of drought in the spring and summer has been reported to increase as much as four times every five years in the Gobi region [3]. Drought has a disturbing effect not only on agricultural productivity and hydrological resources but also on natural vegetation; therefore, it may accelerate the desertification processes associated with destructive human activities (that is, overgrazing) in semi-arid grassland areas in Mongolia.Many drought indices derived from remote sensing (RS-derived) data have been developed and used to effectively detect drought conditions all over the world. Because drought causes stress to vegetation, the extent of a drought can be reflected by changes in the vegetation index. The normalized difference vegetation index (NDVI) is the normalized difference between near-infrared (NIR) and red reflectance and is simple and effective and is now the most widely used index for detecting drought [4,5,6]. Many vegetation indices based on the NDVI have been proposed for diverse regions. To measure the impacts of weather and ecosystem components on vegetation and reduce their deviations, a vegetation condition index (VCI) was developed by Kogan [7]. Water stress in plants results in reduced chlorophyll absorption in the blue and red bands [8], so the blue band can be viewed as the band least sensitive to vegetation moisture variation. Zhang et al. [9] proposed the visible and shortwave infrared drought index (VSDI) by combining the blue, red, and SWIR optical spectral bands; this index is suitable for drought monitoring throughout the America growing season. Shortwave infrared reflectance (SWIR) is sensitive to leaf liquid water content, and a combination of NIR and SWIR data has been used to derive water-sensitive indices for monitoring drought occurrences. Based on NIR and SWIR, the normalized difference water index (NDWI) [10] is sensitive to changes in soil moisture that are strongly related to vegetation drought conditions in the grass and crop land of the Oklahoma Mesonet. Analysis has revealed that combining information from multiple near infrared and short-wave infrared channels into the normalized multi-band drought index (NMDI) [11] enhances its sensitivity to drought severity, a method that is suited to estimate both soil and vegetation moisture. Gu et al. [12] found that the NDWI responds more quickly to drought than the NDVI, and they then developed the drought indicator known as the normalized difference drought index (NDDI), which also has been adopted by Mongolia’s National Remote Sensing Center for monitoring grassland drought [13]. Land surface temperature (LST) derived from thermal radiance bands is a good indicator of the energy balance of the earth’s surface, because temperatures can rise quickly under water stress. Gutman [14] showed that thermal data might be useful for detecting inter-annual changes in surface moisture. Kogan [7] developed the temperature condition index (TCI), which is an initial indicator of water stress and drought.A combination of different indices representing vegetation stress, water deficit, and soil moisture status can describe the severity of and changes in drought better than each index in isolation. Previously, Carlson [15] constructed the vegetation supply water index (VSWI) using the NDVI and LST to assess summer drought, because the ratio of LST to NDVI is shown to increase during drought. VSWI describes the soil moisture changes in agricultural land well and is a rapid and cost-effective method for monitoring drought conditions [16]. Sandholt et al. [17] found that the scatter of LST and NDVI data occupies a triangular space, the NDVI–LST spectral space, and that an index based on this relationship (the temperature vegetation dryness index, TVDI) can be used to better monitor regional drought. A similar indicator, the vegetation temperature condition index (VTCI), was applied to drought monitoring by Wang et al. [18]. The VTCI had better performance than NDVI in classifying relative drought occurrence levels and in studying the distribution of drought occurrences. A typical drought indicator, the vegetation health index (VHI), was proposed by Kogan [7,19] and was based on the combination of vegetation greenness (VCI) and temperature (TCI) indices. AVHRR-based drought indices (VCI, TCI, and VHI) were also proposed by Kogan [19] for monitoring grass conditions in Mongolia; that study found that these indices coherently indicated intensive drought in poor grass.Several researchers are currently monitoring drought conditions in Mongolian grassland using satellite-derived indices [1,19,20], and meaningful results have been obtained. As detailed above, other drought indices have performed well in other countries and climate zones. Which of them can best describe Mongolia’s drought conditions, for prevention and mitigation use by researchers, government departments, or stakeholders, remains unclear. Therefore, this paper’s objectives are as follows: (1) to adopt new reference indicators and comprehensive methods for evaluate Mongolian drought in several scales; (2) to build an integrated and novel adaptability analysis framework to determine the optimal satellite-derived drought indices for the accurate and real-time expression of grassland drought in Mongolia.", 1. Introduction,None,1.
118,"The study region covers grassland throughout Mongolia, located in the central part of the Asiatic continent between latitudes 41°35′N and 52°09′N and longitudes 87°44′E and 119°56′E. Mongolia has a total area of 1,565,000 km2, approximately 80% of which is covered by grass. The extensive grass and shrub steppe grazing lands have the capacity to support a large number of grazing herbivores [21], along with desert, desert steppe, steppe, and forest steppe zones (Figure 1). The national ecosystem is fragile, and Mongolia has one of the highest disaster risks worldwide. The frequency and magnitude of natural disasters (drought, dzud, and fire) are increasing because of global climate change. Mongolia is characterized by harsh weather, and precipitation is unequally distributed temporally and spatially. Approximately 80% of precipitation occurs in the three months of summer (June, July, and August) [22]. In northern Mongolia, precipitation levels reach 400 mm a year, whereas in the southern areas’ levels, which feature semi-arid and desert conditions, are less than 50 mm. Mongolia also experiences extreme daily and annual temperature fluctuations.", 2. Study Region and Data, 2.1. Study Region,2
119," 2.2.1. Station DataAutomatic weather stations (AWSs) built by the Information and Research Institute of Meteorology, Hydrology, and Environment (IRIMHE) are distributed across Mongolia, and each AWS is equipped with instruments that measure micro-meteorological variables. Air temperature at two meters and rainfall data were obtained from 86 meteorological stations covering Mongolia’s grassland. The average air temperature and accumulated precipitation values were calculated every 10 days from 2000 to 2014. Biomass (the total aboveground biomass) was collected in small plots (1 × 1 m [23], in three repeated samplings) at each meteorological station. Plant samples were heated to above 100 °C and oven dried at 80 °C until they reached a constant weight in the laboratory. The final dry weight of each sample was divided by the sampling area and the result was converted to kg/ha. Soil moisture was measured using an earth-boring auger (EBA) at 39 meteorological stations once each 10-day period from 2000 to 2011. The EBA equipment was used to collect soil samples at different depths (for example, 5 cm and 10 cm), those samples were placed into an iron box. Soil moisture content was calculated based on the difference in weight between fresh soil and dried soil. The distribution of the observation stations is illustrated in Figure 1.Meteorological station data must be pre-processed and checked. Verification and temporal stability analyses were performed for the standard data. The data were checked using the range of values, and if data were missing, or their validity could not be determined, they were then excluded from the validation. 2.2.2. Region Drought-Affected DataTo select the optimal drought indices for Mongolia, the conventional field drought assessment data were referred to as the drought-affected region data (RDA data, also referred to as summer condition data by some researchers). RDA value are obtained at IRIMHE every 10-day period according to an evaluation of the vegetation conditions of the growing season of Mongolia based on plant growth, growth stage, and grassland productivity. Also every 10 days, meteorological observers ask local herders and environmental officers about summer conditions. After that they will get assessment values by summary evaluation from the community in the county center. For each county, there is one RDA value. Appraisal RDA values from the IRIMHE range from 1 to 6: 1 = extreme drought, 2 = serious drought, 3 = moderate drought, 4 = slight drought, 5 = no drought (normal conditions), and 6 = good conditions. 2.2.3. RS DataDaily level 1B clear sky data from the Moderate Resolution Imaging Spectroradiometer (MODIS) were derived from the MODIS sensor aboard the TERRA satellite, which views entire earth’s surface in one to two days and was launched in December 1999. These data (MOD02 and MOD03, at 1 km resolution) were downloaded from the Atmosphere Archive and Distribution System (LAADS) of the National Aeronautics and Space Administration’s (NASA) website. The downloaded data covered all of Mongolia from 2000 to 2015 (from May to September). Data projection and resampling were conducted with the MRTSWATH tool (downloaded from the MODIS site). Next, cloud mask, atmospheric correction, NDVI, and LST retrievals were performed through our own codes, developed based on existing literature. Reflectance or thermal radiance bands of these data were calculated by internal calibration parameters and functions. Bands 1–3, 5, 6, 20, 22, 26, 27, 31, and 35 were used for cloud detection with reflectance and brightness temperature thresholds [24]. Aerosol optical depth was retrieved using the dark dense vegetation (DDV) method [25]; then atmospheric corrections were performed based on the 6S model [26]. The NDVI was calculated using reflectivity data based on MODIS bands 1 and 2 after atmospheric correction. The surface albedo was computed from a linear combination of the first seven reflectance bands. Using radiance data based on MODIS bands 31 and 32, and after atmospheric correction, daytime LST were calculated via the split-window algorithm [27]. 2.2.4. Base DataLand cover data was used to divide the study area into three steppe regions: forest steppe, steppe, and desert steppe. Land cover data was obtained from Mongolia’s Land Cover Map 2010, produced by the Mongolian National Remote Sensing Center (NRSC) [28]. The original land cover data included 19 types, which was combined into five types. Administrative data at the province and county levels were obtained from the IRIMHE. Table 1 describes all data types, including satellite-derived data (1 km resolution MODIS1B data) which were used to calculate the drought indices, including meteorological station observation data (such as soil moisture, biomass, precipitation, and air temperature) and RDA, which were used in our adaptability analysis and for validation of the drought indices. Other auxiliary data were land cover and administrative boundaries.", 2. Study Region and Data, 2.2. Data,2
120,"Automatic weather stations (AWSs) built by the Information and Research Institute of Meteorology, Hydrology, and Environment (IRIMHE) are distributed across Mongolia, and each AWS is equipped with instruments that measure micro-meteorological variables. Air temperature at two meters and rainfall data were obtained from 86 meteorological stations covering Mongolia’s grassland. The average air temperature and accumulated precipitation values were calculated every 10 days from 2000 to 2014. Biomass (the total aboveground biomass) was collected in small plots (1 × 1 m [23], in three repeated samplings) at each meteorological station. Plant samples were heated to above 100 °C and oven dried at 80 °C until they reached a constant weight in the laboratory. The final dry weight of each sample was divided by the sampling area and the result was converted to kg/ha. Soil moisture was measured using an earth-boring auger (EBA) at 39 meteorological stations once each 10-day period from 2000 to 2011. The EBA equipment was used to collect soil samples at different depths (for example, 5 cm and 10 cm), those samples were placed into an iron box. Soil moisture content was calculated based on the difference in weight between fresh soil and dried soil. The distribution of the observation stations is illustrated in Figure 1.Meteorological station data must be pre-processed and checked. Verification and temporal stability analyses were performed for the standard data. The data were checked using the range of values, and if data were missing, or their validity could not be determined, they were then excluded from the validation.", 2. Study Region and Data, 2.2.1. Station Data,2
121,"To select the optimal drought indices for Mongolia, the conventional field drought assessment data were referred to as the drought-affected region data (RDA data, also referred to as summer condition data by some researchers). RDA value are obtained at IRIMHE every 10-day period according to an evaluation of the vegetation conditions of the growing season of Mongolia based on plant growth, growth stage, and grassland productivity. Also every 10 days, meteorological observers ask local herders and environmental officers about summer conditions. After that they will get assessment values by summary evaluation from the community in the county center. For each county, there is one RDA value. Appraisal RDA values from the IRIMHE range from 1 to 6: 1 = extreme drought, 2 = serious drought, 3 = moderate drought, 4 = slight drought, 5 = no drought (normal conditions), and 6 = good conditions.", 2. Study Region and Data, 2.2.2. Region Drought-Affected Data,2
122,"Daily level 1B clear sky data from the Moderate Resolution Imaging Spectroradiometer (MODIS) were derived from the MODIS sensor aboard the TERRA satellite, which views entire earth’s surface in one to two days and was launched in December 1999. These data (MOD02 and MOD03, at 1 km resolution) were downloaded from the Atmosphere Archive and Distribution System (LAADS) of the National Aeronautics and Space Administration’s (NASA) website. The downloaded data covered all of Mongolia from 2000 to 2015 (from May to September). Data projection and resampling were conducted with the MRTSWATH tool (downloaded from the MODIS site). Next, cloud mask, atmospheric correction, NDVI, and LST retrievals were performed through our own codes, developed based on existing literature. Reflectance or thermal radiance bands of these data were calculated by internal calibration parameters and functions. Bands 1–3, 5, 6, 20, 22, 26, 27, 31, and 35 were used for cloud detection with reflectance and brightness temperature thresholds [24]. Aerosol optical depth was retrieved using the dark dense vegetation (DDV) method [25]; then atmospheric corrections were performed based on the 6S model [26]. The NDVI was calculated using reflectivity data based on MODIS bands 1 and 2 after atmospheric correction. The surface albedo was computed from a linear combination of the first seven reflectance bands. Using radiance data based on MODIS bands 31 and 32, and after atmospheric correction, daytime LST were calculated via the split-window algorithm [27].", 2. Study Region and Data, 2.2.3. RS Data,2
123,"Land cover data was used to divide the study area into three steppe regions: forest steppe, steppe, and desert steppe. Land cover data was obtained from Mongolia’s Land Cover Map 2010, produced by the Mongolian National Remote Sensing Center (NRSC) [28]. The original land cover data included 19 types, which was combined into five types. Administrative data at the province and county levels were obtained from the IRIMHE. Table 1 describes all data types, including satellite-derived data (1 km resolution MODIS1B data) which were used to calculate the drought indices, including meteorological station observation data (such as soil moisture, biomass, precipitation, and air temperature) and RDA, which were used in our adaptability analysis and for validation of the drought indices. Other auxiliary data were land cover and administrative boundaries.", 2. Study Region and Data, 2.2.4. Base Data,2
124,"MODIS 1B data between June and August during 2000–2014 were pre-processed as described in Section 2.2.3. Data for the blue, red, NIR, and SWIR bands, as well as the NDVI and LST of each day were produced and retrieved. Any remaining cloud-contaminated pixels were removed. Next, the daily band data, NDVI data, and LST data were combined into a 10-day average, NDVI, and LST. Nine indices (TCI, VCI, VHI, NDWI, NDDI, VSWI, VTCI, VSDI, and NMDI) were selected and calculated according to the formulas listed in Table 2. 3.1.1. Pixel LevelsRS-derived drought indices can be calculated using the above equations in Table 2 at the pixel scale, based on drought classification criteria in each formula from the literature cited as shown in Table 2. The pixel value range of RS-derived drought indices was converted into numeric values from 1–5: 1 = extreme, 2 = severe, 3 = moderate, 4 = slight drought, and 5 = normal. RS-derived pixel values were used for correlation and temporal analysis with field data from selected stations. These pixel values can also be used for producing drought severity category (DSC). 3.1.2. County LevelThe percentages of drought acreage (PDA) is calculated by dividing the drought area by the total grass area in each county using the RS-derived data. Then, based on a similar method described in Reference [29], we developed the drought severity level (DSL) indicator using the RS-derived drought indices and the following formula to represent drought severity in every county as follows





D
S

L

s
o
u
m
_
R
S


=
0.4
 
×
 
DrouEX
+
0.3
 
×
 
DrouSE
+
0.2
 
×
 
DrouMO
+
0.1
 
×
 
DrouSL





(1)


where 


D
S

L

s
o
u
m
_
R
S




 is the output of DSL in a county, and 


 
DrouEX
,
 
DrouSE
,


 


DrouMO
,


 and 


DrouSL


 are the PDAs of extreme, severe, moderate, and slight drought rankings, respectively, from the RS-derived drought indices.To ensure that the satellite-derived drought statistics indicator (


D
S

L

s
o
u
m
_
R
S




) is compatible with the RDA data, 


D
S

L

s
o
u
m
_
R
S




 was classified into a drought severity category (


D
S

C

s
o
u
m
_
R
S




) indicator in accordance with the Mongolia local experiential rule: DSC = 1 when DSL ≥ 0.2, DSC = 2 when 0.1 ≤ DSL < 0.2, DSC = 3 when 0.05 ≤ DSL < 0.1, DSC = 4 when 0 < DSL < 0.05, and DSC = 5 when DSL = 0. The DSC range is 1–5: 1 = extreme, 2 = severe, 3 = moderate, 4 = slight drought, and 5 = normal.", 3. Methodology, 3.1. Satellite-Derived Indices,3
125,"RS-derived drought indices can be calculated using the above equations in Table 2 at the pixel scale, based on drought classification criteria in each formula from the literature cited as shown in Table 2. The pixel value range of RS-derived drought indices was converted into numeric values from 1–5: 1 = extreme, 2 = severe, 3 = moderate, 4 = slight drought, and 5 = normal. RS-derived pixel values were used for correlation and temporal analysis with field data from selected stations. These pixel values can also be used for producing drought severity category (DSC).", 3. Methodology, 3.1.1. Pixel Levels,3
126,"The percentages of drought acreage (PDA) is calculated by dividing the drought area by the total grass area in each county using the RS-derived data. Then, based on a similar method described in Reference [29], we developed the drought severity level (DSL) indicator using the RS-derived drought indices and the following formula to represent drought severity in every county as follows





D
S

L

s
o
u
m
_
R
S


=
0.4
 
×
 
DrouEX
+
0.3
 
×
 
DrouSE
+
0.2
 
×
 
DrouMO
+
0.1
 
×
 
DrouSL





(1)


where 


D
S

L

s
o
u
m
_
R
S




 is the output of DSL in a county, and 


 
DrouEX
,
 
DrouSE
,


 


DrouMO
,


 and 


DrouSL


 are the PDAs of extreme, severe, moderate, and slight drought rankings, respectively, from the RS-derived drought indices.To ensure that the satellite-derived drought statistics indicator (


D
S

L

s
o
u
m
_
R
S




) is compatible with the RDA data, 


D
S

L

s
o
u
m
_
R
S




 was classified into a drought severity category (


D
S

C

s
o
u
m
_
R
S




) indicator in accordance with the Mongolia local experiential rule: DSC = 1 when DSL ≥ 0.2, DSC = 2 when 0.1 ≤ DSL < 0.2, DSC = 3 when 0.05 ≤ DSL < 0.1, DSC = 4 when 0 < DSL < 0.05, and DSC = 5 when DSL = 0. The DSC range is 1–5: 1 = extreme, 2 = severe, 3 = moderate, 4 = slight drought, and 5 = normal.", 3. Methodology, 3.1.2. County Level,3
127," 3.2.1. Station LevelPed [30] originally established the PED index to detect the long-term intensity of meteorological drought using corresponding environmental parameters, including air temperature and precipitation, which were monitored at stations over a long period.




P
E

D
i

=
 



T
i

−

T
¯




σ
T



−
 



P
i

−

P
¯




σ
P








(2)


where T is air temperature, P is precipitation, and 



σ
T



 and 



σ
P



 are the standardized deviations of temperature and precipitation. Accordingly, 


T
¯


 and 


P
¯


 are the corresponding means.The PED drought index was used to determine temperature anomalies and precipitation deficits, and it reflects the effects of these two combined parameters on drought. Mongolia experiences particularly extreme annual temperature fluctuations in response to global climate change, and high temperatures may cause water stress and drought [31]. According to the records of 48 meteorological stations distributed over the territory of Mongolia, the annual mean temperature of Mongolia increased by 2.14 °C during the last 70 years, and the number of hot days in the summer season is increasing [32]. In addition, the PED is very effective at monitoring drought in Russia [30] and the Bulgarian low regions [33]; therefore, the PED meteorological index was used in this paper.Drought had a substantial influence on maximum measured aboveground biomass production [34,35]. Since absolute biomass data had shortcomings of spatial and temporal comparability, we developed a normalized biomass (NorBio) for the assessment of grassland drought along similar lines to the development of the VCI equation as a normalized calculation using long-term data. Station biomass data was correlated with the eight RS-derived drought indices. NorBio can be calculated by using the equation





B
i
o
m
a
s

s

n
o
r
m
a
l
i
z
e
d



(

i
,
n

)

=
 


B
i
o
m
a
s
s

(

i
,
 
 
n

)

−
B
i
o
m
a
s

s

m
i
n



(

i
,
 
 
n

)



B
i
o
m
a
s

s

m
a
x



(

i
,
n

)

−
B
i
o
m
a
s

s

m
i
n



(

i
,
n

)








(3)


where 


B
i
o
m
a
s

s

n
o
r
m
a
l
i
z
e
d



(

i
,
n

)



 is the normalized biomass for period i and station n, 


B
i
o
m
a
s
s

(

i
,
n

)



 is the biomass for period i and station n in a certain year, 


B
i
o
m
a
s

s

m
a
x



(

i
,
n

)



 is the multi-year maximum biomass for period i and station n, and 


B
i
o
m
a
s

s

m
i
n



(

i
,
n

)



 is the multi-year minimum biomass for period i and station n.Soil moisture is a good indicator of drought caused by water reduction, and changes in soil moisture can reflect drought change trends. High correlations have been observed between RS-derived drought indices and soil moisture at different depths [36]. The correlation between soil moisture based on ground measurements and RS-derived drought indices was used to evaluate drought severity and validate the accuracy of the RS-derived drought indices. 3.2.2. County LevelThe RDA is considered as qualified assessment for consequences that include are values intended to measure consequences of drought, including vegetation growth rate, vegetation damage, and vegetation adequacy for feeding livestock. RDA data are field-derived regional, manual, and experiential observations based on plant growth, growth stage, and grassland productivity information, and provide a very suitable and exact description of drought severity. Here we recommended this reference data for evaluating the drought results of satellite-based data in county scale.Meanwhile, for compatibility with RS-derived values, we combined the RDA values of 5 and 6 into the single value, which gave the average of 5 (which means no drought). In addition, RDA data was used for constructing a consistence percentage (CP) indicator for consistent evaluation of county-based drought based on field-derived and RS-derived values.", 3. Methodology, 3.2. Ground Data-Derived Indices,3
128,"Ped [30] originally established the PED index to detect the long-term intensity of meteorological drought using corresponding environmental parameters, including air temperature and precipitation, which were monitored at stations over a long period.




P
E

D
i

=
 



T
i

−

T
¯




σ
T



−
 



P
i

−

P
¯




σ
P








(2)


where T is air temperature, P is precipitation, and 



σ
T



 and 



σ
P



 are the standardized deviations of temperature and precipitation. Accordingly, 


T
¯


 and 


P
¯


 are the corresponding means.The PED drought index was used to determine temperature anomalies and precipitation deficits, and it reflects the effects of these two combined parameters on drought. Mongolia experiences particularly extreme annual temperature fluctuations in response to global climate change, and high temperatures may cause water stress and drought [31]. According to the records of 48 meteorological stations distributed over the territory of Mongolia, the annual mean temperature of Mongolia increased by 2.14 °C during the last 70 years, and the number of hot days in the summer season is increasing [32]. In addition, the PED is very effective at monitoring drought in Russia [30] and the Bulgarian low regions [33]; therefore, the PED meteorological index was used in this paper.Drought had a substantial influence on maximum measured aboveground biomass production [34,35]. Since absolute biomass data had shortcomings of spatial and temporal comparability, we developed a normalized biomass (NorBio) for the assessment of grassland drought along similar lines to the development of the VCI equation as a normalized calculation using long-term data. Station biomass data was correlated with the eight RS-derived drought indices. NorBio can be calculated by using the equation





B
i
o
m
a
s

s

n
o
r
m
a
l
i
z
e
d



(

i
,
n

)

=
 


B
i
o
m
a
s
s

(

i
,
 
 
n

)

−
B
i
o
m
a
s

s

m
i
n



(

i
,
 
 
n

)



B
i
o
m
a
s

s

m
a
x



(

i
,
n

)

−
B
i
o
m
a
s

s

m
i
n



(

i
,
n

)








(3)


where 


B
i
o
m
a
s

s

n
o
r
m
a
l
i
z
e
d



(

i
,
n

)



 is the normalized biomass for period i and station n, 


B
i
o
m
a
s
s

(

i
,
n

)



 is the biomass for period i and station n in a certain year, 


B
i
o
m
a
s

s

m
a
x



(

i
,
n

)



 is the multi-year maximum biomass for period i and station n, and 


B
i
o
m
a
s

s

m
i
n



(

i
,
n

)



 is the multi-year minimum biomass for period i and station n.Soil moisture is a good indicator of drought caused by water reduction, and changes in soil moisture can reflect drought change trends. High correlations have been observed between RS-derived drought indices and soil moisture at different depths [36]. The correlation between soil moisture based on ground measurements and RS-derived drought indices was used to evaluate drought severity and validate the accuracy of the RS-derived drought indices.", 3. Methodology, 3.2.1. Station Level,3
129,"The RDA is considered as qualified assessment for consequences that include are values intended to measure consequences of drought, including vegetation growth rate, vegetation damage, and vegetation adequacy for feeding livestock. RDA data are field-derived regional, manual, and experiential observations based on plant growth, growth stage, and grassland productivity information, and provide a very suitable and exact description of drought severity. Here we recommended this reference data for evaluating the drought results of satellite-based data in county scale.Meanwhile, for compatibility with RS-derived values, we combined the RDA values of 5 and 6 into the single value, which gave the average of 5 (which means no drought). In addition, RDA data was used for constructing a consistence percentage (CP) indicator for consistent evaluation of county-based drought based on field-derived and RS-derived values.", 3. Methodology, 3.2.2. County Level,3
130,"An evaluation was performed to assess the quality of the data derived from the model [37]. The index accuracy was then assessed over a widely distributed set of locations and long time periods via ground-truth data. However, for the drought indices, obtaining real drought values in a field campaign is difficult; thus, we assessed drought using other reference data. Normally, soil moisture was correlated with agricultural or vegetation drought [34]. Soil moisture in the field can reflect crop or vegetation drought, which also represent an effective method of evaluating grassland drought. Vegetation affected by drought experiences a sharp decrease in biomass; therefore, the field-based biomass index (NorBio) data is an effective method of assessing grassland drought. Field-based RDA are regional data from drought-affected areas and can directly describe the drought status in a region. Because grass drought is related to meteorological conditions and caused by extreme weather [7], the meteorological index (PED) is recommended in this paper.For correlation analyses at the pixel scale, the consistent and spatial distribution comparisons of drought results were analyzed to identify the most suitable and accurate drought indices for different land cover types to accurately describe drought occurrence and severity in Mongolia. 3.3.1. CorrelationWhen regional ground-truth data values are difficult to obtain or cannot be collected, in situ point data are important for evaluating RS-derived drought indices.Pearson’s correlation coefficient (R) usually indicates the correlation between two variables as






R

x
y


=


∑


i
=
1

n


[


(


x
i

−

x
¯


)


(


y
i

−

y
¯


)


]

/




∑


i
=
1

n


[




(


x
i

−

x
¯


)


2




(


y
i

−

y
¯


)


2


]








(4)


where 



r

x
y




 is the correlation coefficient, 



x

i




 and 



y

i




 are variables, 




x
 

¯



 and 




y
 

¯



 are the mean values of the variables, and n is the number of samples. 3.3.2. Consistence PercentageField drought distribution and statistical data such as county-level RDA can be easily obtained, and represent important drought evaluation information. At the county scale, CP reflects goodness of fit between field-based RDA and drought severity categories determined using satellite-derived drought indices. Higher CP values indicate greater consistency: 100% indicates that the same drought severity was obtained from the RS and field data.Next, CP was used to describe the relationship between field-derived vegetation conditions and RS-derived drought indicators in three land cover types. CP can be calculated by RDA data and DSC via the equation





C

P

c
o
u
n
t
y


=


CN


TN


 
×
 
100
%





(5)

For each unit, CN is the number of consistent drought severity rankings between 


R
D

A

c
o
u
n
t
y




 and 


D
S

C

c
o
u
n
t
y
_
R
S




, and TN is the number of RDA drought severity rankings. 3.3.3. Spatial AnalysisIf regional-scale data can be obtained from field measurements, the spatial distribution of drought based on field observation data and RS-derived drought indices can be analyzed and used to validate the drought indices. An ideal result corresponds to regional true-field data in the form of raster data with a certain resolution. In practice, however, the available data are obtained from different data sources and present various spatial attributes, extents, and resolutions. For this study, field drought distribution maps based on field-derived RDA were created and compared to RS-derived drought index maps to evaluate the spatial distribution differences and temporal change consistencies between them. The inverse distance weighted (IDW) method was used by IRIMHE to convert the in situ RDA into a 1 km raster format in order to create field drought spatial distribution maps [38]. The distribution maps of RS-derived drought indices were produced using ArcGIS 10.0 software and were used to determine whether these indices and RDA data exhibit consistent spatial distributions and temporal fluctuations.", 3. Methodology, 3.3. Suitability Analysis,3
131,"When regional ground-truth data values are difficult to obtain or cannot be collected, in situ point data are important for evaluating RS-derived drought indices.Pearson’s correlation coefficient (R) usually indicates the correlation between two variables as






R

x
y


=


∑


i
=
1

n


[


(


x
i

−

x
¯


)


(


y
i

−

y
¯


)


]

/




∑


i
=
1

n


[




(


x
i

−

x
¯


)


2




(


y
i

−

y
¯


)


2


]








(4)


where 



r

x
y




 is the correlation coefficient, 



x

i




 and 



y

i




 are variables, 




x
 

¯



 and 




y
 

¯



 are the mean values of the variables, and n is the number of samples.", 3. Methodology, 3.3.1. Correlation,3
132,"Field drought distribution and statistical data such as county-level RDA can be easily obtained, and represent important drought evaluation information. At the county scale, CP reflects goodness of fit between field-based RDA and drought severity categories determined using satellite-derived drought indices. Higher CP values indicate greater consistency: 100% indicates that the same drought severity was obtained from the RS and field data.Next, CP was used to describe the relationship between field-derived vegetation conditions and RS-derived drought indicators in three land cover types. CP can be calculated by RDA data and DSC via the equation





C

P

c
o
u
n
t
y


=


CN


TN


 
×
 
100
%





(5)

For each unit, CN is the number of consistent drought severity rankings between 


R
D

A

c
o
u
n
t
y




 and 


D
S

C

c
o
u
n
t
y
_
R
S




, and TN is the number of RDA drought severity rankings.", 3. Methodology, 3.3.2. Consistence Percentage,3
133,"If regional-scale data can be obtained from field measurements, the spatial distribution of drought based on field observation data and RS-derived drought indices can be analyzed and used to validate the drought indices. An ideal result corresponds to regional true-field data in the form of raster data with a certain resolution. In practice, however, the available data are obtained from different data sources and present various spatial attributes, extents, and resolutions. For this study, field drought distribution maps based on field-derived RDA were created and compared to RS-derived drought index maps to evaluate the spatial distribution differences and temporal change consistencies between them. The inverse distance weighted (IDW) method was used by IRIMHE to convert the in situ RDA into a 1 km raster format in order to create field drought spatial distribution maps [38]. The distribution maps of RS-derived drought indices were produced using ArcGIS 10.0 software and were used to determine whether these indices and RDA data exhibit consistent spatial distributions and temporal fluctuations.", 3. Methodology, 3.3.3. Spatial Analysis,3
134,"Eighty-six meteorological stations in Mongolian grassland areas were available from 2000 to 2014, and data from these stations was used for analysis and validation. The land cover of these stations can be divided into three types: forest steppe (18), steppe (41), and desert steppe (27). The effects of meteorological variations on vegetation were observed, and lags in vegetation response (drought or normal growth) were identified. Therefore, we calculated the one-month PED using data from the current 10-day and last two 10-day periods. Long-term analyses of PED meteorological index were performed on the grass-growing periods (June–August) from 2000 to 2014.The NDDI, NMDI, VSWI, and PED indices are positively correlated, whereas the other six indices are negatively correlated (refer to these equations in Table 1). The correlations between the satellite-based drought indices and the PED are shown in Table 3, which shows maximum, minimum, average, and standard deviation values of the correlation coefficients (MAX_R, MIN_R, AVE_R, and STDE_R) for all stations. The results indicate that VHI, TCI, and VSWI were highly correlated with satellite-based drought indices throughout the growing period in the steppe zone, with an average correlation of more than 0.52 at the 99% confidence level (this confidence level also applies to the following). The VHI had the highest average correlation (0.66) with a maximum value of 0.76. VHI and TCI exhibited the highest correlation values for forest steppe and desert steppe areas; the MAX_R of VHI was 0.75 (VHI and TCI averages were 0.61 and 0.56, respectively). The results indicate that VHI, TCI, and VSWI are significantly correlated with PED for the three steppe types, and that correlation between VHI and PED is higher than between TCI and VSWI. Additionally, STDE_R for the three land cover zones varied from 0.07 to 0.24. In forest steppe zones, TCI exhibited the lowest STDE_R, and there was less variability figure across stations. TCI is a stable and reliable index for this zone. Similar results were produced for VHI in the steppe zone and TCI and NDWI in the desert steppe zone. NMDI had the largest STDE_R for all three steppe zones, which demonstrates that this index cannot accurately reflect drought in Mongolia as a whole.Stations Erdenet, Erdenesant, and Saikhan were selected for the forest steppe, steppe, and desert steppe zones, respectively. Figure 3a–i are composed of time series plots based on nine RS-derived drought indices and the meteorological index (PED) from these three stations over the first 10 days of July from 2000 to 2014. The curves of the RS-derived drought indices were extracted using a 3 × 3 km window over the 86 meteorological stations. All nine RS-derived drought indices present obvious changes relative to the PED. The TCI, VCI, VHI, NDWI, VTCI, and VSDI are negatively correlated with the PED, whereas the NMDI, NDDI, and VSWI are positively correlated. Like the TCI, VCI, and VHI for Erdenet (forest steppe) exhibit less consistent changes than other indices. Moreover, the VSDI is not sensitive to the PED and shows a small value range. The Erdenet station is known to have experienced severe drought in the serious drought year of 2002. The lowest values in the time series occurred for the indices TCI, VCI, VHI, NDWI, VTCI, VSDI, and NMDI, and they corresponded to the largest PED values. The overall trend for the VHI, TCI, and VSWI curves are more consistent with the PED curve than for other curves for Erdenesant station (Figure 3d–f). The values of the VHI, VCI, TCI, and NDWI decrease rapidly with increases in the PED, and increase rapidly with decreases in the PED. In the desert steppe station (Saikhan), less vegetation resulted in lower sensitivity of the VCI and NDWI to drought. The VHI is obviously the best index for describing grassland drought, because it combines vegetation changes and temperature anomalies, and the PED also reflects water and thermal conditions. The highest correlation between the RS-derived drought indices and the PED is the VHI.", 4. Results, 4.1. Comparisons with the PED,4
135,"For this study, soil moisture observation data were obtained at depths of 5 cm and 10 cm for each 10 day period from 2000 to 2011 from 39 soil moisture sites (9 forest steppe sites, 23 steppe, and 7 desert steppe). We found that soil moisture at 10 cm was better associated with grass growth and drought conditions than that at 5 cm; therefore, the 10 cm depth soil moisture values were adopted for the analysis in this paper. To account for spatial consistency between soil moisture measurements and RS-derived drought indices, we selected the corresponding nearest pixel for each of the 39 soil moisture site locations and extracted each pixel’s value. Thus we created a dataset that included 39 pairs of site-based soil moisture and RS-derived drought index values for each drought index in every 10-day period.The Rs were determined from satellite-derived drought indices and ground soil moisture data; the results indicate that the TCI, NDWI, and VHI have higher Rs. For each steppe type, the MAX_R, MIN_R, AVE_R, and STDE_R were produced by many stations. In the forest zone, TCI presented the largest maximum and average R, as can be seen in Table 4, though larger STDE_R values occurred elsewhere. The correlation between ground-observed soil moisture at 10 cm and the NDWI in the steppe zone was the highest of the indices (0.69, which was significant at p < 0.01), followed by the VHI (0.67). However, in the desert steppe zone, VHI featured the highest correlation coefficient (0.61) among the indices. Lower STDE_R and higher VHI averages in the desert steppe zone show that these values are stable across stations.Point-derived data (such as soil moisture) only reflect information from a small region, while the drought extent determined by satellite data over large areas and long time periods are pixel values. Errors and uncertainties may occur in both data sets because of the difference in spatial scale.", 4. Results, 4.2. Comparisons with Soil Moisture,4
136,"To test the regional effectiveness of RS drought indices and determine the best index during the grass growing period for different land cover types (across 18 forest steppe stations, 41 steppe, and 27 desert steppe), we compared the RS drought indices with the NorBio index.Generally, the grass-growing period in Mongolia is from May to September. In May, the grass is short. July and August are critical grass-growing periods, and grass biomass data is available from field observations. Therefore, we selected observed biomass data from late July for correlation analysis with the RS-derived drought indices. Using Formula (3), we calculated the NorBio values and constructed a correlation graph for July using the nine RS-derived drought indices and station-based biomass data observed over 15 years (2000–2014). For each steppe type, the maximum, average, minimum, and STDE_R correlation values were produced by many stations (seen in Table 5). The results show high R values for some indices, with maximum values up to and above 0.90. For the forest steppe areas, the NDWI, VHI, VCI, and VSWI have better correlations than the other indices, with AVE_R values of 0.70, 0.62, 0.64, and 0.59, respectively, and MAX_R values of 0.92, 0.87, 0.83, and 0.78, respectively. For the steppe regions, the VHI, NDWI, VCI, and VSWI have higher correlations with the ground-based NorBio values than the other indices, with averages of 0.60, 0.61, 0.57, and 0.59, respectively, and MAX_R values of 0.94, 0.95, 0.94, and 0.88, respectively. VCI, VSWI, VHI, and NDWI have AVE_R values of 0.67, 0.60, 0.59, and 0.48, respectively, and MAX_R values of 0.92, 0.83, 0.82, and 0.86, respectively, in the desert steppe areas. The NDWI coefficient varies greatly among the stations with high STDE_R values, with a MAX_R value of 0.86 and MIN_R value of 0.08. The signs of the VSDI and NMDI correlation coefficients vary: some stations have positive correlations, whereas others have negative correlations.Figure 4a–i show the time series plots of nine RS-derived drought indices and the NorBio values at three stations (representing the three types of steppes) for the last 10-day period of July from 2000 to 2014. The dynamic trend of the NorBio is similar to that of the RS-derived drought indices throughout the studied period. The TCI, VCI, and VHI also showed fluctuation trends consistent with the NorBio. Generally, the TCI, VCI, VHI, NDWI, VSDI, and VTCI had positive relationships with the NorBio, and these values were also substantially lower in the severe drought year of 2002 than in a weak drought year (2003) for the three representative stations, except for the VCI at the Erdenet station (forest steppe, Figure 4a). The TCI, VCI, and VHI values increased more than the NDWI, VSDI, and VTCI values during the severe summer drought of 2003, which suggests that the former are more sensitive than the latter to drought conditions. The relationship between NMDI and NorBio was negative, although opposite results were observed in certain years, as shown in Figure 4b,e,h, indicating that this index is not suitable for detecting drought in Mongolia. When the NDDI was compared with the NorBio, the change trends in certain years (such as 2001, 2004, and 2012–2014 at the Erdenet station) were inconsistent; the VSWI and NorBio curves showed greater consistency.", 4. Results, 4.3. Comparisons with the NorBio,4
137,"The RDA have a specific characterization area due to their nature as field observations, and are used to evaluate vegetation conditions at the county level. The DSC based on RS-derived drought indices represents drought status at the county scale. We adopted CPs (explained in Section 3.3.2) to describe the abilities of the RS-derived indices to monitor summer drought using RDA as field-derived reference data. We calculated the DSC, RDA, and CP for 37 counties and analyzed the results.The CP values for the three land cover types are shown in Figure 5. The CPs of the VHI, VCI, TCI, and NDWI relative to the RDA were higher than those of the other indices. In the forest steppe regions, the highest average CP values were from the VHI, VCI, TCI, and NDWI at 74, 73, 73, and 71%, respectively. The maximum values for these indices were 84, 74, 81, and 87%, respectively. VHI, VCI, TCI, and NDWI predicted the same level of drought severity as RDA for approximately two-thirds of all 10-day intervals during summers from 2000 to 2014. For the steppe areas, the drought CPs between the VHI, VCI, and RDA were higher than those of the other indices, at 74%, although the average CP between the NDWI and the RDA was 73%. The maximum CP values for VHI, VCI, and NDWI were 89, 89, and 88%, respectively. The highest average drought CP (67%) was between VCI and RDA in the desert steppe zone (maximum value of 79%), and an average value of 66% was observed between VHI and RDA across all stations (maximum value of 81%).These results show good consistencies between RS-derived drought indices and the field-derived RDA. The VCI, TCI, VHI, and NDWI are more sensitive to grassland drought and had stronger relationships with the RDA. These indices can accurately describe changes in drought in Mongolia at different temporal and spatial scales. In addition, the CP value for steppe is generally higher than for the other two land cover types, and the lowest CP is found in the desert steppe zone.", 4. Results, 4.4. Comparisons with the RDA in County,4
138,"Mongolia experienced heavy drought conditions in 2002 and slight drought conditions in 2003. Two typical years (the first 10 days of July in 2002 and 2003) of drought monitoring results (Figure 6 and Figure 7) were selected for the visual comparison of the spatial monitoring characteristics of the nine RS-derived drought indices with the reference RDA data. In 2002, drought occurred throughout most of Mongolia except for eastern Mongolia and a few other areas. The VHI and VCI maps showed similar distributions as the reference RDA map in central and southern Mongolia (mainly steppe and desert steppe areas), whereas the NDWI and NDDI maps exhibit good correlations in the northern forest steppe region. The VTCI and VSWI maps showed strong drought conditions, and the NMDI map showed drought in only the southern and western regions. Similar maps were generated for the slight drought year of 2003. The VHI and TCI maps were consistent with the distributions in reference to the RDA map in the central and southern Mongolia. The NDDI and VSWI maps showed heavier drought in the south but slight or no drought in the north or central Mongolia, which was completely inconsistent with the results in the RDA map. In comparison to the RDA and the VHI, TCI, and VCI map, the VTCI showed drought distribution over a larger area, whereas the VSDI showed less drought distribution. In the north forest steppe region, the NDWI and NDDI maps showed only the approximations of the drought distribution. Thus, for the weak drought year of 2003, we find that the VHI, TCI, and NDWI maps were more consistent with the reference RDA map than those of the other indices.To clarify the annual variations, we focused on the temporal fluctuations from 2002 to 2003. The NDWI, NMDI, NDDI, VSWI, VSDI, and VTCI maps had features of the same drought pattern in 2002 and 2003, with less drought extent and severity in 2003. The VHI, VCI, and TCI results indicated decreasing drought extent and severity, consistent with the RDA map and local drought characteristics. Furthermore, the NDWI and NDDI maps showed distribution features in the northern forest steppe region that were consistent with significantly decreasing trends as on the RDA map. Figure 6 and Figure 7 illustrate the advantages of the VHI, VCI, TCI, and NDWI for drought monitoring large areas of Mongolia.", 4. Results, 4.5. Spatial Consistence Comparsions,4
139,"A suitability analysis was conducted by comparing the RS-derived drought indices to the ground-derived results of the PED, soil moisture, NorBio, and RDA for the forest steppe, steppe, and desert steppe areas during the study period at the pixel, county, and regional scales. The output is shown in Table 6. For each area, two levels (best and second best) were used to express sensitivity to reference indicators. The primary results were VHI/NDWI/TCI for forest steppe, VHI/VCI/NDWI for steppe, and VHI/VCI/VSWI for desert steppe. As the VHI index consists of both the VCI and TCI, the VHI can represent those two indices.In terms of statistical distribution, there is an obvious trend point that represents the general level of data, known as the mode. The mode is the value that is repeated most often in a data set. Here, we propose using the mode to select the best indices for grassland drought monitoring. Based on the mode, the best indices are VHI and NDWI. Therefore, we find that these two RS-derived drought indices (VHI and NDWI) accurately describe Mongolian drought in the growing stage.", 4. Results, 4.6. Comprehensive Results,4
140,"This paper proposes a comprehensive suitability analysis method for monitoring drought in Mongolia. The selected RS-derived drought indices (TCI, VCI, VHI, NDDI, VSWI, VTCI, VSDI, and NMDI) and were derived from multi-band data (visible, NIR, SWIR, and thermal infrared). The new method does not depend on only one reference data for evaluation; it takes full advantage of multiple sources of field data (environmental conditions, grass condition, and drought-affected information) to describe drought status at different scales for different aspects.Drought had a substantial influence on maximum measured aboveground biomass production [34,35]. However, biomass data reflect vegetation conditions in different areas at different times, and are limited in terms of spatial and temporal comparability with drought indices. To reduce these shortcomings, the NorBio was implemented to capture regional climate differences and the effects of short-term weather-related fluctuations on vegetation. Additionally, an AVHRR-based VHI was successfully used as a proxy for biomass in Mongolia [28], because the VHI has high correlations with biomass anomalies and estimates of crop yield and grassland biomass in other parts of the world [39,40,41]. The biomass production of a barley crop changes in response to drought depending on the timing and duration of the drought [35]. Drought stress may influence the water supply to vegetation and reduce accumulated biomass and production of crops or grasses. Hence biomass data can reflect the extent and severity of drought; we successfully used biomass index to express drought status in different regions over many years.VHI and NDWI are the best indices for Mongolian drought, based on comparisons with field RDA. Because RDA is regional data, we analyzed the temporal and spatial distributions of RDA and satellite-derived drought indices for the severe drought in 2002 and the slight drought in 2003. The VHI and NDWI had more consistent spatial–temporal drought variability than the other indices. The spatial distribution data was able to express the general drought status, changes, and development better than the pixel- or point-based data.Considering all the multi-aspect and multi-reference comparison results, the VHI and NDWI are the optimal selection. Kogan [28] previously applied the VHI for drought detection and derivation of pastoral biomass in Mongolia and found that VHI could reflect grassland health conditions and water- and temperature-related vegetation stress during drought. Hence the results of this paper are consistent with the findings of pioneering researchers. This index was also used for monitoring drought in other areas. Initially, VHI was used to evaluate the impact of drought on regional agricultural production in South America, Africa, Asia, North America, and Europe [7,39,40], and a very strong correlation was observed between VHI and crop yield, particularly during critical periods of crop growth. In China, VHI has been evaluated for drought monitoring by several researchers [42,43,44], who found that it was a stable and reasonable RS index for monitoring agricultural drought in different agro-meteorological zones of China. Our research has found that the NDWI can also accurately express Mongolian grassland drought over long periods. The NDWI was derived from the NIR and SWIR channels, and it responded to changes in both water content (absorption of SWIR radiation) and spongy mesophyll (reflectance of NIR radiation) in vegetated areas [10]. The NDWI has further been used to monitor the moisture conditions of vegetation canopies over large areas in several investigations [45,46]. Soil moisture is a critical component in interactions between the land surface and the atmosphere, and prolonged soil moisture deficits often lead to drought-induced vegetation stress [47]. We evaluated the performances of the NDWI for drought monitoring, and found that it is more sensitive to Mongolian grassland drought than other possible indices, especially for forest steppe (seen in Table 4). The spatial distribution of NDWI values can best express RDA spatial distribution in forest steppe areas. Additionally, high correlation coefficients between NDWI and NorBio exist for forest steppe and steppe regions. Therefore, the NDWI is a very effective and simple index for monitoring grassland drought.However, certain weaknesses in the proposed RS-derived drought products (VHI and NDWI) and ground data must be mentioned. These differences were caused by several error sources, including the selection of field stations, the distance between repeated points, differences in soil structures, and inconsistencies between the footprint of RS data and the point-based nature of the measured parameter indicators (soil moisture, NorBio, and PED). Soil moisture is a good indicator for vegetative drought; however, it is derived from in situ data, and it is difficult to obtain high correlations between in situ data and the spatial data of drought indices. Future experiments should focus on measurements of regional soil moisture to determine changes in drought. Normally, the PED index requires data over long time periods; however, the currently available dataset only covers approximately 15 years. The RDA is treated as regional field observation data, the data is actually collected by different observers without standardized instruments or equipment, possibly resulting in somewhat subjective results.The VHI may feature additional errors for high-latitude regions, according to A. Karnieli [48]. The relationship between NDVI and LST is positive, but the VHI-based drought index hypothesizes that increasing temperatures act negatively on vegetation vigor and consequently cause water stress and drought. However, in high-latitude or equatorial humid regions, higher temperatures accelerate vegetation growth, and vegetation development is mainly limited by the available energy. Consequently, the VHI may not be the best index for drought monitoring in high-latitude regions. Indeed, this paper has shown that, in forest steppe areas, VHI is not always the best indicator for describing drought (Table 4). Our comparison analysis of NorBio and RDA spatial distribution showed that NDWI was better than VHI. This result is consistent with previous findings [49,50]. In this paper, we adopted the VHI equation used by Kogan’s papers [7,28]. In this equation, the coefficients of TCI and VCI are the same, that is, to 0.5, which is not strictly accurate because the NDVI and the LST exert varying influences on drought in different regions or ecosystems. In the future, focus should be on these shortcomings to find the optimal coefficients for various regions. This will enable the construction of a comprehensive drought monitoring model for the entirety of Mongolia based on the VHI (with various coefficient of TCI and VCI), and NDWI.", 5. Discussion,None,5
141,"To identify the optimal index or indices for monitoring pasture drought in Mongolia, a new adaptability analysis framework was adopted for evaluating the performances of satellite-derived drought indices. Methods based on comparison to a meteorological index (PED), normalized biomass (NorBio) reference indicator, and RDA-based drought consistent percentage (CP) were proposed. Due to valuations at diverse scales (pixel, county, and region) for three land cover types (forest steppe, steppe, and desert steppe), Pearson’s correlation, CPs, and spatial consistency analysis methods were adopted, and an integrated assessment was developed to fully describe drought status. The mode method of statistical significance was used to identify comprehensive results among the comparisons of satellite-derived drought indices and five different reference indicators (PED, soil moisture, NorBio, RDA, and RDA spatial distribution).The VHI and NDWI were found to be appropriate for the assessment of drought characteristics and for monitoring drought conditions in Mongolian grassland. These indices were able to detect the timing of drought onset and processes, and provided realistic quantification of drought severity in the study areas. These two indices can therefore be used to develop a combination drought model for accurately monitoring drought in the future. A comprehensive and novel adaptability analysis framework was built to identify the most appropriate satellite-derived drought indices for the accurate and near real-time detection of droughts in other countries or regions.", 6. Conclusions,None,6
142,"There are two major active remote sensing technologies, light detection and ranging (lidar) and radio detection and ranging (radar). Lidar uses optical wavelengths, while radar transmits microwave radiation and records echoes from the target objects. In forestry inventories and monitoring programs, lidar (such as ICEsat or GEDI) can only collect sparse measurements for large areas, but radar has the advantage of continuous measurements over large areas. Theoretically, given a radar sensor with a fixed wavelength, an incident angle, and a polarization mode, the penetration depth and the backscattering intensity or interference should be correlated to target properties (e.g., soil roughness, moisture, or forest biomass). Thus, radar technology, primarily synthetic aperture radar (SAR), is capable of mapping large-scale forest biomass over the past three decades [1,2,3,4]. 1.1. Microwave Methods for Forest Vertical Structure RetrievalThe forest vertical structure is not easy to retrieve from SAR images. For this purpose, tomography technique, an extension of multi-baseline interferometric, has been proposed to obtain the vertical distribution of backscattering energy in forest. Several studies have achieved the acquisition of forest height, aboveground biomass, and forest structure dynamic changes using SAR tomography at L-band and P-band [5,6,7,8]. However, due to the difficulty in obtaining data with ideal baseline configurations, and the large uncertainty of the reconstructed energy profiles with different inversion algorithms, SAR tomography for forest structures has not yet entered operational stages. Thus, it will be interesting to develop some waveform radar sensors using microwave wavelength, called profile radar, as a complement to SAR and lidar. From 1988 to 1991, an air-borne profile radar system (HUTSCAT) was constructed, operating in X band and C band. HUTSCAT did response from boreal forest, showing clearly the contribution of forest structure and ground [9,10]. From 2012 to 2016, a lightweight Ku-band profile radar (Tomoradar), viable for unmanned aerial vehicle, was designed by the Finnish Geospatial Research Institute (FGI) [11]. Tomoradar is a Frequency Modulated Continuous Wave (FM-CW) ranging radar system with a Global Navigation Satellite System (GNSS) and Inertial Measurement Unit (IMU) system, which offer centimeter accuracy of fly trajectory information. Tomoradar on a helicopter platform can collect, continuously, full polarization backscatter waveforms within a several-meters footprint. Several works have been carried out to quantify the energy of backscatter signals from the ground and canopy, and estimate the elevations at ground level and tree top level [11,12,13,14]. For instance, Chen et al. have proven that the Tomoradar can collect the profile information clearly from tree canopy top to ground level for both co- and cross-polarizations [11]. Feng et al. have used Tomoradar to estimate ground elevation and canopy top elevation, and the root mean square errors (RMSEs) were less than 1 m, compared with lidar measurements [13]. However, until now, there are still very few radiative transfer (RT) models to explain and exploit the profile radar waveform, which limits its value. 1.2. Related Studies on Profile RadarHence, it is essential for a theoretical model to simulate the profile radar waveform of forests, which would support researchers for comprehensively exploring the profile radar response from forests, and probably come up with more accurate methods to forest resource mapping. The water cloud model is one of the most classical microwave scattering models, in which the vegetation is represented by a homogeneous droplet cloud [15]. By describing the vegetation as a single homogeneous layer, Karam and Fung used finite-length cylinders to establish a scattering model for defoliated vegetation [16]. Thus, it is not applicable for canopies with vertical structures. In 1990, Ulaby et al. established the Michigan Microwave Canopy Scattering model (MIMICS), which divided forest canopies into three layers: crown, trunk, and understory [17]. Another multi-layer model, MIT/CESBIO backscatter model, was proposed by Hsu et al. in 1994 to simulate the backscattering in P band, which was a first order RT model [18]. With the coupling of the MIT/CESBIO backscatter model to the architectural tree growth model (AMAP), respectively, Floury et al. simulated the Spaceborne Imaging Radar- C/X-band Synthetic Aperture Radar (SIR-C/X-SAR) data and Martinez et al. developed the HUTSCAT profile waveforms [19,20]. In 2004, Picard et al. simulated the HUTSCAT waveforms by a three-dimension (3D) RT model [21]. However, there is no study to simulate the Ku-band profile radar where the multiple scattering may not be neglected.Recently, a three-dimension RT model, named Radiosity Applicable to Porous IndiviDual objects (RAPID version 2), was proposed, which invented a new approach to solve the radar scattering [22]. To the best of our knowledge, RAPID2 is the first shared unified model that can simulate the full spectrum radiation from optical to microwave wavelength domains, contributing to theoretical study of multi-sources data inversion. However, the initial simulation objective in the RAPID2 model is the backscattering of SAR, a side-looking radar, which cannot obtain the microwave energy profile in forests. 1.3. Aims and ObjectivesThe aim of this work is to simulate the profile radar waveform of forests by extending the RAPID2 model. The RAPID2 model exhibits great potential for improving the understanding of microwave response from forests and contributing to the development of multi-sensor and data fusion. Through the further extension of profile radar waveform simulation function, the advantages of profile radar, which shows the contribution of forest structure and ground more clearly, can be used to better understand the interaction. Moreover, by combining the extended RAPID2 model and forest growth model, the application of profile radar can be more extensive in the forest parameters extraction as well. For many applications using profile radar, the penetration depth tends to be a key information. Therefore, we extended the RAPID2 model to simulate the profile radar waveform of forests and analyzed the sensitivity of the signal penetration depth in various forest scenes in this research.", 1. Introduction,None,1.
143,"Focusing on the research objective, this paper is divided into three major parts (Figure 1): model extension of RAPID2, validation, and sensitivity analysis on penetration depth.First, we realized the RAPID2 model extension of the profile radar waveform simulation function. The extensions of the RAPID2 model are mainly on incidence angle, ground scattering, and waveform recording. As for profile radar, the incident direction is nadir-looking, instead of side-looking; thus, the transmitting and receiving directions of microwave were adjusted to be perpendicular in the extended RAPID2 model. The specular scattering of ground surface was adopted to fit the nadir incidence. Besides, the timing resolution was greatly increased to support waveform recording.Second, to validate the simulation results of the extended model, two plots of waveform data for different forest densities, acquired by Tomoradar HH and HV polarization in October 2016, were adopted as references. The two plots are continuous, which have the similar parameters of branch/twig and dielectric constant properties, making two plots comparable. To obtain the better consistency, the 3D scenes of the two plots were built with parameters extracted from airborne lidar point cloud, which collected simultaneously with Tomoradar. Moreover, the accuracies of profile radar waveform simulations in both co- and cross- polarization for thin and dense forests were estimated.Third, the Ku-band penetration depth at nadir incidence of various forest scenes was studied.Accordingly, the rest of this paper is organized as follows. The RAPID model and extension are introduced in Section 3. Then, the model validation is presented in Section 4. Moreover, Section 5 illustrates the sensitivity analysis of penetration depth. In addition, Section 6 expounds the discussion of the results in detail. Finally, the conclusions are drawn in Section 7.", 2. General Strategy and Framework,None,2
144,"RAPID2 model mainly consists of the built-in 3D scene graphical user interface (GUI) and the radiosity framework. Users can generate forest scenes by setting forest and terrain parameters. Based on the forest scene, remote sensing data of various wavelength ranges from visible/near infrared to thermal infrared and microwave are simulated using a unified radiosity model. The RAPID2 model is freely distributed online (http://www.3dforest.cn/en_rapid.html). Since the purpose of this paper is to simulate profile radar waveform, the microwave backscattering simulation of the RAPID2 model is described in the following sections. 3.1.1. Three-Dimension Scene GenerationThe size and the digital elevation model (DEM) of 3D scenes could be set firstly, according to plot conditions. After that, the 3D objects, such as trees, crops, water bodies, and buildings, could be defined in the scene. In this study, trees and shrubs are the objects on ground, where the default parameters (such as height, length, width, and LAI of crown) are modified according to lidar point cloud (see details in Section 3.2).For vegetation, the solid stem and porous crown layers generally contribute a single plant. Each porous crown layer is composed of leaves (or needles) and branches, characterized by length, thickness, orientation and density, length, and diameter, respectively. Thin discs represent broad leaves; cylinders represent needles and branches. The branches are divided into large branches and small twigs. The leaf angle distribution (LAD) and branch orientation distribution (BOD) are set from 0°to 85°with a step of 5°, assumed to be independent of azimuth. In addition, the porous objects are projected dynamically and drawn as numerous sub-leaves in the optical region or particles in the microwave region, based on the LAI, LAD, and leaf size of the crown, so as to only view factors between porous objects (not between hundreds of small particles) need to be calculated and stored. Therefore, the RAPID2 significantly reduces the huge memory requirements of large and realistic vegetation scenes and the long calculation time of view factors. For ground surface, soil facets are characterized by roughness size and correlation length. A sample forest scene in RAPID2 is illustrated in Figure 2.In microwave domain, dielectric constants of objects are of great significance for their scattering and extinction characteristics. The relative dielectric constants of stem (



ε
t



), branch (



ε
b



), leaf (



ε
l



), and soil (



ε
s



) need to be pre-defined with environment temperature and moisture content [17]. 3.1.2. Radiosity FrameworkComparing to classical radiosity transfer equation, the radiosity is replaced by the Stokes vector and the reflectance is replaced by the scattering matrix in RAPID2. As a result, the extended radiosity theory is able to simulate microwave scattering in RAPID2. For specular scattering, as an example, the Stokes vector (


I


) at the direction (



Ω



) can be expressed as:





I
i


(
Ω
)

 
=



 
I



i
,
0



(
Ω
)

+


∑

j


ρ
i


(


Ω
j

,
Ω

)


F

ij



(


Ω
j


)


I
j


(


Ω
j


)

+


∑

k


τ
i


(


Ω
j

,
Ω

)


F

ik



(


Ω
k


)


I
k


(


Ω
k


)






(1)


where 



I

i
,
0




 is the single scattering Stokes vector of object i; 



Ω
j



 or 



Ω
k



 is the normal direction of object j or k to object i; 



F

ij




 or 



F

ik




 is the directional view factor between j (or k) and i from 



Ω
j



 or 



Ω
k



 to 


Ω


; 

ρ

 or 

τ

 is directional scattering or transmittance matrices, and 

ρ

 can be expressed as Mueller matrix (M):






ρ
 
=
 
M
(

Ω

in


,
 



p
1


→



,
Ω


out


)




=

1


A
0




 
cos
 
θ


s




[





|


S

vv



|

2





|


S

vh



|

2



Re
(

S

vh

*


S

vv


)


−
Im
(

S

vh

*


S

vv


)






|


S

hv



|

2





|


S

hh



|

2



Re
(

S

hh

*


S

hv


)


−
Im
(

S

hh

*


S

hv



)







2
Re
(
S


vv



S

hv

*

)




2
Re
(
S


vh



S

hh

*

)




Re
(
S


vv



S

hh

*



+
S


vh



S

hv

*

)


−


Im
(
S


vv



S

hh

*

−

S

vh



S

hv

*

)






2
Im
(
S


vv



S

hv

*

)




2
Im
(
S


vh



S

hh

*

)




Im
(
S


vv



S

hh

*



+
S


vh



S

hv

*

)




Re
(
S


vv



S

hh

*

−

S

vh



S

hv

*

)



]








(2)


where 



S

pq




 is the complex scattering matrix.The scattering of a porous object is composed of Lambertian and non-Lambertian parts. The non-Lambertian part means its scattering is direction-dependent, which includes forward and specular scattering. For solid objects, such as soil and trunk, the forward scattering is minor and ignored.The total scattering process of a forest canopy is separated into single scattering, double bouncing scattering, and multiple scattering, based on three pre-hypotheses: (1)The specular scattering is independent from Lambertian scattering.(2)The major double bouncing scatterings 



I

i
,
1



(


Ω

spec



)



 include the specular scattering between trunk and soil, and the specular scattering between crown layers and soil.(3)Multiple scattering 



I

i
,
2

+



 only occurs from the Lambertian scattering among the porous objects.Finally, the radar backscattering of vegetation is as follows:





I
i


(


Ω

back



)

 
=



 
I



i
,
2

+

+

I

i
,
1



(


Ω

spec



)






(3)

The major output results of RAPID2 are the total backscattering coefficient of the scene, the backscattering coefficients of each component (crown, trunk, soil) and the simulated radar images of the scene in full polarization modes.", 3. RAPID Model and Extension, 3.1. RAPID2,3
145,"The size and the digital elevation model (DEM) of 3D scenes could be set firstly, according to plot conditions. After that, the 3D objects, such as trees, crops, water bodies, and buildings, could be defined in the scene. In this study, trees and shrubs are the objects on ground, where the default parameters (such as height, length, width, and LAI of crown) are modified according to lidar point cloud (see details in Section 3.2).For vegetation, the solid stem and porous crown layers generally contribute a single plant. Each porous crown layer is composed of leaves (or needles) and branches, characterized by length, thickness, orientation and density, length, and diameter, respectively. Thin discs represent broad leaves; cylinders represent needles and branches. The branches are divided into large branches and small twigs. The leaf angle distribution (LAD) and branch orientation distribution (BOD) are set from 0°to 85°with a step of 5°, assumed to be independent of azimuth. In addition, the porous objects are projected dynamically and drawn as numerous sub-leaves in the optical region or particles in the microwave region, based on the LAI, LAD, and leaf size of the crown, so as to only view factors between porous objects (not between hundreds of small particles) need to be calculated and stored. Therefore, the RAPID2 significantly reduces the huge memory requirements of large and realistic vegetation scenes and the long calculation time of view factors. For ground surface, soil facets are characterized by roughness size and correlation length. A sample forest scene in RAPID2 is illustrated in Figure 2.In microwave domain, dielectric constants of objects are of great significance for their scattering and extinction characteristics. The relative dielectric constants of stem (



ε
t



), branch (



ε
b



), leaf (



ε
l



), and soil (



ε
s



) need to be pre-defined with environment temperature and moisture content [17].", 3. RAPID Model and Extension, 3.1.1. Three-Dimension Scene Generation,3
146,"Comparing to classical radiosity transfer equation, the radiosity is replaced by the Stokes vector and the reflectance is replaced by the scattering matrix in RAPID2. As a result, the extended radiosity theory is able to simulate microwave scattering in RAPID2. For specular scattering, as an example, the Stokes vector (


I


) at the direction (



Ω



) can be expressed as:





I
i


(
Ω
)

 
=



 
I



i
,
0



(
Ω
)

+


∑

j


ρ
i


(


Ω
j

,
Ω

)


F

ij



(


Ω
j


)


I
j


(


Ω
j


)

+


∑

k


τ
i


(


Ω
j

,
Ω

)


F

ik



(


Ω
k


)


I
k


(


Ω
k


)






(1)


where 



I

i
,
0




 is the single scattering Stokes vector of object i; 



Ω
j



 or 



Ω
k



 is the normal direction of object j or k to object i; 



F

ij




 or 



F

ik




 is the directional view factor between j (or k) and i from 



Ω
j



 or 



Ω
k



 to 


Ω


; 

ρ

 or 

τ

 is directional scattering or transmittance matrices, and 

ρ

 can be expressed as Mueller matrix (M):






ρ
 
=
 
M
(

Ω

in


,
 



p
1


→



,
Ω


out


)




=

1


A
0




 
cos
 
θ


s




[





|


S

vv



|

2





|


S

vh



|

2



Re
(

S

vh

*


S

vv


)


−
Im
(

S

vh

*


S

vv


)






|


S

hv



|

2





|


S

hh



|

2



Re
(

S

hh

*


S

hv


)


−
Im
(

S

hh

*


S

hv



)







2
Re
(
S


vv



S

hv

*

)




2
Re
(
S


vh



S

hh

*

)




Re
(
S


vv



S

hh

*



+
S


vh



S

hv

*

)


−


Im
(
S


vv



S

hh

*

−

S

vh



S

hv

*

)






2
Im
(
S


vv



S

hv

*

)




2
Im
(
S


vh



S

hh

*

)




Im
(
S


vv



S

hh

*



+
S


vh



S

hv

*

)




Re
(
S


vv



S

hh

*

−

S

vh



S

hv

*

)



]








(2)


where 



S

pq




 is the complex scattering matrix.The scattering of a porous object is composed of Lambertian and non-Lambertian parts. The non-Lambertian part means its scattering is direction-dependent, which includes forward and specular scattering. For solid objects, such as soil and trunk, the forward scattering is minor and ignored.The total scattering process of a forest canopy is separated into single scattering, double bouncing scattering, and multiple scattering, based on three pre-hypotheses: (1)The specular scattering is independent from Lambertian scattering.(2)The major double bouncing scatterings 



I

i
,
1



(


Ω

spec



)



 include the specular scattering between trunk and soil, and the specular scattering between crown layers and soil.(3)Multiple scattering 



I

i
,
2

+



 only occurs from the Lambertian scattering among the porous objects.Finally, the radar backscattering of vegetation is as follows:





I
i


(


Ω

back



)

 
=



 
I



i
,
2

+

+

I

i
,
1



(


Ω

spec



)






(3)

The major output results of RAPID2 are the total backscattering coefficient of the scene, the backscattering coefficients of each component (crown, trunk, soil) and the simulated radar images of the scene in full polarization modes.", 3. RAPID Model and Extension, 3.1.2. Radiosity Framework,3
147,"Table 1 presents the differences and requirements to extend RAPID2 from SAR mode to profile radar mode. Firstly, there are significantly different observation modes between SAR and profile radar, where the transmitting and receiving directions of microwave were adjusted to be perpendicular. Secondly, compared with the mixture of ground surface scattering and vegetation scattering in SAR data, the ground surface scattering is more independent and stronger in profile radar scattering. The major scattering type contributing to the ground surface scattering changes from Lambertian scattering to specular scattering in profile radar observation. Thirdly, the outputs of SAR and profile radar are different. The output of SAR includes an image and total backscattering coefficients, while that of profile radar is waveform. In consequence, the output function with high resolution of the vertical backscattering intensity records should be added to the extend RAPID2 model.Figure 3 further demonstrates the difference of the major ground surface scattering type between SAR and profile radar.As specular scattering is identified as the main type of ground surface scattering, the intensity of the specular scattering needs to be estimated. In this paper, we adopted Fresnel scattering coefficient to acquire the co-polarization intensity of specular scattering. The co-polarization backscattering coefficient can be defined as [24]:





σ

hh


 
=



 
R



hh


 
=
 



|



cos
θ
−



ε
r

−


sin

2

θ




cos
θ
+



ε
r

−


sin

2

θ





|


2






(4)






 

σ

vv


 
=



 
R



vv


 
=
 



|




ε
r

cos
θ
−



ε
r

−


sin

2

θ





ε
r

cos
θ
+



ε
r

−


sin

2

θ





|


2

 





(5)


where the 



R

hh




 and 



R

vv




 are the Fresnel scattering coefficient; 

θ

 is the incident angle; 



ε
r



 is the complex dielectric constant.Since the backscattering intensity of cross-polarization cannot be simulated by the Fresnel scattering coefficient, an empirical coefficient was adopted to estimate the value, which is related to that of co-polarization backscattering [25]. The cross-polarization backscattering coefficient can be expressed as:





σ

hv


 
=



 
k
∗
σ



hh







(6)

A series of k values from 0.1 to 1.0 with a step of 0.05 are set to optimize the backscattering intensity during the simulation of the ground waveform at cross-polarization. Therefore, a total of 20 simulated waveforms could be obtained, of which the waveform that best matches the real waveform is selected as the final simulated result. It is worth noting that the empirical coefficient is only for cross-polarization, and for a stand with similar density, it only needs to be calibrated once.By modifying the direction of microwave transmitting and receiving, the major type of ground surface scattering, the output format for simulation results and calculating the intensity of specular scattering with Fresnel scattering coefficient, the RAPID2 model has been extended to have the function of profile radar waveform simulation.", 3. RAPID Model and Extension, 3.2. RAPID2 Model Extension,3
148," 4.1.1. Flight ExperimentThe field test was at Evo, located in the boreal forest region in southern Finland (61°19ʹN, 25°11ʹE) as shown in Figure 4a. There was a managed forest with about 2000 ha covered by Scots pine (Pinus sylvestris), Norway spruce (Picea abies), and birch (Betula sp.). The flight experiment [11] by a Bell-206 helicopter was conducted along a north-south direction on the site on September 2016. Both Tomoradar and lidar devices, collecting the backscattering information of the target forest simultaneously, were installed on the helicopter operating at around 60 m altitude with 10 m/s flight speed leading to an 18-meter-width of lidar data acquisition. In order to make the experiment plots have similar parameters of branch/twig and dielectric constant properties, two continuous plots with different density under the flight line were selected for validation, which reduces the errors caused by the uncertainty of the inputs and helps to compare the simulations for different density forest. The lengths of the plot are 21 m (plot 1) and 37 m (plot 2) respectively. Correspondingly, the plot areas are 378 m2 and 666 m2. The terrain of the plots is relatively flat and the location is presented in Figure 4b. It could be observed from the airborne lidar data that plot 2 represents a denser forest relative to plot 1 (Figure 4c).  4.1.2. Profile Radar DataThe Ku-band FM-CW profile radar system, Tomoradar, was used to collect data. The center frequency of Tomoradar is 14 GHz with 163-Hz modulation frequency and the field of view (FOV) is 6°, owing to the beam width of antenna is 3 dB. Tomoradar can receive waveform of four polarization modes (HH, HV, VH, and VV) with 0.15-m range resolution. Since mechanical scanner was not installed, the backscattering signals could be recorded only at normal direction alone the trajectory by Tomoradar. In addition, the footprint of single waveform was determined by the FOV and flight altitude of Tomoradar. The main parameters of Tomoradar are provided in Table 2.In the selected plots, due to the average flight height being 60 m and the FVO 6°, the footprint-width of Tomoradar was about 6 m. Tomoradar continuously collected waveforms with the spacing between the center points of every two footprints alone track of 0.06 m, owing to the average flight speed of helicopter being 10 m/s. The co- and cross- polarization (HH and HV) Tomoradar waveforms of the selected plots were employed to compared, as reference, with the simulated waveforms of the extended RAPID2 model in this paper. In addition, the vertical profiles of plot 1 and plot 2 consist of 556 waveforms and 797 waveforms, respectively. The vertical profiles of plots for both polarizations are illustrated in Figure 5. Chen et al. provide a detailed description of the data processing [11]. 4.1.3. Lidar DataThe lidar data were used to extract forest structure parameters, acquired in the same area during Tomoradar waveform collection, and to reconstruct the 3D scene of the plots in the extended RAPID2 model. The lidar system is a Velodyne VLP-16 laser scanner working with 300,000 pts/s, installed on the same airborne platform, and collecting data simultaneously with Tomoradar. It can generate 16 scan lines uniformly within the FOV of 30°alone, the trajectory and the beam size of transmitted laser pulse is 12.7 mm (horizontal) 

×

 9.5 mm (vertical). The main parameters of the lidar are provided in Table 3. For the selected plots, the lidar data were collected with the average point density of about 80 pts/m2. The lidar point cloud of the two plots are shown in Figure 3c.", 4. Model Validation, 4.1. Flight Experiment and Data,4
149,"The field test was at Evo, located in the boreal forest region in southern Finland (61°19ʹN, 25°11ʹE) as shown in Figure 4a. There was a managed forest with about 2000 ha covered by Scots pine (Pinus sylvestris), Norway spruce (Picea abies), and birch (Betula sp.). The flight experiment [11] by a Bell-206 helicopter was conducted along a north-south direction on the site on September 2016. Both Tomoradar and lidar devices, collecting the backscattering information of the target forest simultaneously, were installed on the helicopter operating at around 60 m altitude with 10 m/s flight speed leading to an 18-meter-width of lidar data acquisition. In order to make the experiment plots have similar parameters of branch/twig and dielectric constant properties, two continuous plots with different density under the flight line were selected for validation, which reduces the errors caused by the uncertainty of the inputs and helps to compare the simulations for different density forest. The lengths of the plot are 21 m (plot 1) and 37 m (plot 2) respectively. Correspondingly, the plot areas are 378 m2 and 666 m2. The terrain of the plots is relatively flat and the location is presented in Figure 4b. It could be observed from the airborne lidar data that plot 2 represents a denser forest relative to plot 1 (Figure 4c). ", 4. Model Validation, 4.1.1. Flight Experiment,4
150,"The Ku-band FM-CW profile radar system, Tomoradar, was used to collect data. The center frequency of Tomoradar is 14 GHz with 163-Hz modulation frequency and the field of view (FOV) is 6°, owing to the beam width of antenna is 3 dB. Tomoradar can receive waveform of four polarization modes (HH, HV, VH, and VV) with 0.15-m range resolution. Since mechanical scanner was not installed, the backscattering signals could be recorded only at normal direction alone the trajectory by Tomoradar. In addition, the footprint of single waveform was determined by the FOV and flight altitude of Tomoradar. The main parameters of Tomoradar are provided in Table 2.In the selected plots, due to the average flight height being 60 m and the FVO 6°, the footprint-width of Tomoradar was about 6 m. Tomoradar continuously collected waveforms with the spacing between the center points of every two footprints alone track of 0.06 m, owing to the average flight speed of helicopter being 10 m/s. The co- and cross- polarization (HH and HV) Tomoradar waveforms of the selected plots were employed to compared, as reference, with the simulated waveforms of the extended RAPID2 model in this paper. In addition, the vertical profiles of plot 1 and plot 2 consist of 556 waveforms and 797 waveforms, respectively. The vertical profiles of plots for both polarizations are illustrated in Figure 5. Chen et al. provide a detailed description of the data processing [11].", 4. Model Validation, 4.1.2. Profile Radar Data,4
151,"The lidar data were used to extract forest structure parameters, acquired in the same area during Tomoradar waveform collection, and to reconstruct the 3D scene of the plots in the extended RAPID2 model. The lidar system is a Velodyne VLP-16 laser scanner working with 300,000 pts/s, installed on the same airborne platform, and collecting data simultaneously with Tomoradar. It can generate 16 scan lines uniformly within the FOV of 30°alone, the trajectory and the beam size of transmitted laser pulse is 12.7 mm (horizontal) 

×

 9.5 mm (vertical). The main parameters of the lidar are provided in Table 3. For the selected plots, the lidar data were collected with the average point density of about 80 pts/m2. The lidar point cloud of the two plots are shown in Figure 3c.", 4. Model Validation, 4.1.3. Lidar Data,4
152," 4.2.1. Forest Parameters Acquisition MethodIn order to reconstruct the 3D scene of the selected plots in the extended RAPID2 model, the parameters of single trees were extracted from the lidar point cloud. The raw data of lidar were segmented into point cloud of each single tree (Figure 6), after a series of processing using LiDAR360 software (http://www.lidar360.com), such as ground points classification [26], normalization based on ground points, and single tree segmentation based on seed points modified by human-computer interaction, so as to extract the location, height, crown length, and crown width of each single tree in the plots.According to the single tree point clouds and Beer–Lambert law, the LAI of trees could be calculated based on the light intensity at the top and bottom of the canopy and the corresponding extinction coefficient [27]. When applied to point cloud data, the light intensity at the top of the canopy can be regarded as the total number of point clouds reaching the forest, and the bottom light intensity is regarded as the number of point clouds, which reach the ground through the forest canopy [28]. Therefore, the LAIs of each single tree in plots were obtained by the following formula.






LAI
 

=
 
−
2
ln



R
g




R
t








(7)


where 



R
g



 is the number of point clouds reaching the ground and 



R
t



 is the total number of point clouds reaching the top of forest canopy.Lidar cannot produce the detailed parameters of needles and branches. Thus, these parameters were obtained according to literatures [29] and iterative fitting of experiment data. The dielectric constants of components in Ku-band were calculated according to Ulaby [30]. 4.2.2. Acquired Forest Parameters and Generated ScenesBased on point clouds of the segmented trees, there are 21 and 41 trees in plot 1 and plot 2, respectively (Figure 7). Table 4 shows the major structure parameters of the two plots extracted from lidar.The main canopy parameters of the plots for simulation are presented in Table 5. The needle length was 5 cm with a diameter of 0.2 cm and the needle zenith angle distribution was set to be uniform. Soil correlation length was 18.75 cm while roughness height was 0.25 cm. Table 6 shows the dielectric constants of components in Ku-band for this study.The 3D scenes of the plots were generated in the extended RAPID2 model utilizing the parameters of single tree and dielectric constant of various components, as described above. The virtual 3D scenes are illustrated in Figure 8.", 4. Model Validation, 4.2. Generation of 3D Forest Scene,4
153,"In order to reconstruct the 3D scene of the selected plots in the extended RAPID2 model, the parameters of single trees were extracted from the lidar point cloud. The raw data of lidar were segmented into point cloud of each single tree (Figure 6), after a series of processing using LiDAR360 software (http://www.lidar360.com), such as ground points classification [26], normalization based on ground points, and single tree segmentation based on seed points modified by human-computer interaction, so as to extract the location, height, crown length, and crown width of each single tree in the plots.According to the single tree point clouds and Beer–Lambert law, the LAI of trees could be calculated based on the light intensity at the top and bottom of the canopy and the corresponding extinction coefficient [27]. When applied to point cloud data, the light intensity at the top of the canopy can be regarded as the total number of point clouds reaching the forest, and the bottom light intensity is regarded as the number of point clouds, which reach the ground through the forest canopy [28]. Therefore, the LAIs of each single tree in plots were obtained by the following formula.






LAI
 

=
 
−
2
ln



R
g




R
t








(7)


where 



R
g



 is the number of point clouds reaching the ground and 



R
t



 is the total number of point clouds reaching the top of forest canopy.Lidar cannot produce the detailed parameters of needles and branches. Thus, these parameters were obtained according to literatures [29] and iterative fitting of experiment data. The dielectric constants of components in Ku-band were calculated according to Ulaby [30].", 4. Model Validation, 4.2.1. Forest Parameters Acquisition Method,4
154,"Based on point clouds of the segmented trees, there are 21 and 41 trees in plot 1 and plot 2, respectively (Figure 7). Table 4 shows the major structure parameters of the two plots extracted from lidar.The main canopy parameters of the plots for simulation are presented in Table 5. The needle length was 5 cm with a diameter of 0.2 cm and the needle zenith angle distribution was set to be uniform. Soil correlation length was 18.75 cm while roughness height was 0.25 cm. Table 6 shows the dielectric constants of components in Ku-band for this study.The 3D scenes of the plots were generated in the extended RAPID2 model utilizing the parameters of single tree and dielectric constant of various components, as described above. The virtual 3D scenes are illustrated in Figure 8.", 4. Model Validation, 4.2.2. Acquired Forest Parameters and Generated Scenes,4
155,"Based on the generated 3D forest scenes, the extended RAPID2 model simulated the profile radar waveforms. To verify the simulation results of the extended RAPID2 model, the Tomoradar waveforms were used as references. To ensure the effectiveness of the comparison, the range resolution of the simulated waveforms has been set to 0.15 m with a footprint-width of 6 m, matching with measured data parametersTo ensure the effectiveness of the comparison, the range resolution of the simulated waveforms has been set to 0.15 m with a footprint-width of 6 m, matching with measured data parameters. In addition, the average waveforms of the two plots at co- and cross- polarization modes were employed for simulated and Tomoradar data in the evaluation. The comparisons between simulated data and Tomoradar data are shown in Figure 9.Figure 9 shows that the modeled average waveforms are in a good agreement with Tomoradar waveforms for both two plots and two polarization modes. The determination coefficients are not less than 0.8. When it comes to the same plot, better consistency was shown at co-polarization, whereas the simulated backscattering was lightly underestimated at cross-polarization. Compared with the average waveforms of Tomoradar, which contained detailed structure in canopy, the simulated waveforms reflected the macro trend of backscattering energy distribution in forest canopies. In addition, the Tomoradar data showed hairy and jagged due to background noise, which did not exist in the simulated data. Therefore, the difference appeared between the simulated data and Tomoradar data, especially at cross-polarization. Small sub-layers were not simulated in canopy (Figure 9d). For the plot with different forest density, the extended RAPID2 model performed better in the thin forest, and their determination coefficients was 0.03 higher than that of in the dense forest for both two polarization modes.In addition, the extended RAPID2 model could describe the ground waveform accurately with the empirical coefficients (k) of 0.25 and 0.50 in plot 1 and plot 2, respectively, at cross-polarization mode.", 4. Model Validation, 4.3. Comparison of Simulation Results,4
156,"The penetration depth of microwave signal generally determines its detection ability of forest vertical structure. Different penetration depth means different contribution sources of scatters. The penetration depth 



δ
p



 in the canopy could be defined as follows [20]:






I

(


δ
p


)



I

(
0
)



 
=


 
1

e






(8)


where 


I

(
0
)



 is the total energy reaching the top of the canopy and e is the Euler number. To avoid confusion, it should be noted that the penetration depth does not mean the depth that profile radar can finally reach. Instead, the penetration depth only reflects the position where approximately half of the total energy is accumulated.A few studies have focused on the influence of canopy structure on penetration depth in the X and L band [20,31,32]. Nevertheless, a more thorough study on the effects of forest density, canopy LAI and branch density on penetration depth would be desirable. It could help to improve the accuracy of forest height estimation and aboveground biomass estimation with a better understanding of the relationship between forest parameters and microwave penetration depth. In addition, sensitivity analysis would interpret effectively the variation trends of the relationships under different forest conditions. The extended RAPID2 model enables the sensitivity analysis by generating a series of forest scenes. In this paper, the effects of stem density, single tree LAI, crown shape, and twig density on penetration depth in the Ku-band were studied. The contribution of each specified factor was locally checked when other forest parameters were fixed. Table 7 presents the variables and their values that we are concerned about; and the others basic default forest parameters are shown in Table 8. It should be noted that, in this section, the simulated scenes were evenly distributed coniferous forests with a size of 50 m × 50 m, and without overlapping between crowns, which avoids the increasing of leaf density within a crown due to overlapping. The crowns were composed of cone and cylinder, with a randomly oriented leaf angle distribution. The crown shape was defined as the ratio of cylinder part to crown.Figure 10a–e depict variations in stem density from 200 to 1000 stems/ha with a step of 200 in simulated scenes, where the leaf area index (LAI) of single trees was 3.0. Five groups of forests scenes (500 stems/ha) were generated, which consisted of different LAI values per tree (Figure 10f–j). Next, five kinds of crowns with single tree LAI of 7.0 are shown in Figure 10k–o, forming 500 stems/ha forests scenes, respectively. In addition, five scenes of different twig densities in the crown were also set when stem density was 500 stems/ha, single tree LAI was 3.0, and the crown ratio of cylinder part was 70%. Simultaneously, the branch density was set to 0.2 to 1.8 with a step of 0.4, matching the twig density variation.For the above-mentioned 20 virtual forest scenes, the profile radar waveforms in Ku-band were simulated by the extended RAPID2 model, and the penetration depths were calculated. Since the vertical resolution of the simulated waveforms was set to 0.15 m, which is consistent with Tomoradar data, the error of penetration depth calculation was not less than 0.15 m. The penetration depth variations of the 20 forest scenes are presented in Figure 11.Figure 11a presents how penetration depth varies with the stem density when other forest parameters are fixed. It can be observed that the penetration depth remained at about 5.46 m, which hardly changed with the increasing of stem density. The penetration of microwave signal tends to be almost not affected by stem density, which is different from previous studies. This may be due to two reasons: firstly, the observation angle of profile radar is nadir-looking, differing to traditional side-looking radar. When the electromagnetic wave is emitted vertically, the interaction occurs in the vertical path, but the stem density mainly determines the number of trees in horizontal direction. Secondly, there was no overlapping between the single tree crowns in these virtual forest scenes; thus, the stem density cannot affect the vertical distribution of needles and twigs within a single tree.Figure 11b shows the relationship between penetration depth and single tree LAI. The penetration depth decreased with the increasing of single tree LAI. Especially when the LAI increases from 1.0 to 2.0, the value of penetration fell off from 6.86 to 5.74 m. In addition, with the further increasing of the LAI, the penetration depth decreased to 4.76 m smoothly. This obvious variation in penetration reflects the fact that needles contribute the microwave backscattering in Ku-band, and more needles weaken the signal penetration.The effect of crown shape on penetration depth is shown in Figure 11c. Crown shape was defined as the ratio of the cylinder part to the whole crown. According to the figure, for the same single tree LAI, the larger the proportion of the cylinder part in the crown, the lower the penetration depth. It is understandable that the crown shape determined the spatial distribution of LAI in this study. The increase of the cylinder part of the crown was essentially the increase of LAI at the top of the crown in this experiment (Figure 10k–o). Therefore, we can conclude that the increase of LAI in the microwave propagation path would decrease the penetration depth.Figure 11d demonstrates the influence of the twig density in the crown on the penetration depth. It can be seen that a gradual decline of penetration from 5.60 to 4.48 m occurred, due to the increasing of twig density in canopy, implying that the twig also contributed to backscattering energy and extensive twigs reduced microwave penetration in the Ku-band.", 5. Sensitivity Analysis of Penetration Depth ,None,5
157,"The waveform simulated by the extended RAPID2 model shows different accuracy under different polarization modes and different forest densities. To our knowledge, there were only two previous similar studies on the profile radar simulation, the HUTSCAT waveforms [20,21]. The vertical resolution of the HUTSCAT waveform is 0.68 m. In the simulations of HUTSCAT waveforms, a continuous canopy model, a distributed 2D canopy model, and a 3D canopy model were used separately; and there was gradually weakened underestimation of backscattering at the lower part in canopy [21]. For the 17-meter-high stand in their study, the simulated results agreed well with the HUTSCAT waveforms at the upper part of the canopy (from 8 to 17 m), but between 2 and 8 m, there were still underestimations of several to dozen dB. The specific values of determination coefficient or root mean square error (RMSE) for the simulated waveforms was not given. Compared to HUTSCAT, the simulations of the extended RAPID2 have a better matching to the Tomoradar waveforms, and the determination coefficients were greater than or equal to 0.8 for the two polarization modes and two forest scenes. The vertical resolution of waveform simulated in this paper is 0.15 m.There are two reasons for the improvement. First, since the extended RAPID2 can generate the scene closing real forest, and the forest parameters were obtained from lidar, the simulated waveforms in this study were better in macro trend. Second, the quality of Tomoradar is higher, for example, the vertical resolution is 0.15 m, which means the simulation in our study can more accurately characterize the backscattering profiles of true forest, but it is possible to make more errors in details as well.Specifically, for the same forest scene, there was a good agreement of simulated backscattering waveform at co-polarization, while a light underestimation was found at cross-polarization, especially in the denser forest. The similar phenomenon occurred in the previous study, where the profile radar waveforms of Australian pine canopies, aged 30 and 40 years old in X band, were simulated [20]. For the 40-year-old canopy, the simulated waveform, a little more, underestimated the backscattering of the lower part at cross-polarization mode than at co-polarization mode. One explanation for this result is that the cross-polarization signals contain more multiple scattering contributions from the canopy relative to that of co-polarization [33]. In addition, the multiple scattering depends on the density of needles and twigs, which are difficult to determine accurately [22]. Another possible explanation is that the cross-polarization signals suffer from a higher proportion contribution of background noise, because the backscattering intensity of cross-polarization signals is significantly weaker than that of co-polarization. Noise floor of the FM-CW radar is typically determined by the internal reflections. In this study, we had to fix the density of twig, for a crown, without varying from top to bottom, because we did not have the corresponding ground measurement, in addition, background noise caused by internal reflections did not exist in simulations.For the forest scenes with different densities, better matching of waveform simulation was found in the thin forest plot. On the contrary, the more errors existed in waveform simulation of the dense forest plot, especially in the interior of the multi-layered canopy, and in the lower part of the forest. This could be because the main forest parameters used to construct the virtual scene, such as the number of single trees, the height, and the crown length, etc., were obtained by lidar point cloud data. For lidar, it is hard to detect the detailed information in complex canopy and understory vegetation, due to the mutual shielding of branches and leaves. Zhou et al. compared the canopy height profiles extracted from the Tomoradar waveforms and lidar data; both data were used in this paper [14]. They found that the locations of the canopy height profiles acquired from the lidar were obviously higher than those from the Tomoradar. It also indicates that detection to the details in the lower part of canopy are difficult for lidar, especially in dense forest. To the end, it results in the error of inputs of the extended RAPID2 model and the error of simulation results.", 6. Discussion, 6.1. Comparisons of Accuracies in Waveform Simulation,6
158,"In this study, microwave penetration depth of various forests in Ku-band was concerned, which appeared to be more prominent (3.50 m to 6.86 m) than previous qualitative results for short wavelength SAR (only ‘a few’ meters) [31,34]. This discrepancy is mainly due to the fact that the penetration depth in the previous study was for side-looking radar. For the radar system with the normal incidence, our findings are consistent with the conclusion by Martinez et al. [20] that the penetration depth is several meters in X band. It appeared to be influenced by the density of both needles and twigs in the Ku-band. A seemingly uncommon finding is that forest stem density was less impacted on profile radar penetration. This is due to the fact that there was no cross between tree crowns in the nadir direction. Despite the increasing of stem density, the volume density of needles or twigs on the path of microwave transmission (such as nadir incidence) did not change significantly. The slight change on penetration is mainly because of the field of view (FOV = 6 degrees), where the off-nadir directions still exist for the profile radar. When the stem density increases to a certain degree, there will be a slight change of backscattering energy in off-nadir directions, leading to the change of penetration depth. Figure 11a presents the phenomenon and provides specific values. Similarly, the sensitivity to stem density should be higher for side-looking radar, since higher stem density means higher density of needles and twigs on the path of off-nadir incidence. Several studies have proven this point: penetration depth decreased significantly with the increasing of stem density for side-looking radar [31,32].To further verify this view, we have realized the variation of needle density on the profile radar observation path by changing the crown shape, namely the ratio of the cylinder part of the crown. As shown in Figure 11c, the results indicated an obvious decreasing trend of penetration depth with the increasing needle density on observation path. Thus, it can be seen that only the change of the density of the components, such as needles, with scattering contribution in the observation path, can cause the change of microwave penetration depth.", 6. Discussion, 6.2. Sensitive Factors on Penetration Depth,6
159,"The current study has a number of strengths over previous research in terms of exploring the interaction between microwave scattering and forests. Firstly, the scenes are generated with forest parameters obtained from the lidar data, which were acquired simultaneously with Tomoradar waveform, thus improving the consistency of the scenes. Secondly, the waveform simulations have higher timing and ranging resolution, which shows the backscattering energy distribution in vertical direction of forest plots clearly. Third, penetration depth of profile radar in Ku-band tends to be more important (from 3.50 to 6.86 m); and sensitivity of a few forest parameters to penetration depth has been analyzed quantitatively. Despite the strengths of the study, there are also some limitations. These limitations are primarily related to the parameters of canopy that were set according to previous studies. It is possible that the inaccuracy of canopy parameters could produce the errors of canopy scattering. However, it is difficult to measure the diameter and length of numerous branches and twigs accurately even if in-situ measurement could be carried out. On the contrary, using the classical canopy parameters directly is beneficial to a more consistent comparison with the previous study. In fact, in complex vegetation canopies, the best parameter setting might be the average value of the different parameters, as long as the simulated waveform is fitted well. Hence, the uncertainty of canopy parameters is acceptable during the simulation of profile radar waveform.", 6. Discussion, 6.3. Advantages and Limitations of Our Approach,6
160,"It is worth noting that before getting a desired simulation of the profile radar waveform, only the observation direction, the ground surface backscattering, and the output format were modified in the process of extending RAPID2 model, while the scattering process of each component within the crown has not been changed. Similarly, Floury et al. and Martinez et al. utilized the same MIT/CESBIO backscattering model [18] to realize the SAR data simulation [19] and profile radar waveform simulation [20] of forest canopy. These findings support our basic hypothesis that there is no difference in the scattering process of the components within the crown between the side-looking radar and profile radar. Therefore, it tends to suggest that it is possible to obtain the backscattering energy distribution of the forest in single track SAR image by making statistics of the range direction within a certain window and integrating it to the direction perpendicular to the ground. Of course, it requires that the data have a very high range resolution (e.g., less than 0.5 m) relative to the height of the forest canopies. By properly setting dielectric constants of background, trunks, branches, and leaves for different frequency radar signals, and calibrating their scattering and extinction functions, the extended RAPID2 model can simulate the profiles for other frequencies (such as L and P band) as well, which are widely used in SAR for forest studies. In the future, the vertical structure information of the forest contained in profile radar waveform and single track SAR data could be compared. Further, the degree to which the single track SAR data obtains the vertical structure of the forest and its corresponding conditions could be studied, so that it can be better used to estimate forest parameters.", 6. Discussion, 6.4. Inspirations from Profile Radar to Explore SAR Ranging,6
161,"In this study, the RAPID2 model has been extended to simulate the profile radar waveform of boreal forest, which offers a better understanding of the interaction between the microwave signals and forest structures. A good agreement has been found at both co- and cross- polarization between the simulated and Tomoradar profiles. The determination coefficients were greater than or equal to 0.8 for the two polarization modes and two forest scenes. To our knowledge, the extended RAPID2 is the first shared 3D radiative transfer model realizing the backscattering simulation of optical, thermal infrared, lidar, side-looking radar, and profile radar based on the unified scene and input parameters. Thus, it will be a wonderful tool for multi-source data fusion research. In addition, our study presents a quantitative assessment on Ku-band penetration in forests, which may widen the use of profile radar data.Moreover, it is a remarkable fact that there is no fundamental modification between the profile radar and side-looking radar for the backscattering calculation of canopy components, which means that it has potential to obtain the backscattering energy distribution of forest to a certain extent by using single track SAR data. In our next study, we will gain insight into how best to reflect forest vertical structure information with single track SAR data. Some forest growth models, such as the Formind model and Zelig model, will be combined with the extended RAPID2, to make the setting of the forest scene in the model more biologically significant.", 7. Conclusions,None,7
162," 1.1. BackgroundCosts and damages from large, high-severity wildfires have been steadily escalating, particularly in the forests of the western United States [1,2]. In Ponderosa pine (Pinus ponderosa) and mixed conifer forests of the southwest USA, a legacy of fire suppression, historical logging practices, and grazing has increased fire risk [3,4]. These activities altered the natural fire cycle due to the increased stand density, accumulation of surface and ladder fuel loads, and regrowth of fire-intolerant trees [5,6,7]. As a result, forests in the southwestern USA that were once characterized by frequent, low-intensity fires are now experiencing catastrophic stand-replacement crown fires [3]. Rising temperatures, extended fire seasons, earlier snowmelt, and ongoing drought will continue to increase future wildfire potential [2,8,9,10,11]. Interactions between altered fire regimes, land use, and climate change are projected to continue intensifying the occurrence, size and severity of wildfires [12,13].Knowledge of forest structure is needed in order to effectively manage and restore forests facing these altered fire regimes and environmental conditions. In particular, above-ground biomass (AGB) is useful for making management decisions such as controlled burns and stand thinning when conducting landscape restoration. Repeating extensive ground-based forest inventories to acquire these data is time consuming, labor intensive, and expensive.Congress appropriated a consistent funding source through the Collaborative Forest Landscape Restoration Program (CFLRP, part of the Omnibus Public Land Management Act of 2009) in recognition of these urgent problems many communities are facing [14]. CFLRP offers competitive awards for implementing large-scale, collaborative, cross jurisdictional restoration plans. CFLRP encourages long-term restoration treatments (10-year period) across national forests, but that also extend across other land ownerships (e.g., federal, state, tribal, and private land) in order to reduce fire risk to vulnerable communities [14,15]. The need to monitor forests with fragmented ownership adds to the expense of accessing ground plots. Estimation techniques that use Earth-observing data provide an alternative toolkit for monitoring landscapes over time [16].The advantages of lidar (Light Detection and Ranging) based approaches include: (1) the ability to collect and process spatially explicit data representing the horizontal and vertical conditions of the landscape over large spatial extents, (2) coverage of difficult to reach terrain and properties, and (3) accurate estimation of forest structure parameters in a timely and economical fashion (reviews by [17,18,19,20,21,22,23]).Landscape scale restoration efforts aim to create conditions where natural fires can be managed for resource objectives without fear of escalation, thereby reducing fire suppression costs [1,24,25,26]. Over 280,000 km2 (70 million acres) of these forests are in need of restoration [1,27]. Awarded projects are required to monitor social, ecological, and economic outcomes for 15 years to adapt future decisions based on new understanding of treatment efficacy and identification of potential unintended negative consequences [28,29,30,31,32].The need for ongoing monitoring is especially important given the emergence of novel conditions resulting from the interactions of climate change and land use [33,34,35]. Restoration treatments are often guided by historical reference conditions and the natural range of variability [36]; however, forests are expected to experience new conditions outside this range [2,11,12,13]. Assessing the efficacy of restoration treatments under new ecological, social, and economic conditions is essential to adapting strategies aimed at increasing resilience of desired forest systems [33]. 1.2. Project GoalsCFLRP projects have invested in the acquisition of both lidar data and the associated field data used to develop models for estimating forest structure. Since the collection of field data for each new project is expensive, a framework that allows project managers to update forest inventories by applying previously developed models to newly acquired lidar data would result in substantial savings. Regression models have been demonstrated to effectively link forest inventory parameters, including AGB, measured in the field with coincident lidar canopy metrics–aggregated to the plot boundary [17,18,19,20,21,22,23]. The resulting models can be applied to the full lidar data to create a continuous GIS raster layer of the forest inventory parameters across the study area. However, few studies have assessed lidar-based inventories in Ponderosa pine and mixed conifer forests of the southwestern USA [37,38,39]. Hall [39] developed Ponderosa pine and Douglas fir forest inventory models for the Front Range of the Rocky Mountains, CO. Sherrill and colleagues [37] use lidar metrics to explain 76% of the variation in field-estimated AGB values in subalpine forests of the Central Rockies. Finally, Kim and colleagues [38] developed models to estimate live and dead AGB in Ponderosa pine and mixed conifer forests in the North Rim of the Grand Canyon National Park with a RMSE of 46.01 Mg/ha (23.66% RMSE). Our large sample size, full range of AGB conditions, and expansive spatial footprint enable us to build on their research. However, the range of AGB values in these three studies did not include stands with high biomass; the majority of values were under 300 Mg per hectare. Sample sizes were small, ranging from 36 [37] to 58 [38]. Further, these studies were built on small data sets and represent a limited spatial extent. Lidar-based regional models have been developed to estimate biomass in boreal, temperate deciduous, temperate coniferous, and tropical forests [40,41,42,43,44]. Regional models for southwestern US forests have not yet been explored.The goal of this work is to develop a regional above-ground biomass (AGB) estimation model using lidar metrics from field data [45] and apply it to new lidar acquisitions. We use AGB estimates from field inventories, discrete-return lidar data, and environmental data to develop a regional lidar model that estimates AGB in Ponderosa pine and mixed conifer forests in the southwest United States. Information from the lidar data is supplemented with data from other sources to explain differences in forest structure due to contrasting environmental conditions, site productivity, and species composition [37,46,47,48,49,50]. AGB was estimated at plots from ground-based data using regional allometric equations.Lidar-derived height, canopy density, and canopy shape metrics are combined with environmental data that represent forest composition and are regressed against the field-based AGB estimates to derive predictive equations. We integrated data from seven distinct field data collection efforts; five were used for model development and the remaining two were used as an independent validation. We evaluate the reliability of the model with two data sets: a reserved subset of the model development data and two coincident field data collection efforts. The latter validation data set was used to assess the transferability of the model on a new lidar acquisition.While certain methods (stepwise regression) are popular, no standard approach has emerged in the literature as a robust, bias-free method to select which lidar metrics are best suited for estimating biomass from the large (overwhelming) pool of candidates. To fully explore the model space, and to avoid researcher bias and overfitting, we use Bayesian model averaging (BMA) methods to specify our model structure from the ensemble of candidates. For a good introduction to BMA, see [51,52,53].The lidar data are from acquisitions collected with similar flight and sensor specifications. We include AGB estimates from seven field data campaigns with similar, but inconsistent plot size protocols and sample designs. While we recognize this is not ideal for model development, it does allow us to examine the influence of cost-saving plot size protocols on our model errors. We investigate the impact of allowing plot size to be determined by average stand stem density, discuss the implications of these inconsistencies on lidar-based AGB estimations, and make recommendations that attempt to balance the need for immediate field inventory savings vs. long-term costs of monitoring these landscapes.We use AGB as our case study to test this approach for two reasons. First, studies have demonstrated accurate biomass estimates can be predicted with lidar data [20,21,23]. We expect that if the method works well for AGB it should then be applicable for prediction of other forest structure metrics that are correlated with lidar derivatives. González-Ferreiro and colleagues [54,55,56,57] demonstrated the effectiveness of using lidar to estimate canopy fuel characteristics. The second relates to the common need of fire restoration projects to monitor effectiveness at reducing fuel densities and prioritizing areas with high fuel loads. Accurate estimates of biomass are also important for forest management, habitat conservation, and global carbon accounting [58]. Biomass provides information about growth, health, and productivity. It is a key parameter in estimating carbon stock, timber production, wildlife habitat, fire behavior, fire impact, and for ecological modeling. Crucially, Sherrill and colleagues [38] have demonstrated success in separating biomass estimates between live and dead vegetation; this is an invaluable metric for assessing fire risk within a landscape.", 1. Introduction,None,1.
163,"This study takes place in Ponderosa pine and frequent-fire (dry) mixed conifer forests in Arizona and New Mexico, USA. Sites were selected based on where lidar acquisitions and coincident field data were available. We include three regions in our analysis: the Four Forest Restoration Initiative (4FRI), the Southwest Jemez Mountain Landscape Restoration Project–both part of the network of Collaborative Forest Landscape Restoration Programs– and the 2009 Kaibab Forest Health Focus (Figure 1).The 4FRI includes 10,000 km2 of forest in northern Arizona and spans across the Coconino, Tonto, and Apache-Sitgreaves National Forests. It is located on the Mogollon Plateau, a northwest-southeast plateau running along the southern edge of the Colorado Plateau into the White Mountains. It is characterized by a gently sloping topography cut by small, steep drainages and infrequent rock outcroppings. The Southwest Jemez Mountain Landscape Restoration Project includes 850 km2 of forestlands in the upper and middle Jemez River watersheds of which 512 km2 was covered by a lidar acquisition. It is located just to the southwest of the Valles Caldera National Preserve in mountains that were formed primarily by volcanic activity. The Jemez River originates within the preserve and flows southwest through the center of the study area, eventually joining the Rio Grande. The Kaibab Forest Health Focus manages land on the Kaibab Plateau. This includes the northern section of the Kaibab National Forest and the Grand Canyon National Park-North Rim, Arizona. It is part of the larger Colorado Plateau and is bounded to the south by the Grand Canyon with tributary canyons on the east and west.Elevation of the study sites ranges from 1700 to 3100 m above sea level. Annual precipitation is bimodal: most falls as snow between November and March, with a smaller amount of precipitation from monsoonal rains and thunderstorms during July and August [59]. Forest composition is strongly influenced by elevational gradients. The colder and wetter conditions of higher elevation areas support dense stands of spruce trees (Engelmann’s spruce, Picea engelmannii and blue spruce, Picea pungens) and mixed fir stands (corkbark fir, Abies lasiocarpa var. arizonica; white fir, Abies concolor; and subalpine fir, Abies lasiocarpa) [60]. A narrow Douglas-fir (Pseudotsuga menziesii) belt occurs below the spruce and mixed fir stands. These are followed by Ponderosa pine (Pinus ponderosa) stands, located at moderate elevations [60,61,62]. The forest matrix includes patches of aspen stands, meadows, and forest openings generated by disturbances such as fire, wind throw, and timber harvesting [60]. Twoneedle pinyon (Pinus edulis), Utah juniper (Juniperus osteosperma), Gambel oak (Quercus gambelii), New Mexico locust (Robinia neomexicana), and rabbitbrush (Chrysothamnus viscidiflorus) are commonly interspersed throughout [59,62,63]. Pinyon-juniper woodlands occur below the Ponderosa pine belt. These woodlands regions are dominated by tree species with multi-stem growth form and smaller maximum heights than the higher elevation species [64]. Due to their different growth form, we masked large areas dominated by these woodland growth forms from the study. However, there are still some small pinyon-juniper patches interspersed throughout the study region.", 2. Materials and Methods, 2.1. Study Area,2
164,"We use information from seven different field data collection efforts and four lidar aquisitions covering the three study sites. Field data were collected between 2013 and 2015 (Table 1) and lidar was flown between 2012 to 2014 (Table 2). All lidar and field acquisitions were during leaf-on periods. The coincident field and lidar data collection efforts were completed within 1–2 years of each other. In all study regions, with the exception of the Coconino N.F. and the Tonto N.F., field plots were located using a stratified random design based on lidar derivatives. The lidar data sets were typically acquired in the summer and delivered in the winter. The sample design was completed in the spring and the field sampling commenced after snowmelt. Areas of obvious change due to fires were not included in the sampling. Due to contracting issues, the Southwest Jemez Mountain field collection efforts was delayed one year. Given the relatively slow growth rate of Southwest forest communities, conditions were unlikely to change much in the time period.Lidar data can be aggregated in a plethora of ways to represent forest attributes. Researchers have identified three categories that perform well and have clear biological interpretation with direct analogs to ecologically significant variables [45,65,66]. Variables representing the canopy height distribution, the variability or shape of canopy height distribution, and canopy cover or density are analogous to variables used in aerial stand volume tables that are used in forest inventory [46]. We represent the canopy height distribution with quantile height metrics. These provide information on the density of the canopy biomass at different heights by measuring the different levels of laser penetration into the forest canopy [66,67]. We included quadratic heights to maintain consistency with the study by Sherrill and colleagues [18,37]. L-moments and central moments provide information on the heterogeneity of forest composition within the plot by representing the location, variability, and shape (skewness and kurtosis) of the canopy height distribution. L-moments provide a more robust set of statistics and are comparable to central moment variance, skewness, and kurtosis but less subject to bias in small samples and are more robust to outliers [68]. Similar to Kim and colleagues [38] we estimate plot-level volume by assessing the interaction of canopy density and height quartiles.The relationship between stand characteristics and lidar metrics vary between tree species, especially those with different crown shapes [44,69,70]. Therefore, we tested a combination of information from optical remote sensing and lidar to represent potential differences in plots with deciduous trees. We explored the predictive power of three ancillary data sets that represent present and potential forest composition, including topographic information, an indicator of phenology, and ecological response units. Topography is an important determinant of forest compositional structure. Phenologic differences can differentiate deciduous from evergreen communities. We estimated the magnitude of seasonal variation of greenness (NDVI) from a Landsat time-series analysis. Ecological response units indicate a combination of potential and current community composition [64]. 2.2.1. Field SurveyField information was collected at over 3000 plots in seven different data collection efforts across the three study regions between 2013 and 2015 (Figure 2 and Table 1). We did not have access to a complete probabilistic sample that covers the full extent of Ponderosa pine and mixed conifer forests in southwest US, but the combination of these seven collection efforts provide information across a broad range of forest conditions. Five of the seven efforts were completed in the 4FRI. The first effort was implemented on the western half of the Apache-Sitgreaves N.F; the second stage in the eastern portion. Data from the second stage of the 4FRI data collection effort were completely withheld from the model development process and used for validation of the regional model. In this section we outline similarities and differences in sample design, protocols determining plot size, and field data collection efforts.Sample design varied by project (Table 1). Generally, the strategy was to capture the full range of variation in forest structure recorded by the lidar sensor. Plots were located using a stratified random sampling scheme based on lidar-derived canopy structure information for all but two of the field inventory projects (Tonto and Coconino N.F., Table 1) [71,72]. Plots were located in areas where the (maximum) canopy cover reached at least 3 meters in height. Plots in the Tonto and Coconino N.F. were systematically located in stands that lack a current inventory. Minimum sample size per stand was 3 plots, but sample size and spacing between plots varied depending on stand area [73]. Plots for two projects were located based on accessibility. Plots within the Kaibab Plateau were within 250 m of level 2 forest service roads, the Santa Fe plots were within 300 m.Field protocols that determined plot size varied between projects (Table 1). The plots within the seven field data collection efforts were distributed as follows: 0.4% 0.008 ha plots, 9.7% 0.01 ha plots, 33.9% 0.02 ha plots, 9.9% 0.03 ha plots, 42.7% 0.04 ha plots, and 3.4% 0.08 ha plots. Plot radius was determined by tree density in all data collection efforts, except on the Kaibab Plateau. The plot size in the Kaibab project was 0.04 ha. The default plot size in the other projects was also 0.04 ha, but was increased or decreased depending on tree density. In the Tonto and Coconino N.F. plot size was decreased in dense stands; in the Southwest Jemez Mountain and three Apache-Sitgreaves N.F. the plot size was increased in low density stands. Overall, 43% of all the plots were 0.04 ha in size; 3.4% were larger; and 54% were smaller.In stands with high tree density in the Coconino and Tonto N.F. the contractor was allowed to select a plot size such that at least 8 trees (DBH greater than 12.7 cm) were present per plot, on average throughout the stand. Sixty-four percent of the plots in these two data collection efforts met these dense stand conditions and were reduced in size to between 0.03 to 0.008 ha. Twenty percent of the plots in the Coconino N.F. were reduced to 0.03 ha; 40% of the Tonto and 40% of the Coconino N.F. plots were reduced to 0.02 ha; and 10% of the Coconino N.F. and 16% of the Tonto N.F. plots were reduced to 0.01 ha or smaller. One stand in the Tonto N.F. had a tree density that resulted in 13 plots with a size of 0.008 ha. In the Southwest Jemez Mountain and three Apache-Sitgreaves N.F. data collection efforts, plot size was doubled from 0.04 ha to 0.08 if there were fewer than 8 trees (DBH greater than 12.7 cm) in the plot. The majority of the 0.08 ha plots are in the Apache-Sitgreaves stage 2 and 3 data collection efforts and were located within the perimeters of the Rodeo-Chediski and Wallow fires respectively.Information was recorded on all trees with a dbh greater than 12.7 cm in six of the projects and a dbh greater than 20.3 cm for the Kaibab study region. Species and dbh were recorded for each live and standing dead tree that met the minimum dbh threshold for each project. Plot location was measured with a Trimble GeoXH6000 with GPS + GLONASS or a Trimble GeoXH with GPS using accuracy based logging settings. Plot center coordinates were recorded with a minimum of 200 positions in the Coconino and Tonto N.F.; and for a minimum of 10 minutes at the other sites. Differential correction was applied using Pathfinder Office. 2.2.2. LidarFour lidar data sets were acquired in our study area between 2012 and 2014 during leaf-on canopy conditions (June to September) (Figure 2). Each acquisition was surveyed with a Leica ALS series sensor with an opposing flight line side-lap greater than or equal to 50% (greater than or equal to 100% overlap) and an average native pulse density greater than or equal to 8 pulses per square meter over terrain. While some variability in pulse density does occur across the acquisitions, all densities are within roughly one standard deviation of each other, with variability of pulse density between study regions equivalent to variation within each region, and thus should not produce significantly different return profiles. The targeted vertical accuracy (RMSE) for each acquisition was less than or equal to 15 cm. The field of view for each survey was generally between 26° and 28°, except for the 2000 m altitude survey in the North Kaibab which was only 20°. The complete lidar acquisition specifications for each site in this analysis are summarized in Table 2.Canopy structure metrics were calculated from the raw lidar point cloud using FUSION software [74]. At each plot, we generated canopy height distributions and density metrics from the lidar point cloud using the relative height measure at each return. Relative height is the difference in terrain surface height (from the digital terrain model provided by the vendor) and the Z coordinate of each point. Canopy returns were points with a relative height above 3 m; in these forests anything lower is typically ground, stones, and low-lying vegetation [37,38]. Fractional canopy cover and density metrics were calculated using this static cover threshold and the dynamic thresholds of mean and mode values. We included a product of height quantiles and canopy density, which we refer to as canopy volume [18,37].Metrics with a correlation in excess of 0.94 with other lidar variables were removed to reduce problems associated with highly collinear predictor variables, particularly ambiguous interpretation issues [52,75]. Most highly correlated variables existed as pairs with almost perfect correlation. The variable in each pair that had the higher correlation with the field AGB estimate was kept for analysis, the other was removed. The lidar metrics are listed in Table 3 (excluded metrics are located in Table S1). 2.2.3. TopographyElevation, slope, and aspect at each plot were determined from the Shuttle Radar Topography Mission (SRTM) digital elevation data with a resolution of 1 arc-second [76]. The topographic derivatives were calculated and sampled at each plot center in the Google Earth Engine platform [77]. 2.2.4. PhenologyPhenology was represented by the amplitude of the seasonal difference in the normalized difference vegetation index (NDVI). We measured amplitude using a harmonic regression time-series analysis on Landsat images recorded between 2012 to 2015. Multiple linear regression is performed on NDVI observations, assuming that there is a sine curve (a harmonic, or Fourier transform) with a frequency of one cycle per year that describes the annual variation in NDVI, Equation (1) [78]. The β’s are the coefficients, f is the frequency, and t is time. Finally, to more easily interpret the cosine and sine coefficients (


β

c
o
s



 and 


β

s
i
n



) we convert these to amplitude, (


β
A


), and phase, (


β
ϕ


), (Equations (2) and (3)) [78]. These calculations and sampling were performed in the Google Earth Engine platform [77].





N
D
V
I
=

β
1

+

β
t

t
+

β

c
o
s


∗
c
o
s

(
f
t
)

+

β

s
i
n


∗
s
i
n

(
f
t
)

+
e





(1)







β
A

=



β

c
o
s

2

+

β

s
i
n

2








(2)







β
ϕ

=
a
t
a
n

(

β

c
o
s


,

β

s
i
n


)






(3)

 2.2.5. Ecological Response UnitEcological Response Units are a system of mapped ecosystem types [64]. They were created using a combination of information on plant associations and structure characteristics that would occur under natural disturbance regimes and biological processes. For the analysis similar ecological response units were grouped into broader categories: herbaceous and grasslands (montane and subalpine grasslands, and Colorado Plateau and Great Basin grasslands), alder and willow (Arizona alder/willow and willow/thinleaf alder units), mixed conifer (frequent fire mixed conifer and mixed conifer with aspen units), and Ponderosa pine (Ponderosa pine, Ponderosa pine with willow, and Ponderosa pine with evergreen oak units).", 2. Materials and Methods, 2.2. Data,2
165,"Field information was collected at over 3000 plots in seven different data collection efforts across the three study regions between 2013 and 2015 (Figure 2 and Table 1). We did not have access to a complete probabilistic sample that covers the full extent of Ponderosa pine and mixed conifer forests in southwest US, but the combination of these seven collection efforts provide information across a broad range of forest conditions. Five of the seven efforts were completed in the 4FRI. The first effort was implemented on the western half of the Apache-Sitgreaves N.F; the second stage in the eastern portion. Data from the second stage of the 4FRI data collection effort were completely withheld from the model development process and used for validation of the regional model. In this section we outline similarities and differences in sample design, protocols determining plot size, and field data collection efforts.Sample design varied by project (Table 1). Generally, the strategy was to capture the full range of variation in forest structure recorded by the lidar sensor. Plots were located using a stratified random sampling scheme based on lidar-derived canopy structure information for all but two of the field inventory projects (Tonto and Coconino N.F., Table 1) [71,72]. Plots were located in areas where the (maximum) canopy cover reached at least 3 meters in height. Plots in the Tonto and Coconino N.F. were systematically located in stands that lack a current inventory. Minimum sample size per stand was 3 plots, but sample size and spacing between plots varied depending on stand area [73]. Plots for two projects were located based on accessibility. Plots within the Kaibab Plateau were within 250 m of level 2 forest service roads, the Santa Fe plots were within 300 m.Field protocols that determined plot size varied between projects (Table 1). The plots within the seven field data collection efforts were distributed as follows: 0.4% 0.008 ha plots, 9.7% 0.01 ha plots, 33.9% 0.02 ha plots, 9.9% 0.03 ha plots, 42.7% 0.04 ha plots, and 3.4% 0.08 ha plots. Plot radius was determined by tree density in all data collection efforts, except on the Kaibab Plateau. The plot size in the Kaibab project was 0.04 ha. The default plot size in the other projects was also 0.04 ha, but was increased or decreased depending on tree density. In the Tonto and Coconino N.F. plot size was decreased in dense stands; in the Southwest Jemez Mountain and three Apache-Sitgreaves N.F. the plot size was increased in low density stands. Overall, 43% of all the plots were 0.04 ha in size; 3.4% were larger; and 54% were smaller.In stands with high tree density in the Coconino and Tonto N.F. the contractor was allowed to select a plot size such that at least 8 trees (DBH greater than 12.7 cm) were present per plot, on average throughout the stand. Sixty-four percent of the plots in these two data collection efforts met these dense stand conditions and were reduced in size to between 0.03 to 0.008 ha. Twenty percent of the plots in the Coconino N.F. were reduced to 0.03 ha; 40% of the Tonto and 40% of the Coconino N.F. plots were reduced to 0.02 ha; and 10% of the Coconino N.F. and 16% of the Tonto N.F. plots were reduced to 0.01 ha or smaller. One stand in the Tonto N.F. had a tree density that resulted in 13 plots with a size of 0.008 ha. In the Southwest Jemez Mountain and three Apache-Sitgreaves N.F. data collection efforts, plot size was doubled from 0.04 ha to 0.08 if there were fewer than 8 trees (DBH greater than 12.7 cm) in the plot. The majority of the 0.08 ha plots are in the Apache-Sitgreaves stage 2 and 3 data collection efforts and were located within the perimeters of the Rodeo-Chediski and Wallow fires respectively.Information was recorded on all trees with a dbh greater than 12.7 cm in six of the projects and a dbh greater than 20.3 cm for the Kaibab study region. Species and dbh were recorded for each live and standing dead tree that met the minimum dbh threshold for each project. Plot location was measured with a Trimble GeoXH6000 with GPS + GLONASS or a Trimble GeoXH with GPS using accuracy based logging settings. Plot center coordinates were recorded with a minimum of 200 positions in the Coconino and Tonto N.F.; and for a minimum of 10 minutes at the other sites. Differential correction was applied using Pathfinder Office.", 2. Materials and Methods, 2.2.1. Field Survey,2
166,"Four lidar data sets were acquired in our study area between 2012 and 2014 during leaf-on canopy conditions (June to September) (Figure 2). Each acquisition was surveyed with a Leica ALS series sensor with an opposing flight line side-lap greater than or equal to 50% (greater than or equal to 100% overlap) and an average native pulse density greater than or equal to 8 pulses per square meter over terrain. While some variability in pulse density does occur across the acquisitions, all densities are within roughly one standard deviation of each other, with variability of pulse density between study regions equivalent to variation within each region, and thus should not produce significantly different return profiles. The targeted vertical accuracy (RMSE) for each acquisition was less than or equal to 15 cm. The field of view for each survey was generally between 26° and 28°, except for the 2000 m altitude survey in the North Kaibab which was only 20°. The complete lidar acquisition specifications for each site in this analysis are summarized in Table 2.Canopy structure metrics were calculated from the raw lidar point cloud using FUSION software [74]. At each plot, we generated canopy height distributions and density metrics from the lidar point cloud using the relative height measure at each return. Relative height is the difference in terrain surface height (from the digital terrain model provided by the vendor) and the Z coordinate of each point. Canopy returns were points with a relative height above 3 m; in these forests anything lower is typically ground, stones, and low-lying vegetation [37,38]. Fractional canopy cover and density metrics were calculated using this static cover threshold and the dynamic thresholds of mean and mode values. We included a product of height quantiles and canopy density, which we refer to as canopy volume [18,37].Metrics with a correlation in excess of 0.94 with other lidar variables were removed to reduce problems associated with highly collinear predictor variables, particularly ambiguous interpretation issues [52,75]. Most highly correlated variables existed as pairs with almost perfect correlation. The variable in each pair that had the higher correlation with the field AGB estimate was kept for analysis, the other was removed. The lidar metrics are listed in Table 3 (excluded metrics are located in Table S1).", 2. Materials and Methods, 2.2.2. Lidar,2
167,"Elevation, slope, and aspect at each plot were determined from the Shuttle Radar Topography Mission (SRTM) digital elevation data with a resolution of 1 arc-second [76]. The topographic derivatives were calculated and sampled at each plot center in the Google Earth Engine platform [77].", 2. Materials and Methods, 2.2.3. Topography,2
168,"Phenology was represented by the amplitude of the seasonal difference in the normalized difference vegetation index (NDVI). We measured amplitude using a harmonic regression time-series analysis on Landsat images recorded between 2012 to 2015. Multiple linear regression is performed on NDVI observations, assuming that there is a sine curve (a harmonic, or Fourier transform) with a frequency of one cycle per year that describes the annual variation in NDVI, Equation (1) [78]. The β’s are the coefficients, f is the frequency, and t is time. Finally, to more easily interpret the cosine and sine coefficients (


β

c
o
s



 and 


β

s
i
n



) we convert these to amplitude, (


β
A


), and phase, (


β
ϕ


), (Equations (2) and (3)) [78]. These calculations and sampling were performed in the Google Earth Engine platform [77].





N
D
V
I
=

β
1

+

β
t

t
+

β

c
o
s


∗
c
o
s

(
f
t
)

+

β

s
i
n


∗
s
i
n

(
f
t
)

+
e





(1)







β
A

=



β

c
o
s

2

+

β

s
i
n

2








(2)







β
ϕ

=
a
t
a
n

(

β

c
o
s


,

β

s
i
n


)






(3)

", 2. Materials and Methods, 2.2.4. Phenology,2
169,"Ecological Response Units are a system of mapped ecosystem types [64]. They were created using a combination of information on plant associations and structure characteristics that would occur under natural disturbance regimes and biological processes. For the analysis similar ecological response units were grouped into broader categories: herbaceous and grasslands (montane and subalpine grasslands, and Colorado Plateau and Great Basin grasslands), alder and willow (Arizona alder/willow and willow/thinleaf alder units), mixed conifer (frequent fire mixed conifer and mixed conifer with aspen units), and Ponderosa pine (Ponderosa pine, Ponderosa pine with willow, and Ponderosa pine with evergreen oak units).", 2. Materials and Methods, 2.2.5. Ecological Response Unit,2
170,"AGB (stem, branch, and foliage biomass) and volume were calculated for each tree (live or standing dead) using the recorded DBH values, species-specific allometric equations, and wood densities [79]. AGB per plot was computed by summing the estimates for all trees within the plot. Analysis was performed using the Central Rockies variant of the Forest Vegetation Simulator (FVS) [79,80]. To take into account the sample design of the field data collection efforts, all sample-based summary statistics were calculated using functions within the survey package in R [81,82].", 2. Materials and Methods, 2.3. Field AGB Estimates,2
171,"Parametric linear multiple regression models have been successfully used to estimate AGB using some combination of metrics representing (1) the canopy height distribution (location, scale, and shape), (2) the density of the canopy, and (3) the interaction between height and density of the canopy metrics (Table 3) [42,46,65]. A visual inspection of linear fits between AGB and the height and canopy density metrics and a box cox analysis suggested a log transform of the response variable, AGB, similar to relationships identified in other studies (e.g., [46]). Therefore, we tested models built with a log transform of AGB and one with no transform. We also tested ecologically important environmental variables, including ecological response units, topography (elevation, slope, and aspect), and the amplitude of seasonal differences in the normalized difference vegetation index. We did not assess non-parametric model functions, such as regression trees, because our response variable and covariates did exhibit strong linear relationships. 2.4.1. Variable Selection with Bayesian Model Averaging and Stepwise RegressionVarious methods are available to select a parsimonious set of metrics to use as predictors. One possible approach is to engage in dimensional reduction of the data, such as a principle component analysis and canonical correlation analysis [37,44,65]. However, the resultant factors can be difficult or impossible to meaningfully interpret. Stepwise regression is another commonly used approach to select covariates from a large pool of metrics (e.g., [18,38,44,45]), however this approach can result in overfit models and is sensitive to multicolinearity issues [83,84].An alternative approach has emerged that avoids choosing a single model and instead generates a distribution of possible models that represents the inherent uncertainty that arises when many possible predictors (with possibly conflicting interpretations) exist [51]. This process is referred to as Bayesian Model Averaging (BMA), and it allows for a large pool of possible models to be enumerated and evaluated for how well they fit the data and for the uncertainty of model fit and parameter values to be clearly represented [85]. This approach reduces the possibility of researcher bias in variable selection than typical step-wise regression approaches [51]. Interestingly, the use of non-specific inference–that is, no single model is used to generate predictions, rather a large suite of possible models are used to produce an average prediction–often outperforms the use of any single model [52].Enumeration and evaluation of large numbers of models can be problematic; however, for normal multiple linear regression, well-behaved, closed form solutions that allow for direct model comparison exist [85]. For managers, use of Bayesian model averaging for prediction may be problematic, because the Bayesian model averaging object used to generate the model is not intuitive. It also needs be reproduced by a user for prediction on new data sets, as compared to the utility and ease of use of a single-model specification. Therefore, we present a final, single model from the ensemble generated by BMA. In order to provide information on how BMA methods compare to other established model selection methods, we examined the classic stepwise approach to model specification. We used bidirectional stepwise elimination. Both the BMA and stepwise model selection methods assessed multiple linear regression models fit using ordinary least squares.Four model selection processes were assessed: (1) the multiple linear model selected from the stepwise regression process, (2) the Bayesian model average object, (3) highest probability multiple linear model from the BMA, and 4) the median probability multiple linear model from the BMA. The highest probability model is the single model with the highest probability of occurrence. The median model includes the set of lidar and biophysical variables that occurred in the population of models more than 50% of the time (posterior probability was greater than or equal to 0.5). We generated predictions using the BMA object using the top 10,000 models (’top’ meaning highest posterior probability). While it is possible to use the full population of models to generate predictions, enumerating the full ensemble of models (2number of covariates) is computationally impractical, and most models have very low probability of occurring. These four model selections processes were completed on both the non-transformed and log-linear transformation of AGB. In total we report on performance of eight models. 2.4.2. BMA SpecificationsBayesian model averaging was implemented with the Bayesian Adaptive Sampling (BAS) package [86] for use in R. BAS allows for more rapid exploration of model space than typical Markov Chain Monte Carlo methods, flexible model and prior specification, includes good diagnostic and predictive tools, and is well documented and under active development. We used a version of BAS that combines Markov chain Monte Carlo (MCMC) with the BAS algorithm, as MCMC approaches tend to be more tolerant of strong correlation between predictors (some of the remaining covariates were under the threshold, but are still correlated). Data were randomly subset for the purposes of model development, with 25% of the data reserved for validation of the model fits. As the focus of this work is on deriving models useful for landscape-level management of forests at risk for destructive fires, we are primarily interested in sites with medium to high AGB. Sites with zero AGB were removed from the data before models were fit to the data.A key component of Bayesian statistical approaches is specifying the prior distribution. The prior distribution provides a way of using known information to adjust how we view new data. If we have strong beliefs about the world, we are more critical of new data; conversely if we have a lot of uncertainty about the world, new data are largely left to speak for themselves. Two prior distributions need to be assigned before fitting of a model can be conducted using BAS: the prior that describes beliefs about model sizes, and the prior that describes beliefs about how likely it is that the coefficients of the model will be non-zero. While the initial pool of variables is quite large, many are correlated and may in effect be duplicates, so a large model is not necessary or likely to occur. Thus a truncated Poisson model with a mean of 10 covariates and a cut-off of 30 covariates was used; the cutoff sets the probability of larger models to zero. For the coefficients, the majority are likely to be zero, but some are expected to be highly significant. Zellner’s g is often used to specify the prior for model coefficients, as it flexibly allows for a varying degree of belief about the coefficients to be included: a large g suggests little prior knowledge (and causes the coefficients to closely approximate their ordinary least squares counterparts), and a small g suggests strong skepticism that the coefficient will be non-zero [87]. We used a hyper-g, a Beta prior on the shrinkage factor of the form in Equation (4), where a is a parameter in the range 


2
<
a
≤
4


 [88]. The benefit of a hyper-g is that we specify a moderately informative prior, splitting the difference between g approaching infinity and 0; but limit the risk of unintended consequences on the posterior results by allowing Bayesian updating of g to be used to adjust outcomes [89]. We set a to 3.






g

1
+
g


∼
B
e
t
a

(
1
,

a
2

−
1
)






(4)

", 2. Materials and Methods, 2.4. Estimating AGB with Lidar Metrics and Ancillary Data,2
172,"Various methods are available to select a parsimonious set of metrics to use as predictors. One possible approach is to engage in dimensional reduction of the data, such as a principle component analysis and canonical correlation analysis [37,44,65]. However, the resultant factors can be difficult or impossible to meaningfully interpret. Stepwise regression is another commonly used approach to select covariates from a large pool of metrics (e.g., [18,38,44,45]), however this approach can result in overfit models and is sensitive to multicolinearity issues [83,84].An alternative approach has emerged that avoids choosing a single model and instead generates a distribution of possible models that represents the inherent uncertainty that arises when many possible predictors (with possibly conflicting interpretations) exist [51]. This process is referred to as Bayesian Model Averaging (BMA), and it allows for a large pool of possible models to be enumerated and evaluated for how well they fit the data and for the uncertainty of model fit and parameter values to be clearly represented [85]. This approach reduces the possibility of researcher bias in variable selection than typical step-wise regression approaches [51]. Interestingly, the use of non-specific inference–that is, no single model is used to generate predictions, rather a large suite of possible models are used to produce an average prediction–often outperforms the use of any single model [52].Enumeration and evaluation of large numbers of models can be problematic; however, for normal multiple linear regression, well-behaved, closed form solutions that allow for direct model comparison exist [85]. For managers, use of Bayesian model averaging for prediction may be problematic, because the Bayesian model averaging object used to generate the model is not intuitive. It also needs be reproduced by a user for prediction on new data sets, as compared to the utility and ease of use of a single-model specification. Therefore, we present a final, single model from the ensemble generated by BMA. In order to provide information on how BMA methods compare to other established model selection methods, we examined the classic stepwise approach to model specification. We used bidirectional stepwise elimination. Both the BMA and stepwise model selection methods assessed multiple linear regression models fit using ordinary least squares.Four model selection processes were assessed: (1) the multiple linear model selected from the stepwise regression process, (2) the Bayesian model average object, (3) highest probability multiple linear model from the BMA, and 4) the median probability multiple linear model from the BMA. The highest probability model is the single model with the highest probability of occurrence. The median model includes the set of lidar and biophysical variables that occurred in the population of models more than 50% of the time (posterior probability was greater than or equal to 0.5). We generated predictions using the BMA object using the top 10,000 models (’top’ meaning highest posterior probability). While it is possible to use the full population of models to generate predictions, enumerating the full ensemble of models (2number of covariates) is computationally impractical, and most models have very low probability of occurring. These four model selections processes were completed on both the non-transformed and log-linear transformation of AGB. In total we report on performance of eight models.", 2. Materials and Methods, 2.4.1. Variable Selection with Bayesian Model Averaging and Stepwise Regression,2
173,"Bayesian model averaging was implemented with the Bayesian Adaptive Sampling (BAS) package [86] for use in R. BAS allows for more rapid exploration of model space than typical Markov Chain Monte Carlo methods, flexible model and prior specification, includes good diagnostic and predictive tools, and is well documented and under active development. We used a version of BAS that combines Markov chain Monte Carlo (MCMC) with the BAS algorithm, as MCMC approaches tend to be more tolerant of strong correlation between predictors (some of the remaining covariates were under the threshold, but are still correlated). Data were randomly subset for the purposes of model development, with 25% of the data reserved for validation of the model fits. As the focus of this work is on deriving models useful for landscape-level management of forests at risk for destructive fires, we are primarily interested in sites with medium to high AGB. Sites with zero AGB were removed from the data before models were fit to the data.A key component of Bayesian statistical approaches is specifying the prior distribution. The prior distribution provides a way of using known information to adjust how we view new data. If we have strong beliefs about the world, we are more critical of new data; conversely if we have a lot of uncertainty about the world, new data are largely left to speak for themselves. Two prior distributions need to be assigned before fitting of a model can be conducted using BAS: the prior that describes beliefs about model sizes, and the prior that describes beliefs about how likely it is that the coefficients of the model will be non-zero. While the initial pool of variables is quite large, many are correlated and may in effect be duplicates, so a large model is not necessary or likely to occur. Thus a truncated Poisson model with a mean of 10 covariates and a cut-off of 30 covariates was used; the cutoff sets the probability of larger models to zero. For the coefficients, the majority are likely to be zero, but some are expected to be highly significant. Zellner’s g is often used to specify the prior for model coefficients, as it flexibly allows for a varying degree of belief about the coefficients to be included: a large g suggests little prior knowledge (and causes the coefficients to closely approximate their ordinary least squares counterparts), and a small g suggests strong skepticism that the coefficient will be non-zero [87]. We used a hyper-g, a Beta prior on the shrinkage factor of the form in Equation (4), where a is a parameter in the range 


2
<
a
≤
4


 [88]. The benefit of a hyper-g is that we specify a moderately informative prior, splitting the difference between g approaching infinity and 0; but limit the risk of unintended consequences on the posterior results by allowing Bayesian updating of g to be used to adjust outcomes [89]. We set a to 3.






g

1
+
g


∼
B
e
t
a

(
1
,

a
2

−
1
)






(4)

", 2. Materials and Methods, 2.4.2. BMA Specifications,2
174,"Model performance was assessed in multiple stages using three subsets of the data. Five of the seven field data sets were used for model development and the remaining two were used as an independent validation to assess transferability of the developed model to new lidar acquisitions. The model development data set was split into a model calibration and validation set with approximately 75% used for calibration and 25% for validation. The model development data sets (calibration and validation) were used to complete the variable selection and trim multicolinear predictors from the model. The model development validation and transferability validation data were used to assess performance of the final trimmed model overall, by project site, and also by each plot size category. We assess the performance of the selected model when applied to new lidar acquisition using data completely independent of the model development phase–one lidar acquisition with two coincident field data collection efforts, which we refer to as the transfer validation data. 2.5.1. Comparison of Product from Four Model Selection ProceduresModel performance of the eight models was assessed based on three criteria: (1) minimized model error and bias, (2) minimized multicolinearity and maximized reliability of estimates of each predictor, and (3) parsimony, the model with the fewest number of terms and predictors. We used these data subset to assess model performance in two stages. The first was completed within the model selection process by BMA and stepwise regression, this was implemented on the model calibration data set. To evaluate the performance of each of the six selected multiple linear regression models we report the coefficient of determination estimates (R2 and adjusted R2) calculated from the model calibration data. The second assessment phase was completed with the model validation data set (the 25% withheld from the five model development field data collection efforts). The root mean square error (RMSE), percent root mean square error, bias, and mean bias are reported using this data subset for all eight models. We visually assess normality, constant variance, and independence of residuals by inspecting marginal plots. Issues with multicolinearity and reliability of predictor estimates were assessed using percent relative standard error (PRSE) and variance inflation factors. We present generalized collinearity factors of coefficients since we have interaction terms [90]. 2.5.2. Model Refinement to Reduce Variance Inflation and Increase Reliability of Model CoefficientsVariance inflation factors greater than 5 suggest issues with multicolinearity [91], although Graham [83] cautions that values as low as two can have serious impacts on models. PRSE values of greater than 20% are considered unreliable in ecological studies [92]. We used these thresholds to trim our selected model structure. We maintained the raw terms of significant interaction predictors even if these metrics indicate they are not significant [93]. Terms are the covariate variables; model predictors include terms and combinations of terms (e.g., a second degree polynomial includes two predictors and one term–or three predictors when considering the constant). 2.5.3. Model Performance by Project and Plot SizeWe report model bias and error metrics for the trimmed model overall, and we also include a summary of these metrics for each observed field data project and for each plot size category. Model bias can exist as fixed or proportional bias. Root mean square error and bias provide information on fixed bias–when values are higher (or lower) across the whole range of measurement. Proportional bias occurs when estimates diverge progressively along the range of values. We tested for proportional bias of the final trimmed model by fitting a linear model between field and lidar based AGB estimates using ordinary least squares and major axis regression [94]. Ordinary least squares regression of observed vs. predicted values is a popular method used in other studies; therefore we include it so that our results can be compared to these studies. However, since errors exist in both the lidar (predictors) and field based estimates (observed) ordinary least squares assumptions are not met, and therefore, it is ill-suited to assess proportional bias in this situation. Field-based estimates of AGB include uncertainty due to natural variability, measurement error, allometric model error and model selection choices [91,95]. Therefore, we also present results from major axis regression, which fits errors or natural variability on both variables symmetrically [96,97,98]. It is impossible to know if error is indeed symmetric between the two, but this approach strikes us as a more realistic assessment tool. Major axis regression was implemented using the Model II Regression package, lmodel2, from the R CRAN repository [99].", 2. Materials and Methods, 2.5. Model Evaluation and Assessment of Lidar AGB Estimates,2
175,"Model performance of the eight models was assessed based on three criteria: (1) minimized model error and bias, (2) minimized multicolinearity and maximized reliability of estimates of each predictor, and (3) parsimony, the model with the fewest number of terms and predictors. We used these data subset to assess model performance in two stages. The first was completed within the model selection process by BMA and stepwise regression, this was implemented on the model calibration data set. To evaluate the performance of each of the six selected multiple linear regression models we report the coefficient of determination estimates (R2 and adjusted R2) calculated from the model calibration data. The second assessment phase was completed with the model validation data set (the 25% withheld from the five model development field data collection efforts). The root mean square error (RMSE), percent root mean square error, bias, and mean bias are reported using this data subset for all eight models. We visually assess normality, constant variance, and independence of residuals by inspecting marginal plots. Issues with multicolinearity and reliability of predictor estimates were assessed using percent relative standard error (PRSE) and variance inflation factors. We present generalized collinearity factors of coefficients since we have interaction terms [90].", 2. Materials and Methods, 2.5.1. Comparison of Product from Four Model Selection Procedures,2
176,"Variance inflation factors greater than 5 suggest issues with multicolinearity [91], although Graham [83] cautions that values as low as two can have serious impacts on models. PRSE values of greater than 20% are considered unreliable in ecological studies [92]. We used these thresholds to trim our selected model structure. We maintained the raw terms of significant interaction predictors even if these metrics indicate they are not significant [93]. Terms are the covariate variables; model predictors include terms and combinations of terms (e.g., a second degree polynomial includes two predictors and one term–or three predictors when considering the constant).", 2. Materials and Methods, 2.5.2. Model Refinement to Reduce Variance Inflation and Increase Reliability of Model Coefficients,2
177,"We report model bias and error metrics for the trimmed model overall, and we also include a summary of these metrics for each observed field data project and for each plot size category. Model bias can exist as fixed or proportional bias. Root mean square error and bias provide information on fixed bias–when values are higher (or lower) across the whole range of measurement. Proportional bias occurs when estimates diverge progressively along the range of values. We tested for proportional bias of the final trimmed model by fitting a linear model between field and lidar based AGB estimates using ordinary least squares and major axis regression [94]. Ordinary least squares regression of observed vs. predicted values is a popular method used in other studies; therefore we include it so that our results can be compared to these studies. However, since errors exist in both the lidar (predictors) and field based estimates (observed) ordinary least squares assumptions are not met, and therefore, it is ill-suited to assess proportional bias in this situation. Field-based estimates of AGB include uncertainty due to natural variability, measurement error, allometric model error and model selection choices [91,95]. Therefore, we also present results from major axis regression, which fits errors or natural variability on both variables symmetrically [96,97,98]. It is impossible to know if error is indeed symmetric between the two, but this approach strikes us as a more realistic assessment tool. Major axis regression was implemented using the Model II Regression package, lmodel2, from the R CRAN repository [99].", 2. Materials and Methods, 2.5.3. Model Performance by Project and Plot Size,2
178,"The average AGB of the model calibration sample was 122.3 (±1.8) Mg per hectare; the model validation sample average was 114.6 (±2.9) Mg per hectare. The composition of the model calibration sample was 72.8% Ponderosa pine forest, 25.5% mixed conifer, 0.5% spruce-fir forest, 0.5% pinyon-juniper woodland, 0.4% herbaceous-grassland, and 0.3% deciduous (narrowleaf cottonwood and shrub, alder, and willow). The transferability validation sample–stage 2 and stage 3 Apache-Sitgreaves N.F. data collection efforts– had average AGB of 71.1 (±5.5) and 89.5 (±5.7), respectively.Table 4 includes average AGB values for each data collection effort, including sample and population estimates (statistic is adjusted based on the sample weights). For most projects, the average AGB of the field plot samples at each project site is higher than the population average for the entire site. This reflects our sample strategy aim to represent the full range of forest conditions. A population estimate for the selected Coconino and Tonto N.F. stands and the full model development data set is not appropriate, because the spatial extent of the combined projects is not a meaningful ecological or political unit. Only a selection of stands were sampled in the Coconino and Tonto N.F.; similarly only a selection of Ponderosa pine and mixed conifer forests of the southwest US were sampled.", 3. Results, 3.1. Summary Statistics of Field Data Estimates,3
179,"We analyzed eight models: the model selected through stepwise regression, the median probability and highest probability models from the BMA object and the BMA for two versions of the response variable–raw AGB and log-transformed AGB (Table 5). For each BMA model population, the median probability (the model composed of parameters with at least a 50% chance of being included in any model) and the highest probability model (the single model with the highest probability of occurring in the population of models) were the same. For brevity we refer to both of these models as the median probability model throughout the remainder of the document.The stepwise variable selection process returned the largest (least parsimonious) models. The log-transformed AGB model specified from the stepwise selection process included 16 terms and 20 predictors. The ERU consists of 5 binary factors, one of which is represented within the intercept value. The stepwise model from the linear AGB included 11 terms and 17 predictors. The increase in terms and predictors did not substantially improve model performance as indicated by the similar adjusted coefficient of determination values. The log-transformed stepwise model had an adjusted coefficient of determination of 0.70; the adjusted R2 value for the log-transformed median probability model was 0.69. The models without a transformed response variable, AGB, explained more of the variation in field-estimated AGB values. The adjusted R2 values were 0.71 and 0.72 for the stepwise and BMA selected models respectively.We selected the median probability (which is also the highest probability) model from the BMA object built with the non-transformed AGB value as the response variable. This model performs similar to the stepwise model but with far fewer terms and predictors. The root mean square error of the non-transformed AGB BMA ensemble was nearly identical to that of the median probability model with a difference less than 1 Mg per hectare. The median probability model explained 72% of the variation in the field based AGB estimates, had an RMSE percent value of 35.8, and negligible percent bias of −0.019. The results and figures reported in the subsequent sections are from this model structure.", 3. Results, 3.2. Assessing Results of Alternative Variable Selection Procedures,3
180,"The median probability raw AGB multiple regression model includes five terms and eight predictors–nine including the intercept (Table 5 and Table 6). The identified significant predictors include the second order polynomial of the 60th height percentile, an indicator of the canopy height variation (the median of absolute deviation from the overall median), a canopy density measure (all canopy returns divided by total number of first returns), and a lower and mid height canopy volume proxy (the product of the canopy density with the 30th and 60th percentile heights). The raw terms that make up the interactions are also included in the model; these include the 30th and 60th percentile heights, and canopy density. Only the lidar derivatives were selected to estimate AGB; no information on topography, phenology, or ecological response units was included in the model.The variance inflation factor of the 30th height percentile and the two canopy volume proxies exceeded 5. The high PRSE metric of these predictors also suggests there are issues with these estimates that need to be remedied. Therefore we removed the canopy density normalized by first returns (Cov>3:1st) and the volume term with the 60th percentile height. The trimmed model included one less term, two fewer predictors, and explained 71% of the variation in field AGB estimates (both R2 and adjusted R2 were 0.71). Table 6 includes the model specifications of the full and trimmed models. For both models, at least one predictor of all terms was significant at p < 0.001. The 60th percentile was not significant in the trimmed model. However, it was kept in the model because it is a term in the polynomial predictor, which is significant [93]. The raw and interaction terms had PRSE and generalized variance inflation factor values that exceeded the recommended thresholds, but colinearity of predictors created from the same terms is expected. An examination of the marginal model plots shows that the quadratic height term, QP60, improves model fit by pulling the estimates of plots with high and low biomass values closer to those observed in the field; without the quadratic term they are under- and over-predicted, respectively. All subsequent analysis was conducted using this trimmed model (Table 6).", 3. Results, 3.3. Median Probability AGB Model Structure,3
181,"The overall percent root mean squared error between the field observed AGB and the AGB estimate from the trimmed model was 35.93% for the model validation sample. It was slightly lower for the two transfer validation data sets: 31.18% and 32.83% for the phase 2 and phase 3 projects within Apache-Sitgreaves N.F. Three of the five samples with AGB field-estimates above 400 Mg per hectare had percent RMSE values above 41% (Figure 3, Table 7). These included the Kaibab Plateau calibration sample, and both the calibration and validation sample from the Tonto N.F. projects. Upon visual inspection of the lidar point cloud and field survey photographs, we found the Kaibab Plateau calibration data set had a plot with obvious edge effect error caused by a tree with large biomass at the edge of the plot border. This partially explains the large RMSE value for this sample.Overall model bias was negligible for the model calibration and validation data sets, with values of −1 × 10−15 and −0.02 respectively. (Table 7). For most project samples the percent bias values ranged between −5 and 5% between project samples. The exceptions were the 1) Southwest Jemez Mountain data collection validation at −16.36% and calibration data at −19.25%, the phase 3 Apache-Sitgreaves collection at −12.22%, and the Tonto N.F. validation data set at −5.15%. However, the 95% confidence intervals of the ordinary least squares trend line between the field and lidar based estimates includes the 1:1 line across the range of values at each of the seven sites, indicating the bias is not significantly different than zero (Figure 3). The 95% confidence interval on the trend line for the Southwest Jemez Mountain project does, however, not fully enclose the 1:1 line (Figure 3f). Further, the Southwest Jemez Mountain data collection effort has the largest negative bias. This project has moderate AGB values; none of the plots have a field-estimated AGB over 400 Mg/ha.", 3. Results," 3.4. Trimmed Median Probability Model Performance, Overall and by Field Data Collection Site",3
182,"In this section we assess how AGB estimation performance varies with regard to the different plot size protocols used in the seven data collection efforts. In the Coconino N.F. and Tonto N.F. when the plots were located in stands with high tree density the plot size was reduced, proportional to tree density. Conversely, in the three Apache-Sitgreaves N.F. and Southwest Jemez Mountain data collection efforts plots with low tree density were doubled in size to 0.08 ha. A majority of the smallest plots are composed of a high density of small stature trees, whereas forest structure in the largest plots (0.08 ha) was defined by larger, thinly-dispersed trees. An examination of the AGB distributions by plot size confirms that the smallest and the largest plot sizes–the 0.008 ha and 0.08 ha plots, respectively—both have relatively low AGB values (Figure 4a and Figure 5a,f).The error rates are not consistent across all plot sizes (Figure 4b and Figure 5). The residuals, the difference between the field-based estimates and the lidar-estimated AGB values, are centered around zero for the four plot sizes ranging from 0.04 to 0.01 ha. However, the smallest and largest plot sizes have residuals that are not equal to zero (paired t-test p-value = 0.04 and <1 × 10−5) (Figure 4b). The RMSE value of the smallest plots is 20.12 and the bias is 29.56 Mg per hectare (Figure 5a). These 0.008 ha plots are all located in one stand that had a high density of small DBH trees in the Tonto N.F.; these plots have lidar-based AGB estimates higher than those estimated from the field (average difference of 31.19 Mg/ha). The inverse is true for the large, sparsely populated stands (0.08 ha plots) where lidar-based estimates are on average 11.57 Mg/ha less than field-estimates and a bias of −13.71 Mg/ha. The RMSE value of these plots is relatively small at 2.95 Mg/ha.Figure 5 shows that the majority of plots with high field-based AGB estimates (above 400 Mg/ha) are located in plots smaller than 0.04 ha—most are within 0.01 and 0.02 hectare plots. The plots with high field-estimated AGB values (>400 Mg/ha) consistently have lower lidar-based estimates. The average disagreement (residual between field- and lidar-estimates) is 142.33 Mg/ha. A trend line fit between the field- and lidar-based estimates using major axis regression indicates that there is proportional disagreement between the lidar and fieldestimates (Figure 6). The effects are most evident in these plots with high AGB field values.", 3. Results, 3.5. Influence of Inconsistent Plot Size,3
183,"Our model exhibited a pattern where plots with large AGB field-estimates were under-predicted by the lidar model. We observe this pattern in scatter plots of observed field vs lidar predictions of other studies (e.g., [38,46,102,103,104]). This disagreement can be partially explained by known errors associated with plot sizes, discrepancies between a minimum DBH requirement in the field and lidar sensors that return pulses from vegetation regardless of DBH thresholds, error structure of the field-based estimates, and model structure. Sheridan and colleagues [103] remedied the issue by using a square root transform of the response; this transformation exacerbated our model bias. Estimates of AGB from field data include measurement error, allometric model error, and error from the choice of allometric model [91]. The magnitude of these measurement errors increases with biomass [105]. Our log-transformed model performed similar to our natural AGB model, however the performance of these models might shift if we had more information about the error structure of the high biomass -s. An examination of the marginal plots of the high biomass sites that were well-predicted (300–400 Mg/ha) and those that were under-predicted (>400 Mg/ha) indicate negligible differences in lidar metric characteristics between the two groups.Model errors decrease with increasing plot size [23,65,106]. The relationship is non-linear and asymptotic, and the influence levels off at a plot size of around 0.2 ha (well above our maximium plot) [23,65]. This is partially explained by the discrepancy between the amount of AGB estimated from field measurement vs. lidar returns due to edge effects. Lidar sensors record information from trees with stems outside the plot boundary but with crowns that extend into the plot; conversely, AGB from a tree near the inside edge of a plot may be less than the amount represented by the portion of the canopy recorded by the lidar sensor. A larger plot radius has a smaller perimeter-to-area ratio, mitigating discrepancies between field and laser measurement protocols at plot edges [65,106]. Co-registration errors are reduced in larger plots due to the higher degree of spatial overlap [65]. Gobakken and Naesset [106] reported that plots larger than 0.03 ha were generally unaffected by positional errors of 5 m or less; however 0.02 ha plots exhibited substantial biases in the estimation of height, basal area, and volume due to slight positional mis-registrations. Small plots have substantial variation around canopy height quantiles which increases disagreement between lidar predictions and field-based estimates.Forty-four percent of the plots in our study are 0.02 ha or smaller, increasing the positional errors as well as the possibility that the lidar and plot data do not represent the same conditions. The increased positional errors and edge effects for locations with large trees (with larger canopies that extend into the study area) that are captured in one dataset but not the other likely contribute to poor model performance in the upper ranges of AGB. Plot size was linked to stem density in the sample design, so a large proportion of the sites with high biomass values were recorded on small plots. All but three of our plots with AGB values in excess of 400 Mg/ha were recorded on plots 0.02 ha or smaller; these same plots tend to have field AGB estimates far in excess—on average 142.33 Mg/ha—of the lidar based estimates. Additionally, there are errors associated with extrapolation of the field-based AGB estimates for large stature trees. The allometric equations used to convert field dbh measurements to biomass estimations were developed on a sample of trees that had a max dbh of 25; just under 2% of the trees in our sample had a larger dbh.We have identified biases in our model that have implications for determining when estimates will be accurate enough for different management applications. The model under predicts AGB in areas with high field AGB estimates (>400 Mg/ha). This has real consequences to management in terms of carbon accounting and perhaps in the identification of fuel loads. For example, the model will likely yield a lower, conservative estimate of total carbon at the landscape scale. However, as areas with very high AGB make up a small proportion of these forested landscapes, we consider these estimates to still be relevant and the model useful for application at broad scales. We also have some reason to question the sensitivity of the model to discern differences in structure of low AGB plots with a high density of small trees vs. a low density of mature trees. This warrants further investigation to determine the suitability of the model in prioritizing where to apply some restoration treatments, such as stand thinning. To refine the model, we suggest an intensified collection of data in areas with AGB in excess of 400 Mg/ha and across a range of low AGB conditions. Finally, data collection efforts that cover the full extent of Ponderosa pine and mixed conifer forests are required to get more precise model error estimates; Johnson and colleagues [102] describe limitations to the application of models developed with data sampled from a narrow definition of forests to regions with tree cover that are not within that definition. Understanding these implications is especially important to determining whether lidar-based models perform well at the interface of public forest and communities, where the costs of fire and fire suppression are the greatest.By combining data from projects with different plot size protocols, we are in an interesting position to examine the potential unintended consequences of cost savings efforts—determining plot size based on stem density—on lidar-based monitoring products. While allowing contractors to collect information on smaller plots in high density stands reduces time and costs of field data collection, our findings suggest that these savings have practical implications on the ability to monitor the landscape and may cost more in the long term. Field data protocols that will assist in remedying disagreement between field and model predictions include consistent plot sizes with a minimum size of at least 0.04 ha.", 4. Discussion, 4.1. Model Bias,4
184,"Our model is consistent with other studies conducted in the same region [37,38,39]. Hall [39] proposed a model using the proportion of ground returns that were not intercepted by the canopy fit using a sample of Ponderosa pine and Douglas fir plots in the Front Range of the Rocky Mountains, CO. Their model had a coefficient of determination similar to ours, 0.74. Sherrill and colleagues [37] used a canonical correlation analysis to predict AGB with a coefficient of determination of 0.76 and a RMSE of 36.5 Mg/ha on a sample from subalpine forests of the Central Rockies. Kim and colleagues [38] proposed a lidar-based model fit to estimate live and dead AGB in Ponderosa pine and mixed conifer forests in the North Rim of the Grand Canyon National Park, a small subset of the forests we have examined. Their best model for (non-transformed) live AGB had an RMSE of 46.01 Mg/ha (23.66% RMSE) and a coefficient of determination of 0.76. Our large sample size, full range of AGB conditions, and expansive spatial footprint enable us to build on their research. The data from these three studies had a limited range of AGB values; a max less than 300 Mg/ha [37], a max below 400 but with only 4 plots above 150 Mg/ha [39], and a max less than 400 Mg/ha [38]. Sample sizes were small, ranging from 36 [37] to 58 [38]. However, plot sizes were larger; 0.1 ha [38] and 0.32 ha [39].The lidar covariates Kim [38] selected for their live AGB model are nearly identical to our total AGB model when you take into account the strongly co-linear nature of many lidar derivatives (Table S1). Their model included a volume product (mean height and canopy cover), 20th percentile height, mean height, and variation of the height metrics. Our proposed model structure includes the addition of theoretically sound predictors that improve on their model limitations. The Kim and colleagues [38] model did not include volume metrics on multiple height quartiles nor did they asses quadratic height quartiles. We found these to be valuable; the 30th percentile metric appeared in our model as a volume metric (P30*CD) as did the quadratic term of the mean height equivalent. The inclusion of the quadratic height term, QP60, also improved our model fit, reducing the tendency of the model to under-predict plots with high AGB values and over-predict those with low values. A comparison of their scatter plot of predicted to observed values indicates that their model under-predicts high AGB plots (starting at about 250 Mg/ha) and over-predicts low AGB plots, especially those with close to zero AGB [38].", 4. Discussion, 4.2. Relationship to Other Modeling Efforts,4
185,"If management to prevent fires that generate ecological regime changes is a goal, it is important to identify and characterize high AGB stands. AGB is a key variable to track for management in terms of fire behavior and restoration to a fire-adapted system. Excess fuels are often densely growing, small-diameter trees with low bases to their crowns, a condition that increases risk of high-severity, stand-replacing fires. Our model builds on existing data sets and allows for regional assessment and identification of high AGB stands based on lidar data and minimal investment in manual collection of stand characteristics. Once such stands have been identified, further work can go forward in designing effective management strategies.It is vital to consider that mananagement must take into account more than ecological concerns in National Forests and CFLRP projects; such forests are managed for multifactorial purposes, and economic and community considerations need to be balanced with ecological concerns. Once identified, thinning of high AGB stands can create biomass as a key product. Some of the biomass will be in the form of trees large enough to be utilized for traditional timber uses, while the rest of the biomass will be in the form of small diameter timber that is most often used for poles, chipped, or burned in piles onsite. Considering possible revenue streams that can be generated in CFLRP and USFS forests is important, as it can be a challenge to get treatments to pay for themselves, particularly in cases of removal of trees too small for traditional timber uses.", 4. Discussion, 4.3. Management Implications,4
186,"As new validation data become available they can be used to refine the model with Bayesian model updating techniques. This approach can be used to improve the known model shortcomings due to the influence of high disagreement between field and model AGB estimates at the upper range of AGB due to small plot size. Hierarchical Bayesian models have proven to be robust in individual tree biomass estimation models [110,111].The focus of this research was on AGB, but we expect this approach can be duplicated to develop regional lidar-based models to monitor other forest structure attributes that are well suited to estimation by lidar (e.g., see [22]). Examples of forest characteristics of particular importance in these fire-prone forests include timber volume, canopy fuels [54,55,57], monitoring management intensity [112], and standing dead biomass [38]. Recognizing the broad applicability of lidar acquisitions (hazards, terrain mapping, etc.) and the decreased unit cost as scanned surface increases, agencies are partnering to form lidar consortiums to fund the continued acquisition of lidar covering a large spatial extent. Therefore, the application of this methodology has the possibility to provide estimates of important biological characteristics of large areas at relatively low cost, using large volumes of already extant data.", 5. Conclusions, Directions for Future Research,5
187,"The depletion of fossil fuel reserves is a major driver of global climate change [1]. A sustainable substitution is urgently needed to maintain our economic, ecologic and social systems. One such promising pathway is to transition towards a bio-based economy using renewable resources [1,2,3,4] for producing fuel, platform materials and new chemicals. The European Commission recommends this approach and has developed a strategy to support a bioeconomy [3]. Apart from alternatives for energy production, this strategy aims to replace materials and products that are currently produced from fossil oil with products based on renewable raw resources like wood, crops and algae [5].As the shift towards a bioeconomy inter alia demands a sustainable supply of resources [6], such a transition will provide opportunities for small- and medium-sized regional companies [1,3,5,7]. In addition, there are potential benefits through the reduction of greenhouse gas emissions, fewer dependencies on fossil fuels and improved food security [3,7].However, since the production of wood is limited, there is a growing demand for regional and large-scale assessments [8,9]. Several studies modelled forest supply chains [10,11,12,13], which at times included the allocation of production facilities for existing technology options (e.g., chipping or power plants) [14,15,16,17]. The latter studies specifically optimized the allocation of heating or wood chipping facilities addressing an optimisation problem. As new, bioeconomy technology options are still under development though, full-scale modelling and optimized allocation are not yet possible. Instead most technology options and processing pathways for bio-based products are under development or in a pilot phase, apart from biofuel production [18,19].Despite such limitations, knowledge-based decisions would benefit from an analysis tool to explore the regional capacity of an evolving bioeconomy. Data about regional resource supplies, resource and transportation costs, infrastructure capacity and other industries obtained before facilities are planned would prevent undesired effects such as competition, biomass from non-sustainable forestry and overcapacity. In addition, positive effects on, e.g., local employment opportunities could be estimated. Maps of resource and production potential from state-of-the-art remote sensing [20,21] are a possibility for investigating large, specific areas that is also expandable to other regions with access to similar data. Geographic Information Systems (GIS) combined with such maps allow analyses to be easily refined by using additional information, e.g., routing-enabled infrastructure data for building up a spatially explicit knowledge-based decision model.We investigated the potential of wood from forests and “trees outside forests” (TOF) as a potential source of renewable biomass as a case study within the German federal state of Baden-Württemberg. More precisely, we present an explorative approach to position prospective bioeconomy conversion plants and demonstrate its practical applicability for a case study in southwest Germany. We also performed a scenario analysis to simulate different facility sizes in terms of resource type and annual throughput.", 1. Introduction,None,1.
188,"The study site was Baden-Württemberg (centre at 48°32′16″ N, 9°2′28″ E), the third largest federal state of Germany that covers 35,751 km2 (Figure 2). The main land use classes are agricultural land (46%), forests (38%) and settlements and transportation areas (14%). The following summary of forest resources was derived from the national forest inventory report (NFI) [22]. The three main ownership classes of forest in Baden-Württemberg are corporate (40%), private (36%) and national/state (24%). The dominant softwood species are Norway spruce (Picea abies (L.) H. Karst, 34%), silver fir (Abies alba Mill., 8%) and pine (mainly Pinus sylvestris L., 6%). The dominant hardwood species are beech (Fagus sylvatica L., 22%), oak (Quercus robur L., Q. petraea (Matt.) Liebl., Q. rubra L.; 7%) and ash (Fraxinus excelsior L., 5%). The mean timber stock in 2012 was 377 m3 ha−1 with an annual increment of 12.3 m3 ha−1 year−1 and a mean harvest of 11.6 m3 ha−1 year−1, or 8.8 m3 ha−1 year−1 after excluding all losses (harvest and deadwood). Additionally, there are about 180,000 ha of TOF areas covered with vegetation at least 2 m in height [21]. These TOFs range from orchards and roadside-vegetation to trees on agriculture land, which constitute another source of lignocellulosic biomass. In Baden-Württemberg, TOF areas provide a mean potential of about 2.6 Mg ha−1 year−1 [21].", 2. Materials and Methods, 2.1. Study Site,2
189,"The basis of our approach were two biomass maps. The first map represented the actual standing volume for all forests in Baden-Württemberg with an original resolution of 30 × 30 m [20]. The map also contained information on ownership classes (national/state, corporate, private). This map represented the theoretically available biomass within the federal state that needed to be converted into annual timber harvest volumes.To calculate timber harvest volumes by different forest types in terms of ownership and tree species, we used datasets from the second (2002) and third (2012) German NFI. First, we estimated harvest volumes for each plot (n = 11,112 after merging) by calculating the mean volume of all harvested trees for the mean year (2007) and scaling this value from the sample plot area to 1 ha. Second, we regressed the interdependency between timber stock and harvest volume using a Generalized Additive Model [23,24]. We found that the standing volume and forest ownership class (private, national/state, corporate) were highly correlated (p < 0.001) with a final explained variance of about 50% of the deviance (r2 = 0.5). To make this approach more applicable, we calculated simple conversion factors for standing volume ha−1 per ownership class: 0.024 for national/state and corporate forest, and 0.022 for private forest. These factors allowed standing volumes to be converted to annual harvest volumes at a regional scale for the study site while excluding harvest losses and deadwood. The second map represented the estimated harvest volume of TOF in dry Mg year−1 from 12 classes with a spatial resolution of 4 m. The map was calculated using a combined approach of LiDAR-based classification and literature research [21].We recompiled both maps to a resolution of 100 × 100 m and merged them at the same resolution with the CORINE Land Cover classification (CLC 2012, [25]) to calculate the share of hardwood and softwood forests. The land use classes “coniferous” and “broadleaf forests” had, at a minimum, 75% conifers and broadleaves, respectively.The maps included data for timber harvest volumes in private, state/national and corporate forest; roadside vegetation; woody vegetation on agriculture land; orchards; vegetation along railroads; vegetation at lakes and rivers; and by tree species. Timber harvest volume is given in Mg of dry biomass for each class. Protected forests such as strict forest reserves and the Black Forest National Park were excluded from this analysis.", 2. Materials and Methods, 2.2. Biomass Maps,2
190,"To simulate varying catchment area and facility sizes, we used a routing-based approach. First, we created a point grid (n = 716) with a regular, staggered pattern of ca. 7.1 km diagonal distance covering the whole federal state. In total, our approach compared 716 possible locations for biomass conversion facilities. We used an Open Street Map (OSM)-derived routing-enabled road network provided by Geofabrik (Geofabrik GmbH, Karlsruhe, Germany). To facilitate the routing process, we snapped all points (locations) to the closest road, created catchment areas with radii (routed distance) equal to 10, 20, 30, 40 and 50 km per location, and calculated the supply of biomass for all locations. The calculation time of this process was accelerated by firstly converting the biomass harvest map (including all necessary data, e.g., dominant tree species, ownership, etc.) from a raster to a polygon point layer (ca. 3.6 million) with the same resolution (100 × 100 m). Secondly, we loaded it into a free PostgreSQL geospatial database (The PostgreSQL Global Development Group). Initially, we calculated theoretical potential as related to transport distances for possible biomass conversion plant sizes in terms of throughput. As feasibility is strongly related to costs, we then built a function to calculate mean transportation costs for each service area radius.", 2. Materials and Methods, 2.3. Calculating Regional Harvest,2
191,"Rates for timber transport are usually negotiated between traders and companies in the wood industry. These data are not publicly available. Therefore, we derived tariffs from business considerations and expert opinions. First, we collected data needed to calculate operating costs of a transportation company (Table 1).The listed costs, especially for fuel, may vary. A timber truck (tractor, crane and trailer) for light construction was selected, which can be loaded with 27 m3 of round timber and is used by the freight carriers of the Bavarian State Forestry. The acquisition cost was €172,400 with a running performance of 96,718 km in 248 operation days per year. Fuel costs varied between 1.14 and 1.44 € L−1 in recent years, and Reich et al. [26] used 1.35 € L−1. Currently the price is slightly lower at 1.25 € L−1, which is the value we used in our analysis. The personnel costs were valued at 3600 € month−1 as calculated from employment days year−1, 9 h of driving time day−1 and an hourly wage of 19.35 € h−1. This is the employer’s cost, which is around €5 more than what the employee receives [26]. Using these assumptions, a cost calculation was made that shows the necessary financial turnover per day for timber transport (Table 2). Expenses were divided into variable and fixed costs, personnel costs and impute costs. Variable costs constituted 96,718 km year−1, fuel consumption, tires, lubricant and maintenance and repair. Fixed costs consisted of annual principal and 4% interest payments [27], vehicle tax, insurance, tolls, charges for vehicle tests (e.g., emission test) and charges for mobile phones and internet connectivity.Personnel costs were calculated for one driver. We estimated the administrative costs were €3000 with an employer liability of 12,000 € year−1. In total, the cost per year for a vehicle and trailer, driver and overhead were €174,613, which corresponded to a rate of 704 € day−1, meaning a truck should have at least this turnover per day.", 2. Materials and Methods, 2.4. Transportation Cost of Woody Biomass,2
192,"A tariff was developed from the calculated annual expense. We used the measurements of Klenk [28] that tracked 34 routes of two haulers using GPS and calculated transport speed, distance and road category used. For our calculation, we used three road classes: forest roads, roads with a speed limit of 60 km h−1 and roads with a speed limit of 80 km h−1. We next derived a function to calculate the mean speed for timber transport from cradle to gate using data from Klenk [28]. One finding of particular interest is that freighters could reduce their share of empty runs up to ~40% through return trips, meaning that trucks were loaded for 60% of the overall distance. For each route, we assumed a distance of 2.7 km on forest roads [28]. Up to 20 km one-way, the section covered on roads with maximum speed of 60 km h−1 was assumed to be the difference between the total distance and the distance covered on forest roads. For distances >20 km, the share of the roads with maximum speed of 80 km h−1 was assumed to steadily increase to 33% at 130 km (Table 3). The average speed for a distance on all road types was calculated to be with load for 60% of the distance and empty for 40%. Consequently, the time per trip of 20 km required a running time of just under 50 min or 0.85 h (2 × 20 km at 47.2 km h−1). With the addition of 0.83 h for loading and unloading, a truck could complete the route in 1.68 h, which corresponded to 5.4 trips day−1 in 9 h day−1 driving time. The tariff for this example was:





T
d
 
/
 
t
d
 
/
 
l
t
 
=
 
c
t
 
=
 
4.86





(1)

Td = Turnover per day (€), td = trips per day (n), lt = load per trip (m3), ct = cost per m3 (€).We calculated these tariffs for all distances between 5 and 130 km (Table 3).To convert timber volume (solid cubic meter) to Mg of dry biomass, we used a conversion factor of 1.866 m3 t−1 at 0% moisture derived from wood densities [29] for mixed softwood and hardwood weighted by the main tree species (abundance > 0.5%) from the third NFI data. Using distance and cost values, we built a simple linear model with a quadratic function (Figure 3). The model featured an r2 of ca. 1 and a RMSE of €0.01, thus allowing for precise fitting of all distance values in the given interval (5–130 km). We used this model to calculate costs according to actual mean transport distances within our service area (Table 4).The mean transport range was calculated according to a circle as 2/3 the radius of maximum transport distance.", 2. Materials and Methods, 2.5. Transportation Tariff,2
193,"Resource assortments and prices were the third crucial factor after the biomass potential and logistics for assessing the economic feasibility of an emerging bioeconomy. We based our estimation on available data supplied by the forest research institute of Baden-Württemberg [30]. These data covered state-owned forest (24% of the forest area) [22] from 2011–2016. The prices at which the timber was sold by the state forest administration were weighted by their relative shares to the assortments and attached to our quantities. To assess the economic feasibility of the positioning of conversion plants, transport and resource prices were estimated as follows: potentially relevant forest assortments as roundwood, fuelwood and pulpwood; and woody biomass from TOF as analogous to fuelwood. As such, 70% of the average annual harvest were roundwood (predominantly softwood), 14% pulpwood and 16% fuelwood (predominantly hardwood; Table 5). ", 2. Materials and Methods, 2.6. Timber Assortments and Pricing,2
194,"Since conversion and fraction technologies for lignocellulosic biomass are under development and a market is beginning to slowly emerge, we decided to build several scenarios to estimate the potential for a regional bioeconomy in Baden-Württemberg. The scenarios were simple and varied by usable resource type, timber assortment and facility size in terms of annual throughput. To estimate the effects of these variables on the positioning of regional lignocellulosic biomass conversion and fractioning facilities, we defined the following scenarios:
Very small facility (VSF) processing 20,000 Mg year−1 of woody biomass.Small-size facility (SF) processing 80,000 Mg year−1 of woody biomass.Medium-size facility (MF) processing 250,000 Mg year−1 of woody biomass.There was a huge price difference between the high-quality roundwood and fuelwood and pulpwood (Table 5). Due to those differences in prices, we assumed it is not reasonable to process high-quality roundwood for bioeconomy products, and thus focused on the cheaper assortments of pulpwood and fuelwood in this analysis. First, we checked the feasibility of the suggested plant size in terms of resource availability. Yet to show the possible impact on the wood market, we calculated those results for three different resource use efficiencies (100%, 50%, 5%). A usage of 100% meant a complete, local displacement of fuelwood or pulpwood use by bioeconomy. The 50% scenario simulated coexistent wood usage as pulpwood, fuelwood and bioeconomy-wood. The last scenario was a no-impact/business-as-usual scenario using just a small share (5%) of the wood for bioeconomy.Without complete conversion (100%) or at least strong influence (50%) on the fuelwood and pulpwood market, only VSF were possible using hardwood or mixed wood with a minimum service area radius of 40 km (Table 7). As such, regional bioeconomy with transport distances of up to 50 km would compete with existing industries. Secondly, the regional (i.e., short distances) potential of low-price softwood was small, while, in comparison, the potential of cheap hardwood was high. Consequently, a bioeconomy seeking to minimise environmental impacts by primarily using regionally available biomass in Baden-Württemberg would need to focus on either hardwood or mixed wood. As those might be the most relevant scenarios, we calculated the optimal positions (see Figure 4) for hard- and mixed-wood processing facilities of all three sizes (VSF, SF, MF) using 50% of the available resources and minimal transport costs in terms of service area radii (Table 7).", 3. Results, 3.1. Scenarios,3
195,"In the final step, we filtered out all positions that did not provide the needed amount of resources for specific facility sizes using 50% of the available hardwood or mixed wood. Figure 4 shows the results of our positioning approach for six scenarios varying in wood type (hardwood or mixed wood), facility size (VSF, SF, MF) and service area radii (10, 20, 40 km) without competition between multiple facilities. For positioning competing facilities with overlapping service areas, a stepwise approach would be used to position one facility after the other. Thereby, the already used biomass would be excluded and is not available anymore for the next facilities.For VSF using hardwood, only a few, wide-spread possible positions could be found across the federal state. The positions changed when conifers were included in our mixed-wood scenario. Specifically, the total number of possible positions rose and concentrated within forested areas such as the Black Forest. The Southeast of the state between Ulm and Lake Constance showed limited potential for all different settings. For a SF with a 20 km supply radius as an example, only one position northwest of Lake Constance fitted the criteria. In contrast, many more positions became possible if the facility were able to process both wood types.For a MF with a 40 km radius, the positions clumped in the centre of the federal state around Stuttgart, Reutlingen and southwest of the latter along the mid-east border of the Black Forest. There were a few positions spread throughout the Black Forest in the mid-north and again northwest of Lake Constance. For the mixed-wood scenario, numerous options were found in the Southeast (Black Forest, Germany) of the federal state.", 3. Results, 3.2. Suitable Positions,3
196,"Combining the results for transport and wood assortment, we calculated resource prices for the different scenarios. We first calculated mean prices for hardwood (90.04 € t−1) and softwood (82.65 € t−1) while excluding roundwood (Table 5). Since in the mixed scenarios the share of softwood varied (5–24%), the exact price was calculated individually for each position. For demonstration purposes though, we calculated the mean price of 89.08 € t−1 for mixed wood consisting of 13% softwood. When transportation costs were integrated for each scenario, we got a mean hardwood price of 96.36 € t−1 for VSF, €97.77 for SF and €100.47 for MF. Using mixed wood, we got prices of 95.43 € t−1 for VSF, €96.81 for SF and €99.51 for MF. The transportation cost had an impact on the final price between ca. 6.7% (5 km) and 31.9% (130 km) that increased roughly €1.8 every 10 km (Table 4). In our optimised scenarios, the share of the transportation in the overall biomass price was between 7.1 and 10.5%. ", 3. Results, 3.3. Final Costs,3
197,"The potential biomass volumes, prices and facility positions resulting from our approach demonstrate the practical applicability of remote sensing-derived potential (in terms of biomass availability) maps to analyse the feasibility of a regional bioeconomy using lignocellulose. The explicit objective was to estimate the potential of a future bio-based economy to replace fossil-based chemicals, but in principle this method could be used for a wide variety of facilities from sawmills to pulp and paper mills to power and heating plants that use woody biomass. Similarly, it could be implemented anywhere on the globe.While the produced results are based on a number of limited assumptions, this methodology for spatially explicit analysis outside those assumptions is possible. For instance, only data on lignocellulosic biomass from forests and TOF were included. Yet the study area could be easily expanded both spatially and to include other resource sources such as short rotation coppice. Spatial limits to such methods have decreased to the extent that global approaches (e.g., [31]) for mapping biomass have already been implemented; global timber harvest maps are only a matter of time.The application of the methodology was straightforward in its combination of geo-referenced resource potential maps, infrastructure data and both transport and resource costs. The results demonstrated that, given the premises on transport distance and facilities’ throughput, the economic feasibility and possible location of a conversion plant can be easily checked.The study clearly demonstrated, however, that large discrepancies between theoretic and economic potential exist. The results showed that up to 3 million Mg of lignocellulosic biomass were theoretically available at a maximum transport distance of 50 km. However, this potential changed dramatically when restrictions were implemented about the type of wood, timber assortment and share of the resource used. Should conversion processes be tolerant to mixed wood as input material though, more suitable positions would become available.Alternatively, if the demand from a facility is more precisely defined, a more refined investigation could be performed. For instance, a single tree species like beech could be selected or the facility could be located close to sawmills, thus making use of existing infrastructure and possibly any by-products. About 40% of the roundwood processed in sawmills is considered waste as, e.g., wood chips and saw dust [32].Other assumptions such as costs and demand are likely to change. We showed that facilities with a throughput of 20, 80 or 250 Gg year−1 fuelled by regionally produced biomass are economically possible at relative low transport costs (ca. 10% of the resource price). Yet, these were mean costs specifically calculated for Baden-Württemberg, and may change over time especially due to fluctuations in the price of fuel. Also, the suggested positions of facilities are located in regions with high biomass potential that meet our defined criteria. These criteria can and will need to be adapted according to implemented conversion technology and associated requirements for raw woody biomass.Additional factors besides biomass cost and availability remain to be implemented such as specific infrastructure (e.g., a harbour or railway station), local tax situation, and political or social influence. These results indicate that an emerging bioeconomy using regionally produced biomass will directly compete with regional wood-fired combustion plants since resource price is currently low and transport costs strongly increase with distance. Thus, local wood prices can be expected to rise if bioeconomy demands large quantities of fuelwood. Whether it is possible to establish a bioeconomy depends on its competitiveness to fossil raw materials-based economy and a supportive governance [4].", 4. Conclusions,None,4
198,"Fire is one of the most important disturbance agents in terrestrial ecosystems on a global scale [1]. It is also devastating and causes irreparable damage to the environment and atmosphere [2]. Many studies have shown that a strong relationship between the biomass burning with the main air pollution gas, such as Particulate Matter 2.5(PM2.5), CO2, and CO [3,4,5]. In addition, it is confirmed that biomass combustion is a major source of PM2.5 in both chemical and Positive matrix factorization (PMF) analysis, harming human health [6]. Meanwhile, biomass burning is not merely playing a role in degrading the air quality, but also, through radiance and cloud formation, affects the weather and climate [7]. In a changing climate, monitoring fire activities is significant so as to understand its response to the recent climate warming [8]. Therefore, it is very important to study the fire changes in the past decades. During the period of 1965–2010, 1614 forest fires happened in Great Xing’an Mountains, in the northeast of China. The sum of burned forest area reached 35,230.19 km2 [9]. It is widely accepted that China is a great agricultural country. In recent years, accompanying the increase of the living standard, crop residue is not used in most areas, so a large amount of crop residue is burned in the croplands [10,11]. Every year, more than 400 grassfires occurred in the northeast of Inner Mongolia Autonomous Region, and the total of burned area reaches about 8000 km2 [12]. A large number of biomass fires in different vegetation types occur in China every year. It is necessary to conduct a comprehensive study of biomass fires in China for the goal of mastering the spatio-temporal characteristics of fires precisely, and we should take the different vegetation types into account for this purpose. However, it is difficult to detect the biomass burning from traditional ways, which need much human and material resources, not to mention the observation of long-term spatio-temporal changes. Studies have used satellite remote sensing to monitor fires from the early 1990s [13,14], which can be applied at large scales. With the rapid development of remote sensing technology, increasingly satellites are used for fire monitoring [15,16,17].In recent years, many studies have been committed to the spatial and temporal characteristics of fires from the global and regional perspectives, using satellite data [18,19,20,21]. Also, many researches are aimed at understanding the spatial and temporal patterns of biomass fires in China, applying different remote sensing data. From 2001 to 2013, 78.6% of the land was influenced by fire in China; forest fires have a large quantity and higher inter-annual variability in the northeast of China [22]. The Great Khingan Range forest area, Guangdong province and Yunnan province were regions with high fire risk from 2001 to 2010 [23]. In the past decades, the grasslands showed a higher fire risk in spring and autumn in Northeast China [24]. The croplands fires are mainly detected in Northeast China especially in spring and autumn, showing a upward trend with limited fluctuations in the past decades [25]. Most of the forest fires are detected in Northeast and Southwest China from 2013 to 2017 [26]. However, most of these studies have focused on fires of one landcover fires, a long-term and a comprehensive analysis of spatio-temporal in different vegetation types is needed in China. In addition, China has experienced a rapid urbanization recently, and around 60% of the population are living in urban areas [27]. Fires in urban areas are more harmful, and this study also takes the urban fires into account. In this research, we have analyzed the fire changes of different land cover types during 2003–2016 in China, using satellite images and the online tool: Google earth engine (GEE). It is expected that this study can help us to understand the fire risk of different land cover types to the changing climate.", 1. Introduction,None,1.
199,"Our study area includes the whole territory of China, except for the Nansha islands. China has a large latitude span with a complex climate, where it is relatively dry in the north and wet in the south [28,29]. The dry areas are mainly distributed in Northwest China because of the long distance from the oceans and the Tibet Plateau that blocks warm, wet air from the Indian Ocean [30,31]. The climate is dominated by the East Asian monsoon in the East China, where the summer is wet and hot while winter is dry and cold [32]. It is known that about 75% of the land areas of China are covered by different vegetation types, mainly including forest, savannas, croplands and grasslands [33]. Therefore, the whole country is divided into five main kinds of land coverage types, including forest, croplands, grasslands, savannas, and urban areas. "," 2. Study Area, Data and Methods", 2.1. Study Area,2
200," 2.2.1. MODIS Fire ProductsWe use NASA’S MODIS fire product in this study, which is the longest fire records at a global scale [34]. The products are obtained from the MODIS sensors onboard the Terra and Aqua satellites launched in December 1999 and May 2002 respectively. Both satellites have a revisit time of twice a day. The Terra crosses the equator at about 10:30 and 22:30 local time, and the Aqua crosses the equator at about 1:30 and 13.30 local time. Since the launch of Terra and Aqua, they have been widely used to study the role of fires in the Earth system [35]. There are fire products from both Terra and Aqua satellites, named MOD14A1 and MYD14A1 respectively, freely available from the USGS/NASA Land Processes Distributed Active Archive Center (https://lpdaac.usgs.gov/). These provide global daily records of burning spots at a spatial resolution of 1 km. These products are mainly derived from 3.9 and 11 μm channels, using a contextual algorithm according to the temperature difference of the fire site and surrounding areas [15]. The active fires detected by MODIS have a high precision. The latest MODIS fire product (C6) is reported to have a noticeable improvement over the last collection, with a low commission error at about 3% in China, and the omission error is about 5% [36]. The difference in overpass time provides a unique insight into diurnal occurrences; our statistics are applied to both products separately rather than their daily average. The fire data are extracted using the online tool of Google earth engine (GEE), which is a cloud platform, for big satellite data processing [37,38,39]. The land cover products for our study are the MCD12Q1 products on the GEE platform.  2.2.2. The Data of Land CoverIn this study, we use the MODIS land cover type product (MCD12Q1), which provides global maps of land cover types at a spatial resolution of 500 m. This product is updated on an annual base. The MCD12Q1 product has 5 legacy classification schemes(International Geosphere-Biosphere Programme (IGBP), University of Maryland classification scheme (UMD), the LAI/fPAR Biome scheme (LAI), the Biome classification scheme (BGC), and the Plant Functional Type scheme described(PFT) and a new three layer legend based on the land cover classification system (LCCS) from the Food and Agriculture Organization [40]. The recent version (C6) has an improvement to both the classification algorithm and product quality compared with the previous versions, especially regarding the reduction of spurious land cover change [41]. The IGBP classification is used in our study, which includes 17 land cover types (Table 1). We reclassified these types into forests (1,2,3,4,5), savannas (6,7,8,9), grasslands (10), croplands (12,14) and urban (13). Other land cover types, including permanent wetlands (11), permanent snow and ice (15), and barren and water bodies (16,17), where there are limited fires, are not analyzed in our study. These land cover types of China are shown in Figure 1. "," 2. Study Area, Data and Methods", 2.2. Data,2
201,"We use NASA’S MODIS fire product in this study, which is the longest fire records at a global scale [34]. The products are obtained from the MODIS sensors onboard the Terra and Aqua satellites launched in December 1999 and May 2002 respectively. Both satellites have a revisit time of twice a day. The Terra crosses the equator at about 10:30 and 22:30 local time, and the Aqua crosses the equator at about 1:30 and 13.30 local time. Since the launch of Terra and Aqua, they have been widely used to study the role of fires in the Earth system [35]. There are fire products from both Terra and Aqua satellites, named MOD14A1 and MYD14A1 respectively, freely available from the USGS/NASA Land Processes Distributed Active Archive Center (https://lpdaac.usgs.gov/). These provide global daily records of burning spots at a spatial resolution of 1 km. These products are mainly derived from 3.9 and 11 μm channels, using a contextual algorithm according to the temperature difference of the fire site and surrounding areas [15]. The active fires detected by MODIS have a high precision. The latest MODIS fire product (C6) is reported to have a noticeable improvement over the last collection, with a low commission error at about 3% in China, and the omission error is about 5% [36]. The difference in overpass time provides a unique insight into diurnal occurrences; our statistics are applied to both products separately rather than their daily average. The fire data are extracted using the online tool of Google earth engine (GEE), which is a cloud platform, for big satellite data processing [37,38,39]. The land cover products for our study are the MCD12Q1 products on the GEE platform. "," 2. Study Area, Data and Methods", 2.2.1. MODIS Fire Products,2
202,"In this study, we use the MODIS land cover type product (MCD12Q1), which provides global maps of land cover types at a spatial resolution of 500 m. This product is updated on an annual base. The MCD12Q1 product has 5 legacy classification schemes(International Geosphere-Biosphere Programme (IGBP), University of Maryland classification scheme (UMD), the LAI/fPAR Biome scheme (LAI), the Biome classification scheme (BGC), and the Plant Functional Type scheme described(PFT) and a new three layer legend based on the land cover classification system (LCCS) from the Food and Agriculture Organization [40]. The recent version (C6) has an improvement to both the classification algorithm and product quality compared with the previous versions, especially regarding the reduction of spurious land cover change [41]. The IGBP classification is used in our study, which includes 17 land cover types (Table 1). We reclassified these types into forests (1,2,3,4,5), savannas (6,7,8,9), grasslands (10), croplands (12,14) and urban (13). Other land cover types, including permanent wetlands (11), permanent snow and ice (15), and barren and water bodies (16,17), where there are limited fires, are not analyzed in our study. These land cover types of China are shown in Figure 1. "," 2. Study Area, Data and Methods", 2.2.2. The Data of Land Cover,2
203," 2.3.1. Extract Burning SpotWe use the geographical information science (GIS) to extract the total fire numbers with the fire products of China [20]. We note that the fire number hereon means the detected fires on each day and each pixel. The MCD12Q1 product has a spatial resolution of 500 m and we aggregate it to 1 km resolution [42] so that it can match the Terra and Aqua fire products [43,44]. 2.3.2. Theil-Sen slope (TS)The Theil-Sen slope (TS) method is used to detect the pixel-wise linear trends in the fire products. The TS method a well-established non-parametric method put forward by Theil in 1950 and Sen modified it in 1968 [45,46]. Compared with traditionally used linear regression, this method is not sensitive to outliers, and thus it is plausible for a more robust estimation of linear trend [47]. It is especially suitable for time series with large inter-annual variations [48]. The formula of the TS method is as follows:



Δ
=
m
e
d
i
a
n

(




x
j

−

x
i



j
−
i



)

.




(1)

In the above formula, median is the median function, xj and xi are the data at time points of j and i respectively.  2.3.3. Mann-Kendall (MK) TestThe Mann–Kendall (MK) test is applied to determine the significance of long-term trends. This method is also a non-parametric statistic that does not need samples to meet a certain distribution. An combination of the MK and the TS methods is an important trend analysis approach [49]. The statistic, S, is calculated as followed:



S
=


∑


i
=
1


n
−
1




∑


j
=
i
+
1

n

s
g
n

(


x
j

−

x
i


)

,




(2)





S
g
n

(


x
j

−

x
i


)

=

{





+
1
,






   

0
,






−
1
,









x
j

−

x
i

>
0







x
j

−

x
i

=
0







x
j

−

x
i

<
0




 
,






(3)


where 


x
i


 
and
 


x
j


 are sequential data values at time i and j (j > i), and n represents the length of data points. The calculation of probability is related to S and n. When 

n
≥
10

, S is generally in a standard normal distribution and the variance is computed as follows:



V
a
r

(
S
)

=


n

(

n
−
1

)


(

2
n
+
5

)

−


∑


i
=
1

m


x
i


(


x
i

−
1

)


(

2

x
i

+
5

)

,


18






(4)


where m is the length of the tied group. The statistic Zs is calculated using the following equations:




Z
s

=

{







S
−
1




V
a
r

(
S
)





,
  
if
 
S
>
0






           
0
,
  
if
 
S
=
0








S
+
1




V
a
r

(
S
)





,
  
if
 
S
<
0
.










(5)

When Zs is positive, the trend is increasing, or vice versa. The bilateral trend test is conducted according to a special 
α
 significance level. The null hypothesis is false if 


|


Z
s


|

>

Z

1
−
α
/
2


 

(


Z

1
−
α
/
2



 is obtained by the table lookup method); if the hypothesis is true, the time series has a significant up- or downward trend. In this study, the significance level 

α
=
0.05

 is applied."," 2. Study Area, Data and Methods", 2.3. Methods,2
204,"We use the geographical information science (GIS) to extract the total fire numbers with the fire products of China [20]. We note that the fire number hereon means the detected fires on each day and each pixel. The MCD12Q1 product has a spatial resolution of 500 m and we aggregate it to 1 km resolution [42] so that it can match the Terra and Aqua fire products [43,44]."," 2. Study Area, Data and Methods", 2.3.1. Extract Burning Spot,2
205,"The Theil-Sen slope (TS) method is used to detect the pixel-wise linear trends in the fire products. The TS method a well-established non-parametric method put forward by Theil in 1950 and Sen modified it in 1968 [45,46]. Compared with traditionally used linear regression, this method is not sensitive to outliers, and thus it is plausible for a more robust estimation of linear trend [47]. It is especially suitable for time series with large inter-annual variations [48]. The formula of the TS method is as follows:



Δ
=
m
e
d
i
a
n

(




x
j

−

x
i



j
−
i



)

.




(1)

In the above formula, median is the median function, xj and xi are the data at time points of j and i respectively. "," 2. Study Area, Data and Methods", 2.3.2. Theil-Sen slope (TS),2
206,"The Mann–Kendall (MK) test is applied to determine the significance of long-term trends. This method is also a non-parametric statistic that does not need samples to meet a certain distribution. An combination of the MK and the TS methods is an important trend analysis approach [49]. The statistic, S, is calculated as followed:



S
=


∑


i
=
1


n
−
1




∑


j
=
i
+
1

n

s
g
n

(


x
j

−

x
i


)

,




(2)





S
g
n

(


x
j

−

x
i


)

=

{





+
1
,






   

0
,






−
1
,









x
j

−

x
i

>
0







x
j

−

x
i

=
0







x
j

−

x
i

<
0




 
,






(3)


where 


x
i


 
and
 


x
j


 are sequential data values at time i and j (j > i), and n represents the length of data points. The calculation of probability is related to S and n. When 

n
≥
10

, S is generally in a standard normal distribution and the variance is computed as follows:



V
a
r

(
S
)

=


n

(

n
−
1

)


(

2
n
+
5

)

−


∑


i
=
1

m


x
i


(


x
i

−
1

)


(

2

x
i

+
5

)

,


18






(4)


where m is the length of the tied group. The statistic Zs is calculated using the following equations:




Z
s

=

{







S
−
1




V
a
r

(
S
)





,
  
if
 
S
>
0






           
0
,
  
if
 
S
=
0








S
+
1




V
a
r

(
S
)





,
  
if
 
S
<
0
.










(5)

When Zs is positive, the trend is increasing, or vice versa. The bilateral trend test is conducted according to a special 
α
 significance level. The null hypothesis is false if 


|


Z
s


|

>

Z

1
−
α
/
2


 

(


Z

1
−
α
/
2



 is obtained by the table lookup method); if the hypothesis is true, the time series has a significant up- or downward trend. In this study, the significance level 

α
=
0.05

 is applied."," 2. Study Area, Data and Methods", 2.3.3. Mann-Kendall (MK) Test,2
207,"Shown in Figure 2 are the annual fire numbers of the Terra and Aqua satellites during 2003–2016, across China. We note that the fire number hereon means the detected fire points on each day and each pixel. It is indicated that, the annual fire numbers range from 0.7 × 105 to 1.7 × 105, and there are significantly more fires detected by the Aqua than the Terra satellite. Notably, fires from both satellites have shown increasing trends during 2003–2016, passing the significance test at 0.05 level. It is thus indicated that China has experienced more and more fires in the past decade. During the study period, there are two pronounced peaks, in 2008 and 2014, indicating more fire occurrences. There are significantly more fires in these peak years from the Aqua versus the Terra satellite. This may relate to the overpass times of the satellites [50]. The overpass times of the Terra satellite are about 10:30 and 22:30, and those of the Aqua satellite about about 1:30 and 13.30. Some fires occurring at morning may last until the Aqua satellite passes; meanwhile, this satellite is the only one that can detect fires occurring at afternoon.We then delineate the fire numbers into land cover types of forests, savannas, grasslands, croplands, and urban areas. Table 2 shows the percentages of fire numbers in different land covers during 2003–2016. We can clearly find that most fires that have occurred are in the savannas, croplands and forests, amounting to totally about 85% from both Terra and Aqua satellites. For grasslands and urban areas, their respective percentages are less than 10% from both satellites. There are rather limited fire occurrences in the other land cover types, which are mostly located in Northwest China.Figure 3 shows the annual fire numbers delineated to the land cover types of forests, croplands, grasslands, savannas, and urban areas during 2003–2016. From the viewpoint of land covers, the fires have shown quite different trends. They are significantly increasing in grassland, cropland and urban areas, which have mostly passed the significant test at 0.05 level. However, in forest and savannas, the fire trends are significantly downward, indicating there are less and less fires in the past decades. The reasons for these opposite trends remain unclear. Croplands and grasslands are noticed to have comparable fire numbers during 2003–2016. However, in forests and savannas there are obviously more fires from the Aqua than the Terra satellite. This may relate to fire durations in different land cover types. Fires in croplands and grasslands may have relatively short durations, those in forests and savannas have a high possibility to last a longer time than can be detected by the Terra but also by the Aqua satellite. In the urban areas, there are significant increasing trends in both products, and there are significantly more fires from the Terra satellite than the Aqua satellite.Sometimes it is of interest to understand the fire changes in different land forest types. Figure 4 shows the change of annual fire numbers in different forest types: broadleaf forest, needleleaf forest and mixed forest areas, during 2003–2016. From the view of different forest types, the fires have shown quite different trends. There is a significant decreasing trend in the broadleaf forests which are mostly located in South China. However, there are not significant changes observed in the needleleaf and mixed forests, which are mostly located in North China. Therefore, we can conclude that the decline of forest fires is mostly due to the changes in the broadleaf forests.", 3. Results, 3.1. Annual Fire Changes,3
208,"Figure 5 shows the annual fire changes in different seasons. It is not surprising to find that both fire products from Terra and Aqua satellites appear to have quite similar trends in each season. In spring, there are increasing trends in both fire products during 2003–2016, and their fire numbers are comparable especially in the latest seven years. In summer, both fire products show significant increasing trends, and there are significantly more fires from the Terra satellite. In autumn, both satellites show similar increasing trends as in spring; however, there are significantly more fires from the Aqua than the Terra satellite, which are opposite to those in spring. In winter, both fire products show trends opposite to those in other seasons, indicating the decreasing fire occurrences in the past decades. We further delineated these annual trends into different land cover types, which are shown in Figure 6. It is obvious that the long-term fire changes in each land cover type differ largely with seasons. Overall, fires in forests show a decreasing trend (Figure 6a); however, this trend is not significant in all seasons. In cold seasons of winter and spring, only the Aqua data show a significant increasing trend, and no significant trends are observed in the Terra data. In autumn, there are significant decreasing trends in both Terra and Aqua data, as in the annual data; however, in summer there is a slight but significant increasing trend in the Terra data. Fires in croplands show a significant increasing trend in terms of the annual amount (Figure 6b); however, a significant increasing trend is only found in spring and autumn, and the trend in autumn is much stronger than that in spring. In summer and winter seasons, there are not significant trends observed from either satellite. In grasslands, there are significant increasing trends in all seasons, and that in spring is strongest. In savannas, there is a significant decreasing trend of the annual fire numbers (Figure 6d); such a trend is observed in spring, summer and winter seasons, and on the contrary a significant decreasing trend is observed in autumn. In the urban areas, annual numbers show an increasing trend (Figure 6e); however, increasing trends are only found in spring and summer seasons, and there are not significant trends in autumn and winter. ", 3. Results, 3.2. Annual Fire Changes in Different Seasons,3
209,"We then analyzed the seasonal variability of the fire numbers from both satellites. To understand the possible data uncertainties, the monthly fire numbers during 2003–2016 are also shown. Figure 7 shows the monthly fire numbers from (a) Terra and (b) Aqua products across China during 2003–2016. Clearly, there are significant changes of the fires in each month during the study period; and obvious increasing trends are seen especially in the months of spring, summer and autumn seasons. Both the Terra and the Aqua products show a very strong seasonality of the fire numbers. It is clearly shown that there are more fires in spring and autumn, while much less in summer and winter. This seasonality of the fire occurrences may relate to the seasonal changes of biomass and the meteorological conditions. Wild fires are mainly affected by dry biomass, temperature, and human activities. In winter, there is maximum dry biomass especially in forests, grasslands and savannas; however, the temperature is low, which hinders fire occurrences. In spring and autumn, the temperature is relatively high and it may promote fire occurrences. In summer, there are the least fires; while the temperature is the highest, the dry biomass is relatively reduced and there is more rainfall, resulting in reduced fires.Next, the seasonality of fire changes from both satellites is studied in different land cover types, which are shown in Figure 8. The seasonal fire changes in forests are distinct with two peaks in spring and autumn respectively. This seasonality of wild fires in forests is largely related to the large amount of dry biomass, especially fallen leaves, and high temperature in spring and autumn. In summer, although temperature is the highest, the dry biomass is the least, which makes it different for fire occurrences. As for the interannual fire variations in forests, long-term decreasing trends during 2003–2016 are seen in most months, especially in the spring and autumn months. In croplands, there is not a distinct seasonality as in forests; however, in months of April–June and September–October, there are relatively more fires. This may relate to the agricultural management system, and there are more fires in the crop harvesting months. As for their long-term changes during 2003–2016, we can see significant fire increases in spring and autumn months in which there are more fires. Grasslands shows a clear seasonal change and there are relatively more fires in spring and autumn as in forests. There are significant increasing trends in almost all months during 2003–2016, except for those in winter. In grasslands, there is a quite similar seasonality as in savannas with more fires in spring and autumn, and less in summer and winter. In the abovementioned land cover types, the seasonal fire changes are obviously the changes of dry biomass, and generally there are more fires in spring and autumn months. However, in urban areas the seasonal fire changes are quite different from the abovementioned land cover types. Clearly, there are the least fires in winter, and then fires gradually increase in spring; fire numbers reach the maximum in summer, and then decrease gradually in autumn. The seasonal fire changes appear to follow a bell curve from both Terra and Aqua satellites. This probability distribution indicates that urban fires are likely to have a close relation with the seasonal changes of meteorological conditions, especially temperature. ", 3. Results, 3.3. Seasonal Fire Changes,3
210,"Shown in Figure 9 are the spatial patterns of the accumulated fire numbers during 2003–2016 from theTerra and Aqua satellites. For a generalized knowledge, we calculate the sum of all fire numbers over each pixel, and then resample the derived data to the spatial resolution of 50 square kilometers. Therefore, the fire numbers in Figure 9 indicate the averaged values over 50 square kilometers; and the values less than 100 are not shown for a better display. In general, both Terra and Aqua products show quite similar spatial patterns. Clearly, most of the fires are scattered in the eastern regions of China. There are three hot regions of fires, including Northeast China, East China and South China. The land covers of Northeast China mainly consist of forests, croplands and grasslands; in the East China the land is mainly covered by croplands, and in the South China, they are mostly forests and savannas. In these regions, the land is more vegetated and there are plenty of dry biomass, especially in spring and autumn, prone to fires. In Northwest China and Tibetan Plateau, there is sparse vegetation and thus quite limited biomass for fires. Figure 10 shows the long-term trends of annual fire numbers during 2003–2016 from Terra and Aqua products. In this picture, we resample the derived data to the spatial resolution of 50 km2 firstly for a better display, and the fire numbers are the sum of those from the 1-km2 resolution pixels. The trends are determined with the TS method, which are subjected to MK significance test at the 5% level. Both products appear to have quite similar spatial patterns of the long-term trends. Strongest increasing trends of fires appear in the central areas of Northeast China. Significant increasing trends also appear in most areas of East China, although less strong than those in Northwest China. Thus, more and more fires are observed in Northwest and East China over the past decades. However, there appears decreasing trends in South China where the land cover types mainly consist of forests and savannas, indicating less and less fires in the past decades. In Northwest China and Tibetan Plateau, there are quite few significant trends observed from both Terra and Aqua products. This country-wide spatial pattern appears much clearer in the Aqua than the Terra fire product. Furthermore, the long-term trends are delineated into different seasons, which are shown in Figure 11. For better display, we resample the derived data to the spatial resolution of 50 square kilometers too, and the fire numbers are the sum of those from the 1-km resolution pixels. The derived spatial patterns of long-term fire trends are very similar from Terra and Aqua products. Obviously, the long-term fire trends appear to be quite different in different seasons. In spring, there are significant increasing trends in the central areas of Northeast China and East China where the vegetation is mostly croplands; there are some decreasing trends in South China, which however do not pass the significance test. In summer, significant increasing trends are observed in East China, including Shandong, Jiangsu and Anhui provinces; there are also some significant decreasing trends observed in the north part of Jiangsu province. In autumn, there are significant increasing trends in northeast and East China, and those in Northeast China are stronger; on the contrary, significant decreasing trends appear in South China, where the land cover types are mainly forest and savannas. These long-term trends appear more significant from Aqua than the Terra product. In winter, there are only decreasing trends observed in South China; similar as in autumn, the decreasing trends in winter are more significant from the Aqua than the Terra product. ", 3. Results, 3.4. Spatial Patterns,3
211,"Climate change has actually affected the wildfire risk all over the world [51,52]. Globally, it is reported that fire weather seasons have lengthened across 29.6 million km2 (25.3%) of the Earth’s vegetated surface, resulting in an 18.7% increase in global mean fire weather season length [53]. If climate keeps changing like this, the fire risk in the northern hemisphere will become three times greater than it is now at the end of this century [54]. The suitable weather conditions for surface fire (temperature, humidity, wind speed, and precipitation) and coincidences of high index values of atmospheric conditions (tropospheric instability and dryness) will increase in frequency in the future [55].Study indicates that global burned area has experienced a human-driven decline in the past decades [56]. Similar as other studies, fires in China are found to be mostly located in Northeast, East, and South China, where there are the most densely populated regions in China [26,57]. In our study, we found that the total fire numbers over China have significantly increased during 2003–2016, based on the Terra and Aqua satellite products. It is indicated that fire numbers in croplands, grasslands, and urban areas have significant increasing trends. In croplands, the fire numbers show significant increasing trends in spring, summer and autumn, especially in the central area of Northeast China and East China, especially Shandong, Anhui and Jiangsu provinces where the land cover type is mostly croplands. Such an increase is suggested to have a link with the burning of crop residuals; with the rapid development of economy in such areas, there is no need to keep the crop residuals and they are often burned after harvesting the crops, leading to a sharp increase of burning fires in the past decades [25]. In recent years, strict policies have been imposed to prohibit burning the crop residuals in order to protect the atmospheric environment. However, the increased fires observed in this study have suggested that more administrative efforts are probably needed to reduce the fires in croplands. The grasslands are mainly located in North China. There appears to be significant increasing trends in grasslands, especially in spring, summer and autumn seasons. In the warming climate, these areas experience more and more droughts due to reduced precipitation and increasing temperature, leading to, at least partly, increasing fires in grasslands. Furthermore, as grassland fires will not cause massive economic loss, limited efforts have been made to prevent the fires [24]. In urban areas, the increasing trends of fires are also significant. On one hand, the rapid urbanization in China may be one reason for it. During 1985–2010, urban areas increased more than 20% in China [58], and the proportion of the Chinese population living in urban areas increased from 17.9% to 52.6% between 1978 and 2012 [59]. On the other hand, an urban heat island (UHI) is more serious accompanying the rapid urbanization. This effect makes the urban temperature higher than the surrounding areas, which is more significant in summer than other seasons [59]. In addition, there are some extraordinary heat sources in urban, such as some factories [60]. Because the algorithm to detect active fire is a contextual algorithm according to the temperature difference of the fire site and surrounding areas [15], it is sensitive to such thermal anomalies in urban areas. The fire numbers may be highly related with the temperature, and the probability density functions show like bell curves within a year. However, the biomass burning in the forest shows significant decreasing trends in the Great Khingan Range and South China, especially in autumn and winter seasons, consistent with a global study of forest fires [23,61]. In recent decades, the international governments have paid great attention to the fire management of forests and savannas. In China, more efforts are made to reduce the forest fire risk, and the decrease in fire trends is likely due to the fire management. Fires in savannas are found to have quite similar temporal patterns as those in forests, especially in South China.", 4. Discussion, 4.1. Spatio-Temporal Changes,4
212,"This study has analyzed the spatio-temporal changes of fires in China during 2003–2016 from both national and land cover perspectives; however, there are some known limitations. Firstly, the spatial resolutions of fire products from Terra and Aqua products is 1 km, which are relatively coarse for fire monitoring. Thus, some fires of smaller scales may not be found. Higher resolution satellite data should be applied for better results in the future. Secondly, the spatial resolution of the land cover product is 500 m, which cannot match with the fire products. In the downscaling process, resampling errors may occur and affect the accuracy of the result. A prototype downscaling algorithm designed for MODIS active fire data [62] can be taken into account in future research, which may improve the result. Thirdly, the urban fires observed by the satellite have some errors, which may be due to the extraordinary heat sources. More detailed statistical data should be added for a more precise analysis. Furthermore, our study showed an increased fire trend in summer (July-August) when there are the least fire events; this is interesting and deserves a detailed study in the future.Apart from this, the cloud change may influence the fire detection. This relationship is worth studying to quantify how many uncertainties remain.In addition, due to the vast territory of China, we only divide it into five categories of discussion. In future studies, higher resolution fire and land cover products from satellites should be taken into consideration. Fires are mainly influenced by both human activities and meteorological conditions. In the context of climate change, it is of interest to understand the effect of changing climate on wild fires, especially in forests, savannas and grasslands. ", 4. Discussion, 4.2. Limitations and Prospects,4
213,"Our study used the fire products from the MODIS satellites to understand the spatio-temporal changes of fires during 2003–2016. Fires are mostly located in the eastern half of China, where it is the most developed and densely populated. In the national perspective, total fire numbers are found to increase significantly, especially in East and Northeast China. However, the long-term trends differ in different seasons. From spring to autumn, the long-term trends of total fire numbers are significantly positive, and in winter these trends are significantly negative. Results from both Terra and Aqua satellites appear to be well consistent.When delineated into different land cover types, the fires show different seasonal variations and long-term trends. Generally speaking, the seasonal variations of fires in forests, grasslands, croplands and savannas are, at least partly, related with the amount of dry biomass, and thus they mostly have peak numbers in spring and autumn; however, the fires in urban areas are likely to follow a bell curve distribution. The long-term fire trends in different land cover types are dramatically different. In forests and savannas, there are significantly decreasing fire trends in the study period, especially in South China where it is densely vegetated in a hot and wet climate. In the grasslands, there are significant increasing trends, especially in North China. The fire numbers in croplands, mainly located in East China and the central areas of Northeast China, are significantly increasing in recent years, and the trends are much stronger in the Northeast China. The urban fires also show increasing trends, similar as in grassland and croplands. ", 5. Conclusions,None,5
214,"Commercial forestry is a primary and widespread land-use activity along the eastern seaboard of South Africa, with nearly 1.2 million hectares being devoted to timber production [1]. The establishment of these plantations has been repeatedly hampered by disturbances, such as forest fires [2], the outbreak of insect pests and disease [3], invasive alien plants [4], and drought [5,6]. Additionally, forest land-use modification that arises from harvesting operations has become the main source of contemporary forest disturbance [7]. Because of the increase in the demand for timber and pulp products, combined with government’s reluctance to grant new forestry permits, South Africa is currently facing timber shortages [8], which are, in part, further heightened by rampant timber theft [9]. Similar concerns about the effects of illegal logging and trade in timber prompted the European Commission in order to adopt the EU Action Plan for Forest Law Enforcement, Governance and Trade (FLEGT) in 2003—an effort that is intended to improve the legitimacy of the production and sale of timber [10]. This plan entails a variety of measures to timber producing countries, such as South Africa, which include promoting public procurement policies, safeguards for financing and investment, addressing the problem of conflict timber, and so on [11]. In this regard, the mapping of forest change provides insight into timber procurement potential and future forest growth patterns [12], as well as risks that are associated with rapidly changing forest landscapes [13].In the face of rapid and multiple forest changes, the stand- and landscape-level information that reveals disturbance patterns is particularly relevant for countries, such as South Africa, whose forestry resources contribute greatly to the economy. The planning and execution of timber harvesting to sustain or increase forest ecosystem services (that is, carbon stocks) prevail in the context of escalating forest disturbances [14] in order to meet forest management objectives [15]. While harvest operations are generally well known in advance by forest authorities, independent means for mapping are often pursued after the event [16]. In addition, the reality of timber theft has been a wake-up call and put forest managers under tremendous strain to aim for optimum production. In particular, the capacity of remotely sensed data to empower forest managers and communities to respond in time to unauthorized and other forest disturbances is increasingly recognized [17,18].Remote sensing has emerged as the most practical and efficient means for extracting forest change information, with great temporal and thematic detail [19]. Consequently, numerous digital change detection methods have been developed in order to monitor forest disturbances [20], most of which involves bi-temporal image differencing procedures [21,22]. However, it should be noted that disturbances do not merely produce differences between conditions after time intervals, but rather a continuous process with varying degrees of occurrence [23]. For this reason, methods that are capable of continuously recording disturbance dynamics in a dense, remote-sensing time series have been developed [24], enabling the tracking of short- to long-term and partial to extreme disturbances [25], in ways that surpass traditional methods [26].Ideally, near-real-time Earth observing platforms, such as AVHRR and MODIS, are desirable for time series analysis, but they are unavailable to record fine-scale alterations that are crucial for management requirements [27]. For example, MODIS misses up to 50% of the forest changes when compared to medium-resolution (30 m) Landsat data [28], and probably more as compared with 10-m Sentinel data. Persistent-cloud conditions also present a challenge for optical satellites, especially in tropical and sub-tropical regions. Instead, the all-weather Synthetic Aperture Radar (SAR) sensors overcome this difficulty by imaging surface features, irrespective of cloud conditions [29]. In forestry applications, microwave observations are increasingly becoming a preferred data source due to their sensitivity to forest-cover loss and growth stages [30]. However, the use of SAR in forest applications has not developed to the extent of optical platforms, partly because of the hitherto limited data processing capability [31]. The policy of making data freely available, which was introduced in 2008, unlocked access to records of satellite data from several space agencies and data suppliers such as NASA, the US Geological Survey and, more recently, the European Space Agency [15,32]. In order to support these resources, the Google Earth Engine (GEE) provides a cloud-computing platform to access massive, freely available, and pre-processed remotely sensed imagery [33], including the Sentinel-1 ground range detected (GRD) SAR and Sentinel-2 archive.Various studies have demonstrated the use of SAR for characterizing forest disturbance with a high degree of success. For example, Salas et al. [34] detected the variability in normalized radar cross-sections under different forest conditions and noted higher L-band HH-backscatter on cleared forest than on established plantations. Santoro et al. [35] applied a simple detection algorithm with the ALOS-2 PALSAR and achieved high accuracies (>50%) for clear-cut detection, despite the shortcomings in terms of delineation. Accordingly, the L-band SAR observations are currently available from the ALOS-2 PALSA-2 mission that was launched in 2014 [36], but only a few images are available each year for most tropical regions, and the costs charged prohibit their operational use [30]. Moreover, the automated monitoring systems of harvest events that capture their spatiotemporal variability are essential for timber management, and they require the SAR backscatter that is sensitive to forest cover with consistent observations over time [35].The recently launched Sentinel-1 satellite offers great possibilities for monitoring forest resources with readily available time series data [37], comprising C-band with a much superior temporal coverage (6–12 days) when compared with previous SAR constellations [38]. Sentinel-1 has already displayed a high ability for monitoring forest applications, such as forest classification [39], forest cover mapping [40], burnt forested areas [41], forest logging [42], and deforestation [30]. In this paper, we further evaluate the utility of the weather-insensitive Sentinel-1 C-band, together with Sentinel-2 multispectral imagery, for monitoring forest harvesting events in KwaMbonambi, South Africa. Despite their potential for forest monitoring, only few studies have utilized these resources in order to detect clear-cut harvest events and, even are limited by exploring the GEE environment. Here, we demonstrate how to reconstruct high-density Sentinel-1 C-band time series in the process classify harvest events in planted forests while using Sentinel-2 within a cloud-based GEE platform and, consequently, stress the value of these resources for this purpose. We then compare the performance of Sentinel-1 with Landsat-8 data in detecting harvest events, as recommended by [43]. Finally, we illustrate how our results serve to identify harvest events in planted forests and how they could efficiently help monitor related disturbances, such as unauthorized harvesting and deforestation in different forest types.", 1. Introduction,None,1.
215,"The study was performed in the KwaMbonambi plantation forests, which are located along the eastern seaboard of South Africa, 30 km northeast of Richards Bay (Figure 1). They are dominated by even-aged Eucalyptus plantations of almost 40,000 ha, which are managed by Sappi, a large South African pulp and paper company. This area is representative of frequently harvested forests and it provides an ideal testing location. The growing stock mainly comprises 6–14-year-old Eucalyptus grandis (E. grandis), E. grandis × Eucalyptus camaldulensis (E. gxc), and E. grandis × Eucalyptus urophylla (E. gxu) hybrid clones. The stands are fairly uniform regarding canopy cover with tree density established at 1667 trees ha–1. It is typical of the northern KwaZulu-Natal forestry region, which is subject to notable forest disturbances, such as fire and insect pest outbreaks. A subtropical climate characterizes the area, and the mean annual temperature is 22 °C [44]. The area receives an annual rainfall averaging 1200 mm, which is highly seasonal and peaks between November and February [45]; the potential evapotranspiration is 1772 mm per year [46]. The landscape of KwaMbonambi is flat and it consists of Quaternary alluvial sediments of clay sands of aeolian deposits [47] and soil with varying levels of organic matter [48], at mean elevation of 74 m above sea level. The high penetrability of the soils permits rapid leaching of soil nutrients due to the high rainfall in this region [47]. These conditions are favorable for fast-growing Eucalyptus plantations [49].We used the vector polygons of known clear-cut compartments from Sappi, comprising felled date, areal extent, stand age classes, and forest types, in order to validate the clear-cut mapping results. These compartments were used to test whether high-density, readily available Sentinel-1 and -2 data can serve to detect harvest events with accuracies that are comparable with those acquired through forest inventories. Table 1 specifies the characteristics of the selected stands against which the competence of Sentinel-1 and -2 data were tested to detect clear-cut harvesting. We studied similar forest species (E. gxu) to compare, because Dostálová et al. [40] attributed differences in microwave backscatter variations to forest type and structure, as can be seen from the table.", 2. Materials and Methods, 2.1. Study Area,2
216,"All 110 available Sentinel-1, C-band SAR dense time series images, covering the KwaMbonambi area between June 2015 to December 2018, were used in order to detect clear-cut harvest events. The images were acquired and preprocessed by the GEE team while using the Sentinel-1 toolbox and available at no charge from the Google Earth Engine (GEE) cloud environment as image collection. The images were collected in Interferometric Wide Swath (IW, 250 km swath width) providing VV (Vertical transmit–Vertical receive) and VH (Vertical transmit–Horizontal receive) polarizations. This 10-m resolution, all-weather imagery with a 6–12-day revisit cycle was already processed at high-resolution Level-1 GRD level, which includes radiometric, geometric corrections and orthorectification [50]. We further applied the speckle filter using the JavaScript code editor in the GEE environment to reduce the speckle effect. As noted by Mermoz et al. [51], this filter produces images with reduced speckle effects, multi-temporal and multi-polarized (VH and VV) products, and are expressed, as follows:




J
k


(
υ
)

=
 


〈

I
k


(
υ
)

〉

N



∑


i
=
1

N




I
i


(
υ
)



〈

I
i


(
υ
)

〉



 
with
 

k
=
1
,
 
…
N




(1)


where Ik(υ) is the radar intensity of output image k at pixel position υ, Ii(υ) is the radar intensity of the input image i, 

〈

I
i


(
υ
)

〉

 is the local average intensity of the input image i (window size of 7 × 7), and N is the number of images.We also used Sentinel-2 Level-1C product representing Top of Atmosphere (TOA) reflectance for classification, again obtained and processed from the GEE environment. The spectrally sensitive Sentinel-2 is being increasingly utilized for various applications because of its high spatial (10-m) and temporal (3–5 days) resolutions.We followed Nagler et al. [52] by using the Landsat-8-derived (L1 terrain corrected at TOA) normalized difference vegetation index (NDVI) and the normalized difference infrared index (NDII) values as references in order to evaluate the performance of Sentinel-1. In the region studied, Landsat data are impaired by data gaps due to persistent cloud cover. We then employed the spline interpolation to fit a cubic spline to each missing NDVI and NDII value over the time series, while using the R statistical package ‘spline’. Cubic spline interpolation is widely used in order to generate a complete time series [53]. Because of different acquisition dates, both NDVI and NDII as well as Sentinel-1 profiles were averaged to represent monthly intervals, so that observations correspond with each other. Moreover, the use of SAR requires the removal of speckle and noise, which are efficiently reduced with monthly composites [41]. The vegetation indices were computed from top-of-atmosphere reflectance, using the following equations:



N
D
V
I
=


N
I
R
−
R
e
d


N
I
R
+
R
e
d






(2)





N
D
I
I
=


N
I
R
−
S
W
I
R
1


N
I
R
+
S
W
I
R
1






(3)

", 2. Materials and Methods, 2.2. Satellite Data,2
217,"The remote sensing of forests has reached the stage that enables scientists to expend their efforts on information generation, rather than data preparation [54]. This has been achieved through the emergence of a cloud-based GEE platform, a computing environment that provides easy access to a multi-petabyte ready-to-use satellite data archive [55]. It affords users superior computing power for processing and analyzing images without computational burden, and coupled with a high-performance, intrinsically parallel computation service. The GEE archive contains the complete Landsat data set as well as Sentinel-1 and Sentinel-2 images, and it also includes climate and other geophysical data sets [55]. The GEE can visualize the data, plot it in time series graphs, and the data can be downloaded for external processing.", 2. Materials and Methods, 2.3. Background and the Use of the GEE Platform,2
218,"The GEE offers a variety of advanced machine learning classifiers for pixel-based classification that can be used for multi-temporal land use mapping [56]. Here, we implemented a Random Forest (RF; [57]) classifier for harvested and forested pixels’ separation, and more information can be obtained from (https://developers.google.com/earth-engine/classification). RF has gained wide popularity, because of its high accuracy and ability to process complex datasets and produce satisfactory results with large numbers of input classification bands and training points [57]. We employed RF based on Sentinel-2 imagery, because it is ideal to classify very small plantations [58]. Certainly, some spectral bands are more important than others for the classification, and it has been established that, when more spectral bands are included, the accuracy is improved until a certain threshold is reached [59]. Thus, all of the spectral bands in the Sentinel-2 imageries were selected to train the classifier (Table 2).Reference data for training and validation comprised harvest records from Sappi management database, in the form of ArcMap shapefile polygons. The shapefiles contained fell dates, areal extent for each compartment, etc. Within GEE, Sentinel-2 TrueColor imagery corresponding to the fell dates were filtered and 60 points for each harvested and forested compartment were sampled throughout the studied area. Up to now, no literature stipulates the minimum number of training samples for machine learning algorithms, and because harvested compartments are clearly discernible from forested ones, we believed that 60 samples are ideal for this kind of classification. In order to produce robust classification results, the classification of Sentinel-2 images was run 1000 times by randomly selecting 50% of reference data from each class for training, and testing against the other 50% [58].In classification, the accuracy assessment is the necessary step in evaluating the performance of algorithm used. We computed producer accuracy (PA), which is calculated by dividing the number of correctly classified pixels in each category by the number of “known” pixels to be of that category, the user’s accuracy (UA), which is computed by dividing the number of correctly classified pixels in each category by the total number of pixels that were classified in that category, and the overall accuracy (OA) that is calculated by dividing the sum of correctly classified pixels by the total number of sampled pixels.", 2. Materials and Methods, 2.4. GEE-Based Random Forest Classification,2
219,"A Taylor diagram was exploited to establish the relationship between spectral indices and the Sentinel-1 backscatter signals. This is a single diagram that synchronously combines three statistical performance metrics: the Pearson correlation coefficient, root mean square difference (RMSD), and the standard deviation in a series of points on a polar plot [60]. The RMSD is a measure of the average error that is produced by a model and it is widely used to gauge overall model performance. However, it does not reveal the types or sources of the error, which would assist greatly in refining the models [61]. The RMSD is calculated as:



r
=




∑


i
=
1


i
=
N



[


(


S
i

o
b
s


−

S

o
b
s



)

.

(


S
i

p
r
e
d


−

S

p
r
e
d



)


]







∑


i
=
1


i
=
N




(

S
i

o
b
s


−

S

o
b
s


)

2

.




∑


i
=
1


i
=
N


(

S

i
=
1


p
r
e
d


−

S

p
r
e
d


)






 
where
,




(4)






−
1
≤
r
≤
1



R
M
S
D
=
 



1
N





∑


i
=
1


i
=
N




(

S
i

o
b
s


−

S
i

p
r
e
d


)

2






(5)

", 2. Materials and Methods, 2.5. Statistical Analysis,2
220,"Figure 2 illustrates the comparisons between VH and VV backscatter signals and the field inventory record. It can be seen that both VH and VV bands detect the clear-cut events over the same area and time period. However, the VH appears fairly constant around −13 dB and −15 dB in uncut stands with a clear decline in backscatter signals over clear-cut stands reaching −21 dB. On the other hand, the VV bands seem to be more sensitive to various forest changes, as illustrated by the spread of weaker backscattered signals that were observed across the plantation, even over uncut stands. Despite this observation, the patterns of clear-cut stands are distinguishable from the VV backscatter, because they are dominant over clear-cut areas. Xu et al. [62] also noted that the VV band suffers from the complex effects of changes in the scattering mechanism. The variation in VV backscatter in 2016 is believed to be associated with the exceptional drought conditions reported by Xulu et al. [6]. Chatziantoniou et al. [63] noted that extreme drought affects the VV signal, because it reduces backscatter, which is sensitive to moisture conditions. The catastrophic character of the 2015–2016 drought led to widespread tree dieback in the Zululand forestry region [64]. This outcome appears to be illustrated by the extensive reduced VV backscatter over the uncut forest stands, as demonstrated in Figure 2.The classification of harvested and forested compartments while using RF based on Sentinel-2 imagery successfully produced overall accuracies as high as 99% for all sampled years (Figure 2). The producer’s and user’s accuracies for both classes were consistently high, with each class attaining over 90%. Our results are consistent with Nomura and Mitchard [58], in their classification of a plantations in a complex forested landscape.While both of the Sentinel-1 bands seem to be reactive to clear-cutting, and despite the small differences between them, the VV bands are seen to be slightly sensitive than the VH band. This observation is also consistent with greater correlation of VV band to highly responsive NDII (shown in the next sections).We performed a time series analysis of VH and VV polarization indices and Landsat-derived NDVI and NDII (as reference) for each year separately over known harvested stands in the KwaMbonambi plantations in order to evaluate the effectiveness of Sentinel-1 backscattering to characterize clear-cut events. These sensors record different, yet related, forest attributes. In particular, VH and VV radar backscattering is highly correlated with fresh forest biomass, whereas NDVI is correlated with photosynthetic activity [31]. Given that clear-cutting is an extreme and abrupt forest change, and that sensors may yield signals with variations as a response to other forest dynamics, this study only considers the most significant breakpoints. We decided to only select three harvested compartments for each year to exemplify the behavior of Sentinel-1 and spectral bands when harvest events transpire, and the analysis is presented below.", 3. Results and Discussion, 3.1. Spatial Patterns of VH and VV Backscatter over Clear-Cut Stands and the Classification,3
221," 3.2.1. Temporal Profile over Harvested Compartment in 2016Figure 3 shows the temporal profiles of Sentinel-1 VH and VV backscatter (a), NDVI and NDII (b), and the shortwave infrared (SWIR1) (c) for the compartment harvested in 2016. The VH and VV polarized backscatter exhibited similar results for this compartment, generally with a virtually uniform pattern throughout the study period with the exception of a notable change in the middle of 2016. An abrupt reduction of 5 dB for VH (−13.7 to −18 dB) and 4 dB for VV (−8.4 to −11.6 dB) backscattering in June 2016 corresponds with a clear-cut harvest event, as confirmed by Sappi’s official inventory records. During this period, it appears, as expected from cleared forest, the VH polarization revealed much less backscattering than the VV signal. This observation is consistent with Nguyen et al. [65], who reported that VH polarized backscatter is generally less than VV, and that the backscattering coefficients for both polarizations progressively increase with tree growth over time. There was an obvious increase in the backscatter signal for both polarizations, corresponding with tree canopy increase after September 2016, reaching a peak of −8 dB (VV) and −13 dB (VH) around March 2017, when the forests reached maturity stage, as illustrated in Figure 3a. An equivalent finding was made by Macelloni et al. [66], who observed an increase in VH cross-polarized backscatter with increasing leaf area index (LAI) over planted forests in the Italian landscape. In a related study, Huang et al. [67] found that VH polarization is more efficient than VV for characterizing forest canopy dynamics, because it is less influenced by soil moisture. Nguyen et al. [66] attributed the reduced backscatter in the VV signal to the lower moisture content of trees during the harvest period; conversely, the VH signal seemed to be the least affected by this factor. Moreover, we agree with Karjalainen et al. [68] that VH polarization is better than VV to characterize the actual biomass variations in forests.The NDII and NDVI values resembled the Sentinel-1 backscatter signals and declined during clear-cutting (Figure 3b). The NDII declined from 1.7 to −0.13 and recovered to 0.39 a few months later. The NDVI also decreased, from 0.54 to 0.32, after a clear-cut event and rose to 0.77 during the forest growth phase.It is important to note the increase of the SWIR1 signal during clear-cutting. At this time, the SWIR1 rose from 0.15 to its highest maximum of 0.28 (Figure 3c). Indeed, clear-cutting is well-known to increase the reflectance in the SWIR1 band [69]. This is particularly so, because the SWIR1 band is sensitive to vegetation density [70]. Thus, as forest canopy complexity increases with time, reflectance in the SWIR1 decreases [71]. Our results are in harmony with this observation—the SWIR1 signal declines as the forest canopy matures. In a related study, Schroeder et al. [72] classified forest disturbances while using Landsat-derived vegetation indices and found the SWIR1 channel to be the most effective for distinguishing clear-cut harvests. 3.2.2. Temporal Profile over Harvested Compartment in 2017Figure 4 shows the VH and VV polarized signals over the compartment that was harvested in 2017. Both of the polarizations exhibited similar backscattering behavior to that of the above, this time decreasing in June 2017. Again, the decline in both polarization signals coincides with clear-cutting records from Sappi. In 2017, two disturbances were detected; the first in April led to reduced VH (−14.27 to −17.76 dB) and VV (−8.04 to −11.76 dB) backscatter signals. A further decrease in VH backscatter to −21.04 dB and to −13.66 dB for VV was witnessed in June (Figure 4a). During this period, a corresponding decrease in NDVI (0.78 to 0.35) and NDII (0.49 to −0.13) is noticeable around April and these values further declined in June to 0.23 and −0.24, respectively (Figure 4b). The increase in SWIR1 corresponds with reductions in the SAR backscatter signals and vegetation indices, as shown in Figure 4c. An initial increase in SWIR1 from 0.11 to 0.36 in April was followed by a further increase to 0.37 during a clear-cutting period. 3.2.3. Temporal Profile over Harvested Compartment in 2018The pattern of VH and VV backscatter signals for the compartment that was harvested in 2018 was similar to that for 2016 and 2017 harvested compartments. The VH backscatter dropped from −13.81 dB in January 2018 to its lowest minimum (−19.82 dB) in July; the VV backscatter also declined, from −8.33 to −12.54 dB (Figure 5a). The NDVI value decreased from 0.72 to 0.21, whereas the NDII declined from 0.48 to −0.19 in the corresponding periods (Figure 5b). As expected, the SWIR1 increased from 0.11 to 0.34 over the time of the clear-cutting (Figure 5c).Figure 3, Figure 4 and Figure 5 seems to indicate that Sentinel-1 can be an efficient weather-insensitive source from which clear-cutting activities are detectable. It is noteworthy that the Sentinel-1 backscatter appear to be responsive to various disturbances, but the dominant backscatter is obvious during clear-cutting. Similarly, the vegetation indices (NDVI and NDII) and the SWIR1 band showed a corresponding pattern to the Sentinel-1 backscatter signals, and these were useful in confirming the results. We now explain the relationship of these signals having described the temporal profiles of data derived from Sentinel-1 and Landsat-8.", 3. Results and Discussion, 3.2. Salient Trends for SAR and Vegetation Indices,3
222,"Figure 3 shows the temporal profiles of Sentinel-1 VH and VV backscatter (a), NDVI and NDII (b), and the shortwave infrared (SWIR1) (c) for the compartment harvested in 2016. The VH and VV polarized backscatter exhibited similar results for this compartment, generally with a virtually uniform pattern throughout the study period with the exception of a notable change in the middle of 2016. An abrupt reduction of 5 dB for VH (−13.7 to −18 dB) and 4 dB for VV (−8.4 to −11.6 dB) backscattering in June 2016 corresponds with a clear-cut harvest event, as confirmed by Sappi’s official inventory records. During this period, it appears, as expected from cleared forest, the VH polarization revealed much less backscattering than the VV signal. This observation is consistent with Nguyen et al. [65], who reported that VH polarized backscatter is generally less than VV, and that the backscattering coefficients for both polarizations progressively increase with tree growth over time. There was an obvious increase in the backscatter signal for both polarizations, corresponding with tree canopy increase after September 2016, reaching a peak of −8 dB (VV) and −13 dB (VH) around March 2017, when the forests reached maturity stage, as illustrated in Figure 3a. An equivalent finding was made by Macelloni et al. [66], who observed an increase in VH cross-polarized backscatter with increasing leaf area index (LAI) over planted forests in the Italian landscape. In a related study, Huang et al. [67] found that VH polarization is more efficient than VV for characterizing forest canopy dynamics, because it is less influenced by soil moisture. Nguyen et al. [66] attributed the reduced backscatter in the VV signal to the lower moisture content of trees during the harvest period; conversely, the VH signal seemed to be the least affected by this factor. Moreover, we agree with Karjalainen et al. [68] that VH polarization is better than VV to characterize the actual biomass variations in forests.The NDII and NDVI values resembled the Sentinel-1 backscatter signals and declined during clear-cutting (Figure 3b). The NDII declined from 1.7 to −0.13 and recovered to 0.39 a few months later. The NDVI also decreased, from 0.54 to 0.32, after a clear-cut event and rose to 0.77 during the forest growth phase.It is important to note the increase of the SWIR1 signal during clear-cutting. At this time, the SWIR1 rose from 0.15 to its highest maximum of 0.28 (Figure 3c). Indeed, clear-cutting is well-known to increase the reflectance in the SWIR1 band [69]. This is particularly so, because the SWIR1 band is sensitive to vegetation density [70]. Thus, as forest canopy complexity increases with time, reflectance in the SWIR1 decreases [71]. Our results are in harmony with this observation—the SWIR1 signal declines as the forest canopy matures. In a related study, Schroeder et al. [72] classified forest disturbances while using Landsat-derived vegetation indices and found the SWIR1 channel to be the most effective for distinguishing clear-cut harvests.", 3. Results and Discussion, 3.2.1. Temporal Profile over Harvested Compartment in 2016,3
223,"Figure 4 shows the VH and VV polarized signals over the compartment that was harvested in 2017. Both of the polarizations exhibited similar backscattering behavior to that of the above, this time decreasing in June 2017. Again, the decline in both polarization signals coincides with clear-cutting records from Sappi. In 2017, two disturbances were detected; the first in April led to reduced VH (−14.27 to −17.76 dB) and VV (−8.04 to −11.76 dB) backscatter signals. A further decrease in VH backscatter to −21.04 dB and to −13.66 dB for VV was witnessed in June (Figure 4a). During this period, a corresponding decrease in NDVI (0.78 to 0.35) and NDII (0.49 to −0.13) is noticeable around April and these values further declined in June to 0.23 and −0.24, respectively (Figure 4b). The increase in SWIR1 corresponds with reductions in the SAR backscatter signals and vegetation indices, as shown in Figure 4c. An initial increase in SWIR1 from 0.11 to 0.36 in April was followed by a further increase to 0.37 during a clear-cutting period.", 3. Results and Discussion, 3.2.2. Temporal Profile over Harvested Compartment in 2017,3
224,"The pattern of VH and VV backscatter signals for the compartment that was harvested in 2018 was similar to that for 2016 and 2017 harvested compartments. The VH backscatter dropped from −13.81 dB in January 2018 to its lowest minimum (−19.82 dB) in July; the VV backscatter also declined, from −8.33 to −12.54 dB (Figure 5a). The NDVI value decreased from 0.72 to 0.21, whereas the NDII declined from 0.48 to −0.19 in the corresponding periods (Figure 5b). As expected, the SWIR1 increased from 0.11 to 0.34 over the time of the clear-cutting (Figure 5c).Figure 3, Figure 4 and Figure 5 seems to indicate that Sentinel-1 can be an efficient weather-insensitive source from which clear-cutting activities are detectable. It is noteworthy that the Sentinel-1 backscatter appear to be responsive to various disturbances, but the dominant backscatter is obvious during clear-cutting. Similarly, the vegetation indices (NDVI and NDII) and the SWIR1 band showed a corresponding pattern to the Sentinel-1 backscatter signals, and these were useful in confirming the results. We now explain the relationship of these signals having described the temporal profiles of data derived from Sentinel-1 and Landsat-8.", 3. Results and Discussion, 3.2.3. Temporal Profile over Harvested Compartment in 2018,3
225,"Given the greater sensitivity of NDII to clear-cutting events, we decided to use it as a reference variable in order to illustrate its relationship with microwave indices (VH and VV) as well as other vegetation criteria. For this purpose, Taylor diagrams [60] were computed in order to provide a graphical representation of how closely a pattern corresponds to the reference signal. The Taylor diagram is explanatory diagram that presents the visualization of the comparative strength of independent parameters to the actual target variable. In the Taylor diagram, the two different statistical metrics (i.e., correlation coefficients (R2) and standard deviations of each model) are used to quantify the comparability between the calculated data (e.g., models) and actual data. The distance from the reference point is a measure of the centered RMSD. The Taylor diagram is designed in such a way that it can graphically indicate which calculated data (or models) is most realistic. Figure 6 shows the corresponding Taylor diagram for the three different compartments, harvested in 2016, 2017, and 2018. The VV polarization was better correlated with NDII (compartment harvested in 2016, R2 = 0.78; compartment harvested in 2017, R2 = 0.81; compartment harvested in 2018, R2 = 0.82) than VH backscatter (2016 harvested compartment, R2 = 0.67; 2017 harvested compartment, R2 = 0.72; 2018 harvested compartment, R2 = 0.79). The values that correspond to these polarizations were grouped around the normalized standard deviation between 1.25 and 1.81, with VV showing less deviation from NDII than VH backscatter. The VV backscatter also had a smaller RMSD value (~1) than the VH signal (~2). Similar to those of Nagler et al. [52], these results reveal the good quality of both products that are derived from independent data sources.As expected, the NDVI and SWIR1 results were more highly correlated with NDII than the Sentinel-1 bands; this was because the former were partly derived from similar bands to those of the NDII and also recorded by the same sensor. The NDVI values showed the greatest correlation (2016 harvested compartment, R2 = 0.93; 2017 harvested compartment, R2 = 0.95; 2018 harvested compartment, R2 = 0.96). Similarly, the SWIR1 results exhibited a strong negative correlation with NDII (2016 harvested compartment, R2 = −0.71; 2017 harvested compartment, R2 = −0.85; 2018 harvested compartment, R2 = −0.91), but a slightly smaller RMSD than that of the NDVI.It is also important to note that the increasing water deficits increase the spectral reflectance in the SWIR1 region, and this largely influences the change in the vegetation values of indices that exploits this band, such as NDII [73]. The greater sensitivity of Sentinel-1 to moisture variations, particularly the VV band, could explain its higher correlation with the NDII.", 3. Results and Discussion, 3.3. Correlation between NDII Sentinel-1 and Other Vegetation Indices,3
226,"Our study demonstrated the impressive capability of Sentinel-1 and -2 in order to detect and map clear-cut events in a complex commercial forestry area. The results showed high RF classification accuracies (99%) for harvested compartments based on Sentinel-2 data, which was consistent with Sentinel-1 backscatter. Our results also exhibited a similar temporal profile of VH and VV backscattering indices to those of NDVI and NDII; the respective signals were consistently relatively strong during the mature forest stage, but abruptly decreased after clear-cutting. In contrast, the SWIR1 band exhibited the opposite pattern with a sharp increase coinciding with clear-cutting, confirming reduced leaf water content prevailing at this time. When correlated with the highly responsive NDII, the VH and VV signals reached the best accuracies of 0.79 and 0.83, whereas the NDVI and SWIR1 achieved 0.96 and −0.91, respectively. The agreement between the VH and VV indices with NDII is satisfactory, because they are all derived from sensors that record different vegetation properties when compared to NDVI and SWIR1, which were not only recorded by the same sensor, but also implicitly contain NDII bands. Nevertheless, the VH and VV bands both consistently detected clear-cut events, the VH record indicated stable low backscattering over clear-cut stands, while the VV band appeared more sensitive, but it is affected by moisture stress and led to weaker backscattering signals even over uncut forest areas. Further research is desirable in exploring this method over broader areas and for different forest types. The responsiveness of the VV to moisture variations could also be tested in drought affected stands. We hope that our results will encourage remote sensing-based forest researchers in order to exploit the freely available GEE resources further and develop methodologies, in support of sustainable forest management, using high-density Sentinel-1 data to characterize forest changes, particularly in regions with poor image availability due to persistent cloud cover.", 4. Conclusions,None,4
227,"In an era of anthropogenic climate change, mangrove forests are important natural ecosystems due to their ability to capture and store carbon as well as to protect coastal areas from erosion [1,2]. In order to evaluate the climate mitigation potential of mangrove forests, it is important to monitor changes in their forest structure and biomass-carbon content. Forest parameters such as the vertical structure (canopy height) and above-ground biomass (AGB) provide useful quantitative measures of carbon stock. Such observations would enable tracking mangrove recovery after destructive extreme weather events and climate change-related phenomena. However, monitoring mangrove forests is challenging due to their large spatial extent and limited accessibility. High-resolution remote sensing technologies have the potential to overcome these challenges.The vertical structure of forest ecosystems has previously been studied using multi-spatial airborne and space-borne remote sensing sensors. The main airborne forest surveying technique has been Airborne LiDAR/Laser Scanning (ALS) [3,4], which is very useful and accurate, but expensive compared to satellite imagery. Space-borne techniques have included Ice, Cloud and Land Elevation Satellite (ICESat) [5], Very-High Resolution (VHR) stereophotogrammetry [6], the Shuttle Radar Topography Mission (SRTM) [3,7], and the TerraSAR-X add-on for Digital Elevation Measurement/TanDEM-X (TDX) [8,9,10]. The advantages of space-borne observations include their large area coverage and their availability to researchers at no or reduced cost. However, the accuracy and spatial resolution of space-borne observations is reduced compared to ALS. The use of ALS observations for validating or calibrating satellite data, provides a means for improving space-borne remote sensing forest structure estimates [8,10]. Simard et al. (2006) used both airborne and space-borne remote sensing techniques to estimate canopy height and AGB in the Everglades National Park (ENP). Their study, which was conducted a decade ago, used ALS data acquired in 2004 in conjunction with SRTM data acquired in 2000 [3]. The resolution and accuracy of their study, 30 m horizontal (pixel) resolution and 2 m in the vertical direction, reflect the accuracy of the SRTM dataset. Over the past decade, new sensors have emerged for obtaining higher resolution topography measurements. One of these sensors is TDX, which was launched in June 2010 with a main mission objective to produce a worldwide high resolution (<2 m relative vertical accuracy and 12 m horizontal raster spacing) Digital Elevation Model (DEM). The TDX mission uses Interferometric Synthetic Aperture Radar (InSAR) observations with its twin satellite TerraSAR-X [11].In this research, we restudy the same areas as Simard et al. [3] using more advanced and accurate forestry remote sensing techniques and with observations acquired more than a decade after those acquired in [3]. The more accurate remote sensing techniques allow us to make a better assessment of canopy height and AGB of the ENP mangrove forest. In addition, a comparison between our results and Simard’s also allow us to detect decadal scale changes in the ENP mangrove forest. During the decade separating the two surveys (Simard: 2000–2004 and ours: 2011–2013) Hurricane Wilma in 2005 caused severe damage to ENP mangrove forests adjacent to the Gulf of Mexico [12]. The comparison between both surveys enables us to evaluate lasting changes in the mangrove structure due to natural disturbances.", 1. Introduction,None,1.
228,"Our study area includes the entire mangrove forests located in the ENP (Figure 1), which were previously estimated to cover an area of 144,447 ha [3]. The mangrove forests are composed of multiple species, including Rhizophora mangle (Red mangrove), Laguncularia racemosa (White mangrove) and Avicennia germinans (Black mangrove). For this study, an ALS dataset was acquired to estimate mangrove canopy height along a Shark River Slough (SRS) transect that has been extensively researched by the Florida Coastal Everglades—Long Term Ecological Research Network scientific community. In this transect there are three well-studied sites (SRS-4, SRS-5, SRS-6) with mangrove communities that differ in canopy height: short (<5 m) (SRS-4), intermediate (<12 m) (SRS-5) and tall (12–25 m) (SRS-6) (Figure 1c–f). Mangrove canopy height can reach up to ~25 m in the western boundary of the park, where SRS connects with the Gulf of Mexico. R. mangle dominates SRS-4 and SRS-5, whereas R. mangle, L. racemosa, and A. germinans are more evenly distributed in SRS-6. SRS resembles the overall spatial distribution of mangrove stature and species in the ENP. ", 2. Study Area,None,2
229,"We acquired ALS data along a 30 km2 transect that covers the mangrove stature gradient across SRS (Figure 1b). The data were acquired on 17 November 2012 using an Optech Airborne Laser Terrain Mapper (ALTM) operated by the National Center for Airborne Laser Mapping (NCALM). Technical specifications for this survey are provided in Table 1. The first laser returns, which mark the location of tree canopies, were interpolated and gridded to generate a 1-m resolution Digital Surface Model (DSM) (Figure 2a). The last laser returns, which mark the location of the ground surface, were interpolated and gridded to generate a 1-m resolution Digital Terrain Model (DTM) (Figure 2b). We produced a 1-m resolution digital canopy model (DCM) (Figure 2c) by subtracting the DTM created with the bare ground points from the DSM created with the top of the canopy points. The DCM was georeferenced into the North American Datum of 1983 (NAD83) and Universal Transverse Mercator (UTM) zone 17 N projection. ALS-derived canopy heights were converted into H100 canopy height, which is extensively used in forestry studies and is defined as the mean canopy height of the 100 tallest trees on a hectare [9,13]. ALS H100 has been used to compare the vertical structure of mangrove forests using satellite datasets from optical and radar sensors [6,8]. The ALS H100 DCM was resampled to 12 m to compare its results with the TDX canopy height results. ", 3. Datasets and Methods, 3.1. Airborne Measurements,3
230," 3.2.1. WorldView-2 Mangrove Cover MapWe used seven WorldView-2 optical images, which were acquired between November 2010 and December 2012 (Figure 3a), to create a mangrove cover map of the ENP (Figure 3b), as the most recent vegetation map was created in 1999. The purpose of the mangrove cover map is to constrain the study area to the mangrove region inside the park and mask this region from the TDX data as the focus of this study is the mangrove forest. The high-resolution (1.84 m Multispectral, 0.46 m Panchromatic) images were atmospherically corrected, mosaicked (Figure 3a) and classified using a supervised classification. Mangroves have a distinct bright reddish spectral signature that is very noticeable in the infrared spectrum (False Color Composite: Bands 7-5-3). The Fast Line-of-sight Atmospheric Analysis of Spectral Hypercubes (FLAASH) atmospheric correction module was applied using ENVI software in order to correct atmospheric effects and get accurate estimates of surface reflectance. The classification step consisted of a supervised classification in ENVI/IDL software that used training points of mangrove versus non-mangrove regions. The supervised classification was used to isolate and cluster pixels of similar spectral signature into two classes (mangroves and non-mangroves). To validate and train the mangrove versus non-mangrove classification, high-resolution geotagged helicopter photography (~2000 photos) was acquired in June 2014 (Figure 4). A total of 200 (100 mangrove; 100 non-mangrove) points (photos) were used to train the supervised classification, and 200 (100 mangrove; 100 non-mangrove) points were used to validate the classification. Our classification results indicate that mangrove forest extends over an area of 131,813 ha in the ENP.  3.2.2. TanDEM-X DataFour TDX scenes were acquired, processed and mosaicked to cover the entire ENP mangrove forests (Table 2). The scenes were single-polarized (HH) and were acquired in bistatic stripmap mode, in which one satellite emits the signal and both satellites receive the backscattered signal nearly at the same time with negligible temporal decorrelation [11]. The single-polarized scenes were retrieved from the German Aerospace Center (DLR) global DEM acquisition archive. The processing of TDX data to obtain mangrove forest height was based on Pol-InSAR inversion, which is used to constrain a volume scattering model known as Random Volume over Ground Model (RVoG) [8,14,15] (Figure 5). Pol-InSAR permits the investigation of scattering mechanisms in natural volume scatterers, such as forests, by assuming that interferometric coherence is related to the vertical distribution of scatterers. A recent study by Lee and Fatoyinbo [8], successfully used dual-pol and single-pol TDX data to extract mangrove forest height information using the RVoG model. Usually, the inversion of single-polarization data for forest height includes the information of an external DTM. However, DTMs are not available for most mangrove forests due to high vegetation density or absence of LiDAR data. Lee and Fatoyinbo [8] suggested a way to estimate the ground topography and phase directly from the TDX interferogram, assuming flat topography as mangroves are located at or near sea level. This assumption proved successful in generating a DCM of the mangrove forests of Zambezi Delta, Mozambique [8]. Our study follows the same procedures outlined and suggested by Lee and Fatoyinbo [8] to invert single-polarization raw TDX data into mangrove forest canopy height in the ENP (Figure 6).", 3. Datasets and Methods, 3.2. Space-Based Measurements,3
231,"We used seven WorldView-2 optical images, which were acquired between November 2010 and December 2012 (Figure 3a), to create a mangrove cover map of the ENP (Figure 3b), as the most recent vegetation map was created in 1999. The purpose of the mangrove cover map is to constrain the study area to the mangrove region inside the park and mask this region from the TDX data as the focus of this study is the mangrove forest. The high-resolution (1.84 m Multispectral, 0.46 m Panchromatic) images were atmospherically corrected, mosaicked (Figure 3a) and classified using a supervised classification. Mangroves have a distinct bright reddish spectral signature that is very noticeable in the infrared spectrum (False Color Composite: Bands 7-5-3). The Fast Line-of-sight Atmospheric Analysis of Spectral Hypercubes (FLAASH) atmospheric correction module was applied using ENVI software in order to correct atmospheric effects and get accurate estimates of surface reflectance. The classification step consisted of a supervised classification in ENVI/IDL software that used training points of mangrove versus non-mangrove regions. The supervised classification was used to isolate and cluster pixels of similar spectral signature into two classes (mangroves and non-mangroves). To validate and train the mangrove versus non-mangrove classification, high-resolution geotagged helicopter photography (~2000 photos) was acquired in June 2014 (Figure 4). A total of 200 (100 mangrove; 100 non-mangrove) points (photos) were used to train the supervised classification, and 200 (100 mangrove; 100 non-mangrove) points were used to validate the classification. Our classification results indicate that mangrove forest extends over an area of 131,813 ha in the ENP. ", 3. Datasets and Methods, 3.2.1. WorldView-2 Mangrove Cover Map,3
232,"Four TDX scenes were acquired, processed and mosaicked to cover the entire ENP mangrove forests (Table 2). The scenes were single-polarized (HH) and were acquired in bistatic stripmap mode, in which one satellite emits the signal and both satellites receive the backscattered signal nearly at the same time with negligible temporal decorrelation [11]. The single-polarized scenes were retrieved from the German Aerospace Center (DLR) global DEM acquisition archive. The processing of TDX data to obtain mangrove forest height was based on Pol-InSAR inversion, which is used to constrain a volume scattering model known as Random Volume over Ground Model (RVoG) [8,14,15] (Figure 5). Pol-InSAR permits the investigation of scattering mechanisms in natural volume scatterers, such as forests, by assuming that interferometric coherence is related to the vertical distribution of scatterers. A recent study by Lee and Fatoyinbo [8], successfully used dual-pol and single-pol TDX data to extract mangrove forest height information using the RVoG model. Usually, the inversion of single-polarization data for forest height includes the information of an external DTM. However, DTMs are not available for most mangrove forests due to high vegetation density or absence of LiDAR data. Lee and Fatoyinbo [8] suggested a way to estimate the ground topography and phase directly from the TDX interferogram, assuming flat topography as mangroves are located at or near sea level. This assumption proved successful in generating a DCM of the mangrove forests of Zambezi Delta, Mozambique [8]. Our study follows the same procedures outlined and suggested by Lee and Fatoyinbo [8] to invert single-polarization raw TDX data into mangrove forest canopy height in the ENP (Figure 6).", 3. Datasets and Methods, 3.2.2. TanDEM-X Data,3
233,"The Pol-InSAR inversion results provide a detailed DCM of the mangrove forest in the ENP with resolution of 12 m (Figure 6). In order to assess the quality of the TDX results, we compared these results with the ALS H100-derived DCM calculated from the ALS data acquired along the SRS. A linear regression analysis indicated a very good agreement between the ALS H100-based DCM and the SRS TDX-based DCM results (Figure 7). The validation plot between the ALS and TDX mangrove canopy heights in SRS yielded an R2 correlation coefficient of 0.85 and an RMSE of 1.96 m (Figure 7c).", 4. Results, 4.1. Quality Assessment of the TanDEM-X Results,4
234,"The large extent of mangrove forest in the ENP required the use of multiple TDX scenes. The four processed TDX scenes were mosaicked and georeferenced into a NAD83 datum and the local UTM (17 N) projection (Table 2, Figure 8). The entire mangrove DCM (12-m horizontal resolution) derived from TDX data is shown in Figure 8, including a zoomed area in the SRS region. We assumed that the same RMSE and R2 we obtained for the ALS SRS swath could be applied to all the TDX scenes, as no ALS data are available beyond the SRS swath. The DCM shows that the tallest mangroves forests (~25 m) are located along the Western coast of the ENP, where SRS connects with the Gulf of Mexico. ", 4. Results, 4.2. Everglades National Park Mangrove Digital Canopy Model ,4
235,"We used ALS and TDX canopy heights as input datasets to estimate AGB in the mangrove forests of the ENP. The AGB estimates were based on the following height-to-AGB ENP mangrove allometric equation [3]:

B(Mg·ha−1) = 10.0 × H(m)


(1)


where B is AGB in Mg·ha−1 and H is canopy height in meters. The allometric equation has an R2 of 0.82 and an RMSE of 37% [3]. The equation was created by a linear regression analysis of AGB estimated from ENP field height and diameter-at-breast-height (DBH) data and non-site specific mangrove allometry in conjunction with SRTM data calibrated with airborne LiDAR height data. In this study, we produced an ALS-based AGB map that covers the mangrove forests along SRS (Figure 9), and a TDX-based AGB map that covers the entire ENP mangrove forests (Figure 10). Both maps indicate that a maximum AGB value of ~250 Mg·ha−1 can be found in the region where SRS connects with the Gulf of Mexico.", 4. Results, 4.3. Above-Ground Biomass Estimation,4
236,"Simard et al. [3] estimated a larger mangrove coverage of 144,447 ha, compared with our estimate of 131,813 ha. The two estimates differ from one another by 8.7%, which is a significant change of mangrove area within a decade. However, this change may reflect the use of different methodologies used in each study, or the fact that our Worldview-2 dataset did not include a Northwest mangrove forest region, which accounts for approximately 5% (7222 ha) of the total mangrove area according to Simard et al. [3]. Adding 7222 ha to our mangrove area estimate yields a revised total mangrove area of 139,035 ha. The new difference in area is 3.7% when compared to Simard et al. [3]. Our mangrove cover is based on a supervised classification on WorldView-2 satellite imagery, whereas the Simard et al. [3] mangrove cover was based on the University of Georgia’s Center for Geospatial Research 1999 vegetation map, mostly based on aerial photography [16]. The spatial resolution of satellite and airborne sensors will also affect vegetation area estimates. Ongoing efforts to update the ENP vegetation maps will provide within the next few years a better assessment of the vegetation within the park, including that of mangrove forest coverage. ", 5. Discussion, 5.1. Extent of the ENP Mangrove Forest,5
237,"At first glance, our TDX-based mangrove DCM (12-m horizontal resolution) (Figure 11b) yields similar results when visually compared with the SRTM-based mangrove DCM (30 m horizontal resolution) from Simard et al. [3] (Figure 11a). The tallest mangrove forests (>16 m) on both DCMs (Figure 11) are located along the Western ENP coast, where the Gulf of Mexico connects with SRS. Intermediate-size (12–16 m) mangroves are located north and south of SRS, and in the mid-region of SRS where the SRS-5 site is located. The rest of the mangrove forests are dominated by small-to-intermediate stature mangroves ranging from 3–12 m. Differences between both DCMs are more noticeable in the SRS-6 site region, where our study shows dominance of mangroves taller than 18 m and Simard et al. [3] shows the domination of mangroves ranging from 16–18 m in stature. This difference could potentially represent mangrove growth in this area as approximately one decade has passed between both studies. Overall, our study suggest that mangrove canopy height in the ENP is dominated by mangroves ranging from of 9 m to 12 m in stature, whereas Simard et al. [3] found that canopy height was dominated by 8-m tall mangrove stands. Additionally, our results show more regions with concentrations of 25-m tall mangroves. Overall, our study shows that there has been an increase in mangrove canopy height as observed differences are higher than the measurement error of both datasets (~2 m), hence statistically significant. Furthermore, we are able to detect finer details as our TDX dataset has higher resolution, when compared with SRTM-based results. Future work in the ENP will include the comparison of multi-temporal airborne LiDAR data and optical satellite imagery to more accurately quantify mangrove migration, growth and/or degradation due to naturogenic causes such as sea level rise, droughts and/or hurricanes. For multi-temporal studies the use of similar sensors is vital, as analyzing data from different sensors (e.g., SRTM and TDX) will result in high uncertainty due to differences in spatial resolution and sensor sensitivity [6].Our TDX-based DCM (Figure 11b) shows fewer short-stature mangrove areas when compared to the SRTM-based DCM (Figure 11a). These areas are composed of mostly short-stature mangroves that our TDX dataset was not able to resolve due to the small spatial baseline at the time of data acquisition [8,17]. TDX data acquisitions with large spatial baselines could potentially solve the issue of not quantifying the canopy height of short stature vegetation [17,18]. Remote sensing data products inherently include uncertainty in their estimations. ALS canopy height measurements have an RMSE or accuracy that is less than 1 m [4,19]. The high degree of concordance between our ALS and TDX height estimates (R2 = 0.85, RMSE = 1.96 m) indicate a high potential to use TDX data for the estimation of mangrove forest canopy height. The ALS data covered a relatively small area (30 km2) along SRS in only one TDX scene. The additional three TDX scenes were located in areas where ALS data are not available, hence, validation was not possible. Overlap regions between TDX scenes were analyzed to find variations in canopy height values. Differences in overlap regions were less than the RMSE, thus we assume the same uncertainty can be applied to all the TDX scenes. ", 5. Discussion, 5.2. Mangrove Canopy Height,5
238,"Mangrove AGB was estimated using ENP-specific height-to-biomass allometry (Equation (1)) developed by Simard et al. [3], which applied this equation to SRTM-calibrated data with an absolute vertical uncertainty of 2 m. We applied this equation to our TDX dataset with an absolute vertical uncertainty of 1.96 m (~2 m). The standard error for the AGB estimates of the allometric equation (Equation (1)) ranges from ± 20 Mg·ha−1 for mangrove stands of 1 m in stature up to ± 40 Mg·ha−1 for mangrove stands of 25 m in stature [3]. Since the equation is a linear relationship between canopy height and AGB, and both height datasets uncertainties are similar (~2 m), the detected height differences between the two studies directly translate into AGB differences. Our results show that mangrove AGB in the ENP can reach up to ~250 Mg·ha−1, 25% higher than the Simard et al. [3] maximum AGB value of ~200 Mg·ha−1. As with the mangrove canopy height, this difference in AGB estimations could be due to mangrove growth as almost a decade has passed between studies. Our results suggest that most of the mangrove AGB lies between 90 Mg·ha−1 and 120 Mg·ha−1 (9 m–12 m canopy height), whereas most of the AGB in [3] study was located around 80 Mg·ha−1 (8 m canopy height). As the height-to-AGB in ENP allometric equation is based on linear regression, canopy height and AGB differences between our study and Simard’s study are linear and constant in nature. Our total estimate for mangrove AGB in the ENP mangroves using the Simard et al. [3] equation is 6.7 × 109 kg. The previous estimate of AGB was 5.6 × 109 kg [3]. Our TDX results do not include some short mangrove stands, suggesting a slight underestimation of total AGB.Our study suggests that there has been an increase in AGB and carbon sequestration during the period of 2000–2013 in the ENP mangrove forests. These results show that the ENP mangrove forests are steadily growing, despite large weather events such as Hurricane Wilma in 2005 [12]. In addition, we were able to obtain more detailed estimates of AGB as our TDX dataset has a very high resolution, compared with SRTM-based AGB estimates. Caution should be taken when converting height to AGB data, as there might be cases where degraded or dead mangrove stands preserve their stem structure and might be interpreted as live AGB in the final estimation. Furthermore, as the ENP height-to-AGB equation [3] was based on non-site-specific AGB allometry [20,21], future studies in the Everglades ecosystem should focus on using ENP-specific allometry [22] in order to increase AGB estimation accuracy.", 5. Discussion, 5.3. Mangrove Above-Ground Biomass,5
239,"We used ALS and TDX data to estimate canopy height and AGB in the ENP mangrove forests. TDX mangrove canopy height results were validated with an ALS dataset acquired along SRS. The comparison between the ALS and TDX canopy height results yielded an R2 = 0.85 and RMSE = 1.96 m. Comparing our results to the previous ENP mangrove canopy height map [3], we detected significant changes in canopy height (up to 6 m), mainly in the region where SRS connects with the Gulf of Mexico. Our study shows the potential of using TDX data for estimating mangrove canopy height. Global TDX DEM acquisitions are based on single-polarized (HH) data, and this study successfully demonstrates the use of single-polarization data for mangrove research. AGB was estimated using a published ENP height-to-biomass allometric equation. Our results showed that AGB reaches up to ~250 Mg·ha−1 near the western coastal mangrove forests and that most of the mangrove AGB distribution is concentrated between 90 Mg·ha−1 to 120 Mg·ha−1. We estimate total mangrove AGB in the ENP at 6.7 × 109 kg, a significant increase compared to the previous AGB estimate of 5.6 × 109 kg. Our canopy height and AGB results suggest that when analyzed altogether, the ENP mangrove forests have been steadily growing despite disturbances that could have destructive effects. Upcoming work will focus on the analysis of multi-temporal airborne LiDAR data in the extensively studied ENP SRS region to quantify mangrove migration, growth and/or degradation.", 6. Conclusions,None,6
240,"Lichen woodlands (LW), and more generally northern open canopy forests, cover extensive areas in the circumpolar subarctic regions. The naming (e.g., “taiga”) and definition (e.g., latitude range) of these forests vary [1]. Some authors [2,3] distinguished three zones from south to north (approximately 50° to 70° north) which they called respectively closed-canopy boreal forests, open canopy woodlands and forest-tundra. Others have more recently defined LW as an ecotone stretching between closed canopy boreal forests and tundra [4,5,6], i.e., a boreal-arctic transition. We will here adopt the latter definition and consider the LW as having a geographical distribution in Canada and Alaska as presented in the map proposed in Reference [4] (Figure 1). According to this definition, subarctic forest cover approximately 2 × 106 km2 in Canada alone. They are characterized by short growing seasons, temperatures varying from 20 °C in summer to −50 °C in winter, and a discontinuous permafrost. Their plant diversity is poor, especially in the case of treed vegetation. In Canada, black spruce (Picea mariana [Mill.] BSP.), jack pine (Pinus banksiana [Lamb.]) and eastern larch (Larix laricina [Du Roy Koch.]) constitute the large majority of LW trees, with the former species being largely predominant. LW are characterized by short and open canopies, and a forest floor mostly covered by lichens (see Figure 2). Although their above ground biomass density (t ha−1, thereafter termed “biomass”) is currently low, a lengthening of the growing season, CO2 fertilization, and the consequent rise in productivity of LW could have a significant global impact on carbon sequestration due to the extensiveness of these woodlands [7,8]. According to Ouranos [9], the length of the growing season in subarctic regions could increase by 20 days by 2050, while the average annual temperature could rise by 3 °C during the same period. This could cause a densification of northern woodlands [10] and an increase of tree height and biomass. Other factors, such as the forest fire regime, could nevertheless cause a migration of LW towards the south [5]. Precisely describing the current state of the boreal-tundra ecotone LW and following their evolution in the coming decades, is, therefore, becoming ever more important. In particular, methods allowing the accurate estimation of the factors that determine the above ground biomass density, such as tree height, basal area (BA) and stem density (stems ha−1) should be deployed over LW to better describe their structure and carbon contents. Compared to the continuous boreal forests, subarctic forests have, however, been much less studied [11]. This can be explained by their low to null commercial interest and their remoteness [12]. The road density in these areas is extremely low, and the airports are very sparse. This makes field work or airborne surveys complicated and extremely expensive, at least in the far north regions of Canada or Russia, and with that, much less intensive than in the southern boreal forest.The key measurements for assessing tree biomass are the height and geolocation of individual trees because diameter at breast height can be predicted from height (e.g., Reference [13]), biomass from height and DBH, and stem density can be obtained by simply tallying the number of trees located within a given area. Apart from field measurements, individual tree heights can be well estimated using photogrammetric methods [14]. In sparse forests, heights can be obtained from single aerial photographs (in monoscopic mode) using the radial displacement of trees viewed obliquely, or by the length of their shadows [15]. More often, the height is calculated based on parallax differences on stereoscopic pairs of photographs [14,15], a method often referred to as “spatial intersection” of the conjugate rays. In the former case, both the top and the base of the tree (or its shadow) must be visible, which is not always the case, even in sparse woodlands. In the latter case, the top of the targeted tree must be seen in both photographs to enable spatial intersection, yielding the XYZ position of the tree top. By measuring the ground elevation near the tree in the same way, or by extracting it from an airborne laser scanning (ALS) digital terrain model [16], the height of the tree can be calculated. The accuracy of the elevation measurement of the tree top depends on the shape of the tree and the spatial resolution of the images. For trees having a tapering crown, underestimation is expected because the tip of the tree often cannot be resolved. For example, Spurr [15] reported an underestimation ranging from 0.6 m at a photographic scale of 1:10,000, to 1.5 m at a scale of 1:20,000 for elongated trees, for analog aerial photographs. For the same scales but for broad crowns, the underestimations were respectively 0.0 m and 0.3 m. All the above methods have so far been exclusively applied to aerial imagery. In theory, such measurements could also be made on high-resolution satellite images. While high-resolution airborne photographic surveys are, as previously mentioned, rather complicated and costly in remote subarctic regions, earth observation from space does not entail logistical difficulties. To the best of our knowledge, however, measurements of individual tree height from space have never been accomplished.Since 1999, with the launch of the IKONOS sensor [17], earth observation from space can supply images having a ground sampling distance of 1 m or less. These are often referred to as high-resolution spaceborne images (HRSI), although the meaning of this acronym may vary. Few studies have attempted to characterize the structure of northern open canopy forests using HRSI. Leboeuf et al. [18,19] proposed a method for mapping biomass, basal area and wood volume based on the retrieval of the proportion of shadows from QuickBird images (0.61 m ground sampling distance), followed by statistical modelling, yielding relative root mean square errors (RMSE) of 17–32%. Although the shadow length, as determined by tree height, certainly influenced the results, the method was not based on measuring it specifically. Only the overall proportion of shadows per plot was statistically linked to biomass. A related approach, but applied at the individual tree level, consisted in using shadow area to predict stem volume, achieving an R2 of 0.61 [20]. However, because shadow-based methods are influenced by the sun elevation at the time of image acquisition, the regression models used to predict biomass are only valid for the images for which they were calibrated, thus hindering generalization. Other studies proceeded by creating a digital surface model (DSM) using stereo image matching, and then by subtracting ground heights provided by either ALS (e.g., Reference [21]), or by a digital terrain model (DTM) extracted from the photogrammetric point cloud itself. Montesano et al. [12] combined stereo WorldView-1 images (0.46 m ground sampling distance) and ICESat-GLAS waveforms [22] to estimate the height of trees in northern Siberia with a RMSE varying from 0.85 to 1.37 m. In this case, the Worldview-1 imagery was used only to assess the ground-level elevations, not the top of the trees. Later for the same region, Montesano et al. [6] used WorldView-1 and -2 stereo-images to reconstruct both the ground and vegetation elevations using the image matching algorithm of the AMES stereo pipeline of NASA [23]. By comparing results obtained from imagery acquired with sun elevations varying from 7° to 43°, they found that the highest accuracy for the DTM reconstruction was achieved in high sun elevation conditions (RMSE < 0.68 m), whereas a low sun elevation was preferable for characterizing vegetation heights. Meddens et al. [24] used the 5-m resolution ArcticDEM [25] elevation product to estimate canopy height in Alaska. The vegetated ArcticDEM pixels identified using multispectral imagery were replaced by values interpolated from non-vegetated pixels. By subtracting the original ArcticDEM with the modified version, an approximate canopy height model (CHM) was created. Forest heights were then predicted with a RMSE generally between 2–3 m by combining this CHM with several other monoscopic predictors derived from WorldView-2 imagery. The calibration of the regression model, however, required several thousand calibration points extracted from ALS data. Several other studies concerned the creation of DSMs over forest canopied using stereo HRSI, albeit not in subarctic woodlands (e.g., References [25,26,27,28,29]).Considering the narrowness of the crowns of subarctic trees, even a ground sampling distance of 0.5–1.0 m is probably insufficient to reconstruct the height of narrow-crown black spruces. Digital Globe launched the Worlview-3 (WV3) satellite in 2014 [30], followed by WorldView-4 (WV4) in 2016. Both provide images with a nominal ground sampling distance of 0.31 m at nadir in panchromatic mode, as well as stereo capacity and several narrower spectral bands at a coarser resolution. Starting in 2020, the Pléiades NEO constellation of four satellites with tri-stereo capacity should start producing images at a resolution of 30 cm [31]. For disambiguation, we will thereafter term the latter class of imaging sensors (pixel size < 0.50 m) “very high resolution spaceborne imaging” (VHRSI). Images from WV3 or WV4 are designed to have a high photogrammetric quality and can be used to generate DSM using automated image matching techniques. Accuracy assessments relative to these sensors are, however, still rare, and none of the existing studies concerned subarctic forests. Aguilar and et al. [32] used WV3 stereo pairs to generate DSMs of different surface types. Compared to a lidar dataset, a RMSE of 0.26 m (compared to ALS) was observed over bare ground surfaces for DSMs generated using the RPC stereo processor matching algorithm [33]. This confirms the high photogrammetric quality of WV3 images and demonstrated the high performance of the matching algorithm for the simplest type of surface. Goldbergs et al. [34], however, showed that commercial stereo image matching software (PCI Geomatica, Canada, and Photomod from Racurs, Russia) designed to work with spaceborne images acquired with pushbroom sensors (here GeoEye and WorldView-1), failed to properly reconstruct the vertical structure of open canopies. Although this study was conducted in an Australian savannah, it illustrates the image matching challenges over sparse woodlands.In general, the quality of photogrammetric data extracted from stereo-pairs of VHRSI with regard to detailed forest structure characterization depends on certain fundamental factors that are independent of the image matching method. First, the tree tops must be visible (non-occluded) in the two images forming a stereo-pair, and must be discernable from other trees, or from other objects such as the underlying ground cover [14]. Therefore, occlusions, or lack of contrast and resolution, impedes on establishing the stereo correspondence. Contrast itself depends on the radiometric properties of the objects and on the radiometric resolution of the sensor. Second, the photogrammetric quality of the sensor (i.e., distortions-free optics, well calibrated internal orientation, etc.), and the capacity of the platform to achieve a viewing geometry (convergence, bisector and asymmetry angles of the conjugate rays, see References [35,36]) that provides good conditions for spatial intersection affect the accuracy of the height measurements. We assert that it is important to assess the impact of the above factors separately from the evaluation of the quality of a derived DSM, because the latter is also altered by the image matching uncertainty.Moreover, although ALS can provide individual heights even for small trees of northern regions when the laser point density is fairly high [37], it is logistically difficult to perform ALS surveys due to the scarcity of airports. What is more, using a lower point density would logically result in many narrow crowns of black spruces being missed as some would lie between scan lines. A few airborne lidar acquisition attempts were made in northern Canada, for example by Margolis et al. [38] using PALS, a laser profiler mounted on a small aircraft. To the best of our knowledge, the largest ALS survey of northern forests of Canada was carried out by Hopkinson et al. [39]. They used an Optech ALTM3100 system to acquire strips of data with a swath width of 640 m, over a total length of 24,000 km between the latitudes of 43°N and 65°N, and with a point density of at least 1 point/m2. This was a rather unique endeavour that is unlikely to the repeated regularly.While airborne surveys are difficult, lidar Earth observation spaceborne platforms provide only partial solutions. LW regions in Canada indeed fall in great part within a latitude range [5] that is not covered by important programs such as data acquisition with the GEDI spaceborne mission [40], that does not cover regions north of 51.6°N, nor by the ArcticDEM program [25], that only covers regions above 60°N. Only the ICESat-2 mission [41], launched on September 15, 2018, will provide sparse 3D point clouds for LW. It will, however, do so in a spatially discontinuous manner, and with a spatial resolution (17 m diameter footprints) insufficient to precisely characterize the structure of subarctic forests.Our main objective was therefore to assess the accuracy of manual individual tree height measurements performed by spatial intersection of conjugate rays on stereo WorldView-3 images of an open-crown Canadian subarctic forest. In addition, we wanted to verify that the plot-level basal area (in m2 ha−1), as a surrogate to biomass, can be predicted from the tree heights. This implies that most trees would have to be detected on both images of the stereo-pair. For this reason, our aim was also to assess the accuracy of density estimates of detectable trees (in stems ha−1). The level of tree detectability (non-occluded and discernable) was assessed for different ground covers to verify the effect of contrast between trees and their background. We performed the stereo measurements manually to ensure that the results depended only on the inherent information content of the imagery rather than on the quality of an image matching algorithm. Indeed, what cannot be retrieved manually because of lack of contrast or occlusions would neither appear in photogrammetric point clouds derived automatically. However, detectable individual trees may be badly reconstructed or entirely missed by automated stereo reconstruction.The methods presented in this study were developed to potentially serve two purposes. The first is to allow building a better characterization of the structure variability of LW by facilitating localized sampling in remote areas using remote sensing means only, thus avoiding the costs and logistical problems of in-situ measurements. The second was to enable researchers to create “virtual plots” anywhere in LW, in sizes and shapes adapted to the calibration procedures of other remote sensing data, such as ICESAT-2, again without field campaigns.", 1. Introduction,None,1.
241,"Field data and imagery were acquired within a 102 km2 area (centered on 78.7°W, 53.7°N) located near the La Grande River, in the Chisasibi municipality of the province of Quebec, Canada (Figure 3). The study area lies within the LW bioclimatic domain [5] (Québec, 2016). Its subarctic climate is characterized by average temperatures of −3 °C and average annual precipitations of 684 mm. The growing season lasts approximately 130 days, with roughly 700-degree days of growth (according to maps published in Reference [42]). Topography is nearly flat (elevations vary from 18 to 68 m above sea level), and soils are thin, sandy and well drained in most areas, except in peatlands, where the organic layer can reach important depths.The most common vegetation formations are sparse woodlands growing on sandy soils covered by cladonia species (e.g., Cladonia stellaris [Opiz. Pouzar & Vĕzda]), i.e., white fruticose lichens approximately 10 cm in height. At least 95% of trees are black spruces, which are accompanied by a few larches and jack pines. The trees sometime reach 12 m in height, but most are less than 10 m high, notably because of their very slow growth (5–11 cm y−1). Their crowns are very narrow and often terminated by a thick and sometimes roundish volume of shoots (Figure 2). Part of the territory is occupied by peatlands sparsely covered by similar trees, but having a different ground cover, which is composed mostly of mosses, herbaceous species and Labrador tea (Rhododendron groenlandicum [(Oeder) Kron & Judd]). Some denser patches of forests can also be found, but these occupy only a small fraction of the study area.", 2. Materials and Methods, 2.1. Study Area,2
242,"Tree measurements and unmanned aerial vehicle (UAV) flybys were carried out in the field from 24 July to 11 August 2017 in 14 well-distributed circular field plots (Figure 3). The plots had radii from 9.77 m to 12.62 m (with plot areas respectively from 300 m2 to 500 m2) depending on the local density of trees. We categorized the plots’ ground cover types as lichen, rocky or peatland. Two different measurement protocols were used. In “standard” plots, the DBH and species of all trees having a height of 2 m or more were recorded. In addition, the height and XY position of five trees representative of the plot’s height distribution were measured. In “intensive” plots, the DBH, species, height and XY location of all trees of 2 m or more were recorded. In addition, five trees per intensive plot (total of 30 trees) were felled and their height was precisely measured with a distance tape after felling. Table 1 summarizes the plot information. The density may appear high therein. This is because the very low size threshold (height < 2 m) for including trees created large totals per plot, with many trees having a DBH of only 2 cm. It is to be contrasted to the majority of forest studies, which use a much larger threshold (e.g., DBH ≥ 9 cm) resulting in lower densities.DBH larger than 4 cm were measured to the nearest mm using a DBH tape. Smaller ones were measured with a fixed-increment caliper, with increments of 1, 2 and 4 cm. The heights were measured with a Sokkia telescopic height pole for trees not exceeding 8 m, and with a Vertex III instrument (Haglöf, Långsele, Sweden) for taller ones. For pole measurements, one operator standing next to the tree deployed the telescopic segments and read the height on the display while another ascertained from a distance that the tip of the pole was level with the tree extremity. In the case of Vertex measurements, the apex of all trees could be precisely seen and was viewed at an angle of approximately 45°. Using the height data from felled trees, the bias of the non-destructive field height measurements (pole or Vertex) was assessed and corrected. Moreover, the position of the trees was measured relative to the plot center by using the Vertex in distance mode. Three reference points were precisely placed at 2 m horizontally from the plot center in respectively the N, SE and SW directions. For each tree, a distance measurement was performed from each reference point. For this procedure, the Vertex was mounted on a supporting pole equipped with a bubble level to ensure its verticality over each reference point during the measurements. The XY positions of trees relative to the plot center were then determined using trilateration. Before initial measurements, and at approximately 30-min intervals, the Vertex instrument was recalibrated to account for eventual changes in air temperature and humidity that might affect the accuracy of its distance measurements, which are based on ultrasound pulses. The relative tree positions were later translated to the absolute plot center location obtained by GNSS positioning (details follow).For all plots, a small UAV (DJI Phantom 3 4k, equipped with a Sony Exmor camera) was used to take still images from an altitude of approximately 20 m above ground. The camera had a focal length of 3.6 mm and a focal plane size of 6.317 mm by 4.738 mm, with 1.57 µm pixels. Viewpoints roughly laid out as a regular lattice provided an image overlap of 85–90% in both directions. The ground sampling distance of the images was approximately 1 cm. Prior to the UAV surveys, four targets (panels with a center mark, see Figure 2) visible from the air were laid out in the plot directly on the ground. One was placed at the exact plot center and three others at the periphery, separated by 120 degrees. These targets, serving as ground control points (GCPs), were surveyed with a SX-Blue 2 GNSS receiver (GPS and GLONASS) from Geneq Inc. (Montreal, Canada). In addition, eight ground elevations were measured in each plot with the GNSS receiver using the above procedure. Two measurements were done in each cardinal direction between the center (already measured) and the periphery, resulting in a cross pattern.Finally, seven well distributed GCPs for georeferencing the WorldView-3 image pair (Figure 3) were geopositioned using the same GNSS procedure. The GCPs corresponded to minute and fixed objects visible on the satellite images, e.g., a white stone emerging from a darker background, the corner of a concrete block, etc. Terrestrial photos were taken at each location during the GNSS positioning to ensure that the pinpointing of the GCP pixels on the images corresponded to the exact field position of the GNSS receiver.For all acquired positions, the GNSS antenna was mounted on top of a 2-m support pole held vertically on the measured point. Antenna height above ground was subtracted from the Z measurements. Positions were corrected in real-time using the Wide Area Augmentation System. GNSS signals were integrated for 1 min at each station and the final geolocation was obtained by computing the average of the 60 positions. During the collection of all GCPs (for plot positioning, UAV image orientation and WV3 image georeferencing), the GNSS point dilution of precision (PDOP) was generally 1.3 or 1.4.", 2. Materials and Methods, 2.2. Field Data,2
243,A Digital Globe WorldView-3 stereo pair was acquired on 7 July 2018 with a convergence angle of approximately 37°. No clouds or haze were present at the acquisition time. Each of the two images was composed of a panchromatic band at 0.31 m nominal ground sampling distance at the nadir and eight spectral bands at 1.24 m resolution [43]. The images were obtained in orthoready 16-bit format (2A) with their rational polynomial coefficients (RPC). The detailed image characteristics and acquisition parameters appear in Table 2., 2. Materials and Methods, 2.3. Remote Sensing Imagery,2
244,"To create the precisely oriented WV3 stereo-model, 30 tie points between the images were manually picked, and the image pair was tied to the 7 GCPs. This resulted in an adjustment of the initial RPC values. This operation was performed using Summit Evolution Professionnal v 7.4 (DAT/EM Systems International, Anchorage, AK, USA). The UAV images were first aero-triangulated using the approximate principal point positions given by the UAV’s GPS data and tie points were automatically generated. For each plot, the aero-triangulated block was then tied to the four geolocated ground targets visible in the images. The above orientation procedures of the UAV images were performed using Pix4Dmapper v.4.1.24 (Pix4D, Lausanne, Switzerland).", 2. Materials and Methods, 2.4. Image Georeferencing,2
245,"The method for assessing the accuracy of tree height (H) measurements from WV3 stereo images aimed to compare these to the best available reference height data and for the largest number of trees. Because the measurements of heights in the field are time consuming, they were not performed on all trees within the standard plots. For these, we have instead used bias-corrected tree heights extracted from 3D point clouds derived from the UAV images using dense stereo matching. Height measurements from low altitude UAV images have been shown to be accurate [44]. These UAV point clouds also helped in establishing the correspondence between the field and WV3 heights. Moreover, even heights measured in the field using a height pole or the Vertex contained small errors. To avoid any bias in the assessment of the error of WV3 based on reference tree height measurements, we have:Estimated the bias between the pole/Vertex heights and the true height measured on the corresponding felled trees (n = 30), and then corrected all the non-destructive height measurements accordingly;estimated the bias between the bias-corrected field heights and the corresponding heights extracted from the UAV 3D point clouds, and then corrected all the UAV heights accordingly.To measure heights from the UAV data, image matching was performed using Pix4dMapper to create a dense 3D point cloud. The ground points were then identified using the lasground function of LAStools (rapidLasso GmbH) with a value of 1.75 for the step parameter. A DTM was created by interpolating these ground points using the LAS dataset to Raster function of ESRI’s ArcMap v. 10.5, taking the average of values falling in each cell. The highest point on the tree apex was identified manually by inspecting the raster values, and the local DTM elevation was subtracted from it to estimate tree height. The bias of this these measurements was assessed by computing the average difference between the bias-corrected field tree heights and the corresponding UAV tree heights (n = 351). This bias was then removed from the UAV heights.The height of individual trees was measured manually using stereo viewing of pansharpened color WV3 image with LCD shutter glasses within Summit Evolution v. 7.4 (DAT/EM Systems International, Anchorage, AK, USA), a software application for capturing 3D information from stereo data. A color composite of the green, red and infrared channels was sharpened with the panchromatic band and contrast-stretched to improve the visual discernibility of trees compared to the black and white panchromatic images. For all trees for which the apex was clearly visible in both images of the stereo pair, the interpreter digitized the 3D position of the apex and that of the nearest visible ground point. This point was in most cases very near the tree (e.g., 1 m), but in denser plots, it sometimes had to be selected some distance away from the tree (e.g., 3–4 m). Because of local topographical variations, greater distances from the tree increase the risk of error. The height of each tree was calculated as the vertical difference between the apex and the nearest ground elevation. The correspondence between the WV3-measured tree heights and the field or UAV tree heights was assessed visually using stereo viewing, and by plotting the XY position of the WV3-detected trees on UAV orthoimages created from the coloured point clouds. The bias of the WV3 measurements was estimated by calculating the average difference between the field or UAV bias-corrected heights and the corresponding satellite-based measurements. The bias was then removed from the WV3 heights before they were used for predicting DBH. Finally, the uncertainty of the WV3 tree height measurements was first assessed by computing the RMSE between the field or UAV heights and the WV3 heights. Also, the R2 and the standard residual error of regression between WV3 heights and the corresponding field of UAV heights were calculated. A flowchart of the overall procedure for all bias corrections and accuracy assessments appears in Figure 4.Furthermore, for the WV3 heights, we assessed the respective impacts of the errors of ground elevations and of tree apex elevations to understand their relative contributions to the overall height error.It should be noted that some trees could not be reconstructed in 3D from the UAV images and that many could not be well discerned or viewed in both of the WV3 images, making the stereo measurement impossible. These trees were therefore ignored. We have however compared the field plot-wise stem counts to the corresponding counts of detected trees on the WV3 images. The rate of omission relative to the field tally was assessed. This rate was compared between the different plot types (cladonia, rocky, or peatland; see Figure 5). We also regressed the WV3 counts against the field counts to compute the R2 and the standard residual error. Because the detection of very small trees proved to be very difficult, two regression models were created: one for all trees (H ≥ 2 m) and one for trees of 4 m and more.", 2. Materials and Methods, 2.5. Tree Height Measurements and Stem Counts from the WV3 Images,2
246,"The basal area (BA) of individual trees was predicted from the WV3 height measurements using a statistical model linking DBH to height that we have calibrated locally based on our data. A single model was developed for all species (largely dominated by black spruce) based on all the field measured height and DBH using linear regression. Although many DBH-H models are non-linear [13], our data clearly showed a linear trend, with just a few outliers. We have therefore used a linear regression approach to predict DBH from H. For every tree that could be detected from space, we predicted DBH by applying this linear model to the bias-corrected WV3 heights. At plot level, we summed the individual tree basal areas computed from the predicted DBH to estimate the plot basal area in m2 ha−1. A linear regression model was developed for relating the WV3 derived BA to its reference value obtained from field data. As for tree counts, one model was calibrated using all trees (H ≥ 2 m) and another using only the trees having H ≥ 4 m. All statistical analyses (stem counts, and H and BA regression models) were performed in R software [45].", 2. Materials and Methods, 2.6. Estimating Basal Area at Tree and Plot Level,2
247,"The WV3 image pair was tied to the 7 GCP with a RMSE of 70 cm, 60 cm and 92 cm respectively in X, Y and Z. The RMSE of UAV image orientations relative to each plot’s four GCPs was on average 20 cm, 26 cm and 17 cm, respectively in X, Y and Z (with a RMSE standard deviation of across plots of respectively 0.22 m, 0.28 m, and 0.15 m). The RMSE of the trilateration of trees positions within plots was 13 cm in XY. For all trees detected from space, field tree heights could be linked unambiguously to the corresponding UAV and WV3 measurements.", 3. Results, 3.1. Georeferencing and Measurement Error in Reference Data,3
248,"Before reporting on the height error assessment, we present the detection rate of trees because it affects the number of trees considered in that assessment. A total of 351 trees (H ≥ 2 m) could be identified in the UAV point cloud in the intensive plots (or from the 5 trees per standard plot) out of 488 trees tallied in the field. Most of the missed trees were small ones located within tree clusters that could not be seen from any angle in the UAV images. The average rate of detection of trees in the WV3 stereo images was 25%. There was no relationship between the number of field trees and the number of trees detected from space when all trees (H ≥ 2 m) were considered (R2 of −0.081). However, for trees of 4 m or more (detection rate of 42%), the R2 rose to 0.41 in the specific case of plots with cladonia lichen (n = 9). Figure 6 shows this relationship along with the equation. There was a significant difference (Kruskall Wallis statistic p = 0.011, with one degree of freedom, for trees with H > 4 m) between the detection rate of trees on a bright background (lichen or rock), compared to a greenish background (peatland).", 3. Results, 3.2. Detection Rates and Stem Density,3
249,"The bias of pole or Vertex height measurements of standing trees relative to the height measurements after felling was −9 cm (pole of Vertex H minus felled tree H). RMSE of the pole/Vertex H was 18 cm. The bias and RMSE of UAV heights (UAV minus corresponding bias-corrected pole/Vertex H) were respectively −37 cm and 55 cm. Figure 7 shows the relationship between these measurements. The abovementioned bias was removed before we used the UAV heights to assess the accuracy of WV3 heights.The heights measured by spatial intersection from the stereo WV3 images were compared to those directly measured in the field for 96 trees over all ground cover types. The bias (WV3 minus field) was of −0.83 m and the RMSE of 1.27 m (Figure 8a). When the WV3 heights were compared to bias-corrected UAV heights (n = 212) used as reference, the bias was 1.09 m and the RMSE was 1.36 m (Figure 8b). The residual standard error (RSE) of the regressions between reference and WV3 heights were 0.85 m and 0.80 m in the respective cases of field and UAV comparisons. Cover type affected the accuracy of the measurements. As shown in Table 3, the accuracy was highest when the background (ground cover) was bright (lichen or rock).Since the height measurements were done by taking the difference between the elevation of the tree apex and that of a nearby ground point, the bias could have been caused by either of these measurements. Table 4 shows the differences in ground elevation between the GNSS measurements and the corresponding UAV ground points (UAV minus GNSS), and between these and manual stereo measurements made on the WV3 images (WV3 minus UAV). It principally shows that the ground elevations are on average underestimated by 44 cm when done from space, thus adding to tree heights. The elevation of tree apices was also underestimated, but by 1.27 m (RMSE of 1.64 m). The tree height downward bias when measured from WV3 can therefore be mainly attributed to the apex measurement. This bias is partly compensated by the downward bias of the ground elevation measurements. The field, UAV, and WorldView-3 height measurement data are available as Supplementary Materials (see appropriate section at the end of this article).", 3. Results, 3.3. Tree Height Measurements from the Imagery,3
250,"A linear model for predicting DBH from H was locally calibrated using field data (n = 418) with a R2 of 0.90 and a RSE of 12 mm (Figure 9).WV3 heights were used to predict DBH using this model, and individual tree BA was calculated from the predicted DBH. BA were then summed up at plot level. Plot level BA error was therefore determined by the uncertainty of the WV3 height measurements, but also by the rate of tree detection. This relationship appears in Figure 10, while Table 5 presents the error of plot-level basal area predictions in two versions, respectively based on: (1) the bias-corrected height of all the detected trees (H ≥ 2 m), and (2), the bias-corrected height of detected trees having H ≥ 4 m. In the latter case, the WV3 predictions were compared to the field BA only for the trees of 4 m and more. Again, the type of ground cover was taken into account in the error assessment. The best relationship was obtained for trees of 4 m and more on lichen or rocky ground cover. Despite the high R2 (0.79), the RSE represented in this case more than a quarter (26.8%) of the average field BA due to these being so small. The relative RSE varied markedly between the different cases because the value of the denominator (average field BA of selected trees and plots) was itself variable.", 3. Results, 3.4. Tree and Plot Level Basal Area,3
251,"Measuring the height of trees by spatial intersection of conjugate rays from VHSRI requires that the tree apex be clearly seen and visually matched in the two images. It is also necessary to measure the elevation of ground points near the targeted trees. We have attempted to perform apex and ground elevation measurements on 14 plots for conifer trees having heights between 2 and 12 m and with very narrow crowns. The results show that while the height measurements were quite accurate, several factors make it difficult to measure the height of a very high proportion of trees, despite the openness of the subarctic canopies.The view angles with which the images were acquired (elevations of 71°) necessarily entail the occlusion of some short trees by higher ones in either one of the images or both, leading in any case to the impossibility of measuring height. This is more frequent in dense plots or in situations where trees grow in thickets separated by open ground. Since small trees are more numerous than taller ones, missing those short ones greatly affects the total count per plot. This is partly alleviated by only considering trees in the 4–12 m range. Our capacity to assess stem density in this case was much better, with a R2 of 0.41 and a relative RSE of 8.8%. The visual discernibility of non-occluded tree crowns also affected the estimate of density. During the height measurements, if the contrast between the apex of a tree and the background made the precise pinpointing of the apex dubious, the tree was simply rejected. This was much more often the case over peatlands because of the color of the ground cover that provided insufficient contrast with the tree, especially for small ones. Different visualization strategies and contrast stretches did not allow overcoming this limitation.Several approaches could be taken to minimize the occlusion problem. Constraining the acquisition angles to be higher (e.g., 80°), if technically possible, would reduce the convergence angle and increase the uncertainty of the height measurements [35]. Moreover, using a tri-stereo approach in which three overlapping images are acquired along track, namely with forward-looking, nadir, and backward-looking view angles, would increase the chance of seeing a given tree top on at least two images, if not three. The current Pléiades sensor currently offers this possibility, but with a 50 cm ground sampling distance, a resolution that is likely detrimental to the discernibility of narrow tree tops. However, in 2020, the new Pleiades NEO will offer tri-stereo with a 30 cm ground sampling distance, which is a potential improvement in tree detection rates. Furthermore, alternative techniques could be used in conjunction with spatial intersection to measure tree heights monoscopically, i.e., radial displacement or length of shadow [15]. While this is only possible in certain geometrical conditions, i.e., both extremities of the tree or its shadow must be visible (non-occluded), it could provide a useful complement to the stereo measurements.Viewing the ground in a stereo to obtain a terrain elevation near a tree did not pose as big a problem compared to tree tops. Most plots were mostly horizontal, such that a horizontal offset of the measured ground point relative to the targeted tree did not cause large errors. Alternatively, a local digital terrain model could be created by interpolating manual ground elevation measurements on WV3 images, and then being used in the calculation of tree height.", 4. Discussion, 4.1. Detection Rates and Stem Density,4
252,"For the detected trees, the RMSE of height measurements from the stereo WV3 images were 1.27 m and 1.36 m when assessed using respectively field or UAV data. It has to be remembered that these RMSE express the “raw” error of WV3 measurements and not the residuals of a regression (RSE). Those were lower, respectively at 0.91 m and 0.80 m. These values are roughly comparable to what was obtained by St-Onge et al. [16] using analog aerial photographs at a scale of 1:8000 for the stereo measurement of the elevation of tree tops and an ALS DTM for that of the tree bases. In their study, the average deviation between photogrammetric heights and field height was 1.01 m. Using digital aerial images at a scale of 1:10,000, Korpela et al. [46] reported RMSE values of 0.93 m and 1.07 m for two conifer species. Somewhat similar ranges of values were reported for the height error of single trees obtained using low density ALS. For example, Kwak et al. [47] achieved a RMSE varying from 1.13 m to 1.31 m using a laser point density of 1.8 points m2.Because this is, to the best of our knowledge, the first attempt to measure individual tree heights from space, we have no basis for comparison to previous work of the same nature. All previous studies using stereo satellite images for estimating forest height involved stereo image matching to produce DSMs of forest canopies (e.g., Reference [26]), while one study consisted of predicting the stem volume of individual trees based on shadow area [20]. Our work, however, provides useful insight for interpreting the matching results reported in those studies. It clearly demonstrates the achievable level of accuracy of manual height measurements at the individual tree level. We thus showed that even if an error-free image-matching algorithm existed, the 3D reconstruction of the canopy surface elevations would nevertheless be affected by problems of occlusions or insufficient contrast.", 4. Discussion, 4.2. Height Measurement Accuracy,4
253,"Despite the limitations in our capacity to correctly estimate stem density at plot level, the predictions of plot-wise basal area were promising, with an R2 of 0.79 in the best case. Leaving aside very small trees (2 m–4 m) had a small impact on BA but allowed the development of a more accurate relationship between WV3-derived BA and corresponding field data. It is to be noted that our approach for estimating BA from WV3 stereo images relies on bias-corrected heights. We therefore assumed that the estimate of the average bias performed using a sample of more than 200 trees is representative. Considering that our samples were well distributed within the images (Figure 3) and cover the entire range of heights present in this territory, we contend that this assumption is reasonable. Since the relationship between H and DBH is very strong (R2 = 0.90, n = 419), the uncertainty in the BA estimates mostly results from the WV3 height measurement error. Because BA and above ground biomass are closely related (see for example Reference [48], for a theoretical explanation), the height measurement capacity provided by VHSRI stereo images also signifies that biomass could be well estimated as well. Precise height measurements, accompanied by a relatively high rate of detection, were, however, only possible in woodlands with a bright ground cover. Results in peatland were much less accurate, to a point that probably precludes accurate BA or biomass estimations in this type of environment. One possible solution would be to acquire imagery at a time where there is a snow cover on the ground and tree crowns are devoid of snow. In this case, however, the ground elevations would have to be acquired from summer images. One other limitation of winter images is that larches, being deciduous, are leafless in winter and would be hard to detect.", 4. Discussion, 4.3. Basal Area and Biomass,4
254,"As it stands, the method that we have proposed, once calibrated, is much less labor-intensive than field work. It is, of course, much more so than automated methods such as stereo matching. For this reason, it can only be deployed on a very small fraction of the LW extent. It, however, can serve to sample LW across latitudinal gradients, using spatial sampling schemes (e.g., stratified random sampling) that would be prohibitive if implemented in the field due to logistical constraints. Using the data gathered from these samples, a better characterization of the average biomass and of its variability in LW could be made possible. This method is in theory applicable to any open forests or woodlands in which the ground is visible between trees, such as open savannahs, etc.We consider the number of trees and their spatial distribution within the footprint of the WV3 stereo images to be largely sufficient to support conclusions about the accuracy of height measurements by spatial intersection from space. However, because of the priority goal of this work and due to logistical and financial constraints, the number of plots remained limited at 14. It should be increased in the future to improve the certainty of the error assessment of plot-level basal area.Furthermore, the ICESAT-2 mission is acquiring 3D point cloud data over most of the globe with its single photon lidar sensor. This data is being captured along three pairs of tracks separated by 3.3 km. Along each track, the photons returned from laser pulses backscattering are collected within 17-m diameter footprints. In forested areas, only a few photons will be acquired per footprint. Therefore, the principal data product for vegetated areas will be in the form of 17 m by 100 m transects. Provided that stereo Worldview-3 of -4, or other HRSI, is available over ICESAT-2 tracks, measurements of tree heights, BA and predictions of ABG could be made using manual stereo measurements within a sufficient number of plots to relate the detailed structural characteristics of sparse woodlands to the metrics derived from ICESAT-2 point clouds. This could potentially enable the calibration of biomass prediction models that could be deployed extensively over the LW of North America.", 4. Discussion," 4.4. Limitations, Usefulness and Implications",4
255,"Our work consisted of attempting to measure individual tree height by spatial intersection of conjugate rays from a stereo pair of WorldView-3 images. Stereo measurements were performed manually on trees that could be visually discerned. The DBH and basal area were then predicted from the heights measured, and the plot level basal area was computed. Height and basal area estimated were then compared to accurate field data. Based on this assessment, we reached the following conclusions:It is possible to accurately measure (residual standard error of 0.80–0.91 m) the height of individual conifer trees from space in sparse woodlands;the underestimation of heights (bias of −0.83 to −1.07 m) was mainly caused by that of the elevation of the tree top (−1.27 m), while the bias of ground elevations was much smaller (−0.44 m);it is difficult to measure a large proportion of trees because many of the smaller ones are occluded by taller trees on at least one of the images, precluding stereo measurements;tree top discernibility is higher when the background (ground cover type) is bright because it increases the contrast with the relatively dark crowns.We also conclude that it is possible to assess basal area at plot level (R2 = 0.79) in good conditions, i.e., trees having a height of 4 m or more, growing on a bright background (lichen-covered or rocky surfaces), under the conditions found in this study. This should allow for the “virtual” collection of plot data, i.e., the acquisition of individual tree heights and related attributes without having to perform measurements in situ in these remote regions. It should contribute to improving the characterization of the structure and biomass of lichen woodlands, and should help calibrate models that make use of extensive remote sensing data, such as those of the ICESAT-2 mission.", 5. Conclusions,None,5
256,"Mapping wetland extent and quantifying how the extent changes over time is an important task for both scientific and societal applications. Wetlands are the largest natural emitter of atmospheric methane, a potent greenhouse gas, yet with the widest uncertainty range [1], and feedbacks between wetlands and the global carbon cycle are still poorly understood [1,2,3,4]. Understanding wetland dynamics is important for predicting the transmission of mosquito-borne diseases like malaria [5], and quantifying the rapid rate of wetland collapse is also important, as they provide economic and ecologic benefits to surrounding communities [6].Current techniques used to map wetlands are not able to fully capture the sometimes-rapid changes in wetland extent, high spatial variability in inundated or saturated areas, or successfully map water beneath dense vegetation canopies. For example, in situ observations of wetlands are often sparse and seldom made, as many wetlands are located in areas too remote to map regularly. Satellite remote sensing has been widely used to map wetlands and seasonal changes in wetland extent. Optical techniques (e.g., [7]) are unable to map water underneath vegetation or see the land surface through cloud cover, both of which decrease the temporal frequency of observations and underestimate the total extent of inundated areas. Microwave instruments onboard satellites, either monostatic synthetic aperture radars (SARs) or radiometers, are able to see through clouds and, depending on the wavelength, some amount of vegetation cover. Currently available products deriving inundation extent from microwave instruments have primarily used data from radiometers, with an extremely coarse (>25 km) spatial footprint [8,9]. Data from SARs have also been used extensively to quantify seasonal changes in inundation extent in wetland complexes (e.g., [10]), though the only publicly available data are from C-band, which cannot penetrate dense vegetation cover, and the long temporal repeat cycles of a single SAR instrument inhibits their ability to capture short term changes in inundation dynamics.A new observational technique, Global Navigation Satellite System Reflectometry (GNSS-R), has shown promise to map wetland inundation, even in the presence of dense, overlying vegetation. In [11], significantly higher power was observed in reflections over inundated rice fields compared to dry land. These results motivated a dedicated flight campaign to observe GNSS reflections over a variety of wetland sites and vegetation types, with a focus on Caddo Lake, located on the Texas-Louisiana border. Caddo Lake was chosen because it is one of the most heavily vegetated bodies of water in North America—large portions of the lake are densely covered with tall cypress forests. The cypress forests stand up to 50 m tall, and the trees are sometimes surrounded by cypress knees, which are small knobby structures that support the cypress trees’ stability. Cypress knees stand 20–30 cm above the water surface and prevent the passage of even the smallest watercraft through the forests. In addition to the cypress trees, a distinctive feature of Caddo Lake is the presence of an invasive floating weed, giant Salvinia (Salvinia molesta). These floating mats can completely obscure the open water and move with the lake currents—infestations can appear and disappear within a matter of weeks.In addition to [11], there have been additional investigations into the potential of GNSS-R to map wetlands using CYGNSS (Cyclone Global Navigation Satellite System; e.g., [12,13,14]), a constellation of space-based GNSS-R instruments. However, these studies have been limited by the spatial footprint of the CYGNSS measurement (7 km × 1 km), which is artificially large due to its optimization for ocean surface remote sensing. With a footprint of this size, it is nearly guaranteed that there will be multiple landcover types contributing to surface scattering within each footprint. The aircraft GNSS-R experiment presented here allows a more detailed assessment of GNSS-R’s forward-scattering geometry, and at a much higher spatial resolution. In particular, it allows for the quantification of the attenuation of the GNSS-R signal through specific canopy types, with less uncertainty introduced by mixed pixels. Other GNSS-R aircraft flight experiments have been done in the past (e.g., [15,16]), though these experiments were for the purpose of understanding the sensitivity of GNSS-R to soil moisture and typical agricultural crops and not for the purpose of sensing standing water under trees.This study will present GNSS-R data from the aircraft experiment over Caddo Lake and quantify the attenuation of the signal through the vegetation that typifies the Caddo Lake area to better understand the potential of GNSS-R to map inundation underneath different types of vegetation canopies. In order to put the results in the context of other remote sensing techniques, we will compare the results to those from Sentinel-1, a C-band SAR instrument that is routinely used to map inundation dynamics in wetland areas. Although it is well known that, in theory, L-band data should be able to penetrate further into a dense vegetation canopy and therefore be more sensitive to water underneath vegetation, there have been no quantitative assessments of the increased ability of GNSS-R to sense inundation relative to Sentinel-1 when the data collected by the two instruments are on a similar spatial scale. The comparison with Sentinel-1 will quantitatively show the increase in sensitivity of GNSS-R to inundation for specific wetland types relative to the more well-known and trusted Sentinel-1 data.", 1. Introduction,None,1.
257,"Keystone Ariel Survey, Inc. (Keystone) provided the aircraft, a Cessna 310, for this experiment, as shown in Figure 1a. Keystone also provided a pilot, while we ran the equipment, verified it was working in flight, and oversaw the data collection and flight plan. Most flight data were collected while flying at between 2.4 km (8000’) and 3 km (10,000’) altitude. The flight over the Caddo Lake region took place on 2 May 2017, and consisted of a flight in the morning, when large North/South (N/S) and East/West grids centered on Caddo Lake were performed. During the afternoon flight, another N/S grid at a lower altitude was performed, followed by multiple passes over the Northwest region of Caddo Lake, which has especially dense vegetation over the water. We separately toured this Northwest region that morning by boat to collect in situ data on inundation and tree density.", 2. Experimental Campaign , 2.1. Aircraft Flights,2
258,"The Cessna 310 had been modified to have a large hole on the underside of the aircraft, which was typically used by Keystone for their commercial optical surveys. For our experiments, Keystone removed their optical camera, and the hole covered with an aluminum plate hosting a 9-element, down-looking, patch array antenna, mounted flush with the airframe. Each patch antenna element provided dual polarization, horizontal and vertical (H/V), at both GPS L1 and L2 frequencies. We flew a custom open-loop recorder, capable of recording up to 40 MHz 1-bit samples from 32 channels. Our front-end electronics had eight antenna inputs, each electronically tunable to two simultaneous local-oscillator (LO) frequencies, resulting in 16 complex (I/Q) sampled data streams, or 32 single-bit sampled streams, matching our recorder’s capability. Figure 2 shows our instruments and down-looking antenna. The recorder was monitored in real time during the flight using a laptop computer.The Cessna had installed an up-looking commercial aircraft GPS antenna, mounted on top of the aircraft, along with a commercial Novatel GPS receiver, for its navigation system. We split the signal going from this antenna to the Novatel to gain access to the direct signal. For our experiments, we used seven of the eight antenna inputs, recording the H and V outputs from three of the down-looking patch antennas, along with the direct signal from the aircraft’s up-look antenna, all at both the GPS L1 and L2 frequencies. For the Caddo Lake experiment, we combined the H and V outputs from a 4th patch element to form a Left-Hand Circularly Polarized (LCP) signal, and recorded the GPS L1 and L5 frequencies from that patch element.Most of our data were collected with a sampling rate of 20 MHz, however, some 40 MHz sampled data were collected during the afternoon flight. Our sampled data was stored onto a disk array of SSD hard drives having a total capacity of 8 TB. This allowed about 15 h of continuous recording using a 20 MHz sampling rate.In addition to the patch antenna and corresponding recording system, we flew a downward-pointing optical camera fastened to the aluminum antenna mount over a small viewing hole, which took high quality optical images every 2 s. Finally, for aircraft positioning, we used the output from the Novatel receiver Keystone had installed on their plane.", 2. Experimental Campaign , 2.2. Flight Equipment,2
259,"After a preliminary examination of the data, it was clear that the theoretical antenna gain pattern being used for the downward-looking patch elements resulted in geometrically correlated inconsistencies in the resulting surface scattering coefficient. It was assumed that a measurement of the antenna gain pattern would help remove these effects. With limited funding, we chose to perform a simple antenna calibration experiment, differencing the measured gains between our flight antenna and a well-measured geodetic antenna while observing GPS signals as their positions in the sky moved over several hours.On 21 August 2018, both our 9-element patch array antenna and a well-measured geodetic choke-ring antenna were located near Jet Propulsion Laboratory’s (JPL’s) antenna range at a site with clear open sky views and few nearby objects to minimize multipath, as shown in Figure 1b. The antennas were placed up-looking, with the patch antenna configured as it was during flight, mounted on its aluminum plate with the same low-noise amplifiers (LNAs) on each antenna input. Data were collected as in the aircraft experiment, but with the aircraft’s up-looking geodetic antenna replaced with our choke ring antenna. Although these antennas were placed near each other, we did not observe any mutual coupling. We collected over 7 h of data in two continuous sessions, rotating the patch antenna 180 degrees in the second session for better azimuthal coverage. Since both antennas observed the same GPS transmitters and were located the same distance from them, the ratio of observed power between the antennas would be equal to the ratio of the antenna gains in that direction. By observing over several hours while the geometry of the transmitters changed, and knowing the gain pattern of the geodetic antenna, the patch antenna’s relative gain pattern over much of its beam pattern could be measured. The peak measured gain of the geodetic antenna was 6.8 dBIc while each linear polarization of a single patch was measured to have a peak gain of 5.4 dBIc.", 2. Experimental Campaign , 2.3. Antenna Calibration,2
260,"The 20 MHz and 40 MHz raw samples recorded from the aircraft’s usual GPS antenna on top of the plane were processed through a software GPS receiver. All of the GPS signals in view were detected and tracked with delay and phase locked loops. The models used to track these signals were recorded, along with the correlation results. The main processing pass for GNSS-R used these models derived from the direct signals to correlate with data from the down-looking patch arrays.All correlations were performed coherently each 20 msec. The correlations were performed while offsetting the data relative to the models by between −50 and +500 samples, or lags. The 550 correlations were computed for five Doppler values ranging from −2 to +2 times 39 Hz, using Fast Fourier Transforms (FFTs) and cyclic convolution for efficient computation. For an aircraft flying horizontally, the Doppler offset is close to zero—the additional offsets were to model slight upward and downward movements of the plane. The early correlations were computed to calibrate the system noise, while the later correlations covered the expected range of delays between the direct and reflected signal reception. The 500-lag range corresponds to a path delay of up to 7330 m, while all data were recorded below about 10,000’ altitude, or a maximum of 6100 m path delay. Due to the significant processing time to create (550 × 5) DDMs at 50 Hz, only three antenna inputs were processed: the direct signal from the plane’s up-looking antenna and the H and V signals from one of the three down-looking patches used in the experiment. The three DDMs were written to disk along with ancillary data each 20 msec for all GPS signals in view as the primary software-receiver output.The aircraft position was obtained by processing the aircraft’s Novatel GNSS receiver data through JPL’s Gipsy software, a state-of-the-art sub-cm GNSS navigation software used by hundreds of academic and industry partners and dozens of NASA space missions. A geometric model was developed by combining these receiver positions with a surface height model based on SRTM 1” (30 m) data, and JPLs GPS transmitter positions. The 50-Hz DDMs were combined incoherently into 10-Hz DDMs by summing the power from five consecutive DDMs. This was to increase the signal to power ratio (SNR), average down the measurement noise, and to reduce speckle for incoherent reflections. For each of these resulting DDMs, an iterative procedure was used to compute the corresponding specular point on the surface given the uneven surface topology. The output of this processing step consists of the 10-Hz DDMs’ peak power and corresponding delay and Doppler values for the three processed antenna inputs, along with noise estimates and geometric model information, including the specular point location.The peak power of the DDM is proportional to the surface reflectivity, however, it is also affected by other factors like system noise levels and receiver instrument gain. To mitigate these factors, the signal-to-noise ratio (SNR) was calculated, which is the peak power of the DDM normalized to a noise floor, which is defined as the mean cross-correlation before the leading edge of the reflection in the DDM.", 3. Data Processing, 3.1. Software Receiver and Geometric Modeling,3
261,"The antenna calibration data were also processed through the software receiver and the signal-to-noise ratio was averaged each 5 s, for both the patch antenna H and V outputs, and the geodetic antenna. In processing the choke-ring antenna data, a simple quadratic polynomial as a function of boresight angle was found to fit the data well, after accounting for an average transmitter power for each satellite, with scatter of the 5-sec residuals under 0.4 dB. This function also agreed with published measurements to better than 0.5 dB. This agreement gave confidence in the derived average transmit power values from each transmitter, which differed from each other by up to 4 dB.The patch antenna data were processed similarly, however the average transmitter power values were fixed to those found from the choke-ring antenna. Here, a clear azimuthal dependence was seen, and modeled with a simple sin(cos) of the azimuthal angle for the H(V) patch output with amplitude 4.2 dB, times the sin of the inclination angle. With these corrections, a quadratic polynomial fit the data reasonably well with 1.0 dB scatter. The power residuals showed slowly varying correlated trends from each transmitter on the order of 1 dB, presumably from multipath effects. Thus, the polynomial gain models for the patch H and V channels are likely good to better than 1 dB, but there may be 1 dB of systematic effects in the aircraft data.", 3. Data Processing, 3.2. Antenna Calibration Data Processing,3
262,"In assessing the observables to be used for inundation detection, two scattering models were considered, both assuming distributed targets (see [19] for a more refined scattering model): one where the signal is absorbed by the surface and retransmitted, and another where the surface is assumed flat and conducting. The first model follows the standard derivation of the radar equation [20], where the received surface-reflected power, 


P
r


, is given by





P
r

=



P
t


G
t



4
π

R

t
s

2



σ



A
r



4
π

R

s
r

2







(1)

The RHCP transmitted power, 


P
t


, is amplified by the transmitter’s antenna in the direction of the surface specular point with effective gain 


G
t


. The signal then suffers a free-space loss of 

4
π

R

t
s

2


 traveling from the transmitter to the surface, a distance of 


R

t
s



. The signal’s power is absorbed by the surface and retransmitted in the direction of the receiver from an effective cross-sectional area given by 
σ
. The signal suffers another free-space loss of 

4
π

R

s
r

2


 traveling the distance 


R

s
r



 from the surface to the receiver. The signal is then collected by the receiver with an antenna having effective area 


A
r


. This development ignores losses due to the atmosphere and instrumentation, and this equation holds separately for each polarization. Figure 7.1 in [20] shows the geometry explicitly.The second model assumes the surface approximates a flat conductor, so the signal travels from the transmitter to the receiver’s mirror image below the surface a distance 


(


R

t
s


+

R

s
r



)


, and suffers an attenuation expressed as the reflectivity 


Γ
r


 at the surface. The received power is then given by





P
r

=



P
t


G
t


Γ
r


A
r



4
π



(


R

t
s


+

R

s
r



)


2







(2)

At the aircraft altitudes used in these experiments, 


R

s
r



 is much smaller than 


R

t
s



, and can be neglected in Equation (2). With that change, the difference in the two scattering models is in how the signal interacts with the surface and travels to the receiver. In the first, the signal power is reradiated from an effective area 
σ
 and suffers a free-space loss traveling to the receiver, while in the second model, the signal reflects coherently with surface reflectivity 


Γ
r


. The surface reflectivity will change depending on the surface dielectric constant (e.g., wet vs. dry ground) and the roughness of the surface. Surface reflectivity is also expected to be attenuated by overlying vegetation canopies.Both models can be expressed as





P
r

=



P
t


G
t


G
r


λ
2





(
4
π
)

2


R

t
s

2



α




(3)


where 
λ
 is the 0.19 cm GPS L1 wavelength, and 
α
 is given by:



α
=

σ

4
π

R

s
r

2







(4)


for the former, incoherent model and 

α
=

Γ
r


 for the latter, coherent model, and 


G
r


 is the gain of the down-looking reflection antenna. A model for the expected received power from the direct transmitter-to-receiver signal is given by:




P
d

=



P
t


G
t


G
d


λ
2





(
4
π
)

2


R

t
r

2







(5)


where 


P
d


 is the received direct-signal power, and Gd is the gain of the up-looking antenna mounted on top of the aircraft.", 3. Data Processing, 3.3. Scattering Model,3
263,"The surface spot size that is sensed by a coherent GNSS-R reflection has been assumed to be given by the size of the Fresnel zone [20], which is typically defined to be the iso-delay ellipse corresponding to a wavelength delay compared to the specular arrival (some authors use 1/2 wavelength). The major axis of an iso-delay ellipse corresponding to a delay (distance) of 

Δ
,

 is: 



a
=

1

cos
θ






2
Δ

R

t
s



R

s
r





R

t
s


+

R

s
r






≅




2
Δ

R

s
r






cos
θ






(6)


while the minor axis is given by the same expression without the cosine term, and 
θ
 is the surface incidence angle.", 3. Data Processing, 3.4. Surface Spot Size,3
264,"The received power values from the Caddo Lake aircraft passes, which were taken as the peak values from the 10 Hz DDMs, were divided by the received power from the aircraft’s up-looking antenna. Dividing Equation (3) by Equation (5), this ratio is given by:






P
r




P


d
 





=



G
r




G
d



α




(7)


where 


R

t
r



/


R

t
s



 is taken to be one. By computing this ratio, the effects of unknown GPS transmit power and gain are canceled out. Correcting for the direct and reflected antenna gains, the calibrated power 


P

c
a
l



 results in an estimate for 
α
:






P

c
a
l


≡



P
r


G
d




P
d


G
r





=
α
~

σ


R

s
r

2



 
(
incoherent
 
scattering
)






=
α
~



 
Γ


r

 
(
coherent
 
scattering
)







(8)


where 
~
 denotes proportionality. Note that 


P

c
a
l



 is not a calibrated power in the usual sense, but an SNR that is proportional to 


P
r


 in Equation (2). By mapping spatial changes in 


P

c
a
l



, we can thus relate them to spatial changes in the surface reflectivity. Our dataset included GNSS-R reflections from the following PRNs: 3, 7, 8, 9, 11, 14, 16, 22, 23, 26, 27, 28, 30, and 31. Data were obtained from a range of incidence angles (min: 10.7 deg, max: 60 deg, mean: 34.7 deg). No notable relationship between 


P

c
a
l



 and incidence angle was observed.", 4. Analysis Data Sets, 4.1. Caddo Lake Calibrated Data,4
265," 4.2.1. Sentinel-1 DataSentinel-1 data for 8 May 2017 was obtained from the University of Alaska Fairbanks Vertex data portal, which was the overpass closest in time to the aircraft flight. The Sentinel-1 toolbox (S1TBX) was used to process the data, following the recommended practices set forth by the United Nations Office for Outer Space Affairs [21]. VV-pol amplitude data were calibrated to produce sigma nought values, and these were speckle filtered using a 7 × 7 Lee filter. Finally, speckle-filtered sigma nought values were geometrically corrected and re-projected using the digital elevation model from the shuttle radar topography mission (SRTM). 4.2.2. Landsat ImageryLandsat 8 data were obtained over Caddo Lake for 8 May 2017, which was the overpass closest in time to the aircraft flight. The Level 1 geotiff data product was converted into an RGB image using the band specific multiplicative and additive rescaling factors and corrected for the sun elevation angle using values within the metadata. The resulting 30 m image was pan-sharpened to 15 m. The Landsat 8 image identifies the extent and location of floating Giant Salvinia mats in Caddo Lake at the time of the flight experiment. 4.2.3. Landcover Classification MapLandcover classification data for the Caddo Lake area were obtained from the Caddo Lake Institute, which simplifies the National Wetlands Inventory (NWI) habitat data into seven categories [22]. Here, we use both the NWI definitions as well as the simplified landcover categories to describe the different environments in Caddo Lake. Table 1 shows the wetland classes and respective abbreviations.", 4. Analysis Data Sets, 4.2. Ancillary Data,4
266,"Sentinel-1 data for 8 May 2017 was obtained from the University of Alaska Fairbanks Vertex data portal, which was the overpass closest in time to the aircraft flight. The Sentinel-1 toolbox (S1TBX) was used to process the data, following the recommended practices set forth by the United Nations Office for Outer Space Affairs [21]. VV-pol amplitude data were calibrated to produce sigma nought values, and these were speckle filtered using a 7 × 7 Lee filter. Finally, speckle-filtered sigma nought values were geometrically corrected and re-projected using the digital elevation model from the shuttle radar topography mission (SRTM).", 4. Analysis Data Sets, 4.2.1. Sentinel-1 Data,4
267,"Landsat 8 data were obtained over Caddo Lake for 8 May 2017, which was the overpass closest in time to the aircraft flight. The Level 1 geotiff data product was converted into an RGB image using the band specific multiplicative and additive rescaling factors and corrected for the sun elevation angle using values within the metadata. The resulting 30 m image was pan-sharpened to 15 m. The Landsat 8 image identifies the extent and location of floating Giant Salvinia mats in Caddo Lake at the time of the flight experiment.", 4. Analysis Data Sets, 4.2.2. Landsat Imagery,4
268,"Landcover classification data for the Caddo Lake area were obtained from the Caddo Lake Institute, which simplifies the National Wetlands Inventory (NWI) habitat data into seven categories [22]. Here, we use both the NWI definitions as well as the simplified landcover categories to describe the different environments in Caddo Lake. Table 1 shows the wetland classes and respective abbreviations.", 4. Analysis Data Sets, 4.2.3. Landcover Classification Map,4
269,"It has been assumed that the received power from GNSS-R signals reflecting from water are coherent and follow the scattering model given by Equation (2) [11,23]. We attempted to verify this by selecting data over the open-water portions of Caddo Lake, which should show a relatively constant calibrated power level, and assessed whether 


P

c
a
l



 or 


P

c
a
l



R

s
r

2


 fit the data better. The 


P

c
a
l



 values should ideally show a constant value, however there are systematic effects at the 1–2 dB level that appear correlated with the plane’s direction. Since strong wind currents were encountered during the experiment, these systematics may be related to the plane’s unmodeled orientation, and thus, an unmodeled change in the antenna gain. Despite these systematic changes in power, the standard deviation of the open-water data was 2.2 dB for 


P

c
a
l



 but 2.8 dB for 


P

c
a
l



R

s
r

2


, indicating the coherent model was favored. There was also one satellite (PRN 16) that was visible in both the 3 km (10,000’) and 2.4 km (8000’)-altitude grids. The difference in average 


P

c
a
l



 between these grids for that satellite was 1.0 dB while the difference in average 


P

c
a
l



R

s
r

2


 was 3.8 dB. Again, the coherent scattering model seems favored, and is assumed below.", 5. Results, 5.1. Scattering Model,5
270,"We performed a data search for ground tracks passing cleanly from water to land, or tracks passing over a river or small lake. Measuring the transition time as the power level rises or falls, and knowing the receiver velocity, we can estimate the surface spot size. We found several dozen examples, all showing approximately the same rise and fall times, and present one example here.Figure 3 and Figure 4 show an example track over three bodies of water—a small pond, an inundated area, and a river. The track over the pond and river are reasonably clear and can be used to estimate the surface spot size, while the inundated area’s extent is uncertain due to overlying vegetation. The total duration of the pond and river crossings are approximately 0.8 s and 1.6 s, and their sizes under the track are about 31 m and 72 m, respectively. With an aircraft velocity of 81 m/s and assuming a simple boxcar (step-function) model for the spot, the spot size is estimated to be 34 m from the pond data and 58 m from the river data. This scene was chosen because it exemplifies the range of sizes deduced for essentially all the clear water transitions and crossings observed. Figure 5 shows a blowup of these crossings with their respective spot sizes indicated as yellow ellipses. The spots shown also account for the 33° incidence angle and the reflection plane being 170° CCW from the velocity vector. Both crossings have vegetation, flat open land, and/or buildings nearby, which can affect the measurements. With 


R

s
r



 being within a few meters of 3130 m over this track, Equation (6) would predict the spot size along the track to be about 41 m, which is in good agreement with the observed values, given the boxcar model approximation and measurement uncertainties.", 5. Results, 5.2. Estimate of Surface Spot Size,5
271,"Figure 6a shows a pansharpened RGB image of the Caddo Lake area. Superimposed yellow lines are the paths the boat took concurrently with the GNSS-R flight. This region, the northwestern corner of Caddo Lake, is the area where inundated cypress forests are abundant. Giant Salvinia appears light green in the image shown in 6a.Figure 6b shows a landcover classification map of Caddo Lake [22]. Abbreviated classes shown in legend are expanded in Table 1. The northwestern region of Caddo Lake contains a variety of intermittently, seasonally, semi-permanently, and permanently inundated cypress forests, scrub-shrub wetlands, and emergent species. The moving transient mats of giant Salvinia are not included in the landcover map. At the time of the aircraft experiment, they were prevalent predominantly in the areas denoted as permanently flooded cypress forests (PFCF1) but were also found in the semi-permanently flooded cypress forests (CF7/CF5), which can be seen in the Landsat 8 image in Figure 6a.Selected photos depicting the conditions of Caddo Lake at the time of the aircraft experiment are shown in Figure 6c–e, and their respective locations are indicated by the colored dots in 6a. Figure 6c,d show typical cypress forests with a mixture of open water and giant Salvinia underneath the cypress trees. Figure 6e,f show two locations where giant Salvinia mats were particularly thick—the mats in 6f were thick enough to prevent further passage of the boat. Part of this analysis will show the effect of this aquatic vegetation on the ability for both C- and L-band signals to sense the underlying water.Figure 7 shows GNSS-R data (LHCP transmit, V pol received as well as LHCP transmit, Hpol received) collected during the flight experiment (a,b) and C-band data from Sentinel-1 (c; VV polarization). The Sentinel-1 data were collected on the same day as the Landsat image (Figure 6a), 8 May 2017. We do not expect there to have been significant variation in the inundated areas within and around Caddo Lake in the six days that spanned between the aircraft experiment and the acquisition date of the Sentinel-1 and Landsat data. Here, and in all figures that follow, we present the GNSS-R data as their values relative to their mean value over the upland landcover class (abbreviated U). In other words, we subtract the mean value obtained for observations falling over uplands from all observations. We do this in order to more clearly show the sensitivity of the GNSS-R signal to different wetland types. Overall, GNSS-R data from both V and H pol are very similar to one another, though on average the H pol data showed higher Equation (8)’s Pcal by 1.7 dB.From Figure 7c, it is clear that the open water towards the eastern side of Caddo Lake is easily distinguishable in the Sentinel-1 data, apparent in the low sigma nought values. As stated above, low sigma nought values can indicate a very flat surface (e.g., smooth water) that results in little to no backscattering. As expected, the GNSS-R data in Figure 7a,b show the converse of this: the smooth open water on the eastern side of Caddo Lake produces high observed Pcal. The northwestern side of Caddo Lake, with both cypress trees and giant Salvinia to obscure the water, is a more complex scattering environment. There is no qualitative distinction between the flooded cypress forests in the northwest and the surround upland areas, at least not as obvious of a distinction as that between the open water to the east and nearby uplands. There appears to be higher Pcal in the northwestern flooded forests relative to surrounding uplands, but without complete spatial sampling, this cannot be definitively concluded without a quantitative analysis.In order to quantify the sensitivity of both the GNSS-R aircraft data and that from Sentinel-1 to water obscured by vegetation, we first binned the observations by the landcover classes shown in Figure 6b. When binning the Sentinel-1 observations, we only used the data that corresponded to the locations where the GNSS-R data were collected, such that a direct comparison could be made. We calculated the mean and standard deviation of the sigma nought and Pcal observations within each landcover class, and we show this in Figure 8. For this analysis we again show GNSS-R data relative to its mean value over the upland land cover class, and now we show Sentinel-1 data also relative to its own mean value over uplands. Thus, for both the GNSS-R and Sentinel-1 data, the upland class (U) is plotted with a value of 0, and all other classes are relative to this value. Since results for the GNSS-R V- and H-pol data were so similar, the following results are described for only the V-pol data, though the H-pol data may be seen in Figure 8.First, we focus on the sensitivity of the GNSS-R and Sentinel-1 data to the open water (OW) class, relative to uplands (U). Both show a several dB change between the classes: the mean increase in Pcal between uplands and open water was 13.61 dB, and the mean decrease in backscattering was 8.55 dB. In both the GNSS-R and Sentinel-1 data, the landcover class that came closest to open water was the intermittently exposed cypress forests (CF6). This type of landcover is only found in a very small portion of Caddo Lake—it is in the extreme northeastern part of the lake shown in Figure 3b. Although the sample size is small (n = 64), it appears that there is no attenuation of the GNSS-R signal through the vegetation canopy, as the observed mean Pcal was actually 1.29 dB higher than that observed over open water. This could indicate that the vegetation sheltered the water surface from any slight roughening from the wind, though given the relatively large standard deviation of the observations, the difference between open water and this vegetation class was small. The Sentinel-1 data show some attenuation through the vegetation, as there was a 4.4 dB increase in backscattering in the Sentinel-1 data.Pcal over the permanently flooded cypress forests (PFCF1, n = 8345) also showed a high signal, only 2.15 dB lower than Pcal over open water. Sentinel-1 data over this landcover class was 6 dB higher than that over open water and 2.5 dB different than the backscattering over uplands. We attribute changes in the GNSS-R signal and Sentinel-1 data mostly to the presence of the giant Salvinia mats, and only partially to the presence of cypress trees in this class, as the spacing between the trees in this class is usually at least 50 m, which is more than the spatial resolution of both the GNSS-R and Sentinel-1 data. This indicates that there is some attenuation of the forward-scattered L-band signal through the giant Salvinia, but only 2.15 dB. For the backscattered C-band signal, the giant Salvinia geometry or biomass is not sufficient to produce a double bounced signal, but the vegetation itself is dense enough to produce significant backscatter, which makes the signal closer to that from upland rather than open water.Another notable landcover class was the semi-permanently flooded cypress forests (CF5, n = 1781), which produced a Pcal of 8.3 dB higher than upland, and a sigma nought of 0.14 dB below the upland value. We again attributed this to the extensive presence of giant Salvinia in these areas at the time of acquisition.In the densest cypress forests (CF8, n = 3816), we still saw a mean Pcal value 4.25 dB above the upland value, which was an indication that at least some of these forests were likely inundated. The sigma nought value was 0.5 dB higher than that for uplands. Despite the fact that parts of these forests were flooded, and the cypress trees having significant geometric components that might at L-band produce double bounce, it appeared that the C-band signals were not able to penetrate these types of canopies. Similar conclusions could be drawn for the other landcover classes in and around Caddo Lake.The only notable distinction between the GNSS-R Pcal H-pol and V-pol data in terms of sensitivities to different landcover classes is the difference in mean Pcal over the EM1 landcover class (emergent reeds, semi-permanently flooded). In this case, the V-pol data show a few dB increase relative to the upland landcover class, whereas the H-pol data show a slight decrease relative to uplands. After closer examination, we found this single class to be misidentified, and instead of emergent reeds it should have been classified as uplands.", 5. Results, 5.3. Caddo Lake,5
272,"Exploring the sensitivity of the GNSS-R signal to different wetland types based on a static landcover map is inherently an imperfect exercise. For example, just because the landcover map classifies an area as ‘semi-permanently flooded’ does not mean it actually was flooded during the flight experiment. Due to the extremely dense nature of the vegetation in Caddo Lake, it was not possible to conduct an extensive survey of flooded areas. In particular, we found many misclassifications of open water (OW) after comparing the Landsat 8 image and Google Earth images to the landcover classification map. These misclassifications were primarily small ponds to the north of Caddo Lake which had dried up or been converted to uplands in the time since the wetland inventory was conducted in 1983. These misclassifications can be seen in Figure 8, which also contains the mean Pcal value for individual landcover regions (i.e., each region classified as a particular landcover class instead of the class as a whole), indicated by the grey dots. Some individual regional averages for the open water (OW) class are quite low compared to the total average—these are the misclassified regions.We plotted all individual region averages for each landcover class in Figure 8, not just for open water. For the most part, these regional averages cluster together, with individual region averages in the Sentinel-1 data mimicking what is observed in the GNSS-R data. A notable exception to the overall clustering of individual regions is for the EM2 (emergent reeds) class. In this case, there were two small clusters of observations over two different areas classified as EM2 in the southeast portion of Caddo Lake, separated by a larger region classified as CF7 (cypress forests). The cluster of observations closer to open water had a much higher mean Pcal V-pol than the cluster of observations adjacent to the upland/dry land. We interpret this as meaning that the cluster of observations in the EM2 region close to open water were probably responding to water underneath the reeds, whereas the reeds closer to the uplands/dry lands might have been dry. By considering these observations as being a part of one group only, a large standard deviation is the result.", 6. Discussion,None,6
273,"From this aircraft experiment we have shown the scattering model in Equation (2) was appropriate for inundation and that the spot size in this case was approximately the Fresnel zone. From a comparison of L-band GNSS-R data with C-band Sentinel-1 data, we could conclude the following: The GNSS-R signal was able to penetrate the dense cypress canopies that typify Caddo Lake and other swamps in the southeast United States. There were several dB of attenuation, but the signal was still significantly higher than that over dry land. In addition, the presence of giant Salvinia only minimally attenuates the GNSS-R signal by ~2 dB. C-band backscatter data, on the other hand, was significantly attenuated by both of these vegetation types. This study was not able to conclude whether L-band backscatter signals, such as those collected by PALSAR-2, would be able to detect water underneath these types of vegetation, as there were no data publicly available. This study also did not quantify the saturation point for GNSS-R with respect to vegetation, as the GNSS-R signal was able to penetrate the vegetation canopies overflown here. Future GNSS-R aircraft flights, which could fly over denser vegetation canopies, might be able to quantify the saturation point, if there is one. Future studies should also focus on obtaining coincident L-band backscatter data, which could identify the relative strengths of the two data types without wavelength being a confounding factor.", 7. Conclusions,None,7
274,"Forests act as one of the main terrestrial carbon sinks [1]. Monitoring forest changes and estimating forest biomass are therefore mandatory for several applications, including studies on global changes, natural disaster prevention, and management of forest resources. The possibility to observe forests from satellite and/or aircraft instruments is thus very attractive. In this respect, Synthetic Aperture Radar (SAR) has proven to be a suitable instrument for forest investigations. The SAR capability of estimating several forest parameters, such as forest density, tree height, and forest biomass, was demonstrated in several studies (e.g., [2,3,4,5,6,7,8,9,10,11]). The SAR capability of observing forest parameters depends on the operating frequency, that is, at microwaves, the sensitivity of low frequencies (i.e., P- or L- band) to forest biomass was largely proven [12,13,14]. The sensitivity increases with the wavelength, that is, at L band, the relationship between the backscattering coefficient (σ°) and biomass is logarithmic, and a saturation is shown for biomass values higher than 100–150 t/ha [15,16]. Some research has also pointed out a decrease of the signal for biomasses above this threshold [17]. At P-band, previous experiments and model simulations pointed out that saturation occurs for biomass values higher than at least 300–350 t/ha (e.g., [15]). Research has also demonstrated that, depending on the penetration capability, P-band is better related to the trunk and stem biomass, whereas L-band is better related to the crown biomass [18,19]. At present, only few SAR data at P-band are available, mainly from airborne campaigns, and therefore the potential of this band has not yet been fully exploited. A significant improvement in the remote sensing of forests is therefore expected with the upcoming BIOMASS satellite mission of the European Space Agency (ESA), carrying onboard an SAR operating at P-band [20].Waiting for BIOMASS, research mainly focused on L-band and on the few data available at P-band from airborne campaigns. The L-band SAR backscatter variability in tropical forests was assessed using ALOS-2/PALSAR-2 data collected on the entire tropical forest region from 2016 to 2018 [21]. The authors in [22] investigated the relationship between polarimetric SAR backscatter at L- and P-bands and forest biomass using data acquired within the BioSAR1 ESA campaign in southern Sweden, and they attempted the retrieval with regression methods. At L-band, the biomass was estimated with a root mean square error (RMSE) between 31% and 46%, whereas P-band exhibited better retrievals, with RMSE between 18% and 27%.The retrieval of forest biomass in northeast Costa Rica was addressed by the authors in [23], using P- and L- band SAR data acquired by the AIRSAR NASA/JPL airborne SAR system in March 2004. By using algorithms based on polarized radar backscatter, they estimated forest biomass with RMSE = 22.6 t/ha for biomass < 300 t/ha at P-band and RMSE = 23.8 t/ha for biomass < 150 t/ha at L-band.Tomographic applications have also been considered, thanks to their capability of separating the contributions of several layers of vegetation and soil surface. The potential of TomoSAR data at L-band to monitor temporal variations of forest structure was addressed by using simulated and experimental datasets in one study [24]. In another study [25], the application of tomography to SAOCOM L-band SAR data allowed the retrieval of biomass using a single polarization (HH) with a 26–30% RMSE and a small effect from the observation geometry and local topography.The potential of machine-learning (ML) methods for addressing forest biomass retrieval is evaluated in this study. Depending on its ability to solve nonlinear problems, ML has been previously employed for the retrieval of surface parameters from remote sensing data, providing more accurate results than other methods (e.g., [26,27,28]).In this framework, both Artificial Neural Networks (ANNs) and Supported Vector Regressions (SVRs) demonstrated their potential in addressing the retrieval of surface parameters, showing their peculiar capability of combining inputs from different sources for addressing the retrieval.ANNs have been already applied to several remote sensing problems (e.g., [29,30,31]), demonstrating a good trade-off between retrieval accuracy and computational cost. Past studies have pointed out that the availability of an extensive reference dataset for training the ANN is the main constraint for obtaining satisfactory retrievals (e.g., [32]). However, only a few examples of ANN applications to the retrieval of forest biomass are available in the literature, and in a couple of these [33,34], ANN were applied to retrieve the forest biomass in Mediterranean areas by combining L- and C- band SAR data.SVR is another method of machine learning that has gained an increasing interest in the remote sensing of geophysical variables [35,36], thanks to the flexibility and robustness to noise in the training data. SVR was successfully applied to the retrieval of surface parameters by the authors in [37], where this method was also compared to ANN.In this study, two algorithms for the retrieval of forest biomass, based on ANN and SVR, respectively, were implemented and validated using P- band polarimetric airborne SAR data acquired by the ESA during the BioSAR, AfriSAR, and TropiSAR campaigns [38,39,40,41,42,43]. Inputs of both algorithms are the polarimetric SAR backscattering, and output is the biomass. Considering the dependence of SAR measurements on the acquisition geometry [44,45,46,47], both algorithms have the local incidence angle (LIA) as additional input.The paper is organized as follows. Section 2 gives an overview of the test areas and the datasets considered in this study. The ANN- and SVR-based retrieval algorithms are presented in Section 3. The sensitivity of SAR measurements to forest biomass is described in Section 4. The algorithm validation is presented in Section 5, the obtained results are discussed in Section 6 and conclusions and future work are presented in Section 7.", 1. Introduction,None,1.
275,"The entire dataset made available by the ESA in the framework of the Biomass Retrieval Algorithm Inter-Comparison Exercise (BRIX) [48] was considered for implementing, training, and validating both the ANN and SVR algorithms. BRIX is an initiative promoted by the ESA that is intended to intercompare different approaches for retrieving forest biomass from P- band fully polarimetric SAR sensors. The BRIX dataset was composed of the P-band polarimetric SAR data acquired during the airborne experiments carried out in preparation for BIOMASS. The calibrated and geocoded backscattering data from each campaign were delivered by the ESA through the “Testbed”, as described in the BRIX documentation [48]. We referred to the support documentation of each campaign for the description of the SAR data processing and of the in situ biomass measurements [38,39,40,41,42,43]. The main dataset was derived from the joint NASA and ESA AfriSAR experiment, which was conducted in Gabon. The experiment was composed of two campaigns—the first was carried out in 2015 with the ONERA (Office National d’Études et de Recherches Aérospatiales) SETHI SAR system and the second one in 2016 with the NASA (National Aeronautics and Space Administration) Land Vegetation and Ice Sensor (LVIS) LiDAR, the NASA L-band UAVSAR, and the DLR (German Aerospace Center) F-SAR [38]. The area covered by the flights was composed of four test sites. The main site was located in Lopé National Park (0.5° S, 11.5° E), a UNESCO World Heritage site protected since 2007, in which high closed-canopy forests are merged with open savannas. SAR campaigns were carried out in three more sites, including the protected area of Mondah, close to Libreville (0.6° N, 9.6° E), the Mabounié mining site (0.7° S, 10.7° E), and the Rabi site (1.9° S, 10° E). In Mondah, integer patches of forest are mixed with others significantly disturbed by human activities. Mabounié is forested for the most part but with traces of ongoing building, while Rabi is an onshore oil-drilling site in which some areas were preserved. Ancillary LiDAR measurements were collected for generating biomass maps at 50 m to be used for validation. Direct biomass measurements were also carried out on a total of 12 plots of 50 × 50 m (33 subplots of 25 × 25 m) for calibration and validation purposes.The other datasets were derived from the three BioSAR campaigns [39,40,41] and from the TropiSAR campaign [42,43]. The data included biomass values up to 500 t/ha, being representative of forest types that included boreal and equatorial forests. The datasets also included very low biomass values, clearly referring to non-forested areas. These data were kept in the training to make the algorithms capable of identifying the low vegetated areas as well. All the test areas had flat or gently undulated topography. For instance, the La Lopé area included a 600 m tall hill rising over a 200 m ground: thus, the effect of local slopes on the measured σ0 was accounted for by including the LIA in the algorithm inputs.By combining all the available data, a dataset was obtained composed of about 4500 sets of backscattering coefficients (σ°) at four polarizations (HH, HV, VH, and VV), as well as corresponding LIA and biomass values from LiDAR or in situ measurements.The ANN and SVR algorithms were trained by dividing the entire BRIX dataset into two parts, or the subsets of each campaign in the case of specific algorithms. The training set was composed of 50% of the entire dataset, while the other 50% was used for validating the algorithms. The flowchart in Figure 1 shows how the training and validation sets were obtained. The interleaved sampling was also evaluated for dividing the dataset; however, negligible differences were obtained in the training and validation results. It should be mentioned that the sampling cannot be considered purely random in the case of the general algorithm, since the training and validation sets are obtained by combining together the specific sets randomly sampled, so the general training and validation sets include the 50% of data from each campaign.", 2. Experimental Sites and SAR Data,None,2
276,"ANN can be regarded as a statistical method based on the minimum variance, which is able to approximate the existing relationship between the given input(s) and output(s) [49,50].The core of the algorithm is based on the Feedforward Multi-layer Perceptron Artificial Neural Networks (MLP-ANNs) available in the MATLAB® Neural Networks toolbox. In MLP-ANN, each neuron is connected to all the other neurons of the previous and following layers. The connections are weighted and biased by coefficients that are iteratively adjusted during the training, thus modifying the strength of every connection. In each neuron, the inputs are weighted, biased, and added each other to produce an output value, called activation, which is then passed through the so-called transfer function and moved to the neurons of the following layer. In this study, transfer functions of linear, hyperbolic tangent sigmoid (tansig), and log-sigmoid (logsig) types were considered.The weights and biases were adjusted by the Back Propagation (BP) learning rule, namely BP is a gradient descendent algorithm aimed at minimizing the Mean Square Error (MSE) between the ANN output and the desired value.In the implemented algorithm, ANN inputs were the SAR backscattering coefficients (dB) at all polarizations (HH, HV, VH, VV) and the corresponding local incidence angle (LIA), and output was the forest biomass (t/ha). It is worthy to mention that, according to the reciprocity property of passive targets for monostatic observations, no difference was found in using one or the other cross-polarized channel, and therefore the two cross-polarized channels were provided to the algorithms as mean average. Several combinations of inputs were evaluated, by implementing specific algorithms for each dataset (AfriSAR Onera, AfriSAR DLR, BioSAR, and TropiSAR), and a general algorithm which was trained and validated on the entire dataset.The training set was further divided into 60%, 20%, and 20% by using random sampling [32]. The ANN training was carried out on the first subset, using BP for adjusting the ANN parameters. The other two subsets were used for a posteriori tests at each training iteration. The “early stopping” rule was applied for preventing overfitting, that is, training stops as soon as the errors on the three subsets are diverging.The best dimensioning of ANN, in terms of number of neurons and hidden layers, is obtained by iteratively increasing the number of neurons and hidden layers from one hidden layer, with a number of neurons equal to the number of inputs, and up to two hidden layers, with a number of neurons each equal to three times the number of inputs. The training of each configuration is repeated 100 times for each transfer function, by resetting each time the initial ANN weights. At the end of the iterations, the results are compared and the ANN giving the highest correlation estimated vs. target is chosen as optimal. Such systematic optimization helps in preventing both underfitting and overfitting; underfitting occurs when the ANN architecture is too simplistic for the given problem, and overfitting happens when the ANN architecture is overly complex and it also fits the noise in the training set, causing large errors when applied to other datasets.It should be noted that the training described here is carried out one time only; after training, the ANN is saved and loaded again to be applied to the validation set and, in this case, to any new datasets. Since the training is the only time-consuming step of the implementation, the algorithm can be applied to new data in near real time.Moreover, the training can be updated every time new training sets are available, for improving the retrieval accuracy. This represents a unique feature of the ANN and, in general, of the data-driven approaches based on machine learning, in comparison to the conventional retrievals that are based on the inversion of electromagnetic forward models.The validation, to which the results presented in Section 5 refer, was obtained by applying the saved ANN to the validation set, which was not involved in the training, to keep training and validation as independent as possible.", 3. Retrieval Methods, 3.1. ANN,3
277,"The second machine-learning approach to the retrieval was based on the Supported Vector Regression (SVR) techniques. Similarly to ANN, past research has proven the SVR capabilities for remote sensing applications (e.g., [36,51]). SVRs were demonstrated capable of handling complex and nonlinear problems and of managing different kinds of inputs. While neural networks can handle nonlinear problems having only a large training dataset, SVRs can achieve high accuracies, even if few training data are available [51]. Actually, SVRs overcome this limitation because they are based on a geometrical concept [52]. The method uses a so-called kernel function, for mapping the m-dimensional input space of the original problem into a higher dimensional space, in which the function underlying the data can be linearly approximated.While neural networks try to populate the feature space with as many data as possible considering all the available combinations of inputs and outputs for mapping the functions, SVRs aim at identifying the boundaries of the tolerance tube around the input data to map the function without the need of larger datasets [53].The problem of retrieving the biomass from the P-band backscattering at different polarizations was set as follows:




y
=
f

(


x
1

,

x
2

,
…
.

x
m


)

+
e




(1)


where f is the desired function, y is the biomass, x1, x2,... xm is the backscattering coefficient at different polarizations, and e is the white noise. The y estimation is obtained by determining the mapping function f′ as close as possible to the true mapping f for the given problem [37]. Given a set of N reference samples {xi, yi |i=1,…N}, the ε-insensitive SVR attempts to identify a smooth function f′ approximating f while keeping at most ε deviation from the targets yi [54]. f′ is obtained by mapping the input domain at m-dimensions into a higher dimension feature space, in which the function flatness is increased. In the new space, f′ can be linearly approximated, according to the following equation:





f
′


(
x
)

=
w
·
Φ

(
x
)

+
 
b




(2)


where w represents the weights of the linear function, Φ is the mapping function that transforms the samples into the higher dimensional space, and b is the bias.The cost function combining the training error and the model complexity is minimized to obtain the optimal linear function in the transformed feature space [36]. The loss function f′ is ε-insensitive— ε being the tolerance to errors, f′ ensures that losses smaller than ε are neglected [53]. An example of a possible choice of the ε-insensitive loss function is shown in Figure 2. The second term of Equation (2) is computed as the Euclidean norm of the weight vector w. The latter is inversely related to the geometrical margins of the solution and therefore to the model complexity [36]. A regularization parameter C is also introduced with the scope of adjusting the trade-off between the complexity (flatness) of the function f’ and the tolerance to the empirical errors. We referred to [37] for the detailed mathematical formulation.The training phase acts on reference samples composed by field data coupled with remote sensing data, to train the SVR algorithm and tune the kernel parameters C and ε. This process is called model selection [53]. During the training phase, the SVR algorithm uses a subset of the training dataset, called the test dataset, to tune its performances step by step. After this phase, the algorithm is applied to the validation set for evaluating the algorithm performances on independent data. At this point, the learning phase is over and the regressor can be used (operational estimation phase). The trained SVR is a good approximator of the mapping function between input data, which in this case are represented by HH, VV, HV, and VH P-band backscattering, and the target variable represented by the biomass. The separation among training, test, and validation follows the same approach proposed for ANN.Similar to ANN, specific SVR training regressors were computed from each of the missions provided in the input dataset, while a general SVR training regressor was computed from the entire dataset. The input/output configuration is the same of ANN—algorithm inputs are the backscattering coefficients at all polarizations (HH, VV, HV, VH), while the output is the forest biomass.", 3. Retrieval Methods, 3.2. SVR,3
278,"A sensitivity analysis was carried out to understand the relationship between σ° and forest biomass for all the experimental data available in BRIX.The analysis of the BRIX dataset confirmed the sensitivity of σ° to the forest biomass; the direct sensitivity of σ° at each polarization to forest biomass for the AfriSAR dataset is shown in Figure 3. The plots show an increase of σ° when biomass increases up to 500 t/ha, although some saturation is evident for biomass values higher than 300–350 t/ha, as already pointed out by previous research (e.g., [15,16]).The backscattering however does not saturate completely, and some increase with biomass can also be observed beyond this threshold. All scatterplots exhibit vertical clustering of σ°; this depends on the σ° variability between the different SAR acquisitions in each test area that composed the dataset. Moreover, the same values of in situ biomass correspond to different subareas and, therefore, to different σ° values, depending on the spatial variability of forest structure and on the speckle [23]. This further increased the spread of data.The results of the sensitivity analysis conducted on the entire BRIX dataset is shown in Figure 4, where the backscattering at the four polarizations is represented as a function of the in situ biomass.Different colors correspond to different campaigns (AfriSAR, BioSAR, TropiSAR), showing some separation of the data coming from the different campaigns. In particular, at least two different clusters can be identified, one including the AfriSAR and TropiSAR data and one including the BioSAR data. These clusters can be explained by considering the differences in the instrumental setups and calibrations of the different SAR instruments used in the campaigns [38,39,40,41,42,43].The analysis of correlation coefficients (R) reflects this behavior, with higher correlation when considering the AfriSAR dataset (R from 0.64 to 0.76) and low values when considering the entire dataset (R from 0.16 to 0.34). The R values for each campaign are summarized in Table 1.Table 1 points out that the three BioSAR datasets have the worst correlation to in situ biomass. This can be attributed to the boreal forest type, which is characterized by more sparse trees and lower biomasses. Therefore, soil and undergrowing vegetation are expected to contribute to the total backscattering. The correlation computed by grouping the three sets slightly increases (0.17 ≤ R ≤ 0.24) but is still very low. Depending on the lower biomass range, σ° saturation was not observed in the BioSAR datasets.The dependence of the relationship σ°–biomass on the site characteristics suggested that, along with a general algorithm able to apply to all datasets, specific algorithms for each dataset improve the retrieval performances.", 4. Data Analysis,None,4
279,"The ANN algorithm validation is summarized in the plots of Figure 5. Each scatterplot shows the predicted vs. in situ biomass values for the validation set of each campaign, obtained by applying the specific ANN to each given validation set, plus the result obtained by applying the general ANN to the whole validation set.The correlation coefficient between estimated and target biomass ranged from R = 0.69 to R = 0.98, while the RMSE was between 14 t/ha and 58 t/ha (Figure 5a–f). The result obtained by the specific ANN for the two AfriSAR missions was 0.92 ≤ R ≤ 0.94 with 42 ≤ RMSE ≤ 57 t/ha. Some underestimation of the highest biomass values can be identified in the scatterplot, possibly attributed to the saturation exhibited by the SAR signal for biomasses higher than 350 t/ha (Figure 5a,b). The ANN for TropiSAR dataset obtained better results (R = 0.98 and RMSE = 17 t/ha—Figure 5f); in that case, the underestimation of higher values was not evident. Among the specific ANN for BioSAR missions, the first and the second obtained similar results in terms of both R and RMSE (Figure 5c,d), whereas worse results were obtained for the third one (Figure 5e).Finally, the validation result for the general ANN is reported in Figure 5g). Looking at the σ° correlation to the forest biomass listed in Figure 4, this result is quite surprising, since the correlation between biomass estimated by the ANN and reference values was R = 0.93, while the σ° at various polarizations and target biomass on the entire dataset was R ≤ 0.23. The p-value was < 0.05 for the general and all the specific algorithms.", 5. Results, 5.1. ANN,5
280,"The learning process of the proposed algorithm was performed for any of the six missions and a further analysis was performed for the learning process by using the complete dataset. Then a trained SVR regressor was obtained for each dataset.The performances of each SVR regressor were computed using the validation dataset and using as metrics the correlation and the RMSE between true biomass and estimated biomass (Figure 6a–g), where the green line represents the regression line.From the scatterplots, we can see that the correlation coefficient between estimated and target biomass ranges from R = 0.65 to R = 0.93, while the RMSE is between 15 t/ha and 65 t/ha.Despite a lower sensitivity of the backscattering coefficient with high biomass values, the SVR regression appears to predict quite well the higher biomasses. On the other hand, the higher sensitivity of the backscattering coefficient with low biomass values does not correspond to the lower ability of the SVR regressor to forecast low values of biomass.The SVR regressor obtained for AfriSAR DLR dataset shows R = 0.88 and RMSE = 65 t/ha. For biomass values greater than 200, the SVR regressor shows rather good performances with RMSE = 47 t/ha, whereas for values lower than 200 it shows an overestimation in the estimated biomass (Figure 6a). The result obtained for AfriSAR Onera shows R = 0.9 and RMSE = 55 t/ha with some bias that however does not hamper the accuracy (Figure 6b).The results obtained for the BioSAR 1 and 2 datasets are quite good, as demonstrated by R = 0.92 and 0.93 and RMSE = 24 t/ha and 15 t/ha, respectively (Figure 6c,d). As for the ANN algorithm, the accuracy was lower in the case of the BioSAR 3 dataset (RMSE = 53 t/ha and R = 0.65). Moreover, a consistent underestimation of the target biomass can be observed (Figure 6e). For the TropiSAR dataset, SVR obtained R = 0.87 and RMSE = 48 t/ha, with some overestimation of the biomasses in the range 200–300 t/ha (Figure 6f).The general SVR regressor for the complete dataset obtained R = 0.86 and RMSE = 64 t/ha (Figure 6g). Similar to ANN, the condition p-value < 0.05 was verified in all cases.", 5. Results, 5.2. SVR,5
281,"After validation, the ANN and SVR algorithms were applied to the available SAR images for generating biomass maps of the entire area covered by the SAR acquisition. Figure 7 shows, as examples, three biomass maps, namely two generated by ANN and one by SVR using the AfriSAR DLR dataset. The maps are generated pixel by pixel from the input SAR data. Along with each map, the corresponding validation scatterplot using the in situ data available is shown. The areas other than savannah are covered by very dense forest and therefore the majority of points in the scatterplot is concentrated around very low and very high values. The correlation coefficient is 0.88 ≤ R ≤ 0.95 and both machine-learning approaches behave similarly, by slightly underestimating the highest values of biomass. The qualitative inspection of the maps shows that non-forested areas, mainly composed of meadows and grassland, are identified and the local patterns of biomass are correctly reproduced.", 5. Results, 5.3. Biomass Maps,5
282,"The comparison of the results obtained by ANN and SVR (Figure 5 and Figure 6) did not indicate significant differences in the retrieval performances between the two methods. Both ANN and SVR exhibited similar accuracies, being able to estimate the target biomass with a slight underestimation of the values higher than 350 t/ha. Such underestimation can be attributed to the saturation of SAR data for biomass values higher than this threshold (see Figure 3 and Figure 4), as already pointed out by past research [15]. It should be noted that both algorithms require only SAR data as input, without the need of any ancillary information. The results of the general algorithms could be affected by the different instrumental setups that generated the clusters of data in Figure 4. Better retrievals could therefore be expected if data are collected by the same instrument, thus overcoming any intercalibration issue.The computational cost of both ANN and SVR was also similar. The training was the only time-consuming step—for both algorithms, training each configuration using the BRIX dataset took a few minutes on a recent machine with an INTEL I7 6 Core processor, while applying the trained algorithm to the validation set occurred in near real time.The validation results were in line with other studies (e.g., [22,23,25]), although differences in the test areas and datasets make the direct comparison difficult. For instance, the RMSE obtained by both ANN and SVR in the validation using BIOSAR1 data is in the same range reported in [22]. Similar conclusions can be drawn from the comparison between the ANN and SVR results obtained on equatorial forests (AfriSAR and TropiSAR datasets) and the results at P-band presented in [23]. It should be remarked that, in this case, both algorithms were also able to retrieve biomass beyond the 300 t/ha threshold indicated in [23], although with a slight underestimation of the higher values. Both algorithms can manage nonlinear relationships and, therefore, they are able to exploit the residual sensitivity of backscattering to biomass higher than 300 t/ha shown in Figure 3.Concerning the disadvantages of these methods, the algorithm exportability to other areas should be verified before claiming a general validity. Indeed, depending on the experiment-driven training, the obtained results could be site-dependent and they could change significantly if applying the algorithms to other test areas. Previous studies indeed reported that retrieval errors of ML methods could be large if the test data are not properly represented in the training (e.g., [32]). However, updating the training with new data to enable the algorithms working on other areas is quite straightforward and it can be achieved without modifying the algorithm structure. Another possibility that will be investigated in the pursuance of this study is to train the algorithms by merging the experimental datasets with data simulated by electromagnetic models, such as the Water Cloud Model [54,55], for a wider range of forest conditions. Such a strategy should allow overcoming the site dependency of experiment-driven training, by obtaining more general algorithms, which can also retrieve the forest biomass with satisfactory accuracy in areas other than the ones considered in the training.", 6. Discussion,None,6
283,"In this study, two algorithms based on machine learning, namely ANN and SVR, were implemented, trained, and validated to estimate forest biomass from P- band airborne SAR data.Both ANN and SVR exhibited similar retrieval performances, displaying a general capability of retrieving the target biomass with a slight underestimation of the values higher than 350 t/ha. Such underestimation can be attributed to some saturation exhibited by the SAR signal for the highest biomass values.The characteristics of the available dataset suggested implementing general algorithms trained and tested on the entire dataset and specific algorithms for each test area.The validation of the general algorithms resulted in R > 0.85 for both SVR and ANN, with RMSE ≃ 60–70 t/ha and bias negligible, while the validation of the specific algorithms resulted in R from 0.65 to 0.98 and RMSE between 11 and 65 t/ha, depending on the dataset and on the algorithm.This investigation demonstrated the capability of machine-learning techniques for the remote sensing of forest biomass by using SAR. In this respect, ANN and SVR can be substantially considered equivalent in both retrieval accuracy and computational cost, since the investigation did not point out any aspect in which one of the two methods outperformed the other.In the pursuance of this study, we plan to merge the experimental dataset with data simulated by electromagnetic forward models for training the algorithms. This strategy should overcome the limits of experiment-driven training, by filling the gaps in the training set and enabling the application to other areas.", 7. Conclusions and Future Work,None,7
284,"Forests are subject to a variety of disturbances, which are strongly influenced by climate change and human activities [1]. Forest disturbance due to fires is a major challenge for forest management in various ecosystems due to the loss of life and infrastructure, emissions of greenhouse gases, degradation, soil erosion, and the destruction of species, biomass, and biodiversity [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]. According to the Intergovernmental Panel on Climate Change (IPCC), climate change tends to increase the risks of major fires on Earth.Accurate information that is related to the impact of fire on the environment is a key factor in quantifying the consequences of fires on the landscape, planning and monitoring restoration and recovery activities, and providing relevant data for understanding the dynamics of fire, serving as a basis for future monitoring [31]. After a fire, detailed and rapid knowledge of the level of damage and its spatial distribution are the first desirable information. Accurate and complete data on fire sites and burned areas are important for a variety of applications, including quantifying trends and patterns of occurrences in a variety of natural and social systems [32,33,34,35,36,37,38,39,40,41].The understanding of fire regimes and forest recovery patterns in different environmental and climatic conditions improves the management of sustainable forests, facilitating the process of forest resilience, according to Chu and Guo [42].In the last decades, the use of remote sensing has allowed unprecedented advances in mapping fire dynamics, mainly to locate the occurrence of fire in time and space, and to quantify the total extent of the burned area. Several remote sensing studies have been carried out to map burned areas on a global and regional scale [10,12,38,39,43,44,45,46,47,48,49,50,51,52,53,54,55,56]. In particular, some authors have studied burned areas in Portugal using remote sensing techniques by [12,47,49,51,52,53,57,58,59].The availability of well-calibrated global remote sensing data since the late 1990s has enabled the production of a variety of global and multi-annual products for burned areas, which are now freely available [60]. Several of these products are based on data from orbital sensor systems with different spatial resolutions (coarse, medium, and high), such as: Operational Land Imager (OLI)/Landsat-8, MultiSpectral Instrument (MSI)/Sentinel-2, Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER)/Terra, or Moderate Resolution Image Spectroradiometer (MODIS)/Terra. According to Libonati et al. [61], the development of a precise algorithm to detect changes in surfaces that are caused by fires on a global scale is hampered by the complexity, diversity, and high number of biomes involved. The limitations of estimating burned areas, on a global scale, can be reduced with the development of algorithms that consider characteristics, such as vegetation type, soil, and climate, and where validation and calibration exercises are less complex to implement [61]. Mapping burned areas using remote sensing techniques is based on post-fire changes due to the burns [57]. The approaches include supervised and unsupervised classification techniques at the pixel level. The quality of the classification of the natural environment is associated with the precision and reliability derived from satellite data, which are determined by the classification algorithm. This involves the image resolution (pixel, window, or segment size) that is used in the classification process. To evaluate the classifiers and obtain thematic precision, it is necessary to take the different classes of forest identified into account [62]. In the last decades, non-parametric methods, algorithms that are based on machine learning (MLAs), have gained great attention from applications based on remote sensing [63,64], although some of them, such as the k-Nearest Neighbor (kNN), have been used since the 1950’s [65,66,67,68,69,70,71]. MLAs have become widely accepted as evidenced by their use in mapping burned areas [44,46,72]. They perform well in situations that involve category prediction of spatially dispersed training data and are especially useful when the process under investigation is complex and/or represented by a high-dimensional input space [73].In recent years, Landsat, Sentinel-2, and Terra data have been used in conjunction with MLAs to distinguish and map fires in different types of biomes, anthropogenic types of land use (including plantations), and degraded forests ([61,74,75]). Many of the classification algorithms have been compared with standard products from burned areas and active fires derived from satellite data, such as MCD64A1 [76], MCD14DL [75], Landsat Burn Area [77], or Fire_cci [78]. MLAs have also been implemented in satellite data to map fires, examine spectral properties, accurately delineate the area affected by the fire [79], analyze fire severity [72], and carry out precision analysis of the product [43,61]. Some of the most common MLAs for classifying and mapping burned areas include support vector machines (SVM), kNN, and Random Forest (RF) [80,81]. RF, for example, allows for integrating data from different scales and sources, which explains its wide use in many mapping applications based on satellite images [72]. In particular, several studies show the RF potential that is applied to satellite images for the detection of forest fires [82,83,84,85,86,87,88].The ability of MLAs to distinguish and map different forest types, which have suffered varying levels of fire severity and their consequences across the planet, needs to be further assessed by different orbital sensors. This will support conservation management, being able to serve in places of different territorial extension. However, it should be noted, that there are few published studies on the performance of kNN and RF using different orbital platforms in areas burned by fire at the local scale, especially in Portugal [81,89,90,91,92].In this work, the feasibility of kNN and RF classification algorithms to map areas that are burned by forest fires in a region of native pine vegetation in the municipalities of Santarém and Castelo Branco (central Portugal) is evaluated using Landsat-8, Sentinel-2, and Terra satellite data. The main aims are: (i) to examine the effectiveness of different remote sensing data sources for delineating the area affected by the fire; (ii) to compare, while considering the advantages and limitations of the sensors used, the performance of two MLAs (kNN and RF) that are commonly used to delineate and map forests that suffered fires; and, (iii) to evaluate the structural and spectral properties of the burned area and its influence on the classification.We found that no significant differences in the burned area are obtained with each algorithm for each image sensor. The classifications carried out using both kNN and RF algorithms mapped the burned areas with high accuracy for the different sensors, regardless of the spatial resolutions and the spectral characteristics of each source data. ", 1. Introduction,None,1.
285,"Portugal is characterized by a mild Mediterranean climate with climatic variability, involving droughts and desertification in the southern sector, according to Miranda et al. [93]. The majority of burned areas in Portugal (80%) are due to fires, which occur in a small number of summer days (10%) when the atmospheric circulation forms a prominent ridge over the Iberian Peninsula with a strong flow to the south [94].The study area (Figure 1) covers a 93.4 km2 fire that occurred on 20 July 2019 in the districts of Santarém and Castelo Branco (central Portugal). In this area, the vegetation of maritime pine and microclimate predominate with prolonged summers, having very limited rainfall. High temperatures reduce the moisture content of forest fuels, often resulting in large fires when combined with strong winds [95].According to Nunes et al. [96], who analyzed a set of 506 fires that occurred in Portugal in 1991, large fires (greater than 1500 ha) mainly occur in posts of Pinus pinaster, Eucalyptus globulus Labill., and Eucalyptus/Pine trees mixture, and later by bush. On the other hand, as these types of vegetation are sowers, which respond to fire through the rapid dispersion of seeds, post-fire regeneration in the central region of Portugal will crucially depend on the destruction of seeds that are present on the soil surface during the fire episode [97]. Therefore, it can be predicted that the magnitude of fire damage will play an important role in the dynamics of vegetation in this region.", 2. Materials and Methods, 2.1. Study Area,2
286,"In this work, the following multisensor satellite images fully covering the study area, including Landsat-8, Sentinel-2, and Terra, as well as their spectral bands, were selected and used to discriminate the area that is affected by the fire in the pixel distribution format on the digital number (DN) scale: (i) A Landsat-8 scene acquired on 1 August 2019 by the OLI sensor (LC08_L1TP_203033_20190801_20190801, orbit/point: 203/033) with a spatial resolution of 30 m obtained from the Earth Resources Observation and Science Center of the US Geological Survey (USGS) [98]. This is a product of level 1T (corrected terrain) and adjusted with the solar angle with the processing steps described in [99].(ii) A Sentinel-2 scene acquired on 3 August 2019 through the cloudless MSI sensor (S2A_MSIL1C_20190803T112121_N0208_R037_T29SND_20190803T132806) with 20 m spatial resolution obtained from the European Space Agency (Copernicus Open Access Hub). It is a Level 1C Top of Atmosphere (TOA) Reflectance product, which includes radiometric and geometric corrections (UTM projection with Geodetic Reference System WGS84), together with orthorectification [100].(iii) For Terra satellite, one scene acquired on 25 July 2019 by the ASTER sensor. It is a cloud-free 1T level product with 15 m spatial resolution obtained from the USGS EROS Center [98]. For ASTER, unfortunately, shortwave infrared (SWIR) bands were not available for the study region, as they are no longer usable since 2008.(iv) Additionally, for Terra satellite, one scene was acquired on 28 July 2019 by the MODIS sensor using the surface reflectance product (product MOD09A1). We also used the MODIS Terra MOD09A1 (Version 6) product from the Oak Ridge National Laboratory’s Distributed Active Archive Center (ORNL DAAC) (Global Subset Tool: MODIS/VIIRS Land Products: https://modis.ornl.gov/cgi-bin/MODIS/global/subset.pl (accessed on 14 February 2021)). This product, with 500 m spatial resolution, provides spectral surface reflectance of the MODIS 1–7 Terra bands corrected for atmospheric conditions (for example, gases, aerosols, and Rayleigh scattering) at eight-days interval. For each pixel, a value is selected from all acquisitions within the eight-day compounding period. The criteria for choosing the pixel include cloud and solar zenith. When several acquisitions meet the criteria, the pixel with the minimum value of channel 3 (blue) is used [101]. Table 1 summarizes the bands that were used in this study for the different sensors. In the case of MSI, an image composition with all bands (10 and 20 m) was performed, resulting in a product of 20 m of Ground Sampling Distance (GSD).  2.2.1. FlowchartFigure 2 summarizes the classification scheme and analysis followed in this work. Fire area classification methods using kNN and RF algorithms were used to explain the effects of different satellite images on both classifiers.The workflow for the supervised classification of burned vegetation using kNN and RF algorithms was implemented with multispectral images from Landsat 8/OLI, Sentinel-2/MSI, and Terra (ASTER/MODIS) through training samples using photointerpretation features. The classification accuracy was determined making use of validation data and the results obtained from the analysis of the classification parameters using the generated confusion matrices. After image composition, the procedure includes the following steps: training samples, spectral separability analysis, classification with kNN and RF algorithms, validation, and accuracy analysis. 2.2.2. Training SamplesThe initialization of a supervised classification process requires composite images and training samples (polygons). The sample polygons selected in the composite images are used to obtain the burned and unburned areas class descriptors. The training areas were randomly collected, with 30 polygons with an area of 65 km2 for each class, respecting the separation limits that are based on the ICNF burned area product. 2.2.3. Separability AnalysisThe purpose of the separability analysis was to evaluate the spectral separability in all of the bands used in the classification of burned and unburned areas and contribute, for instance, to the decision of which bands have greater classification properties in supervised classification algorithms. The separability of each pair between classes can be quantitatively measured by the average distance between the class density distributions of the pairs or histograms of the values of each band [75]. The Jeffries–Matusita (JM) distance is one of the most widely criterion used in remote sensing in the field of pattern recognition and feature selection. In comparison with other separability indices, JM distance has been suggested as more reliable in separability measures, and also more suitable for less homogeneous main classes [102]. Therefore, we chose the JM distance to indicate the separability between the burned and unburned vegetation. It is calculated according to Equation (1), as [103]:



J

M

i
j


 
=
 


2


1
−

e

−
B






 




(1)


where B is the Bhattacharyya distance given by Equation (2), as:




B

i
j


=

1
8






μ
j

−

μ
i




T








Σ
i

+

Σ
j


2





−
1





μ
j

−

μ
i



+

1
2

l
n







Σ
i

+

Σ
j




2








Σ
i






Σ
j











(2)

For classes i and j, μ is the mean vector of the reflectance values and Σ is the variance-covariance matrix. Previous research has shown that the JM distance can provide a more accurate classification than other distance measures, such as the Euclidean distance or divergence [104]. It ranges between 0 (completely inseparable) and 2 (completely separable) [102]. 2.2.4. kNN ClassifierThe kNN algorithm proposed by Aha et al. [105] is an instance-based learning method that classifies elements based on the closest k training samples in the resource space. These data play important roles in spatial forecasting, in addition to being the main adjustment parameter of the kNN algorithm. kNN is a common classification tool used in remote sensing data mining applications [63,105], and it is widely used for mapping burned areas [106,107]. kNN is a non-parametric MLA, which makes no assumptions regarding the main data set. This is important when classifying processes of change in territory, such as floods and fires, for which there is little or no prior knowledge of data distribution. In kNN, the pixel whose class is unknown is a member of a class, as described by its spectrally closest neighbors whose class identities are recognized. Figure 3 shows the scheme of the kNN algorithm. Initially, the parameter k, which represents the number of closest neighbors, must be selected. This parameter will direct the number of neighbors. In the case of k = 5 in a binary group, the five closest points are identified by the Euclidean distance. In this way, through the shortest distance between the existing k neighbors, which is, the point to be classified and all points in the data set, it is possible to know which class is most similar to. Thus, the classification is completed, and the unknown point is classified. The parameter k plays an important role in the performance of the kNN, being the main kNN adjustment parameter. In this study, we tested different k values (5 to 20) to select the ideal parameter for the kNN classifier based on the lowest estimate of the Root Mean Square Error (RMSE), using different subsets of data. However, in previous studies, as in Cariou et al. [108] and Noi and Kappas [63], it was revealed that this is not the only criterion for selecting an appropriate k value because a small or large k value has characteristics that are suitable for each case. We used SNAP (Sentinel Application Software, ESA) software for this classification. 2.2.5. RF ClassifierThe RF algorithm is based on the creation of several decision trees, combining them to obtain a more accurate and stable forecast. According to Rodríguez-Galiano et al. [109], the RF algorithm has advantages in remote sensing area, as it generates an internal unbiased estimate of the generalization that is represented by the Out of Bag (OOB) error, which is a way of validating the RF model. Therefore, it is relatively robust for outliers and noise, in addition to being computationally lighter than other tree set methods. The RF is trained using bootstrap aggregation, where each new tree is adjusted based on a bootstrap sample from the training observations. OOB is the average error for each calculated tree using predictions from trees that do not contain it in their respective bootstrap sample. This allows for the RF classifier to be adjusted and validated while being trained [110].The Information Gain Rate criterion [111] and the Gini Index [112] are the attribute selection measures most frequently used to induce the decision tree. We chose the Gini Index, which measures the impurity of an attribute in relation to the classes. For a given T training set, it randomly selects a case (pixel) and determines the class that it belongs to.In this work, the RF classification was tested for 10 to 400 trees for the set of images composed for each sensor. One-third of the training number of trees was used to test the error that is associated with the predictions, the above-mentioned OOB error. In RF, the parameter MTRY, the optimal trees at each node, controls the number of variables available to split at each node of a tree [113]. In this study, a default value was used as provided by the SNAP software. 2.2.6. Validation and Accuracy AnalysisThe validation of remote sensing data is generally based on measurements that were obtained in field campaigns, which are seen as a reference on site. In many cases, the validation process is carried out by remote sensing products provided by official institutions or by sensors with high spectral or spatial resolutions. In this work, the validation product that was used as a reference was the 2019 annual burned area of the atlas provided by the National Institute for Conservation of Nature and Forests (ICNF) of Portugal.The data were made available on the website http://www.icnf.pt/ (accessed on 14 February 2021) in an ESRI shapefile format covering the entire national territory through the representation of polygons from areas that are affected by fires, coupled with information such as area, date, duration, and the cause that started the fire. The elaboration of the national mapping of the burned areas through the compilation of all geospatial files comes from semiautomatic classification processes using Landsat, Sentinel, or other satellite images [114].The quality of a given thematic map that is derived from remote sensing data is generally assessed by systematic comparison with other maps also derived from remote sensing [6]. Quality assessment is generally carried out based on verification measures derived from confusion matrices [115]. The choice of validation methods and objectives must be guided by the end use of the products. The cross-tabulation approach is the most common way to assess thematic accuracy. In this context, the comparison and analysis of the quality of the burned area maps that were obtained by the kNN and RF classifications in the different tested sensors were carried out.The burned area polygon that was obtained by the ICNF map was used as a spatial reference in this study. The pixel-based analysis was based on a confusion matrix (Table 2). Following the terminology that was presented by Fawcett [116], the reference data (true class) will be referred to as positive or negative (burned or unburned). If the instance is positive (burned) and classified as positive (burned), it will be counted as a true positive (TP); if it is classified as negative (unburned), it will be counted as false positive (FP). On the other hand, if the instance is negative (unburned) and it is classified as negative (unburned), it will be counted as true negative (TN); if it is classified as positive (burned), it will be counted as false negative (FN) (Table 2).The confusion matrices aim to determine the probability of detection of burned areas in the different sizes of fractions of this area at the study site. This explains the error inherent in the burned areas due to the difference between the reference product and the resolutions between the sensor images. According to Cohen [117], the classification methods are evaluated while using statistical parameters, such as the Omission Error (OE), Commission Error (CE), Overall Accuracy (OA), and Dice Coefficient (DC).OE is related to the producer’s accuracy, which is, when a pixel is classified as unburned area being really burned area. CE is related to the user’s accuracy, which is, when a pixel is attributed to a class of burned area to which it does not really belong. OA is defined as the fraction of pixels correctly classified as burned or unburned [61]. Finally, DC is a measure of similarity between the classifier and reference map in terms of the number of common burned pixels. OE and CE vary on a reverse scale of (0–100%), where the lowest values indicate the best estimates. For OA and DC, on the contrary, the largest values indicate the best estimates. 2.2.7. ROC Curve and AUCThe ROC curve has been used in studies of burned areas analysis to verify the general performance of classifiers and models. The ROC curve and a useful statistic calculated from it, the area under the curve (AUC), are mainly used to compare diagnostic tests and act as a performance measure for classifying binary data. The AUC value, as in Equation (3), shows the success rate of the model through the analysis of the training data set and its forecast rate for the tested data set.




AUC
 
=
 


∑
TP
+
∑
TN


M
+
N






(3)


where M and N are the total number of pixels in the burned and unburned areas. An AUC value that is close to 1 indicates a better performance. An AUC value of 1 indicates a perfect model, while an AUC value of 0 indicates a poor performance model. Between these values, the model performance is classified as excellent (0.9–1), very good (0.8–0.9), good (0.7–0.8), medium (0.6–0.7), and poor (0–0.6).", 2. Materials and Methods, 2.2. Data and Image Processing,2
287,"Figure 2 summarizes the classification scheme and analysis followed in this work. Fire area classification methods using kNN and RF algorithms were used to explain the effects of different satellite images on both classifiers.The workflow for the supervised classification of burned vegetation using kNN and RF algorithms was implemented with multispectral images from Landsat 8/OLI, Sentinel-2/MSI, and Terra (ASTER/MODIS) through training samples using photointerpretation features. The classification accuracy was determined making use of validation data and the results obtained from the analysis of the classification parameters using the generated confusion matrices. After image composition, the procedure includes the following steps: training samples, spectral separability analysis, classification with kNN and RF algorithms, validation, and accuracy analysis.", 2. Materials and Methods, 2.2.1. Flowchart,2
288,"The initialization of a supervised classification process requires composite images and training samples (polygons). The sample polygons selected in the composite images are used to obtain the burned and unburned areas class descriptors. The training areas were randomly collected, with 30 polygons with an area of 65 km2 for each class, respecting the separation limits that are based on the ICNF burned area product.", 2. Materials and Methods, 2.2.2. Training Samples,2
289,"The purpose of the separability analysis was to evaluate the spectral separability in all of the bands used in the classification of burned and unburned areas and contribute, for instance, to the decision of which bands have greater classification properties in supervised classification algorithms. The separability of each pair between classes can be quantitatively measured by the average distance between the class density distributions of the pairs or histograms of the values of each band [75]. The Jeffries–Matusita (JM) distance is one of the most widely criterion used in remote sensing in the field of pattern recognition and feature selection. In comparison with other separability indices, JM distance has been suggested as more reliable in separability measures, and also more suitable for less homogeneous main classes [102]. Therefore, we chose the JM distance to indicate the separability between the burned and unburned vegetation. It is calculated according to Equation (1), as [103]:



J

M

i
j


 
=
 


2


1
−

e

−
B






 




(1)


where B is the Bhattacharyya distance given by Equation (2), as:




B

i
j


=

1
8






μ
j

−

μ
i




T








Σ
i

+

Σ
j


2





−
1





μ
j

−

μ
i



+

1
2

l
n







Σ
i

+

Σ
j




2








Σ
i






Σ
j











(2)

For classes i and j, μ is the mean vector of the reflectance values and Σ is the variance-covariance matrix. Previous research has shown that the JM distance can provide a more accurate classification than other distance measures, such as the Euclidean distance or divergence [104]. It ranges between 0 (completely inseparable) and 2 (completely separable) [102].", 2. Materials and Methods, 2.2.3. Separability Analysis,2
290,"The kNN algorithm proposed by Aha et al. [105] is an instance-based learning method that classifies elements based on the closest k training samples in the resource space. These data play important roles in spatial forecasting, in addition to being the main adjustment parameter of the kNN algorithm. kNN is a common classification tool used in remote sensing data mining applications [63,105], and it is widely used for mapping burned areas [106,107]. kNN is a non-parametric MLA, which makes no assumptions regarding the main data set. This is important when classifying processes of change in territory, such as floods and fires, for which there is little or no prior knowledge of data distribution. In kNN, the pixel whose class is unknown is a member of a class, as described by its spectrally closest neighbors whose class identities are recognized. Figure 3 shows the scheme of the kNN algorithm. Initially, the parameter k, which represents the number of closest neighbors, must be selected. This parameter will direct the number of neighbors. In the case of k = 5 in a binary group, the five closest points are identified by the Euclidean distance. In this way, through the shortest distance between the existing k neighbors, which is, the point to be classified and all points in the data set, it is possible to know which class is most similar to. Thus, the classification is completed, and the unknown point is classified. The parameter k plays an important role in the performance of the kNN, being the main kNN adjustment parameter. In this study, we tested different k values (5 to 20) to select the ideal parameter for the kNN classifier based on the lowest estimate of the Root Mean Square Error (RMSE), using different subsets of data. However, in previous studies, as in Cariou et al. [108] and Noi and Kappas [63], it was revealed that this is not the only criterion for selecting an appropriate k value because a small or large k value has characteristics that are suitable for each case. We used SNAP (Sentinel Application Software, ESA) software for this classification.", 2. Materials and Methods, 2.2.4. kNN Classifier,2
291,"The RF algorithm is based on the creation of several decision trees, combining them to obtain a more accurate and stable forecast. According to Rodríguez-Galiano et al. [109], the RF algorithm has advantages in remote sensing area, as it generates an internal unbiased estimate of the generalization that is represented by the Out of Bag (OOB) error, which is a way of validating the RF model. Therefore, it is relatively robust for outliers and noise, in addition to being computationally lighter than other tree set methods. The RF is trained using bootstrap aggregation, where each new tree is adjusted based on a bootstrap sample from the training observations. OOB is the average error for each calculated tree using predictions from trees that do not contain it in their respective bootstrap sample. This allows for the RF classifier to be adjusted and validated while being trained [110].The Information Gain Rate criterion [111] and the Gini Index [112] are the attribute selection measures most frequently used to induce the decision tree. We chose the Gini Index, which measures the impurity of an attribute in relation to the classes. For a given T training set, it randomly selects a case (pixel) and determines the class that it belongs to.In this work, the RF classification was tested for 10 to 400 trees for the set of images composed for each sensor. One-third of the training number of trees was used to test the error that is associated with the predictions, the above-mentioned OOB error. In RF, the parameter MTRY, the optimal trees at each node, controls the number of variables available to split at each node of a tree [113]. In this study, a default value was used as provided by the SNAP software.", 2. Materials and Methods, 2.2.5. RF Classifier,2
292,"The validation of remote sensing data is generally based on measurements that were obtained in field campaigns, which are seen as a reference on site. In many cases, the validation process is carried out by remote sensing products provided by official institutions or by sensors with high spectral or spatial resolutions. In this work, the validation product that was used as a reference was the 2019 annual burned area of the atlas provided by the National Institute for Conservation of Nature and Forests (ICNF) of Portugal.The data were made available on the website http://www.icnf.pt/ (accessed on 14 February 2021) in an ESRI shapefile format covering the entire national territory through the representation of polygons from areas that are affected by fires, coupled with information such as area, date, duration, and the cause that started the fire. The elaboration of the national mapping of the burned areas through the compilation of all geospatial files comes from semiautomatic classification processes using Landsat, Sentinel, or other satellite images [114].The quality of a given thematic map that is derived from remote sensing data is generally assessed by systematic comparison with other maps also derived from remote sensing [6]. Quality assessment is generally carried out based on verification measures derived from confusion matrices [115]. The choice of validation methods and objectives must be guided by the end use of the products. The cross-tabulation approach is the most common way to assess thematic accuracy. In this context, the comparison and analysis of the quality of the burned area maps that were obtained by the kNN and RF classifications in the different tested sensors were carried out.The burned area polygon that was obtained by the ICNF map was used as a spatial reference in this study. The pixel-based analysis was based on a confusion matrix (Table 2). Following the terminology that was presented by Fawcett [116], the reference data (true class) will be referred to as positive or negative (burned or unburned). If the instance is positive (burned) and classified as positive (burned), it will be counted as a true positive (TP); if it is classified as negative (unburned), it will be counted as false positive (FP). On the other hand, if the instance is negative (unburned) and it is classified as negative (unburned), it will be counted as true negative (TN); if it is classified as positive (burned), it will be counted as false negative (FN) (Table 2).The confusion matrices aim to determine the probability of detection of burned areas in the different sizes of fractions of this area at the study site. This explains the error inherent in the burned areas due to the difference between the reference product and the resolutions between the sensor images. According to Cohen [117], the classification methods are evaluated while using statistical parameters, such as the Omission Error (OE), Commission Error (CE), Overall Accuracy (OA), and Dice Coefficient (DC).OE is related to the producer’s accuracy, which is, when a pixel is classified as unburned area being really burned area. CE is related to the user’s accuracy, which is, when a pixel is attributed to a class of burned area to which it does not really belong. OA is defined as the fraction of pixels correctly classified as burned or unburned [61]. Finally, DC is a measure of similarity between the classifier and reference map in terms of the number of common burned pixels. OE and CE vary on a reverse scale of (0–100%), where the lowest values indicate the best estimates. For OA and DC, on the contrary, the largest values indicate the best estimates.", 2. Materials and Methods, 2.2.6. Validation and Accuracy Analysis,2
293,"The ROC curve has been used in studies of burned areas analysis to verify the general performance of classifiers and models. The ROC curve and a useful statistic calculated from it, the area under the curve (AUC), are mainly used to compare diagnostic tests and act as a performance measure for classifying binary data. The AUC value, as in Equation (3), shows the success rate of the model through the analysis of the training data set and its forecast rate for the tested data set.




AUC
 
=
 


∑
TP
+
∑
TN


M
+
N






(3)


where M and N are the total number of pixels in the burned and unburned areas. An AUC value that is close to 1 indicates a better performance. An AUC value of 1 indicates a perfect model, while an AUC value of 0 indicates a poor performance model. Between these values, the model performance is classified as excellent (0.9–1), very good (0.8–0.9), good (0.7–0.8), medium (0.6–0.7), and poor (0–0.6).", 2. Materials and Methods, 2.2.7. ROC Curve and AUC,2
294,"Table 3 summarizes the JM separability values at the study site, where the burned and unburned pixels were analyzed for each spectral band used between the OLI, MSI, ASTER, and MODIS sensors.In general, less separability is observed for the visible bands in all sensors, mainly for the bands B1 and B2 for ASTER, and especially in the green range for OLI, MSI, and ASTER, where the bands presented low separability values, with the exception of MODIS, which presented slightly greater separability in this range. The near infrared (NIR) is the spectral region where the sign of recent fire scars is the strongest, being generally considered to be the best spectral region for detection and mapping burned areas [118] and, therefore, of crucial contribution to image digital classification processes. This is seen in the results of Table 3 with the high values of separability in all sensors, even with some existing spectral and spatial resolution disparities. In addition, the results corroborate the spectral resolution of the sensors, where the thinner infrared range of MODIS and OLI (Table 1) ensured greater separability, very different from the sparse range of MSI and ASTER, even with a slight difference in the spatial resolution and methods of pre-processing.In the visible–NIR transition bands, there was high separability, as shown in bands B6 = 1.82 and B7 = 1.83 for MSI sensor, except in band B5 = 0.45. However, the band B5 presented low separability, because it is closer to the red band in relation to bands B6 and B7.The short-wavelength infrared SWIR bands showed low JM separability values. ", 3. Results, 3.1. Spectral Separability Analysis,3
295,"In this study, we tested different k values (5 to 20) to select the ideal kNN classifier parameter for each set of images. The lowest RMSE value was used as a criterion to select the best k parameter. Thus, despite the low RMSE, from Figure 4 we can see that, after tests, the k parameter was set to 5. It shows that, the lower the value of k, the higher the accuracy of the classification. ", 3. Results, 3.2. kNN Training,3
296,"Figure 5 shows the distribution of OOB errors for a different number of trees from 10 to 400. It is observed that the classification error between the sensors in the same tree does not change significantly. However, with the increase in the number of trees, the error decreases considerably. In this study, we used the number of trees that had the lowest OOB error. It can be seen that 400 is the best value for trees. One of the advantages of using the RF classifier is its versatility with the processing time, and this can be verified in this work. The classification performed with 10 trees took 10 s, while for 400 trees it took two minutes, a moderately acceptable time interval. ", 3. Results, 3.3. RF Training,3
297,"Figure 6 and Table 4 show the pixel distribution and size of the burned area for the classification provided by the different sensors with both kNN and RF algorithms. The finer spatial resolution of OLI, MSI, and ASTER showed a burned area with greater spatial detail, but with less density of features. In turn, the map that was generated by MODIS presented, as expected, a burned area with less detail at the edges and a high distribution of overestimated features within the burned area. When comparing the classifiers, the maps visually showed no significant differences with variations in the burned areas ranging between 0.36 and 1.43 km2, with the lowest differences being for MODIS (0.36 km2) and the largest for MSI (1.43 km2). However, they presented important errors in the total burned area when compared to the ICNF reference map. The errors in the total burned area are not constant, ranging between 4.3% and 51.1% (Table 4), and being the difference sensitive to the technical specifications of the images.", 3. Results, 3.4. Burned Area Analysis,3
298,"Figure 7 shows the spatial distribution of the OE and CE for the classification of burned and unburned areas from OLI, MSI, ASTER, and MODIS sensors using the kNN and RF algorithms. It is observed that, in general, all of the classifications have low CE more frequently within the perimeter that is affected by the fire, although, for ASTER, there is a significant presence of missing mixing pixels and CE outside the burned area (Figure 7e,f).For ASTER images, the classifications present the smallest OE, with a spatial distribution of 8.73 km2 of areas with missing pixels for kNN and 8.19 km2 for RF. In contrast, despite the lower spatial resolution of MODIS, there was a moderate frequency of missing pixels within the burned area when compared to the other sensors, which decreased the sensors OE reaching ~13–14 km2. It is more evident in the upper border, as shown in Figure 7g,h, the place of transition between burned and unburned areas, which, in turn, is more susceptible to errors that are caused by low spatial resolution. ", 3. Results, 3.5. Classification Errors,3
299,"The differences in areas that were classified as burned in our classifications and the reference map were the lowest for ASTER (4 km2) and the highest for MODIS (47 km2).This result is consistent for the images with better spatial resolution and greater proximity to the date of the reference product, such as OLI, MSI, and ASTER, resulting in a stable thematic quality. When the time interval between the data is too long, it is difficult to know exactly what period the pixel finally extracted from the image refers to. This statement is disconnected from the results that were obtained by the MODIS sensor, which, despite the proximity of the day of the burning occurrence, its spatial resolution, and its eight-days compaction form, was an important factor as mentioned above.In terms of algorithms, RF was the classification method that presented the smallest error in the total burned area in relation to the ICFN reference area with values of the order of 4 to 17 km2 for the finer spatial resolution sensors (Table 4) and good estimates of OA and DC, as can be seen in Table 5.The results show that the classification based on kNN and RF for the different sensors mapped the burned area with a very high accuracy (OA > 89% and DC > 0.8) and without significant variations in the computed OA and DC values for all of the sensors. ", 3. Results, 3.6. Overall Accuracy (OA),3
300,"A ROC curve analysis was performed to graphically assess the sensitivity and specificity of the classifications carried out. From the analysis of Figure 8, it can be seen that, as the score point increases, the discriminating power also increases, which is, the curve is closer to the upper left corner and, consequently, a greater area is obtained below the ROC curve. In both classifiers, the largest value was recorded for ASTER and the lowest for MODIS, corroborating the results obtained by the OE and CE. ", 3. Results, 3.7. Algorithms Errors,3
301,"The errors that were found in the classification of burned areas were caused by several factors, one of which was the spectral similarity of burned areas with other surface elements, mainly darker bodies, in addition to the technical disparities of the kNN and RF classifiers. However, the spatial accuracy of the images was the most important agent in reducing the performance of the products. This behavior can be seen in the maps that are generated by MODIS sensor, due to its coarse spatial resolution.The assessment of the ability to detect burned areas was performed using the JM separability index in the different bands (Equations (1) and (2) and Table 3) and the results of the confusion matrices represented by OE, CE, OA, DC, and AUC (Figure 7 and Figure 8 and Table 5). In agreement with previous studies [123,124,125], less separability is observed for the visible bands in all sensors in our results, mainly for the bands B1 and B2 for ASTER [126] and especially in the green range. This occurred because forest fires affect the leaf structure and photosynthetic capacity. They also decrease the green pigment of the leaf (chlorophyll) and increase the brown-yellow pigment (carotenoids, pheophytin, and xanthophyll) [124]. In the visible-NIR transition bands, there was high separability corroborating the studies conducted by Fernández-Manso et al. [127]. The authors proved that recent fires in healthy vegetation show a characteristic increase in the reflectance from red to NIR, associated with variations in chlorophyll content.The analysis was able to show good discrimination of the burned areas. This approach improved the spatial homogeneity of the affected areas (even if random) of the classification thresholds, as shown by the high values of AUC (>0.88), reducing the dependence on having information on land cover, usually used in automatic burned area algorithms. Although it is important to emphasize that the lack of information on land use for adapting the algorithms behavior can imply the recurrence of systematic errors, increasing the uncertainty of the final burned area classification, as shown in Figure 9. As already mentioned, we note the presence of features that presented spectral behavior that was similar to the burned area (for example, low reflectance values in the NIR), which can be caused by topography shadows and changes in land cover not associated with fires, such as very humid soils. Therefore, it is recommended to take special care in regions where these characteristics and events occur close to the area that is affected by the fire, in addition to controlling the photointerpretation with the size of the samples of interest, especially in applications with sensors of different spatial and spectral resolutions [128]. Thus, as a future study in the study area, assessing the separability for different classes of land use and the influence of sample size may be a good alternative.", 4. Discussion, 4.1. Separability Analysis,4
302,"The reference mapping that is generated by ICNF proves to be quite efficient in the generation of geospatial data, providing a database that is rich in accurate information of the burned areas throughout the national territory and of open access. However, here we list some advantages and limitations of the product, based on a visual comparison after the classification process. Initially, we emphasize the thoroughness of the delimitation at the edges of the burned area that is generated by the ICNF product, in front of a complex landscape, where the study area is inserted. This could be proven in both product classifiers that are generated by the MODIS sensor, as expected, with a high frequency of omission and commission pixels at the edges of the burned area and in urban areas, as shown in Figure 7. However, according to Mouillot et al. [45], OE and CE found at the edges of burned areas cannot be strictly seen as false or omitted alarms. For a given level of CE and OE, it is acceptable as long as both are similar. We can also see that the influence of the spatial validation product provided by ICNF was crucial for the errors that are shown in Figure 7, since this product is based on the 10 m resolution bands of MSI [129], thus causing the lowest error estimates for the ASTER sensor (15 m) due to its greater proximity to spatial detail.Even with the absence of the blue and SWIR bands in the ASTER images, this sensor showed the highest accuracy parameters in both of the classifiers, although the good results found in OLI and MSI can be attributed to the use of these bands. Therefore, the 15 m GSD of ASTER was responsible for this good performance, although its proximity to the date of the reference mapping must also be taken into account.", 4. Discussion, 4.2. Validation Product,4
303,"The RF algorithm presented the highest quality values of the classification among all of the sensors and a greater stability in relation to the data change in the attribution of burned and unburned classes. This result corroborates the low complexity of its application, low cost of time, and memory. Despite the variations found in the OOB error with the number of trees, this parameter may not be very relevant in binary classifications, since the use of two classes reduces the voting options of each set of trees in the data set. In general, empirically, the error in the classification with this algorithm depends on the strength of the individual tree and the correlation between two trees in the forest. Strength can be interpreted as a performance measure for each tree. Increasing the correlation increases the error rate of the forest, and increasing the strength of an individual tree decreases the error rate of the forest, since a tree with a low error rate is a strong classifier. On the other side, reducing the number of selected random attributes reduces correlation and strength [85,130]. In our study, we selected 400 trees. In several studies of buried areas by the RF classifier, the largest number of trees commonly used ranges from 100 to 1500 [83,84,131].However, kNN, even with accuracy values very close to the RF, mainly in the AUC parameter, has a direct relationship with the k parameter, time, and memory. Once a k value is given, more training samples are needed to improve the performance, but more time and storage memory were needed. In this study, the k value that was based on the RMSE was used. Therefore, the disparities found in the quality of the mapping of this classifier can be attributed to other parameters not tested here. The values are consistent with the studies conducted by Meng et al. [132]. The value of k may not present significant differences in relation to the final result of the mapping; however, this value directly influences the processing time. It is worth mentioning that, for k = 5, the processing time was 0.56 min, while, for k = 20, the time was approximately 70 min. This time interval depends significantly on the resources of the computer used and are common for kNN classifications, depending on the size and composition of the data set [133]. Blanzieri and Melgani [134] show that the best values of k were found empirically below k = 5 using SAR data, which could be explained by the image filtering applied to the true soil homogeneity. This indicates that the decrease in k is associated with the registration of optically active elements in the images. This statement is also related to the location of the pixels to be classified in relation to the training samples. When the k neighboring pixels are close enough, the precision will naturally tend to the value very close to the sample pixel set, consisting of a decrease in time and error. ", 4. Discussion, 4.3. kNN and RF Classifiers,4
304,"It is observed that, in general, all of the classifications have low CE more frequently within the perimeter that is affected by the fire, although, for ASTER, there is a significant presence of missing mixing pixels and CE outside the burned area. This behavior may be related to the confusion of the classifiers in distinguishing between burned areas and dark soils with little vegetation. As said, this was quite evident in the classification with ASTER images, since, for this sensor, only three bands (green, red, and NIR) were used in the classification, which is, less resources for feature detection, which also favored the increase of false alarms pixels in relation to the other sensors for both classification algorithms, as also found in [59]. This is spectrally true while taking the results found with OLI and MSI sensors into account because of NIR and SWIR bands used in the classification probably influenced the presence of low CE. These channels strongly reflect the spectral signal of change detection in the vegetation state in addition to having high separability between burned and unburned areas, as shown in Table 3 and in several works [46,135,136,137], who also used this region of the spectrum for the separation of burned areas obtaining satisfactory results. According to Lambin et al. [138], reflectance generally decreases in the NIR range after the fire event due to the removal of vegetation retained by water due to the fire. The decrease in brightness is more substantive than in the visible, which makes the NIR range more suitable for discriminating burned areas. The low CE for OLI, MSI, and ASTER can be attributed to the higher spatial resolution, since this condition improves the performance of classifying algorithms mainly in places with homogeneous and more compact distribution of the burned area [31,139]. For the classifications that were performed with MODIS, the largest CE of the data series were observed with pixels well distributed throughout the affected perimeter. In this case, the low spatial resolution of this sensor was the main cause of the errors, causing a high frequency of underestimated pixels inside and outside the burned area.OE, being represented by pixels mistakenly classified as unburned areas, presented significant and well distributed values on the maps, with emphasis on the east sector of the burned area in both classifiers. These errors are related to the high frequency of pixels referring to small urban centers that are inserted in the burned area, which, in turn, were correctly classified as unburned areas, but, due to problems of pixels spectrally mixed at the edges of these features, there was a high presence of pixels of burned areas omitted from their assignment in the classification. This problem was also found in [46,140], who showed moderate performance in mapping burned areas in optically complex locations, caused by ambiguity problems in the classification and spectral mixing.In the western sector, the same problem occurred, but, more frequently, because, in addition to the housing polygons, agricultural areas also caused confusion in the classifiers. This directly influenced the results of the spatial distribution of the missing pixels in burned areas, where both of the sensors presented area variations between 17 and 18 km2 for kNN classifier and between 16 and 17 km2 for RF, which is, a high frequency of pixels incorrectly classified as unburned areas.It is observed that for ASTER images, the classifications presented the smallest OE, with a spatial distribution of 8.73 km2 of areas with missing pixels for kNN and 8.19 km2 for RF. These values were already expected, since this sensor has the best spatial resolution of the set of images and, consequently, reduced spectral mixing problems, even using only visible bands. In addition, the use of ASTER images limited the overestimation of the burned areas due to the pixel size, most suitable for classifying unburned areas that are inserted in the investigated fire polygon [141].In contrast, despite the lower spatial resolution of MODIS, there was a moderate frequency of missing pixels within the burned area when compared to the other sensors, which decreased the sensors OE reaching ~13–14 km2. It is more evident in the upper border, as shown in Figure 9g,h, the place of transition between burned and unburned areas, which, in turn, is more susceptible to errors that are caused by low spatial resolution. Another influencing factor can be explained by the process of creating the image composition of the MODIS sensor with the acquisition of the best pixel within the eight-day period. The result generates an image with moderate quality once some information is lost.For the classifications that are generated by the best spatial resolution sensors (OLI, MSI, and ASTER), errors were found in the different elements of land use in the study area, for example, in the products generated by the OLI and MSI scenes. We detected a high frequency of OE on the main highways that cut the area that is affected by the fire, especially the highways N2 and N244 (Figure 9a,b,k,l), thus showing the limitation of the ICNF product in the detection of burned areas in these characteristics. In addition, these errors were also found in the ASTER images, but more frequently in the areas of pasture and agriculture with approximately ~0.06–0.1 km2 (Figure 9g,h). However, the reference product proved to be advantageous in the classification of areas of soil degradation in kNN and RF classifiers, erroneously classifying these areas as burned areas, as shown in Figure 9i,j.Finally, kNN and RF classifiers were not efficient in differentiating water bodies and burned areas in all sensors, causing several CE pixels, as shown in Figure 9c–f. This result is in accordance with Roy et al. [74], Palomino-Ángel et al. [142], and Shimabukuro et al. [143], who reported classification errors in burned areas caused by the spectral similarity with water bodies. ", 4. Discussion, 4.4. Accuracy Analysis,4
305,"Overall, the classifications present good estimates of OA and DC. These OA values are also related to the correct classification of unburned areas and, for this reason, particular attention needs to be paid to this parameter, not using it as the only thematic quality parameter [61]. The high DC values, as summarized in Table 5, show a good performance in continuous adherence with the reference data for the class of presence of burned area, even when considering the sensitivity of this parameter to false alarms and missing pixels shown in the maps of Figure 7.Although Tanase et al. [144], in studies of burned areas in Tropical Africa, suggested that temporarily short sample units may underestimate the accuracy of the detection of burned areas, Schroeder et al. [145] showed, in their studies in the Brazilian Amazon, that the date of the imaging must be as close as possible with respect to the spatial reference data, which may have intensified the OE or increased areas with different time on the hour scale. The methods of detecting changes based on the application of temporal metrics to assess sudden variations in the pixel signature of moderate and coarse resolution sensors are gaining importance as better-quality satellite data sets become available [146,147].In general, ASTER presented the highest values of OA and DC in relation to the values of the other sensors, because its spatial resolution may have a greater influence in detecting the details of fire scars. MODIS sensor showed the lowest values of OA and DC of all the sensors, being, however, large values. These data are important, as they show that even the low spatial accuracy of MODIS in relation to the reference map as well as OE and CE greater than 10% did not drastically decrease the estimates of OA and DC, because, with both classifiers and sensors, the maps were considered to be excellent according to Cohen’s classification [117]. The same behavior was seen in Lanorte et al. [141], who showed, in applications of ASTER and MODIS sensors in burned areas in southern Italy, that these data were efficient in allowing the detection of burned areas and discriminating the severity of the fire.The OLI and MSI sensors did not show significant variations in OA and DC, displaying MSI the best results, which is attributed to the low OE that was made in the classification. An identical result was found in [71,148], who reiterated that the reason why the classification provided by Sentinel-2 is more accurate than by Landsat 8 is due to the higher spatial resolution of Sentinel-2 images. Because of this, the burned areas obtained with the classification process on Landsat-8 may have been overestimated. Other studies following this approach also found similar OA values, for example, 90% in Axel [149], 79.2% in Liu et al. [75], 95% in Libonati et al. [61], 94.7% in Zhang et al. [150], 99% in Alonso-Cañas and Chuvieco [46], and 96% in Roy et al. [74].It is worth noting that both of the classifiers require that choices be made by the modeler concerning numerous parameters under different performances. In general, the classifiers based on kNN and RF brought high quality in the classification of burned areas with AUC values above 0.88, DC above 76%, and OA above 89%, in addition to the ability to process data efficiently and enable parallel training of the same samples in different orbital data sets.Therefore, the results show a statistically significant ROC curve with an AUC varying between 0.88 and 0.94 for both algorithms, showing that, even in the case of supervised classifications, approximately 90% of the burned areas were well classified by the algorithms in the different sensors. This result agrees with the initial study by Chou et al. [151], where the classification improvement was significant when accounting for spatial autocorrelation in logistic fire probability models in Southern California. Likewise, Siljander [152] found values of AUC in the order of 0.86–0.94, indicating that the fire classification models that were responsible for the spatial distribution of the affected areas showed themselves to be superior in the estimate of burned area on a regional scale when compared with products of global scale burning. In addition, Dlamini [153] found high precision with AUCs of 0.94 and 0.97 in models of Bayesian networks for data of active fire and burned area in ASTER images, respectively. The author also stressed the validity of the Bayesian networks and that the probability estimation based on the data from the burned area can estimate the fire risk a little better than from the active fire data.", 4. Discussion, 4.5. OA and Algorithms Errors,4
306,"Based on kNN and RF classifiers and using Landsat-8, Sentinel-2, and Terra imagery, a methodology for assessing their performance in the classification of burned areas in a forest fire occurred in central Portugal is proposed. The main conclusions are as follows:(i) Less separability is observed for the visible and SWIR bands in all sensors, particularly in the green range, and high separability for NIR region.(ii) For kNN classification algorithm, k = 5 was found as the best parameter. In the same line, for RF, 400 trees were selected as an optimal value.(iii) No significant differences in the burned areas that were obtained with each classifier for each sensor were found.(iv) When compared with ICNF validation data, the lower errors in the total burned area were found in the classifications that were performed with ASTER and the largest errors with MODIS.(v) Contrary to expectation, the classification that was performed by OLI had greater precision but lower accuracy when compared to MSI. In general, high precision and accuracy were found in the classifications.(vi) The lowest CE (<5%) were found in the classifications carried out with kNN and RF in OLI, MSI, and ASTER, and large CE, of the order of 15%, with MODIS, with a significant presence in ASTER outside the burned areas. Related to OE, significant and well distributed values were found in all sensors (8–20%), with emphasis on the eastern sector of the burned area, being the low values for ASTER.(vii) The classification that was based on kNN and RF for the different sensors mapped the burned area with a very high accuracy (OA > 89% and DC > 0.8). The results show a statistically significant ROC curve with an AUC varying between 0.88 and 0.94 for both classifiers, showing that, even in the case of supervised classifications, approximately 90% of the burned areas were well classified by the algorithms in the different sensors.It is possible to observe that the visible, intermediate, and SWIR bands showed low values of separability, which corresponds to the results that were found by Pereira et al. [118], who stated that the spectral changes induced by fire in the SWIR are similar to those in the visible range, since the burned areas are generally more reflective than green vegetation, but darker than vegetation predominantly in savannas during the dry season. It is important to note that the SWIR band has the advantage of having low interference with atmospheric scattering during the scene recording process. Following this premise, there may be no significant reduction in the spectral contrast of the surface in the images, consequently resulting in increased separability indices. However, this behavior was not observed in our experiments. This methodology can be useful for mapping the burned areas in regions of native vegetation and the improvement of methods for monitoring the burned areas in Portugal, in addition to assisting in the management of fire in the region and estimating the impacts that are generated by it. The availability of detailed information on the spatial and temporal distributions of the burned areas is currently crucial. Therefore, the applied method makes it possible to survey the scars of fires while using geospatial data with the greatest possible accuracy, assisting in the maintenance of an information bank, serving not only the management of the territory, but also the comparison with related future events.In general, the errors that were found in both kNN and RF classifiers can also be related to the creation of very heterogeneous objects, even in a region with a predominance of sparse vegetation. Despite the similar results of OE and CE and the differences in the processing of each algorithm, it was shown that the spectral resolution and, especially the spatial resolution, is a more important factor in the process of classification of burned areas. OE and CE are directly linked to the burned areas used as reference mapping, as product incompatibility can generate low generalization capacity and, consequently, OE and CE close to 100% as found in Lizundia-Laiola et al. [154]. Finally, this study opens up the possibility of using multiple Earth Observation data to assess environmental disturbances, increasing the range of possibilities for implementing these data when, for example, there is no scene or a specific band for a given period or problems with cloud cover.", 5. Conclusions,None,5
307,"The estimation and monitoring of Above Ground Biomass (AGB) and Leaf Area Index (LAI) in tropical forests is of great relevance for understanding biogeochemical cycles and the effects of climate change on forest resources. Such measurements also support international protocols such as the United Nations Reducing Emissions from Deforestation and Forest Degradation (REDD+) [1]. AGB is regarded as an important indicator in ecological studies and management of vegetation, whereas LAI is a key parameter in plant ecology.Due to frequent cloud coverage [2], Synthetic Aperture Radar (SAR) remote sensing has been shown to be an important tool for the assessment of both LAI and AGB in tropical regions [3,4,5]. This is due to the capacity of SAR systems to both penetrate clouds and interact with vegetation canopies, with the volumetric backscattering component being a function of canopy structure. Although SAR systems are not able to retrieve the vertical structure of vegetation as easily as airborne Light Detection and Ranging (LiDAR) systems, the wide swath orbital coverage capability of SAR systems is useful for assessing large wetland ecosystems such as the floodplains along Amazonian rivers, known for their biodiversity, complexity and difficult access [6].The applicability of SAR data to determine forest biophysical parameters depends on the number of polarizations and the frequency or wavelength used [6,7]. Most orbital SAR platforms acquire data in only single- and dual-polarization modes, thus having limited potential for discriminating subtle structural differences in the vegetation [7,8,9,10]. Quad-pol, or full-polarimetric mode, provide the complete scattering matrix of the backscattered wave, allowing the calculation of polarimetric decomposition and other polarimetric descriptors, which can potentially better describe canopy structural properties [11,12]. This has already been shown by several studies [12,13,14,15,16,17,18,19,20]. Multi-frequency SAR data can also be used as an alternative to single-frequency single- or dual-pol data. Its synergy enables discrimination of subtle vegetation types and assessment of structural properties, albeit with different degrees of success, as different frequencies interact with distinct sections of the plant canopy [15,21,22,23].To date, provision of orbital quad-pol SAR data has been limited to experimental mode, with limited swath coverage, and/or the data are more expensive than single- and dual-pol images. Multi-frequency analysis entails acquisition of data from different orbital sensors provided by different space agencies, therefore raising project costs and computational demands and complexity. However, it is still important to assess the efficacy and feasibility of applying both multi-polarimetric and multi-frequency methods to estimate forest structural attributes. SAR literature indicates that both X- and C-band backscattering coefficient images (σ0) saturate at relatively low AGB levels (i.e., up to 50 and 250 t/ha, respectively [21,24,25,26,27,28,29]). L-band saturates at 88 to 900 t/ha [30,31,32,33,34,35,36], depending on vegetation structural complexity. In general, SAR signal saturation thresholds tend to decrease with vegetation structural complexity, especially for tropical forests. Therefore, exploring the saturation threshold and investigating the potential of polarimetric features in such environments is still necessary.Várzeas are eutrophic river floodplains associated with large high-sediment load (“white water”) rivers in the Amazon. They occupy approximately 200,000 km2 within the Amazon basin [37], providing important ecosystem services to human populations and hosting endemic fauna and flora species, such as the Amazonian manatee (Trichechus inunguis) [38] and the Pirarucu fish (Arapaima gigas) [39]. They also have an important role in regional biogeochemical cycles, although estimates are still quite uncertain as they are one of the most under-sampled Amazon ecosystems [40,41]. Várzeas are currently threatened by anthropogenic land-use/land-cover changes [42]; approximately 54% of the original forest cover in lower Amazon várzeas was lost between 1984 and 2009 [43,44]. Therefore, developing efficient remote sensing methods for assessing structural forest attributes such as Leaf Area Index (LAI) and Above Ground Biomass (AGB) is of major importance to further ecological and biogeochemical studies in várzeas, because these attributes have noticeable relationships with ecophysiological processes such as evapotranspiration, photosynthetic activity, carbon assimilation and biomass stocks [45]. Such information may also serve as more accurate proxies for habitat structure in biodiversity studies. Quantitative data about várzea forests can also assist decision-makers, public governance and environmental policies regarding planning and conservation.Therefore, this paper answers two questions: (a) Does multifrequency SAR data perform more efficiently than single-frequency data in estimating LAI and AGB of várzea forests?; and (b) Are quad-pol SAR data more efficient than single- and dual-pol SAR data in estimating LAI and AGB of várzea forest?", 1. Introduction,None,1.
308,"The study area is located within Pará State (Brazil) and encompasses an ~88 ha section of the Lago Grande de Curuai (Figure 1). This floodplain lake has an annual and monomodal flooding regime, with high-water season occurring between May and June, and low-water season occurring from November to December [46].The vegetation comprises a mosaic of vegetation types, including grasslands, shrubs and forests, whose distribution, species composition, canopy structure and phenology are strongly linked to the seasonal flooding dynamics [40,47,48]. Specifically, the land cover in the study area comprises six major classes, previously defined and mapped using dual-season PolSAR Radarsat-2 data [8].The Open Water class corresponds to the water surface previously mapped using C-band SAR imagery (Figure 1d) acquired during the low-water season. The water surface during the high-water season was mapped using the L-band SAR image (Figure 1e) and will be referenced here as Open Water High Season class. Therefore, the class Várzea Fields was mapped as the difference in water surface between the two periods.In this study, floating and emergent macrophytes (Figure 1d) were merged because they are not distinguishable from each other in L-band SAR scenes [21]. As the Várzea fields correspond to the regions colonized by grasses during the low-water season, we decided to group all these classes into a new class named Non-forested. Therefore, the following classes were examined in this study: (1) Floodable Forests: forest growing on high floodplains subject to shorter seasonal flooding periods; (2) Shrubs: shrubs and/or early succession tree vegetation with sparse canopies and low height, subject to longer seasonal flooding; and (3) Non-forested: emergent and floating herbaceous plant communities dominated by palustrine grasses, with high biomass and density levels and subject to longer seasonal flooding periods, and floodplain regions that are colonized by terrestrial herbaceous plants during low-water season.The flowchart (Figure 2) summarizes the main steps described in the following sections.Forest inventories were carried out from 18 October 2013 to 29 October 2013, during the low-water season, by establishing eighteen 25 × 25 m (0.0625 ha) sample plots, distributed between Flooded Forest areas (Figure 1c). LAI was measured using an LAI-2200 Plant Canopy Analyzer (Li-Cor Inc., Lincoln, NE, USA). Eight measurements were taken within each sample plot beneath the canopy (two rows of four measurements), using a 270-degree lens cap with the closure turned towards the holder. All measurements were taken with the sun at low elevation angles, always located behind the operator, avoiding the incidence of direct light on the sensor. Clear sky reference measurements were taken before and after plot sampling, no earlier or later than 10 min from the observations, at nearby clearings.At each sample plot, we measured the total height (h, in m) and the diameter at the breast height (DBH > 10 cm) (d, in cm) for all living tree individuals. Each single tree species was identified in the field by a trained parabotanist. Based on this identification, we compiled measurements of wood density (p, in g cm3) from Wittmann, et al. [49] and from the Global Wood Density Database—GWDD; (http://datadryad.org/handle/10255/dryad.235). Wood density of similar species within the family/genera was used whenever the species were not found in the database.The AGB of each single tree was computed as the average AGB obtained from Equations (1)–(3), according to Schöngart and Wittmann [50] for Amazonian flooded forests.



A
G

B
1

=
F
∗
P
∗
h
A
G

B
1

∗
π



(

d
/
2

)


2





(1)





A
G

B
2

=
0.112
∗



(

p
∗
h
∗

d
2


)



0.916






(2)





A
G

B
3

=
0.0509
∗
p
∗
h
∗

d
2





(3)

In (2), F is a fixed form factor of 0.6 [51]. The AGB of individual trees of each plot were then summed, and their values scaled to t/ha. Boxplots for both AGB and LAI helped identify possible outliers that could impact model fitting [52].", 2. Materials and Methods, 2.1. Study Area and Field Inventories,2
309,"SAR satellite data from three sensor platforms were acquired: advanced land observing satellite (ALOS)-phased-arrayed L-band (i.e., 1.27-GHz center frequency, ~23 cm) SAR (PALSAR-1) [53], Radarsat-2 at the C-band frequency [54], and TerraSAR-X at the X-band frequency [55]. Radarsat-2 and TerraSAR-X images were provided through the Science and Operational Applications Research (SOAR) program of the Canadian Space Agency (CSA), and PALSAR-1 scenes were provided by the ALOS Kyoto & Carbon Initiative and the ALOS PI program of the Japan Aerospace Exploration Agency (Table 1).All SAR images were acquired in October (low-water season), except for the ALOS/PALSAR-1 PLR scene, which was obtained during the high-water season. This seasonal variation may influence forest backscattering signals according to vegetation structure, affecting the estimates of LAI and AGB. It must be noted that forest inventory was not concurrent with satellite overpasses. Nevertheless, most Floodplain Forest regions have remained unchanged for the past seventeen years, according to [56].", 2. Materials and Methods, 2.2. SAR Image Acquisition,2
310,"The full polarimetric image processing is summarized in Figure 3. The Radarsat-2 SQ image was multilooked using four looks in azimuth and one look in range, resulting in approximately 20 × 20 m ground-range spatial resolution. The ALOS/PALSAR-1 PLR image was multilooked using six looks in azimuth and one look in range, which resulted in approximately 23 × 23 m spatial resolution. Both Radarsat-2 and ALOS/PALSAR-1 PLR scenes were used to compute the Covariance (C) and Coherence (T) matrices. In order to minimize speckle noise and preserve image spatial resolution and information, the Refined Lee adaptive filter with a 5 × 5 window size was applied over the full-polarimetric scenes. For consistent results, filtering with similar window sizes was applied to both ALOS/PALSAR-1 FBD and TerraSAR-X images. Table 2 shows the polarimetric decomposition and incoherent SAR features (including sigma-nought (σ0)) extracted from the full-polarimetric data.Range-doppler terrain correction and georeferencing were applied using the digital elevation model (DEM) extracted from the Shuttle Radar Topography Mission (SRTM), with a spatial resolution of 3 arc-seconds (90 m) and approximately 5 m of vertical resolution [63]. All processing steps were performed with the polarimetric SAR Data Processing and Educational Tool (PolSARPRO) software, version 5.0 [64], with exception of the range-doppler correction, which was carried out with the Sentinel-1 Toolbox version 4.0 [65].TerraSAR-X and PALSAR-1 FBD images were converted to sigma-nought (σ0) intensity backscattering coefficients (dB) using the Equation (4) [66,67].




σ
0

=
10
∗


log


10


〈
D

N
2

〉
+
C
F




(4)


where DN is Digital Number (amplitude) and CF is the calibration factor in dB for the channels. For PALSAR-1 FBD and TerraSAR-X MGD the CF is equal to −83 and −46.7, respectively.", 2. Materials and Methods, 2.3. Image Processing,2
311,"In order to answer the proposed scientific questions, the SAR data were grouped as follows: (i) single/dual pol: TerraSAR-X band, ALOS PALSAR-1 FDB, and the features (HH and HV) extracted from Radarsat-2 SQ and PALSAR-1 PLR (acquired in the high-water season); (ii) multifrequency group: combination of the features extracted from TerraSAR-X, Radarsat-2 and ALOS/PALSAR-1 FBD images acquired during the low-water season; (iii) full-polarimetric data (Table 3).", 2. Materials and Methods, 2.4. Assembly of SAR Modeling Sets,2
312,"Univariate and multivariate Generalized Linear Models (GLMs) were estimated for predicting both AGB and LAI, using SAR datasets as predictor (Table 3). Two different link functions were tested for GLM specification, the identity function (i.e., Multivariate Linear Regression, Equation (5)), and the log link function (Equation (6)), since AGB and LAI variables ϵ R+ [68]. The predicted quantities will hereafter be referred as E(Yi) and lnE(Yi), respectively.




E

(

Y
i

)

=

μ
i

,
 
Y
i
~
N

(


μ
i

,

σ
2


)





μ
i

=

b
0

+

b
p


x
p

,
 
p
=
1
,
 
2
,
 
…
,
j





(5)






ln
E

(

Y
i

)

=

μ
i

,
 
Y
i
~
N

(


μ
i

,

σ
2


)





μ
i

=

b
0

+

b
p


x
p

,
 
p
=
1
,
 
2
,
 
…
,
j





(6)


where b0, bρ, xp, ln are the intercept, regression coefficients, the predictor variables (features) and natural logarithm, respectively.Mean SAR responses (Table 2) correspond to a homogenous region around each 0.0625 ha plot, encompassing a minimum of four pixels. A routine was implemented in the R scripting language [69] for automatic model calibration, selection and assessment, as well as for outputting AGB and LAI maps (Supplementary Material). The core package of the routine is the “glmult” package [70], which allows model fitting using all predictor variable combinations. A two-level routine (Figure 4) applies different numerical criteria for defining the best models. Thus, for j independent predictor (Table 3), the number of calibrated models is 2j + 1.In the first selection level, the small-sample-size corrected version of the Akaike information criterion (AICc) was applied, following the recommendation that models with ΔAICc ≤ 2 units, relative to the lowest AICc value, should not be dismissed [71] (Figure 4). At the second level, models were assessed based on statistical significance (α = 0.05), R-squared (R2) or pseudo R-squared (for lnE(Yi)), and leave-one-out cross-validation using the Root Mean Squared Error (RMSEcv). To support model assessment, the relative overall RMSEcv (Rel. RMSE) in percentage, bias and average relative error (ARE) were also reported. Pixel level spatial prediction maps (output maps) were then generated from all significant models and submitted to visual assessment.Given the high computation cost of full-polarimetric based models (i.e., j = 40), polarimetric features were split into three groups of analogous decompositions that could represent similar information (Figure 5). Then, each group was submitted to the levels of selection (see gray box in Figure 4). The predictors of the selected models were then regrouped into a new set of predictors (k’), which was subsequently used as input to the “Levels of selection”, showed as step B in Figure 5.", 2. Materials and Methods, 2.5. Above Ground Biomass and Leaf Area Index Modeling,2
313,"Finally, the LAI and AGB output maps from selected models for both polarimetric and non-polarimetric SAR data were submitted to visual analyses (Figure 4 and Figure 5) in order to assess their suitability with respect to the reference map, land-cover classes (Figure 1c–e; Table 1), and ground information regarding land-use and land-cover classes (April 2011) and from field observations provided by Arnesen, et al. [72], Furtado, et al. [73] and Furtado, Silva and Novo [8]. The best model was that with the minimum RMSEcv and the highest agreement with the spatial distribution of woody vegetation cover classes (Figure 1), assessed by inspecting the output maps. To facilitate this inspection, the maps were generated automatically in ascending order of RMSEcv.All final predictions were cut considering the lower and upper thresholds observed in the LAI and AGB data (Figure 6). Thus, the lower and upper bounds for AGB were 0 and 600 t/ha, and for LAI, 2 and 6. Values outside this range were clipped to the nearest threshold.", 2. Materials and Methods, 2.6. Visual Assessment of Maps LAI and AGB Maps,2
314,"Both boxplots contain two AGB (the largest-Figure 6a) and LAI (the smallest-Figure 6b) values that may be outliers. To better understand the impact of these possible outliers on model calibration and/or map accuracy, the selection process was carried out by including and excluding them. To refer to the number of LAI or AGB samples used in the model calibration, subscribed numbers (16 or 18) were added to the dataset acronyms henceforth (Table 3). To compare the results of equivalent models calibrated with either 18 or 16 samples for both LAI and AGB, their observed versus predicted scatterplots (OBS vs. PREDs) were joined.", 3. Results, 3.1. Exploratory Analysis of LAI and AGB Data,3
315,"In general, all model biases were low, however the LAI estimates obtained from the lnE(Yi) models had better spatial correspondence with land-cover classes (Figure 1), supported by the empirical knowledge of study area (Table 4). Models selected from RC2(POL) and PL-PLR(POL)16 did not provide reliable maps and were therefore not considered further. Among the models selected from SAR single/dual-pol dataset, PL-FBD18 showed the highest R2 and the lowest RMSEcv and Rel. RMSE with HV-dB as predictor (Table 4). The same feature was also ranked in the model PL-FBD16 OBS vs. PREDs distribution (Figure 1). The best output LAI map resulted from the 18 LAI samples model (Figure 7a).Regarding the multifrequency dataset, the best model (highest R2 and the lowest RMSEcv and Rel. RMSE was provided by PL-FBD+TX18 (Figure 7b). Despite the similarity in the R2 and the RMSEcv and Rel. RMSE statistics of both PL-FBD+TX18 and PL-FBD18, their output maps are quite different. This is clearly observed when comparing the regions with high and low LAI values (i.e., green and red regions, respectively) because there are not coincident. PL-FBD18 was selected as best model, because it presented coherent results based on visual analyses and consists of a single predictor (HV-dB) (thus having operational advantages).Visual analysis of the best LAI map (Figure 7a) indicated that the regions in red (i.e., lowest values set for the LAI maps) match with the locations of the Non-forested class (Figure 1). This is a clear indication that L-band dual-pol SAR images are less sensitive to lower LAI values (i.e., 2 or less), likely due to the longer wavelength. The LAI map also shows that the Flooded Forest class is clearly discriminated from the Non-forested class, because most of the regions with the highest LAI values are located within it, except for some of the Shrub areas.", 3. Results, 3.2. LAI Models,3
316,"The AGB models fitted with lnE(Yi) presented lower RMSEcv and Rel. RMSE values and, in general, showed better spatial correspondence with land-cover classes (Figure 1) than those estimated with E(Yi) models (Table 5). The models estimated using single/dual-pol SAR data did not provide satisfactory results, neither in terms of RMSEcv, Rel. RMSE and R2 values, nor for map visual analysis. Thus, these models were not considered further.As can be observed in the graphic OBS vs. PRED in Figure 8, the absence of possible outliers in the estimated models did not positively impact their accuracy. Thus, the further analyses considered only the models calibrated with 18 samples of AGB.The models PL-FBD+RC218 and MULT18 presented satisfactory accuracy (i.e., the lowest RMSEcv, Rel. RMSE and highest R2). However, the last one displayed better results in the map visual analyses (Figure 8a). Therefore, considering multifrequency data, the best result was achieved by MULT18 (Figure 8a).The RMSEcv, Rel. RMSE and R2 values were similar, with a low bias for the models calibrated from full-polarimetric data (i.e., RC2(POL)18 and PL-PLR(POL)18); their output maps are displayed in the Figure 8b,c, respectively. The best AGB map was estimated from PL-PLR(POL)18 model (Figure 8c). This map, unlike other AGB maps, shows the highest AGB value within the Flooded Forest class and in some high-density shrub areas (indicated by a yellow arrow in this Figure). This also allows us to discriminate the Flooded Forest class from the Non-forested class. Furthermore, most of the regions with highest AGB values (around 600 t/ha−1) are located in the interior regions of the Flooded Forest class, which agrees with the AGB spatial distribution patterning observed during field work. This model also presented the best accuracy, resulting in the lowest average relative error (46.4%). Therefore, we can conclude that the best AGB model is PL-PLR(POL)18.", 3. Results, 3.3. AGB Regression Models,3
317,"The RMSEcv, Rel. RMSE and relative error were comparatively low (0.65, 13% and 10.3%, respectively) for the LAI model adjusted with only one predictor, HV-dB. Thus, the model had satisfactory accuracy. These results indicate the importance of cross-polarized data in providing information about the structural complexity of vegetation canopy by means of volumetric scattering in wetland environments [74]. As the results (i.e., map visual analyses and statistic indexes) from model PL-PLR18 were less accurate than those provided by PL-FBD18, we inferred that the hydrological seasonality of the region might impact the accuracy of the models and the estimated maps.Considering the AGB range analyzed in this work and the structural complexity of floodable forests, we can state that the selected model for AGB provided good results, with comparatively low RMSEcv (74.59 t/ha), Relative RMSEcv and average relative error (both around 46%). The predictors composed of the polarimetric models were coherent, that is, phase dependent. One of them is VZD, which provides information about the proportion of double-bounce scattering generated by Van Zyl decomposition [60]. The others two selected parameters are ΦαS1 and ΦαS2, extracted by the Touzi decomposition [58]. These predictors provide information about the first and the second dominant phase difference between trihedral and dihedral scattering, respectively. Some works, such as Martins, et al. [75], identified that the proportion of double-bounce scattering is an important feature for estimating the AGB in the Amazon forest. A possible explanation is that this kind of scattering mechanism may be enhanced due to the clear floor of floodable forests and the reduced understory layer [74,76]. However, this may be detected only by L or longer SAR band systems [77].In relation to the predictors ΦαS1 and ΦαS2, some researchers, such as Li, et al. [78], Sartori, Imai, Mura, Novo and Silva [12], Storie, et al. [79] and Touzi [58], reported that ΦαS1 improves the classification accuracy and thus the discrimination between some wetland vegetation types, such as macrophyte, open bog and small shrubs. This predictor has also been reported as sensitive to the water under vegetation [80].The analyses related to AGB, presented above, lead us to conclude that L-band full-polarimetric data is an important predictor of AGB in both Amazonian flooded forests and dense forest regions characterized by high AGB values; thus, it has the potential to overcome the current limitations of orbital SAR data in mapping AGB with reliable accuracy in dense forest regions [5].Furthermore, vegetation structural parameters such as canopy height and crown diameter are important for the development of ecological studies related to dynamic and spatial characterization of vegetation [81], which can also be used indirectly for estimating AGB (i.e., as data input in the allometric equations) [82] or can be integrated with other methodologies such as presented in [83].Since the SAR signal is sensitive to form and structure of targets—rather than tree species and wood density, which are important parameters for estimating ground AGB [84]—we expect that the L-band polarimetric will presented the same or even more potential to estimate and map vegetation structural parameters such as canopy height and crown diameter. Therefore, we encourage the development of studies with this aim and highlight that the routine presented in this work can assist in their development.These results endorse and reinforce the potential of the forthcoming SAR missions at L-band, such as TanDEM-L [85]. Although data policy will restrict public access to the data, TanDEM-L is expected to overcome the current SAR data limitation in both mapping and monitoring AGB on a global scale with satisfactory accuracy and spatial resolution [86].This potential is amplified with Airborne Light Detection and Ranging (LiDAR) data, which can be used to calibrate and validate SAR-adjusted models through the upscale approach, reducing the dependency of field inventory data. This is especially true in regions with difficult access, such as several environments found in the Amazon forest biome. Furthermore, information such as crown diameter, canopy height and number of individuals (trees) can be extracted directly from this source of data and can potentially be used as input in the allometric equations and, indirectly, to improve AGB estimation [82]. Thus, the data generated by future missions such as Global Ecosystems Dynamics Investigation Lidar (GEDI) [87] can extend the applicability of the methodology presented in this work to other forest environments worldwide. In addition, we stress that the quad-polarimetric SAR images with larger wavelengths, such as P-band and S-band, provide results quite similar or even better than those achieved in this work [88]. This is especially true given that the SAR signal can penetrate deeper in the dense multi-layer of the tropical forests. Thus, missions such as BIOMASS, which will generate P-band SAR images [88], and NISAR, which will generate quad-polarimetric images in L-band and S-band frequencies, hold promise for mapping and monitoring AGB with relatively high accuracy on a global scale [89,90,91,92].", 4. Discussion,None,4
318,"Our results show that the model approach lnE(Yi) generally presented better results than E(Yi), especially in the visual analyses of the AGB and LAI maps. Furthermore, the models selected for both AGB and LAI were parsimonious, and their output maps matched with the classes and empirical knowledge about the study area. For both LAI and AGB retrievals, the best results were achieved using the features extracted from ALOS-PALSAR-1 scenes. This result indicates that, for the estimation and mapping both LAI and AGB parameter in a Floodable Forest environment, single-frequency polarimetric L-band images are more efficient than multifrequency dual-pol or single-pol SAR. For the estimation of LAI, the cross-polarization data (HV-dB) was sufficient. For AGB, however, the features extracted from polarimetric decompositions seems to be essential. Thus, for mapping LAI, dual-pol SAR images performed best, as they have operational advantages when compared with quad-polarimetric SAR. For AGB mapping procedures, the full-polarimetric data is preferable. These results reinforce the potential of this kind of data in mapping AGB in Floodable Forest environments. We also believe that this result can be extended to other dense forest environments worldwide.Considering the wide range of AGB values contemplated in this work, we strongly believe that the results achieved by the best AGB model were satisfactory and that the methodology presented is suitable for estimating this parameter. We believe this can be extended to vegetation structure parameters such as canopy height and crown diameter. However, to confirm these findings, more tests must be performed in other regions and environments, with more samples of AGB if possible. To better understand the potential and limitations of this routine, we encourage the development of future works with other modeling methods such as random forest and genetic algorithms.Finally, the authors believe that the results and the feature selection process presented in this research may provide important information for the scientific community regarding the applicability of L-band quad-polarimetric SAR images. This is related to the estimation of AGB and its potential to overcome the current limitation in the context of wetlands and densely tropical forests environments. In this sense, we expect to collaborate on the construction of a background for analysis and assessment of current (PALSAR-1 and -2) and future missions (NISAR, GEDI, BIOMASS, Tandem-L), which we believe have enormous potential for mapping of AGB with high accuracy on a global scale in the near future. Such information can provide essential information for future generations to better understand the dynamics of our planet in the face of modern issues such as climate change and anthropogenic land-cover change.", 5. Conclusions,None,5
319,"Tropical Forests play a vital role in the global carbon cycle, and subsequently within the global climate [1]. Tropical forests are incredibly complicated, diverse, and frequently threatened. Indeed, there’s a crucial demand to develop a new technology to help in surveying and revealing the dynamics of tropical forests. The dynamic processes like growth, regeneration, decay, and disturbance, strongly affects the forest 3D structure. Forest 3D structure is so closely associated with their history, diversity, function, and micro-climate [2]. At the same time, forest structure information is essential for developing a precise forest biomass estimators. The latter is needed to observe better and evaluate forest ecosystems’ contribution in the overall carbon cycle [3,4,5]. Traditionally, forest structure observation has been implemented by inventory plots at local scales. Inventory measurements provide correct estimates of a variety of single trees and stand parameters. However, these measurements are time demanding and they are performed at smaller scales. The extrapolation of those plot measurements from into larger scales depends on the ability of these measurements to represent their surrounding landscape [6]. The establishment of the temporal continuity of these measurements is challenging. Remote sensing techniques have the potential to overcome this limitation and make an enormous contribution in qualitative and quantitative observation of three-dimensional forest structure [7,8,9,10].Today, Tomography Synthetic Aperture Radar (TomoSAR) and airborne LiDAR are the two technologies that allow the measurement of 3D forest structure. Measures derived from the LiDAR waveform are utilized to evaluate structural forest parameters as forest height and biomass [11]. Recently, continuous forest mapping with global coverage at spatial and temporal resolutions is assessed and established using SAR imaging configuration. Indeed, a big effort has been put to demonstrate the potential of typical SAR configurations to estimate spatial biomass utilizing SAR measurements [12]. The SAR system provides measurements sensitive to the whole vegetation and from the underlying ground at high spatial resolution. The initial step started with introducing SAR interferometry as it has an exaggerated sensitivity to forest geometry and vertical structure components. Polarimetric interferometric SAR measurements allows model-based inversion to assess vertical forest structure parameters such as forest height and biomass [13,14,15,16]. The next step is using multi-baseline interferometric acquisitions in order to reconstruct the vertical distribution of the scatterers [17]. Recently, tomographic acquisitions, which will be seen as an extension of multi-baseline interferometric acquisitions, have been used to reconstruct the three-dimensional radar reflectivity of forests [17,18,19,20,21,22,23]. The promising outcomes accomplished initiated the execution of TomoSAR acquisition modes in future spaceborne SAR missions, like Biomass [24] or Tandem-L [25], for mapping structural forest parameters and to enhance the performance of biomass estimators at a global scale. TomoSAR has been demonstrated to be a powerful tool for observing forested areas from space owing to its capability in providing vertical resolution based on multi-baseline observations [17,26,27,28]. Tomographic techniques consist of power estimation strategies applied to the multi-baseline Single Look Complex (SLC) data to retrieve the back-scattered power that characterizes the vertical profile of forests [29,30]. In its most simple formulation, TomoSAR aims to extract the vertical distribution of the backscattered power within the system resolution cell. A potential answer to the current problem is to take advantage of super-resolution techniques like Capon beamforming, Multiple Signal Classification, Singular Value Decomposition analysis, and others [26,31]. A unique solution could also be found within the works by Fornaro et al. [32] and Cloude [33,34], wherever super-resolution is achieved by exploiting prior information concerning target location, like ground topography and canopy height model [34]. The capabilities of L-band TomoSAR to characterize 3D vertical structure of tropical forests are still in early stages of development while those of P-band TomoSAR have been discussed and evaluated. Ho Tong Minh et al. [35] used the airborne data that were acquired during TropiSAR campaign to prove that the use of L-band tomographic imaging in tropical forests seems limited. The first experience in testing TomoSAR in tropical forest areas was carried out in French Guiana by the TropiSAR campaign in 2009. However, these data were sub-optimal to assess the performance of multi-frequency TomoSAR in monitoring the forest structure and estimating forest structure parameters as forest top height. To overcome such limitation, and acquire optimal tomographic and polarimetric data, the AfriSAR campaign was successfully carried out over the dense forests of Gabon in 2015 and 2016. Nevertheless, the link between physical forest structure and the reconstructed 3D radar reflectivity is still not understood and is far from being established. The main challenge, thus, is the interpretation of 3D radar reflectivity in terms of the 3D forest structure parameters.The 3D radar reflectivity relies on the operating system frequency and polarization. Plus, it also depends on the used acquisition geometry (e.g., incidence angle), and the achieved 3D spatial resolution. In fact, the generic interpretation of 3D reflectivity is difficult because scatters that are seen by radar are changing with frequency and polarization. Accordingly, this paper focuses mainly on comparing the capabilities of L- and P-band TomoSAR to extract forest top height. First, the P- and L-band vertical profiles are validated with a Canopy Height Model (CHM), which is obtained from a Small Footprint LiDAR (SFL) dataset. Second, qualitative comparisons of the Capon beamforming profile at HH and HV (H: horizontal, V: vertical) polarizations with Land Vegetation Ice Sensor (LVIS) Level 1B waveform LiDAR data and CHM and Digital Terrain Model (DTM) from SFL data, over the region of interest in Gabon Lopé National Park, are carried out. Additionally, forest top height is retrieved from the TomoSAR data. The paper is organized as follows: Section 2 describes the study area, datasets, and methods used for the tomographic analysis. Section 3 illustrates the validation of the results. Section 4 is devoted to discuss and interpret the tomography results. Section 5 demonstrates the concluding remarks.", 1. Introduction,None,1.
320,"To develop algorithms that assess the performance of BIOMASS SAR measurements in different forest ecosystems, several airborne field campaigns have been designed and implemented. One can name the AfriSAR campaign in Gabon, BioSAR campaign in Sweden, and TropiSAR campaign in French Guiana (Figure 1).The AfriSAR campaign aims to provide support to forthcoming NISAR, GEDI and BIOMASS missions. Four sites presenting various forest structures have been selected: Lopé, Mabounie, Mondah, and Rabi, located, respectively, at 250 km, 180 km, 25 km, and 260 km from the Libreville airport, where the calibration site was deployed. In this section, we will focus on the presentation of Lopé, which is the primary acquisition site. Lopé National Park, a 4913 km2 national park in central Gabon, is known as one of the largest parks in the area. The scene of the northern part consists of the last remnants of grass savanna that was created in central Africa, during the ice age from 15,000 years ago. This natural site is composed of vast areas of Savanna in the north, which is surrounded by the Ogooué River and frequently burned in order to preserve the forests’ Savanna areas, in addition to an extended area of tropical forests that are combined with parts of successive forests of complex structure, which were developed throughout time with savanna recolonization [36]. Lopé is a convenient natural view to prove the adequate performance of tomographic imaging because of the gradient of forest biomass from the forests’ savanna boundary (up to 100 Mg/ha), to dense undisturbed humid tropical forests (greater than 400 Mg/ha). The height and structure of the trees vary gradually from savanna into forests, which provide uniform mono-dominant trees of okoume (OKO) of tall: 30–50 m for regions with the presence of significant gaps in mid-canopy. This creates skewed vertical profiles. Lopé topography is also diverse. It varies between either broad flat plains or steep sloping terrains. OKO2 region is selected to perform a qualitative analysis between UAVSAR–TomoSAR L-band, SETHI P-band vertical profile, and LiDAR waveforms.", 2. Materials and Methods, 2.1. Study Area,2
321,"During the AfriSAR campaign, different datasets have been acquired over the Gabon Lopé National Park. The NASA sponsored AfriSAR campaign involved three data sets, L-band UAVSAR data, LVIS LiDAR data, and SFL data. ONERA and DLR defined a common configuration for P-band imaging of their radar systems. P-band SAR P-band acquisitions were performed by ONERA (SETHI radar system) in July 2015 and by DLR (F-SAR radar system) in February 2016. 2.2.1. LiDAR Data-SetsThroughout the AfriSAR campaign, the SFL data set was collected by the NASA Jet Propulsion Laboratory (JPL) in July 2015, with a footprint diameter of 10 cm. Canopy Height Model (CHM) and Digital Terrain Model (DTM) rasters are provided with 1 m spatial resolution. The second LiDAR dataset was collected in March 2016, NASA’s Land Vegetation Ice Sensor (LVIS) acquired the LiDAR data set as part of NASA–ESA’s BIOMASS, GEDI, and NISAR calibration and validation activities. LVIS is a large-scale, waveform LiDAR with applications for measuring ground elevation and vertical profile of the vegetation structure in various ecosystems. The LiDAR datasets LVIS consists of two levels: Level 1B and Level 2 (data can be downloaded from https://lvis.gsfc.nasa.gov/Data/Data_Download.html). Level 1B data contain geo-referenced LiDAR returned waveforms, such that, at each footprint, we have a corresponding shot number, and, using this shot number, one can get the LiDAR waveform at each footprint. Level 2 data contain geo-referencing data for different reflecting surfaces within the laser footprint, the locations of which were derived from the Level 1B waveform. 2.2.2. Radar Acquisition ConfigurationThe tomographic data set here consists of seven fully polarimetric Single Look Complex (SLC) data L-band NASA/JPL UAVSAR from AfriSAR data conducted over the Lopé during the AfriSAR campaign in 2016. The operating band of UAVSAR platform is 1217.5–1297.5 MHz. The scanning of about a 22 km wide area, with incidence angles extending from 25 to 60 degrees, is performed by the Gulfstream III jet at that flight at an altitude of 12.5 km. The ground range and azimuth resolution of the UAVSAR polarimetric SLC are 1 m and 2.5 m, respectively. The tomographic SLC data acquired over Lopé by increasing the flight altitude by 20 m each flight track. The configuration of L-band UAVSAR is shown in Table 1, while the P-band data consists of 13 fully polarimetric SLC data acquired by ONERA over the Lopé in the AfriSAR airborne campaign (July 2015). The data collection is performed using the SETHI SAR system developed by ONERA and onboard a Falcon 20 aircraft. The pixel resolution of the SLC images is 1.54 m in azimuth range and 3 m in slant range. The configuration of P-band SETHI data including acquisition geometry, bandwidth, carrier frequency, and aircraft altitude are shown in Table 2.The tomographic 125 MHz data set considered in the Paracou experimental site consists of six fully polarimetric SLC images at L and P-band acquired on 24 August 2009. All the acquisitions took about 1 h (from 9:00 a.m. to 10:00 a.m.), resulting in almost no temporal decorrelation.In this paper, we also used six tracks fully polarimetric images acquired during TropiSAR campaign over Paracou. In the following section, we will compare P and L band tomographic results conducted over Gabon Lopé Park with the LiDAR data set SFL.", 2. Materials and Methods, 2.2. Data-Set,2
322,"Throughout the AfriSAR campaign, the SFL data set was collected by the NASA Jet Propulsion Laboratory (JPL) in July 2015, with a footprint diameter of 10 cm. Canopy Height Model (CHM) and Digital Terrain Model (DTM) rasters are provided with 1 m spatial resolution. The second LiDAR dataset was collected in March 2016, NASA’s Land Vegetation Ice Sensor (LVIS) acquired the LiDAR data set as part of NASA–ESA’s BIOMASS, GEDI, and NISAR calibration and validation activities. LVIS is a large-scale, waveform LiDAR with applications for measuring ground elevation and vertical profile of the vegetation structure in various ecosystems. The LiDAR datasets LVIS consists of two levels: Level 1B and Level 2 (data can be downloaded from https://lvis.gsfc.nasa.gov/Data/Data_Download.html). Level 1B data contain geo-referenced LiDAR returned waveforms, such that, at each footprint, we have a corresponding shot number, and, using this shot number, one can get the LiDAR waveform at each footprint. Level 2 data contain geo-referencing data for different reflecting surfaces within the laser footprint, the locations of which were derived from the Level 1B waveform.", 2. Materials and Methods, 2.2.1. LiDAR Data-Sets,2
323,"The tomographic data set here consists of seven fully polarimetric Single Look Complex (SLC) data L-band NASA/JPL UAVSAR from AfriSAR data conducted over the Lopé during the AfriSAR campaign in 2016. The operating band of UAVSAR platform is 1217.5–1297.5 MHz. The scanning of about a 22 km wide area, with incidence angles extending from 25 to 60 degrees, is performed by the Gulfstream III jet at that flight at an altitude of 12.5 km. The ground range and azimuth resolution of the UAVSAR polarimetric SLC are 1 m and 2.5 m, respectively. The tomographic SLC data acquired over Lopé by increasing the flight altitude by 20 m each flight track. The configuration of L-band UAVSAR is shown in Table 1, while the P-band data consists of 13 fully polarimetric SLC data acquired by ONERA over the Lopé in the AfriSAR airborne campaign (July 2015). The data collection is performed using the SETHI SAR system developed by ONERA and onboard a Falcon 20 aircraft. The pixel resolution of the SLC images is 1.54 m in azimuth range and 3 m in slant range. The configuration of P-band SETHI data including acquisition geometry, bandwidth, carrier frequency, and aircraft altitude are shown in Table 2.The tomographic 125 MHz data set considered in the Paracou experimental site consists of six fully polarimetric SLC images at L and P-band acquired on 24 August 2009. All the acquisitions took about 1 h (from 9:00 a.m. to 10:00 a.m.), resulting in almost no temporal decorrelation.In this paper, we also used six tracks fully polarimetric images acquired during TropiSAR campaign over Paracou. In the following section, we will compare P and L band tomographic results conducted over Gabon Lopé Park with the LiDAR data set SFL.", 2. Materials and Methods, 2.2.2. Radar Acquisition Configuration,2
324,"TomoSAR implementation requires accurate handling concerning the relative phase difference between different acquisitions. The rationale of TomoSAR is to use multiple flight tracks that are nearly parallel to each other [35], as shown within the left panel of Figure 2.The ensemble of all flight lines allows the formation of 2D synthetic aperture, ensuing the coherent multiple Single Look Complex (SLC) images of various passes, providing the likelihood of focusing the signal within the entire 3D space. We will refer to (r, x, 
ξ
) as the slant, azimuth, and cross ranges, respectively. Consider a dataset of SLC images acquired by N parallel track sensors, denoted by 

Y
n

(r, x, 
ξ
), representing the SLC value inside the resolution cell (r, x, 
ξ
) within the n-th image. The expression of topography-compensated (tc) SLC data are often approximated [37] as:





Y
n



(
r
,
x
)


t
c


=
∫
P

(
r
,
x
,
ξ
)

e
x
p

(
j

K
n

ξ
)


d
ξ
,




(1)


where P(r, x, 
ξ
) denotes the projection of target reflectivity on the cross-range axis 
ξ
, and 
ξ
 represents the cross-range coordinate, orthogonal to the measuring system line-of-sight (LOS) that are outlined by the slant range coordinate. In TomoSAR applications, the vertical sensitivity of the phase difference between two acquisitions is linked through the vertical wavenumber kn expressed by:





K
n

=


2
π


H
o
A


=


4
π


λ
R



b
n

,




(2)


where HoA is the height of ambiguity, 
λ
 is the radar wavelength, R is the slant-range distance, and 

b
n

 is the horizontal distance between the two acquisitions.", 2. Materials and Methods, 2.3. Tomography SAR,2
325,"SAR data were acquired over forests from slightly different altitude and incidence angles, providing helpful information within the vertical direction [29]. In this paper, the Capon beamforming power estimator was applied to represent the vertical profile of vegetated areas. The Capon spectral estimator is a conventional non-parametric method in tomographic analysis that enables one to obtain the endless vertical profile of the vegetation without any prior knowledge on the statistical properties of the data [38]. The Capon estimator vertical profile 


P
c


(
ξ
)


 is retrieved from the covariance matrix of the SLC data [26]:





P
c


(
ξ
)

=

1

a


(
ξ
)

t


W

−
1


a

(
ξ
)



,




(3)


where a(
ξ
) is the steering vector containing the interferometric information for a scatter at cross range 
ξ
 for all the baselines relative to a master track, and W is the maximum likelihood estimation of the covariance matrix. 


t

 is the transpose operator.", 2. Materials and Methods, 2.4. Tomography Inversion,2
326,"The previous section described the theoretical model for tomographic analysis assuming no disturbances on the path of the propagating signal. Prior to Multi-baseline SAR algorithms, the phase calibration of the TomoSAR data should be taken into account, in order to compensate the phase residuals that influence the focusing of Multi-baseline SAR data. These phase disturbances originate from atmospheric propagation delays or uncertainties in allocating the platform position.Indeed, for airborne systems, the atmospheric perturbations are limited (no ionosphere propagation). The phase screen compensation method chosen to be applied on the Lopé data are largely inspired by the work of Tebaldini et al. [37]. A simple proposition is to assume that the phase residuals only result from uncertainties in the antennas’ positions (Figure 3). The phase screens 

α
n

 can be approximated as a function of 

d

Z
n


 and 

d

Y
n


, which represent, respectively, the position errors of the platform n in altitude and in the ground range direction for a fixed position in azimuth [37]:








α
n

=


4
π

λ


(
−
d

Y
n

s
i
n
θ
+
d

Z
n

c
o
s
θ
)

.







(4)

The Double Localization iterative procedure described in detail in [37] is then put in place. The calibration is carried out by removing phase screens from the original SLC data to obtain the calibrated SLC data:










Y
n



c
a
l


=

Y
n

·
∗
e
x
p

(
−
j
·

α
n

)

.







(5)

", 2. Materials and Methods, 2.5. TomoSAR Phase Calibration,2
327,"The main parameter we want to estimate is forest top height. The principal challenge in tropical forests is the estimation of the forests’ top height since it is usually difficult to clearly recognize the top leaf or part of a tree in the canopy. Utilizing the Capon beamforming power estimator, we can recover the 3D backscatter profile from the multi-layer SLC and demonstrate the vertical backscatter distribution function. To do this, we applied the method proposed in [39] and we estimated the forest top height H from L- and P-band data:







H
(
r
,
x
)
=
a
r
g
m
i
n

(
P
(

H
n

,
r
,
x
)
−
P
(

H
c

,
r
,
x
)
−
K
)

,







(6)


where P(Hn, r, x) is the backscatter at the phase noise level, Hn is the elevation of the noise level, K is the power loss value, and Hc is the LiDAR height value from SFL data. Since the forest top height retrieval depends on the choice of the power loss value K, we used the CHM from the SFL dataset to select the optimal power loss value. One can estimate the canopy height model from TomoSAR data by either ranging the power loss from the phase center location in the upper envelope of the Capon profile, or by ranging the power loss from the noise level (location of the highest return detected by the TomoSAR) from Hn down to the canopy contribution peak elevation in the upper envelope of the 3D profile. At each position, the Root Mean Square Error (RMSE) between the H height and Hc is calculated at given K value (H(r, x) − Hc(r, x)); once we have the lowest value of RMSE, we get the forest top height H at each (r, x) position.", 2. Materials and Methods, 2.6. Forest Structure Parameters,2
328,"Figure 4 presents the tomographic profile of a constant range section at P-and L-band in tropical Paracou forest and Boreal Krycklan forest. For better visualization, the panels have been normalized in a way that the sum along the height is unitary. In the boreal Krycklan forest, the white line denotes forest top height derived from LiDAR measurements. At the tropical forest in Paracou, the L-band tomogram is not clear at all, as there is a blurring phenomenon, while, on the other hand, the P-band tomogram is clear. The different vegetation layers are illuminated correctly. However, for the Boreal Krycklan forest, the tomograms at L- and P-band are clear with no significant disturbances.", 3. Results, 3.1. Limitation of L-Band TomoSAR in Tropical Forest (TropiSAR Data),3
329,"Figure 5 presents the tomographic profile at a constant slant range cut (centered on the pixel number 200) before and after phase screen correction at a P-band HH channel. Note that UAVSAR L-band data are adapted to phase screen correction. The improvement brought by the phase screen removal for this region is highly visible, providing side lobes’ attenuation.In Figure 6, the estimated tomographic profiles for two cuts of the Lopé site in the slant range direction at P-band HH channel, L-band HH channel, and LVIS data are presented. The Capon beamforming estimator has been applied on radar data using a sliding window of 10 m × 25 m (area of 250 m2 for each position in the range direction. Using the same sliding window, the average of LiDAR LVIS Level 1B power layers is estimated. It is noticed that the tomograms from different sources of data achieve a good agreement with CHM from SFL data. In addition, we can observe from the tomogram of LVIS data at the two cuts that the penetration capabilities of the Lidar LVIS platform are weak when compared to the penetration performance of radar data. The canopy and ground layers are clearly detected by L- and P-band tomography while it is not the case when applying tomography on LVIS data. It is worth mentioning that, for some pixels, the canopy layer is not well detected by TomoSAR; this requires studying the physical aspects of radar signals taking into account the ground slopes and the forest type (dry, wet).Figure 7a–c represent the canopy height peak estimated from LiDAR waveform, L-band tomographic data, and P-band tomographic data, respectively. The estimation is performed over a study area of 875 m × 2000 m (1,750,000 m2). The histogram of the differences between canopy peak height estimated from the three different datasets is displayed in Figure 8. The RMSE between the canopy peak height estimated from P-band data and canopy peak height estimated from L-band data are about 3.25 m, where the bias value is equal to 0.28 m. However, the RMSE values between L-band and LiDAR on one hand, P-band and LiDAR, on the other hand, are 9.55 m and 9.76 m, respectively. Their corresponding bias is −6.43 and −6.7, respectively. The coefficient of determination had a value 0.95, 0.85, and 0.86, respectively.The vegetation profile of OKO2 region at Lopé has been obtained from L-band (HH channel), P-band (HH channel), and LVIS Level 1B data (Figure 9). The histograms of SFL data for ground and canopy elevations (DTM and CHM) are shown in Figure 9a, while Figure 9b presents the vegetation profile at OKO2 from L- and P band data at both HV channels.", 3. Results, 3.2. TomoSAR Profiles at L- and P-Band (AfriSAR Data),3
330,"Figure 10 shows the HH backscatter for the original, ground layer (0 m), 15 m layer, and 30 m layer at P- and L-band and LVIS Level 1B data. It is noticed that the ground layer image is characterized by better contrast information compared to the original data at both P- and L-band. This can be explained as the signal at ground level being focused on the tomography processing, and rejecting contributions from the upper vegetation allows a better characterization of the polarimetric signature of ground scattering.", 3. Results, 3.3. TomoSAR Multi-Layers,3
331,"In Figure 11a, the CHM from SFL data is shown, while Figure 11b shows the forest top height estimated from L-band TomoSAR data in the same area. The relative differences between L-band CHM and SFL CHM data are shown in Figure 9c (Relative height difference = (LbandCHM − (LidarCHM)/(LidarCHM)). Figure 11e presents the forest top height estimated from P-band data. The relative difference between P-band CHM and SFL CHM data are shown in Figure 11f (Relative height difference = (PbandCHM − (LiDARCHM)/(LiDARCHM)). The difference between the estimated height from L-band, P-band and CHM from SFL data are shown in Figure 11d,g, respectively. The bias of the difference (histogram) between L-band CHM and SFL CHM is equal to −0.0681, where the RMSE value is 3.68 m; the coefficient of determination shows a value of 0.93. Regarding the histogram of the difference between P-band CHM and SFL CHM, the bias value is equal to −0.1151, where the RMSE value is equal to 3.02 m, and the coefficient of determination shows a value of 0.95.", 3. Results, 3.4. Forest Top Height Estimation from L- and P-Band,3
332,"The average Height of Ambiguity in L-band tomographic TropiSAR data are about 30 m in the near range and 50 m in the far range. The L-band tomogram is quite disturbed when compared to the P-band tomogram (Figure 4) for a dense forest of 30 m and above. In this condition, the use of tomographic imaging at L-band in tropical forests appears limited. Such limitation needs more elaborated processing either in the configuration setup of the acquisitions or in the tomographic techniques and phase calibration. However, when the forest top height is roughly below 20 m (e.g., in forest regrowth), the tomographic results are expected to be the same as in boreal forests.", 4. Discussion, 4.1. Limitation of L-Band TomoSAR in Tropical Forest (TropiSAR Data),4
333,"The analysis is done here in the azimuth direction for a fixed slant range positions (sliding window centered on the pixel number 300 m and 650 m). The Capon profile for the HH channel is shown in Figure 6 for the corrected data only. In this profile, it can be noticed that, even if the SFL data and the corrected tomographic profiles seem to show generally a good correlation at the two bands L and P, the mean SFL elevations can sometimes be notably different from the positions of the peaks of the Capon profiles. This could be linked to the SFL data that do not describe the same location due to the difference in penetration capabilities between radar signals and SFL or to other uncompensated effects. After analyzing the histograms of Figure 8, the differences in the canopy height peak estimated from L-band, P-band, and LiDAR waveform are mainly originated from the difference in the penetration capabilities of TomoSAR at L- and P-band, and the LiDAR LVIS platform. In addition, this was expected. The platform resolution is another cause for the high observed bias.The same interpretation is carried out for a specific region of interest in the Lopé named OKO2. The difference in the vegetation profile shapes between the LVIS and the Capon profiles may be originated from a difference in penetration capabilities or a variation of profile resolution between LVIS and TomoSAR data. After comparing the LVIS and the Capon profiles, the results show significant similarities. Despite the fact that tomography SAR in L & P bands with Capon estimator may not be able to produce vertical profiles with a resolution as good as the LVIS imaging system, it can always reveal stronger ground contribution as shown in the studied ROI (OKO2).", 4. Discussion, 4.2. TomoSAR Profiles at L- and P-Band (AfriSAR Data),4
334,"By observing Figure 10, and by comparing with the original SAR image at L- and P-band TomoSAR data, we found that the ground layer image has better contrast information. This implies that a ground-level signal is focused by tomography processing, thus rejecting contributions from vegetation layers and permitting the characterization of polarimetric signature of the ground scattering. The behavior of a polarimetric signature can be studied with respect to the topographic terrain ground slope. It often uses a physical model for interpreting this behavior to better understand the various scattering mechanisms (single bounce, double bounce). To compare with TomoSAR layers, the LVIS Level 1B and level 2 data as tomography were processed through reconstructing the LiDAR waveform along the z-axis; thus, the LVIS multi-layer similar to TomoSAR layers was obtained (Figure 10). Qualitatively, regarding the ground layer (or 0 m), no ground contribution is present because of the LiDAR LVIS penetration capabilities, which are lower than those of SAR.", 4. Discussion, 4.3. TomoSAR Multi-Layers,4
335,"The canopy height estimation is performed using the L-and P-band TomoSAR data in the Gabon Lopé National Park. By evaluating the vertical forests structure from tomographic profiles, the forests’ top height can be retrieved using CHM from SFL data as a reference. Here, RMSE was estimated to be 3.68 m for L-band TomoSAR as Figure 11d, while the value of RMSE is 3.02 m using P-band TomoSAR data. This reveals as before that no limitation is present for the implementation of canopy height retrieval algorithm with the L-band and P-band TomoSAR. The penetration performance of P-band is better than that of L-band due to its longer wavelength. The latter permits fewer interactions with the leaves and the branches, thus leading to deeper penetration of the radar signals to reach the ground layer. In order to give precise knowledge about the accuracy of the proposed method that is applied in estimating the forest top height, Figure 11c,f show the spatial distribution of height differences between L-band TomoSAR, P-band TomoSAR and that of LiDAR height. By analyzing the histogram of Figure 11d,g, one can notice that the height difference histogram between TomoSAR and LiDAR tends to be normally distributed. Our results considerably reinforce the proposal that L-band TomoSAR will be able to provide a highly accurate 3D vertical structure even in the densest forests worldwide.", 4. Discussion, 4.4. Forest Top Height Estimation from L- and P-Band,4
336,"As prospective work, we aim to estimate the forest structure indices as the vertical and the horizontal indices that support biomass retrieval algorithms and enhance forest management activities. However, the forest structure is an important factor in its ecology as it is correlated with many ecological processes [40,41,42]. Furthermore, it is also used as an indicator to detect the biodiversity, where the vertically structured forests foster some taxa biodiversity [43,44,45]. In addition, either the horizontal or the vertical structural heterogeneity can enhance the forest ecosystems’ resistance against disturbances [46,47]. Previous studies have also explored the forest structure’s effects on the productivity of the forest [45,48,49,50], where they found that the main drivers of the productivity of forest are the variables that characterize the structure of the forest rather than the biodiversity-related variables. Though it is highly important to know the structure of the forest in order to understand its dynamics, there are still no available global forest structure maps yet. There are only a few coarse-resolution maps that are present, but these only show the components of the structure of forest (e.g., the height of a forest from MODIS and ICESat, resolution 1 km, Indeed, larger regions of multi-layered forest structure should be efficiently analyzed. Recent satellite missions have been (e.g., GEDI, ICEsat2 sensor) and will be launched (e.g., BIOMASS, and Tandem-L) where new technologies will be used in order to measure, on a global scale, the structure of forest including its height and its vertical heterogeneity. Nowadays, there are two main elements: the vertical and horizontal forest structures [11,48,51,52]. Finding a clear and suitable definition for forest structure is highly difficult. Furthermore, the metrics of forest structure differ depending on whether they are based either on remote sensing or on field data. The remote sensing-based descriptors often depend on the heterogeneous canopy structure for a given area; however, the field-based descriptors for the forest structure are derived from size measurements of each individual tree [51]. Terrestrial Laser Scanning (TLS) is a hybrid approach for forest structure, which is measured by both field and remote sensing data [53]. It gives highly detailed measurements for every single tree and for the forest canopy structure. TLS is the best replacement for plot-level inventory data in many systems. We note hereby that TLS cannot be considered as an alternative to large extent remote sensing techniques, but it is a critical component of calibration and validation of EO products. Therefore, in order to capture forest structure on a larger scale, either airborne or satellite-based remote sensing data could be suitable choices for this.In our future studies, we are interested in using the forest modeling, LiDAR remote sensing, and airborne TomoSAR in order to be able to answer the question, “How can we estimate structure of a forest by using remote sensing, and what is the role played by forest structure in estimating the forest biomass and the above-ground wood productivity?” Our aim is to use the vertical and horizontal descriptors that can be measured by remote sensing in order to classify the forests into structural categories. Using this structural classification, we will explore if we will be able to estimate more accurately both forest biomass and above-ground wood productivity in case we included the structural information.", 4. Discussion, 4.5. Forest Structure Indices and Parameters,4
337,"In this work, TomoSAR analysis has been applied for the estimation of the forests’ canopy height and terrain using L-band UAVSAR and P-band SETHI from AfriSAR data, collected over the Gabon Lopé Park on 2015 and 2016. Prior to tomographic imaging, a phase residual correction methodology based on phase calibration via phase center double localization was implemented. The tomographic P- and L-band Capon profiles at different sections in the forests are validated in a good correlation with SFL LiDAR data CHM from the SFL data set as a reference. Second, the vertical profile of the vegetation at different sections in the Lopé using a Capon power estimator at HH, HV polarizations with LVIS Level 1B waveform LiDAR data, carried out over the OKO2 region in the Gabon Lopé National Park, was compared. The 3D profiles from Lidar waveform and from L- and P-band TomoSAR data show a high correlation. Finally, we report on the performance of forests’ top height retrieved from the TomoSAR L-band and P-band data. Forests’ top height from TomoSAR data that are estimated and validated with SFL data have an RMSE of 3.68 m for the L-band data. The RMSE value of P-band forest top height with respect to SFL was 3.02 m. The corresponding coefficient of determination was 0.95 and 0.93 for P- and L-band, respectively. Together, these results demonstrate the potential of TomoSAR to retrieve forest structure parameters. The development of tomographic SAR techniques allows for the reconstruction of the 3D radar reflectivity opening the door for 3D forest monitoring. As the link between physical forest structure and the reconstructed 3D radar reflectivity is still not understood and is far from being established, the 3D radar profiles obtained open prospects to derive algorithms that are able to link these profiles to the physical structure of the forest. For future work, we aim to provide an algorithm to estimate horizontal and vertical structure descriptors. These descriptors can be derived from TomoSAR data, which allow the characterization of the physical forest structure. Horizontal and vertical structure descriptors are crucial in boosting up the performance of biomass estimators. We hope that our results reinforce the scientific basis to estimate tropical forests’ structure indices and give support for the upcoming biomass missions.", 5. Conclusions,None,5
338,"Forest aboveground biomass (AGB) is considered an essential climate variable and plays an important role in the climate system and the global carbon cycle [1]. Accurate estimation of forest AGB and its dynamics have been gaining widespread attention from the research community. Many scholars have attempted to map the spatial distribution of forest AGB across large regions from satellite observations using various algorithms, and a great number of AGB maps have thus been generated from local to global scales, with a spatial resolution mainly ranging from 250 m to 1 km [2,3,4]. For some specific regions, high-resolution AGB maps (e.g., 30 m) are also available [5,6].On the global scale, Ruesch and Gibbs [7] provided the first spatially explicit estimate of vegetation biomass and carbon stocks at a 1-km resolution for the year 2000. They compiled a total of 124 carbon zones or regions with unique carbon stock values using the IPCC (International Panel on Climate Change) Tier-1 method and then mapped these unique carbon zones with spatial datasets, including land cover maps, ecoregions zones, and forest age, to generate the gridded carbon stock dataset. However, field data were not used in the generation or validation of the biomass dataset, and little is known about the uncertainties of the global carbon stock dataset. Following this study, Hengeveld et al. [8] provided global forest biomass at 1° spatial resolution with five-year intervals from 1950 to 2010 with forest area and growing stock data. Kindermann et al. [9] produced a global forest biomass dataset at 0.5° spatial resolution for the year 2005 based on the forest resources assessment (FRA) biomass and the assumed linear relationships between net primary production and biomass and between human activity and biomass. Liu et al. [10] derived global forest biomass carbon estimates at 0.25° spatial resolution from 1993 to 2012 from the empirical relationship between the Saatchi et al. [11] AGB map and the vegetation optical depth data that were estimated from passive microwave data. However, due to the lack of field data in these studies and the coarse spatial resolution of generated biomass maps, it is difficult to evaluate the accuracies of these global biomass datasets. Recently, some studies have adopted more advanced approaches for generating global forest AGB maps by integrating field data with multiple satellite datasets and ancillary data using machine learning algorithms. For example, Hu et al. [12] mapped the global forest AGB at 1 km resolution for the year 2004 through the integration of field inventory data, the Geoscience Laser Altimeter System (GLAS) data, optical imagery, climate surfaces, and topographic data using random forests (RF) model. Validation results with field data showed that the AGB map achieved accuracy with R2 of 0.56 and RMSE of 87.53 Mg/ha. Yang et al. [13] presented a global forest AGB map at a 1 km resolution for 2005 by combining field data with multiple satellite products, including leaf area index (LAI), gross primary production, canopy height map, vegetation continuous fields using the gradient boosting regression tree algorithm. Validation results from 20% independent samples, which were compiled from field data and regional biomass maps, showed the accuracy of generated forest AGB map had an R2 of 0.90 and RMSE of 35.87 Mg/ha. Despite these efforts to map forest AGB, substantial inconsistencies and uncertainties remain in existing forest AGB maps [14]. Different studies have produced quite diverse biomass maps in terms of both the magnitude and spatial distributions due to the uncertainties in the allometric equations used to calculate field biomass and the usage of different satellite data and mapping algorithms to estimate regional biomass [15,16]. To improve the situation, some recent studies have proposed reducing relevant uncertainties by comprehensively compiling field reference datasets [17], developing more advanced machine learning algorithms [18], and using novel remote sensing techniques (e.g., the European Space Agency P-band radar data and the Global Ecosystem Dynamics Investigation Lidar data) [19,20]. An alternative and promising method for improving the accuracy of AGB mapping is postprocessing the existing AGB maps using data integration or fusion techniques. Currently, a large number of forest AGB maps have been generated from multisource data using diverse algorithms [14], which offers the possibility of improving the accuracy of AGB mapping by combining this complementary information and advantages of each individual AGB map using data integration algorithms.Data integration or data fusion is not novel in remote sensing fields. Previous studies have integrated multiple high-level satellite data products to estimate parameters with higher accuracy in geoscience [21,22]. For example, Chatterjee et al. [23] applied a simple geostatistical data fusion approach to merge multiple aerosol optical thickness (AOT) datasets and obtained an optimal fused AOT dataset. To solve the computational bottleneck that occurs when geostatistical data fusion methods are used for massive remote sensing datasets, Nguyen et al. [24] employed the spatial statistical data fusion approach in which the spatial covariance term was expressed by spatial basis functions and Gaussian random variables to integrate multiple AOT datasets. Wang and Liang [25] used the empirical orthogonal function (EOF)-based data integration method to estimate the leaf area index (LAI) from multiple high-level satellite data products and achieved significantly improved results compared with each of the original products. Compared with geostatistical approaches, the EOF-based algorithm is easy to implement and does not require a precalculated covariance model and estimation error matrix. In addition, studies on integrating satellite-derived products have included the multiresolution tree (MRT) method to fuse multiple land surface broadband albedo products, land surface emissivity, and the fraction of absorbed photosynthetically active radiation by green vegetation [26,27,28], the Bayesian maximum entropy method to fuse multiple-satellite AOD products and sea surface temperature products [29,30], and the geographically weighted regression model to integrate different global land cover maps and forest cover products [31,32].However, in the field of forest AGB mapping, integrating available forest AGB maps to generate more accurate results has been largely ignored. Currently, few studies have attempted to combine existing forest AGB maps for a more accurate estimation of forest AGB. Ge et al. [33] first combined three source biomass maps covering East Africa with reference datasets using the weighted averaging approach and obtained more accurate biomass maps than each of the individual source biomass maps. Following this study, Avitabile et al. [34] fused pantropical forest biomass maps produced by Saatchi et al. [11] and Baccini et al. [4] using bias removal and the weighted linear averaging method and improved the estimation of forest AGB across pantropical regions. Here, we aimed to make the best use of existing AGB maps from local to global scales to generate a global forest biomass map with greater accuracy than existing AGB maps.As noted, many algorithms have been proposed to integrate satellite data products. However, most of them are based on the assumption that satellite products have white noise that follows a normal distribution [21], which is rarely satisfied by regional and global forest AGB data. Additionally, the complex structures of these fusion algorithms affect the computational efficiency for calculating the weightings of individual datasets, which limits their application on a large scale [35]. Instead of only considering the effectiveness of the fused results, linear combination methods can achieve good results in effectiveness and efficiency and thus have received much attention in information retrieval, especially in the big data environment [36]. The linear combination method can be very flexible since different weights can be easily assigned to different data products. According to the weights used in the combination, diverse linear combination methods have been developed, but which weighting schema is good remains an open question [37]. In this study, to reduce the complexity of the fusion algorithm that was used to generate a more accurate global forest AGB map, we proposed a linear combination algorithm that first removes the corresponding errors from gridded forest AGB datasets and then simply averages the calibrated forest AGB data for the fusion of multiple forest AGB datasets. The objectives of this study were thus to (1) improve the accuracy of biomass estimates by integrating multiple forest AGB maps with the proposed error removal and simple averaging algorithm and (2) generate an accurate forest AGB map at a global scale.", 1. Introduction,None,1.
339,"We collected existing regional and global forest AGB maps that were derived from satellite observations. If more than one version of a gridded AGB map was available, the improved version with higher accuracy was used for the fusion algorithm in this study. Ten forest AGB maps were finally selected and served as input layers for global forest AGB mapping (hereafter referred to as source AGB maps). The 10 source AGB maps should represent state-of-the-art AGB estimates covering different regions. To facilitate description, they were named producers plus biomass (e.g., Avitabile biomass) if they did not have a specified name. The spatial and temporal coverage, spatial resolutions, and mapping algorithms of 10 source AGB maps are listed in Table 1, and more details about these datasets can be found in the corresponding references.GLC2000, Global Land Cover 2000; MODIS, Moderate Resolution Imaging Spectroradiometer; EOSD, Earth Observation for Sustainable Development of Forests; ASAR, Advanced Synthetic Aperture Radar; NLCD, National Land Cover Dataset; PALS, Portable Airborne Laser System; GEZ, Global Ecological Zones; NDVI, Normalized Difference Vegetation Index; SRTM, Shuttle Radar Topographic Mission; DEM, Digital Elevation Model; InSAR, Interferometric Synthetic Aperture Radar.The pantropical Avitabile biomass map was derived from existing AGB datasets published by Saatchi et al. [11] and Baccini et al. [4] and had higher accuracy [34]. Due to the incorporation of Avitabile biomass map, Saatchi biomass and Baccini biomass were not considered as source AGB maps in this study. The Avitabile biomass map was provided in a geographic projection (WGS-84) at 0.00833 degrees (approximately 1 km) resolution and resampled to 0.01°.Thurner et al. [3] provided forest carbon density at 0.01° resolution in Northern Hemisphere boreal and temperate regions (30°–80°N) based on a growing stock volume product retrieved from synthetic aperture radar, wood density, and biomass compartment data. They used a carbon fraction of 0.488 for broadleaf tree species and 0.508 for needleleaf tree species to calculate carbon density. We adopted a common factor of 2.0 to convert the carbon density (Mg C/ha) to AGB (Mg/ha) since forest types might be a mixture of several forest types at the pixel level, and it is difficult to separate them. Similar to Thurner et al. [3], the maps generated by Wilson et al. [39] provided aboveground carbon density (Mg·C/ha), and a carbon concentration of 0.5 gC·g−1 was used to convert carbon density to AGB (Mg/ha).Neigh biomass and Margolis biomass were generated using similar methods that tied ground plot AGB to airborne profiling lidar metrics as well as GLAS data and had a spatial resolution of 500 m [38,43]. The preprocessing of both datasets included reprojection to the WGS84 coordinate system and aggregation to the 0.01° resolution by computing the mean value of the pixels whose center was located within each 0.01° cell.Additionally, Blackard biomass, Wilson biomass, NBCD2000, and Su biomass were not expressed in the geographical coordinate system and were first reprojected from their original projection type to the geographical coordinate system with WGS84 datum using the nearest-neighbor resampling method. Source AGB maps with spatial resolutions finer than 0.01°, such as Blackard biomass and NBCD2000, were aggregated to the 0.01° resolution.", 2. Materials and Methods , 2.1. Regional and Global Source AGB Maps,2
340,"The reference AGB data were used to calibrate source AGB maps and validate the accuracy of the generated global forest AGB map using the data fusion technique. Reference AGB was obtained by compiling field measurements and high-resolution biomass datasets that were originally derived from field data and lidar data [44]. Field biomass measurements were compiled from plot-level AGB that were acquired on or after the year 2000 from the published literature and online databases. These plots were mainly located in the mature or primary forest with minimal human disturbances. For each plot, the coordinate information, plot name, plot code, plot size, forest status (e.g., old-growth or regrowth), sampling years, as well as the corresponding forest AGB were recorded. Plot-level AGB was estimated using allometric equations developed for a specific region or a specific type of forest. Only trees above a defined diameter at breast height (1.3 m above the ground) larger than or equal to 10 cm were considered to computing plot-level AGB [45,46,47,48]. For field plots that provided carbon density rather than AGB, a carbon concentration of 0.5 gC·g−1 was used to calculate AGB in the unit of Mg/ha. To ensure the representativeness of in-situ plot measurements to the forest conditions of corresponding locations and reduce the potential error in data geolocation, the collected plots less than 0.05 ha in size were filtered out [49,50]. A total of 5885 field plots from 25 sources were selected and aggregated into 2199 reference AGB cells with 0.01° resolution (Table 2).High-resolution biomass datasets were used to generate reference AGB data because of their relatively high accuracies. Generally, field plots had a size of approximately 0.25~1.0 ha, corresponding to a pixel size of approximately 50~100 m; therefore, we only considered gridded biomass maps with spatial resolutions finer than 100 m to ensure that field datasets and high-resolution biomass datasets could match well at the spatial scale. Six datasets were selected to derive reference AGB data, including the Cook biomass map at four forested sites in the US: Garcia River Tract in California, Anne Arundel and Howard Counties in Maryland, Parker Tract in North Carolina, and Hubbard Brook Experimental Forest in New Hampshire, for the nominal year of 2011 at 20–50-m resolution [70]; the Babcock biomass map at 13-m spatial resolution in the Penobscot Experimental Forest (PEF) in Bradley, Maine, for the year 2012 [71]; the Dubayah biomass map at a 30-m spatial resolution for Maryland for the nominal year 2011 [72]; the Dubayah map for Sonoma County, California, for the nominal year 2013 [73]; the Labberière River biomass data at two sites in French Guiana and four areas in Gabon [58]; the Fatoyinbo biomass map at a 1-m spatial resolution for a mangrove forest in the Zamamamamé Delta Mombita Mozaque forest [74]. Consistent with the preprocessing of source AGB maps, the preprocessing of high-resolution biomass maps included reprojection to the geographical coordinate system and aggregation to the 0.01° scale. For the biomass maps that provided carbon density values instead of AGB, the common factor 2.0 was used to convert carbon density to AGB.We combined the aggregated field reference data and high-resolution reference biomass datasets and generated a global reference AGB dataset. Since the mismatches in spatial scales between field plots and pixels of satellite products may lead to uncertainties of forest AGB mapping, particularly when forest AGB showed strong local spatial variation [75], we assessed the spatial variation in reference AGB datasets using the coefficient of variation (CV) of tree cover data from Hansen et al. [76] within each 0.01° pixel and removed the reference AGB data with a CV of tree cover larger than 1.0, leaving 13,597 pixels (Figure 1).", 2. Materials and Methods , 2.2. Reference AGB Datasets,2
341,"Based on the generated reference AGB data in Section 2.2, source AGB maps were integrated using the linear combination method. The integration of multiple-satellite data products was essentially a weighted combination of multiple datasets. Estimating forest AGB from multiple source AGB maps can be expressed as:



Y

(
k
)

=


∑


i
=
1

N


w
i


(
k
)


X
i


(
k
)





(1)







∑


i
=
1

N


w
i

=
1




(2)


where k represents the forest pixel, Y(k) is the estimated biomass of pixel k, N is the number of source AGB maps with biomass values for pixel k, Xi is the AGB value of the i-th source map, and wi(k) is the weight that was set for the i-th source AGB map at pixel k. For any pixel, the sum of all the weights of the source AGB maps is equal to 1.Since the calculation of weights greatly affects the estimated AGB, we explored several algorithms, including the adaptive-weighted average algorithm that computes the weights of each source AGB map by its prediction performance [77] and the skill and independence weighted average algorithm, which can account for both the performances of source AGB maps and independences among these AGB maps [78], and found that these weighted average algorithms could not provide accurate estimates of forest AGB. Therefore, we proposed the error removal and simple averaging method for the fusion of ten source AGB maps.Using the error removal and simple averaging algorithm, estimated pixel-level AGB was derived as follows:




Y
i


(
k
)

=

1
N



∑


i
=
1

N


(


X
i


(
k
)

−

E
i


(
k
)


)





(3)


where k represents the forest pixel, Y(k) is the estimated biomass of pixel k, N is the number of source AGB maps with biomass values at pixel k, X is the observed biomass of the i-th source AGB map, and Ei(s) is the error of the i-th source biomass map at pixel k.According to Equation (3), estimating AGB from multiple source maps consisted of the following steps: (1) determine the pixel-level errors of each source AGB map, (2) calibrate the source AGB by removing the corresponding pixel-level errors, and (3) average the calibrated source AGB maps with equal weights. The core of the proposed error removal and the simple average algorithm was to obtain pixel-level errors associated with each source AGB map. Once we modeled the errors of each source AGB map, estimated AGB through the fusion of source AGB maps could be obtained using Equation (3).", 2. Materials and Methods , 2.3. Data Fusion Framework,2
342,"The accuracies or performances of a source AGB map were not uniformly distributed across its whole coverage, and in addition, source AGB maps were not accompanied by a pixel-level error or uncertainty map. It was thus necessary to estimate the pixel-level errors of AGB data. For each source AGB map, pixel-level errors of AGB values corresponding to reference AGB data points were obtained from the differences between extracted AGB from the source AGB map and coincident reference AGB data and used as the training samples for estimating pixel-level errors of AGB. Pixel-level errors of source AGB maps were obtained by extrapolating the dispersed observational errors into the same spatial extent as the source AGB maps. In this study, we implemented extrapolation with the random forest regression tree algorithm. Predictor variables were the leaf area index (LAI), forest canopy height, forest cover, elevation and slope, and temperature and precipitation, which were correlated with forest AGB [34].The Global Land Surface Satellites (GLASS) LAI product, with a temporal resolution of eight days and a spatial resolution of 1 km from 2000 to 2010, was used [79,80]. To reduce the noise in the LAI time series and minimize the impacts of LAI seasonality on biomass estimates, we aggregated the 8-day LAI to the monthly scale and extracted the maximum monthly LAI within one year as the maximum annual LAI. The LAI used in the error modeling was the average of the maximum annual LAI values from 2001–2010. The global forest canopy height map was provided by Simard et al. [81], with a 1-km spatial resolution. The global forest cover map at 30-m spatial resolution generated by Hansen et al. [76] was aggregated to 0.01 degrees and used as one of the covariates of errors. It also served as the base map of the global tree cover. Forests and shrubs with a tree cover of no less than 10% were considered forest pixels, and other pixels were masked [82]. Additionally, the land surface elevation and slope information derived from the Global Multiresolution Terrain Elevation Data (GMTED) 2010 dataset at 7.5 arc-second resolution [83], as well as the average monthly temperature and precipitation data at 30-s resolution download from WorldClim (http://worldclim.org/version2) [84], were included in the modeling of errors associated with each source AGB map. For consistency with AGB datasets, predictor variables, including LAI, forest canopy height, forest cover, elevation and slope, and climate data, were all reprojected to the WGS 84 geographical system and resampled to 0.01 degrees.", 2. Materials and Methods , 2.4. Estimating Pixel-Level Errors of Source AGB Maps,2
343,"Ten-fold cross-validation was performed to evaluate the accuracy of estimated forest AGB from multiple source AGB maps using the error removal and simple averaging algorithm. Evaluation metrics were the correlation of determination (R2), bias, and RMSE.Intercomparison was also performed to indirectly assess the accuracy of our estimated results relative to global forest AGB maps from published studies, with AGB maps provided by Kindermann et al. [9], Liu et al. [10], Hu et al. [12], and Yang et al. [13]. Liu et al. [10] provided forest carbon estimates from 1993 to 2012 at a 0.25° resolution. We converted the carbon to biomass using the common factor and took the average AGB from 2001 to 2010 as the Liu biomass map used in the comparison. The Liu biomass map and the Kindermann et al. [9] AGB data for 2005 at a half-degree resolution had a spatial resolution coarser than 0.01° and were resampled to 0.01° for consistency with other global forest AGB maps.We extracted the estimated AGB from four previous studies and fused the AGB of this study for the reference AGB pixels and assessed how closely the five global forest AGB data matched the reference AGB data. Their similarities with reference AGB data were quantified in terms of the correlation coefficients, standard deviation, and centered root-mean-square difference (RMSD) and graphically described by the Taylor diagram [85].Additionally, we obtained the different AGB maps by subtracting each of the four global forest AGB maps from the fused AGB. Statistical analysis of AGB differences for different continents and frequency distributions of each global AGB map for different forest types were conducted. The forest types were separated according to the MODIS land cover type product (MCD12Q1, version 6) for 2005 and the International Geosphere-Biosphere Program legend [86]. Consistent with other global forest AGB data, the 500-m resolution data were first reprojected to the geographical coordinate system using the nearest-neighbor resampling method and then aggregated to the 0.01-degree resolution by selecting the most dominant land cover type within the extent of each 0.01-degree pixel. We extracted the AGB values with a corresponding tree cover of no less than 10% and forest types, including deciduous broadleaf forests (DBF), deciduous needleleaf forests (DNF), evergreen needleleaf forests (ENF), evergreen broadleaf forests (EBF), mixed forests (MF), open shrublands (OSH), closed shrublands (CSH), woody savannas (WSA), and savannas (SAV), and performed statistical analysis of the number of pixels within 20 Mg/ha bins. Since different definitions of forests were used in the generation of these forest AGB maps, all the statistical analyses were carried out on the pixels that were considered forests by the AGB datasets used in a comparison.", 2. Materials and Methods , 2.5. Validation and Intercomparison,2
344,"Pixel-level errors associated with each source AGB map were modeled using the RF algorithms, and the results showed that the modeled errors were close to the observation errors, which were calculated from the difference between the reference AGB data and the corresponding gridded AGB extracted from the source map (Figure 2). The correlation coefficients between modeled error and observation error at reference AGB data points ranged from 0.76 for Su biomass to 0.90 for Hu biomass and Wilson biomass, while RMSEs of predicted errors in source AGB maps ranged from 26.48 Mg/ha to 79.59 Mg/ha. Three source AGB maps had RMSEs of less than 30 Mg/ha, four source datasets had RMSEs of 30~40 Mg/ha, and for the three remaining source AGB maps, including the Su biomass, Barredo biomass, and Avitabile biomass, the differences between observation errors and modeled errors at the reference AGB data points were relatively large. Nevertheless, the pixel-level errors in the majority pixels of each source AGB map were modeled accurately, very close to the observation errors, which also suggested the efficiency of our approach in estimating errors of source AGB maps (Figure 2).", 3. Results, 3.1. Modeled Errors Associated with Source AGB Maps,3
345,"Based on the pixel-by-pixel errors of each source AGB map, source AGB maps were calibrated and then averaged to generate the global forest AGB map for the 2000s (Figure 3). The results showed that tropical forests stocked the most carbon in the aboveground per hectare [9,12,87]. When aggregated to the country level, New Zealand, French Guiana, Equatorial Guinea, Gabon, Suriname, Guyana, Brunei Darussalam, and Congo were found to have the highest forest AGB, with corresponding forest area-weighted averages of AGBs higher than 300 Mg/ha. At the continental scale, the AGB of Oceania and South America was higher than those of other continents. Europe and Asia had the lowest forest AGB but exhibited different spatial patterns. In Europe, nearly all countries had low biomass densities, whereas, in Asia, there were large discrepancies in forest biomass among different countries.", 3. Results, 3.2. Spatial Patterns of the Fused Global Forest AGB Map for the 2000s,3
346,"Cross-validation results showed that the generated forest AGB map achieved a good overall accuracy, which had an R-squared of 0.61, RMSE of 53.68 Mg/ha, RMSE% of 30.28%, and bias of 3.15 Mg/ha globally (Figure 4). To the best of our knowledge, this accuracy is the best among studies on estimating forest AGB on a large scale. Another study that used satellite data and the RF algorithm to predict the forest AGB had an R-squared of 0.56 and RMSE of 87.53 Mg/ha on a global scale [12].", 3. Results, 3.3. Validation Results,3
347,"Compared with global AGB maps from other studies, the forest AGB map generated by the fusion of source AGB maps (fused AGB) was closer to the reference AGB (Figure 5). Estimated AGB from Yang et al. [13] and Hu et al. [12] for the reference AGB pixels was similar in terms of correlation, standard deviation, and RMSD. AGB estimated by Liu et al. [10], Yang et al. [13], and Hu et al. [12] had similar standard deviations, but their correlations with reference AGB were slightly different. AGB estimated by Kindermann et al. [9] was quite different from other studies; it had the least standard deviation and correlation and the largest RMSD.The spatial distribution of AGB differences between fused AGB and global AGB maps from other studies also showed substantial discrepancies in AGB estimation among different studies on a global scale (Figure 6). The fused AGB tended to be higher than the Liu AGB and Kindermann AGB for most forests in the world (Figure 6 and Figure 7) but slightly lower than the Hu AGB map at a global scale, which was probably caused by the extremely low fused AGB in Europe and Central and South America (Figure 7).At the continental scale, the differences in five global forest AGB maps were not substantial in Europe and North America as in Oceania, Africa, Asia, and South America, consistent with published studies that emphasized the uncertainties of estimated AGB in tropical regions [4,88]. Since boreal forests have lower AGB than tropical forests, it is not appropriate to directly compare the uncertainties in estimated AGB for different regions. The intercomparison results of relative AGB differences showed that larger discrepancies in estimated AGB among different datasets existed for forests in Europe and North America, while the relative AGB differences in South America and Africa mostly ranged within ±50% (Figure 8). This indicated the strong necessity to improve the accuracy of AGB estimates in boreal forests, which is largely ignored in previous studies.Comparing the frequency distributions of five global forest AGB datasets, we found that the frequency of fused AGB for all forest types except CSH had one peak, and the number of pixels with corresponding AGB values within the peak bins was small, suggesting that fused AGB had dispersed distributions compared with other datasets within each forest type (Figure 9). The Kindermann AGB data had quite different distributions from the other datasets, particularly in ENF, EBF, DNF, DBF, MF, and CSH. All the datasets except Kindermann revealed higher AGB in EBF than those in other forest types. DBF also had high AGB values, while DNF had lower AGB, distributed within a narrower range. Large discrepancies in the frequency distribution of Liu AGB with other datasets were also found in all forest types except WSA and SAV. In CSH, OSH, WSA, and SAV, this study provided lower AGB with more reasonable distributions than other datasets.", 3. Results, 3.4. Intercomparison Results,3
348,"The generated global forest AGB map was derived by merging ten source AGB maps using the error removal and simple averaging method. Uncertainties of this fused AGB map thus mainly come from the uncertainties of pixel-level errors of source AGB maps. If the errors of source AGB maps can be estimated accurately, the derived forest AGB map will have a high level of confidence. Although this study provided more accurate AGB estimates than published datasets globally, uncertainties are still large in some regions, partly attributed to the remotely sensed datasets used. The primary datasets were from optical sensors, which were responsive to canopy cover, rather than vertical structure. This could affect the accuracy of modeled errors of source AGB maps. Predictors that describe the vertical structure of forests should be included to improve the accuracy of modeled errors and further AGB estimates in future studies.In this study, the accuracy of the modeled errors had R-squared values ranging from 0.58 to 0.81 and RMSE values ranging from 26.48 Mg/ha to 79.59 Mg/ha. Cross-validation results suggested that estimated global forest AGB achieved accuracy with an R-squared of 0.61 and RMSE of 53.68 Mg/ha, located within the accuracy of modeled errors of source biomass maps, which was probably because the discrepancies between real observation errors and the corresponding predicted errors accounted for the majority of uncertainties in forest AGB estimation. The results of this study indicated that accurate quantification or knowledge of uncertainties was not only important for understanding the uncertainty of the datasets and facilitating their application in related fields but also indispensable for improving the accuracy of estimated forest AGB.Previous studies have quantified the pixel-level errors or uncertainties of biomass estimates mainly by the error propagation approach, calculating the uncertainties due to model algorithms, datasets used, the choice of allometric equations, and the mismatch of field data and remotely sensed data [89,90,91]. However, it is difficult to measure all the uncertainties in the AGB estimation since the influencing factors are so complex, and nearly all the studies have quantified only parts of the uncertainties in the AGB estimation. This study provided a new perspective to describe uncertainties without distinguishing the sources of uncertainties, which can help in understanding and quantifying uncertainties in forest AGB estimation in future studies.", 4. Discussions, 4.1. Uncertainty Analysis of Global Forest AGB Mapping,4
349,"The true AGB value can be mathematically described as the sum of observed or estimated AGB and the associated errors. If we can infer the errors associated with the estimated forest AGB, the true or actual forest AGB will be known. Therefore, to generate an accurate global forest AGB map, it is essential to quantify the pixel-level errors of source AGB maps accurately. Since it is difficult to quantify the errors or uncertainties in AGB estimates, the RF algorithm was used to model the pixel-level errors of each source AGB map in this study. The results showed that the modeled errors were close to the observational errors of the source biomass maps, which were obtained by comparison with reference AGB data. Different from most studies that use RF algorithms to estimate forest AGB with ancillary datasets, we used similar methods to estimate errors of AGB maps rather than AGB [92,93]. The underlying principle is that errors of estimation are often negatively correlated with the AGB values, partly due to the underestimation of AGB at low values and overestimation at high values caused by datasets and empirical modeling methods used, as demonstrated in previous studies [68]. Through estimating errors of source biomass maps and further calibrating these AGB maps with predicted errors, this study produced forest AGB at a global scale by simple averaging these calibrated AGB maps, which rectified parts of the overestimation and underestimation existing in the original AGB maps or estimated AGB through direct empirical modeling [94,95].Previous studies used other methods, such as the weighted average method, to combine source biomass maps [34]. We tried this to estimate global forest AGB in this study and achieved accuracy with an R-squared of 0.42, RMSE of 88.51 Mg/ha, RMSE% of 49.88%, lower than the results of this study. The error removal and simple averaging method was thus used to generate the global forest AGB map. Moreover, the proposed error removal and simple averaging algorithm made no assumptions about the source AGB maps and their errors and was quite simple to deal with massive datasets.However, it is noteworthy that the proposed method is subject to currently existing biomass maps. Despite its good performance in producing forest AGB maps, this methodology will not be as efficient as the generation of a global forest AGB map using data-driven machine learning algorithms when we attempt to generate accurate biomass map time series or monitor forest biomass changes.", 4. Discussions, 4.2. Strength and Limitation of the Error Removal and Simple Averaging Method,4
350,"In this study, the reference AGB data and ancillary datasets used to model errors were mainly for 2000 and after. Source AGB datasets were also from 2000 to 2010, but most of them were for a specific year or a small period rather than for the whole period 2001–2010, which suggested that they may correspond to different forest statuses due to the existence of forest disturbances and growth. Therefore, the temporal mismatch between reference AGB data with the generated global forest AGB map using the error removal and simple averaging approach could have affected the evaluation results. Fortunately, forest disturbances generally occur only in a small part of forests [76,96,97], and the reference AGB data selected had minimal disturbances; therefore, the impacts of the temporal mismatch of datasets on the estimation and evaluation results should be limited.Additionally, reference AGB was considered accurate without uncertainties, which is slightly far from the fact, despite the efforts of extensively collecting and carefully preprocessing field biomass data and high-resolution AGB maps. This assumption could also lead to uncertainties associated with the validation and intercomparison. In future studies, the uncertainties of reference AGB datasets should be examined, and the associated impacts on the validation and intercomparison results should be considered. The number of reference data points could also have had a great effect on the evaluation results. For a certain source biomass map, a limited number of reference data points located in the corresponding region indicated the limited training datasets to predict the errors, which would further lead to the dispersion of modeled errors in Figure 2. As suggested by previous studies, the derivation of AGB maps from sparse field measurements was not advocated, and AGB could be best mapped using a combination of remotely sensed datasets calibrated and validated using a substantial number of carefully compiled reference datasets [17]. Therefore, more reference biomass datasets could be incorporated to increase the robustness and accuracy of modeled pixel-level errors of source biomass maps and further reduce the uncertainties of estimated forest AGB in the future.", 4. Discussions, 4.3. Factors Influencing the Assessment of Fused Global Forest Maps,4
351,"In this study, we integrated ten existing forest AGB maps with substantial uncertainties and generated an improved global forest AGB map for the 2000s at 0.01° spatial resolution using the proposed error removal and simple averaging algorithm. Cross-validation using reference AGB data that were compiled from in situ measurements as well as high-resolution biomass data derived from field data and airborne lidar data showed the high accuracy of the generated forest AGB map with an R-squared of 0.61, RMSE of 53.68 Mg/ha, and bias of 3.15 Mg/ha at a global scale. The intercomparison with several published studies also demonstrated a better accuracy of our generated global forest AGB map. We found large differences in the estimated AGB of boreal forests among different studies, which were largely neglected in published studies. Since it is difficult to quantify the errors involved in the biomass estimation, such as the allometric error, errors caused by the mismatch between field data and satellite data, as well as errors of the dataset used and the mapping algorithms directly, this study directly predicted pixel-level errors of existing forest AGB maps using RF models, which offers an alternative perspective to quantify errors of the estimated biomass at a large scale. Although much work is needed to improve the accuracy of global forest AGB estimates, this study moves one step forward for climate mitigation strategies and advances our understanding of the global terrestrial carbon cycle by providing improved benchmarks of global forest carbon stocks.", 5. Conclusions,None,5
352,"Full polarimetric synthetic aperture radar (PolSAR), a recently developed, advanced remote sensing technology, has been widely used in the field of earth observation. Because PolSAR combines the merits of microwave penetration and polarisation measurement, it has advantages in the estimation of forest traits, such as forest aboveground biomass (AGB). However, its application is greatly limited by the terrain. Owing to the characteristics of side-looking illumination by SAR sensors, terrain undulations seriously affect the radiometric quality of SAR images. The correction of these effects becomes crucial when quantitative analysis is performed with respect to the derivation of geo- and biophysical parameters [1]. This correction is typically referred to as Radiometric Terrain Correction (RTC) [2]. For single- or dual-polarisation SAR, the object of RTC is a backscattering coefficient value for different polarisations, such as σHH, σHV or σVV. However, for PolSAR, the object of RTC is a polarisation scattering matrix, such as the Sinclair matrix (S), polarisation covariance matrix (C) or polarisation coherency matrix (T). Compared to single- or dual-polarisation SAR, the influence of topography for PolSAR is more complex.For SAR data, the effect of terrain can be summarised in three aspects. The first is variation in the effective scattering area (ESA), which depends on the local imaging geometry. For example, on the front slope, one pixel in an SAR image corresponds to more ground area than it would on the back slope. The second is variation in scattering mechanisms and penetration depth, among others. These phenomena are collectively known as the angular variation effect (AVE), which mainly appears in areas of vegetation [3,4]. The third is variation in polarisation states, caused by azimuth slopes, which induces polarisation orientation angle (POA) changes [5]. This effect occurs only in PolSAR data.ESA correction requires accurate description of the SAR imaging geometry based on the topological relationship between slant range radar coordinates and the map grid of local topography. Several studies have been published on this topic. The methods are based on local incidence angle [6], surface tilt angle [2,7], projection angle [8], and area integral [9,10]; the most accurate of these are the projection angle and area integral methods. The topological relationship used in these methods may be divided into two types: homomorphic [2,6,7,8] and heteromorphic [9,10], as proposed by Small [9,11]. It has been shown that homomorphism is not an appropriate assumption, compared to heteromorphism [9,11]. However, the prerequisite for heteromorphism is high-resolution Digital Elevation Model (DEM) data, which must have resolution equal to or better than that of the SAR data [9].Among the three terrain correction steps, ESA correction is the most fundamental. In the case of single- or dual-polarisation SAR and over areas not covered by vegetation, ESA correction is sufficient. However, for areas with vegetation coverage, it is necessary to perform further AVE correction through a basic model using the nth power of the cosine of the local incident angle [12]. The key problem lies in determining the value of n, which depends on the terrain cover type, radar frequency, and polarisation mode. Castel et al. [3] proposed a semi-empirical model to determine the value of n based on radiative transfer theory, which has a single parameter describing the canopy optical thinness. Sun et al. [13] adopted a three-dimensional (3D) radar backscatter model to simulate a series of SAR images for one forest scene with various surface slopes. The value of n was acquired by analysing the variation rule of the simulated backscattering values. However, these two methods are ordinarily too difficult to perform because both require a priori knowledge. Therefore, the objective of the current study is to find a more automated method to determine the value of n.As mentioned above, the two correction processes are typically sufficient for single- or dual-polarisation SAR data. However, for PolSAR data, POA correction is also required. Related theories were first raised by Lee and Schuler [5], who proposed using the classic circular polarisation method to calculate the shift angle of POA; the shift angle may be used to compensate for the azimuth slope effect in PolSAR data. Villard et al. [4] proposed a new numerical method to calculate the POA shift angle from a polarisation coherency matrix. The difference is that circular polarisation method nullifies the real part of T23 (2nd row, 3rd column element of T), whereas the numerical method of Villard aims at cancelling the complex terms T13 (1st row, 3rd column element of T) and T23 through a quadratic positive cost function [4]. Kobayashi et al. found that the correlation between industrial plantation forest parameters and decomposition parameters in PolSAR data improved following the POA correction process [14].Currently, SAR data terrain correction methods are mainly a combination of the three correction types. For example, Castel et al. [3], Sun et al. [13], and Hoekman et al. [15] combined the ESA and AVE corrections to handle the terrain effects for single- or dual-polarisation SAR data in forest-covered areas. Wang et al. proposed an improved PolSAR RTC method combining ESA and POA correction methods; improved results were obtained when they applied their approaches to PolSAR data for land cover classification [16]. In a study of forest AGB retrieval using P-band PolSAR data, Villard et al. adopted the ESA, AVE, and POA correction methods to develop a new backscattering coefficient called t0 that yields a better correlation with forest AGB [4]. However, in their AVE correction procedure, the value of n was also determined according to expertise.In summary, the general consensus is that a single correction method is insufficient to handle topography effects in PolSAR data. A comprehensive and systematic RTC method is urgently needed to treat PolSAR data. Furthermore, the correction should be changed from a single backscattering coefficient to a full polarisation scattering matrix. The overall correction process should be more automated to facilitate practical application. Nevertheless, such practical approaches have not yet been developed.In this study, we propose a novel approach to determine the value of n in AVE correction adaptively. By integrating the AVE correction method into the entire correction process, we developed a three-step terrain correction method for PolSAR data. The three-step method, specially developed for PolSAR matrix data, is comprehensive, convenient, and efficient, requiring less prior knowledge. In addition to the proposed method, which includes the POA, ESA, and AVE correction methods, we present a demonstration and analysis of the method as applied to a forested area using ALOS-2 PALSAR-2 PolSAR data.", 1. Introduction,None,1.
353,"The processing flow chart presented in Figure 1 provides details of the proposed method, which includes three key data processing steps. In PolSAR data pre-processing, single-look complex (SLC) PolSAR data must be calibrated, multi-looked, or filtered. Next, geocoding of terrain correction (GTC) is performed. In satellite SAR, the geocoding process is completed based on precise satellite orbit information and DEM data using a Range Doppler (RD) position model. This is an indispensable step in the SAR RTC process [1]. Then, we obtain the mapping relationship (GTC model) between SAR slant-range space and geographic space, and local imaging geometry information that is also required for ESA and AVE correction, in order to compute the projection angle and local incidence angle. Finally, the terrain correction process involves POA, ESA, and AVE correction.To clarify the RTC process, the geometry space of PolSAR data at different data processing steps and its topological relationship are illustrated in Figure 2. POA correction is performed in SAR range geometry (Figure 2b), and ESA and AVE corrections are completed in map geometry. The GTC model includes the topological relationship between radar range (Figure 2b) and map geometry (Figure 2c). Although the relationships are heteromorphic (“one-to-many” for front slopes and “many-to-one” for back slopes), because ESA and AVE corrections are performed in map geometry, we assume homomorphism rather than heteromorphism in this study. However, in the absence of high-resolution DEM data (compared to SAR data) and extremely steep slopes, this assumption has little impact because the heteromorphic situation will be close to homomorphism. That is, the “one-to-many” relationship of front slopes will approach a “one-to-one” relationship.", 2. Methods, 2.1. Framework of the Proposed Method,2
354,"For a reciprocal medium illuminated by a monostatic SAR, PolSAR data can be represented by a complex scattering vector on a linear basis:





h
=



[






S

h
h







2


S

h
v







S

v
v







]


T






(1)


where the superscript “T” denotes the matrix transpose. Most PolSAR data are multi-looked and filtered for speckle reduction. Multi-look PolSAR data can be represented by a polarisation covariance matrix (C):







C
=
E

(

h
⋅

h

*
T



)





=

[






〈




|


S

h
h



|


2


〉






〈


2


S

h
h




S

h
v


*


〉






〈


S

h
h




S

v
v


*


〉








〈


2


S

h
v




S

h
h


*


〉






〈

2



|


S

h
v



|


2


〉






〈


2


S

h
v




S

v
v


*


〉








〈


S

v
v




S

h
h


*


〉






〈


2


S

v
v




S

h
v


*


〉






〈




|


S

v
v



|


2


〉






]
,








(2)


where “*T” denotes the conjugate transpose of the matrix. E( ) denotes multi-look averaging. The polarisation coherency matrix (T) may be acquired from the covariance matrix through unitary transformation [17].", 2. Methods, 2.2. PolSAR Data Format,2
355,"For polarimetric imaging radar, we most frequently encounter linear polarised systems, but the polarisation electromagnetic waves emitted by radar may also be described by a polarisation ellipse based on polarisation synthesis theory (Figure 3). Two parameters of the ellipse directly relate to the polarisation state. One is its ellipticity angle, ε; the other is its tilt angle τ, also called POA.As shown in Figure 3, the polarisation ellipse was rotated due to the azimuth slope. As a result, the radar cross section of different polarisation channels changes as the POA changes. Based on the circular polarisation method [5], the POA shift angle can be obtained by Equation (3):





δ
=

1
4


[



t
a
n


−
1



(



−
4
R
e

(


〈


(


S

h
h


−

S

v
v



)



S

h
v


*


〉


)



−

〈




|


S

h
h


−

S

v
v



|


2


〉

+
4

〈




|


S

h
v



|


2


〉




)

+
π

]
.






(3)

Here, δ denotes the POA shift angle. When δ > π/4, δ = δ − π/2. Once δ is obtained, the correction method for this slope effect is straightforward. For polarimetric covariance matrix (C), the data compensation can be achieved by Equation (4):








C

P
O
A
c


=
V
C

V
T

,




V
=

1
2


[





1
+
cos
2
δ





2

sin
2
δ




1
−
cos
2
δ






−

2

sin
2
δ




2
cos
2
δ





2

sin
2
δ






1
−
cos
2
δ




−

2

sin
2
δ




1
+
cos
2
δ





]
.








(4)

Because the POA shift angle is derived directly from the PolSAR data without satellite orbit or local terrain information, we may apply the POA correction immediately after PolSAR data pre-processing.", 2. Methods, 2.3. Step 1: Polarisation Orientation Angle Correction,2
356,"For distributed targets, the backscattering coefficient is defined as the average radar cross section (RCS) per reference area. If the reference area is defined as the slant range area of the SAR image, the backscattering coefficient, β0, is defined as:






β
0

=


R
C
S

/


A
β



 
with
 


A
β

=

δ
a


δ
r


,





(5)


where δa is the azimuth resolution and δr is the range resolution. Aβ depends solely on the radar system.However, for most practical applications of SAR, the effective area Aσ is typically used as a reference area. Rugged terrain affects the backscattering coefficient corresponding to Aσ due to changes in the local geometry of SAR imaging. Aσ can be converted from Aβ through the conversion factor proposed by Ulander [8]:






A
σ

=

A
β

/
c
o
s
ψ
,





(6)


where ψ is the projection angle between the surface normal and the image plane normal (Figure 4).For each map coordinate on the DEM grid, we can obtain the unit vectors of the surface normal (



N
^



), azimuth direction (



X
^



), and incident direction (



R
^



), based on precise satellite orbit information and DEM data. Thus, two pivotal angles can be made explicit:





c
o
s
ψ
=

N
^

⋅
(

X
^

×

R
^

)





(7)






c
o
s

θ

l
o
c


=

N
^

⋅
(
−

R
^

)
.





(8)

We can then obtain an accurate expression for the backscattering coefficient with corresponding ESA from Equations (5) and (6):






σ
0

=

β
0

c
o
s
ψ
.





(9)

For PolSAR data, the components of the polarisation covariance matrix associated with a pixel can be compensated equally by the same factor:






C

E
S
A
c


=
C
⋅
c
o
s
ψ
.





(10)

Beginning with ESA correction, the correction process will be performed within the map geometry. Therefore, ESA and AVE corrections are made under the assumption of homomorphism. Following the GTC process, PolSAR and DEM data have the same image size and pixel size.", 2. Methods, 2.4. Step 2: Effective Scattering Area Correction,2
357,"Areas covered by vegetation, such as forests, have complex structures; terrain undulations affect not only the ESA of each pixel, but also its local physical scattering mechanisms. The correction of the topography effect caused by AVE typically adheres to the following basic model or a variant [3,12]:






σ


θ

l
o
c




=
σ
⋅
k

(
n
)

=
σ
⋅



(



c
o
s

θ

r
e
f




c
o
s

θ

l
o
c





)


n

,





(11)


where σ is the uncorrected backscattering coefficient; k(n) denotes the correction coefficient, which is a function of n. θloc is the local incidence angle; σθloc is the corrected backscattering coefficient; θref is the reference incidence angle, such as the angle θ in Figure 4. The value of n is generally determined through a priori knowledge or expertise, and these methods are inconvenient for practical application of PolSAR. The current study presents a novel and automated method to determine the value of n.Based on the basic Model (11), we may evaluate the correction result by the correlation between the corrected backscattering value and the local incident angle, here denoted as ρ( ). Therefore, we define a function of n:





f
(
n
)
=

|

ρ
(

θ

l
o
c


,

σ


θ

l
o
c




)

|
.






(12)

According to Equation (12), the optimal value of n should correspond to the minimum value of f(n), such that the terrain influence of AVE has been removed. Hence,





n
=
argmin

{

abs

[

f
(
n
)

]


}
.






(13)

In this way, we can obtain the optimal value of n for each polarisation channel, such as nhh, nhv and nvv. With these correction coefficients for each polarisation, we can obtain the correction coefficient matrix K for the polarisation covariance matrix:









C
AVEc

=
C
⊙
K
,




K
=

[





k

(


n

h
h



)







k

(


n

h
h


+

n

h
v



)









k

(


n

h
h


+

n

v
v



)











k

(


n

h
h


+

n

h
v



)







k

(


n

h
v



)







k

(


n

h
v


+

n

v
v



)











k

(


n

h
h


+

n

v
v



)









k

(


n

h
v


+

n

v
v



)







k

(


n

v
v



)






]
,









(14)


where ⊙ denotes the Hadamard product.", 2. Methods, 2.5. Step 3: Angular Variation Effect Correction,2
358," 3.1.1. Test SiteThe test site was located in Genhe, Inner Mongolia, China (121.5°E, 50.8°N), where elevation ranges from 650 to 1390 m (Figure 5). The slopes in this area are relatively long and steep, with slope angles up to 35°. This area belongs to the Daxinanling forest region, where the dominant tree species are white birch (Betula platyphylla Suk.) and Dahurian larch (Larix gmelinii (Rupr.) Kuzen.). 3.1.2. PolSAR and Reference DataOne scene of ALOS-2 PALSAR-2 PolSAR data was acquired over the test site on 29 August 2014. It was level 1.1 data and the observation mode was full polarimetry high beam quad (HBQ). The azimuth and range resolution of this model were 4.3 and 5.1 m, respectively. The coverage of the data (Figure 5, red rectangle) was 42 km wide (east–west) and 70 km long (north–south). The pixel spacing of the azimuth and range were 2.86 and 2.84 m, respectively. The centre incidence angle was 36.5°. Figure 6 shows the Pauli RGB display of the PolSAR data (multi-looked). The front slopes were very bright.The green polygon area was covered by airborne LiDAR data acquired in August to September 2012 (Figure 5). The forest AGB product of 30-m resolution shown in Figure 7 was estimated from airborne LiDAR and field forest plot data. The plot setting strategies of the area take topography into consideration to avoid biased estimates, with a total of 60 plots. A step-wise multivariate regression model was established to determine the relationship between field plot biomass and LiDAR-derived features (i.e., LiDAR metrics). We divided all 60 plots into a training dataset (70%) and a validation dataset (30%) to establish and test the model. The final regression model is:





l
n
W
=
8.466
+
1.323
×
l
n
(
H
25
)
+
0.904
l
n
(
D
70
)
,





(15)


where H25 is the height at the 25th percentile and D70 is the number of all points returned at the 70th height percentile divided by all points returned; these two variables were shown to be good indicators of biomass in previous studies in this region [18]. The validation results yield a root mean square error (RMSE) of 23.1 t/hm2 and a coefficient of determination (R2) of 0.78. This region has been classified as a nature reserve since 2005. As a result, the forests of this region were not greatly affected by human activities between 2012 and 2014. For example, there were no large forest disturbances, such as forest fires, during these two years. Thus, the LiDAR-derived forest AGB may be used as reference data to evaluate the effectiveness of terrain correction, despite an interval of two years for PolSAR data. The ASTER DEM (30 m) shown in Figure 8 was used for GTC and to derive local slope information.", 3. Experiments, 3.1. Test Site and Data,3
359,"The test site was located in Genhe, Inner Mongolia, China (121.5°E, 50.8°N), where elevation ranges from 650 to 1390 m (Figure 5). The slopes in this area are relatively long and steep, with slope angles up to 35°. This area belongs to the Daxinanling forest region, where the dominant tree species are white birch (Betula platyphylla Suk.) and Dahurian larch (Larix gmelinii (Rupr.) Kuzen.).", 3. Experiments, 3.1.1. Test Site,3
360,"One scene of ALOS-2 PALSAR-2 PolSAR data was acquired over the test site on 29 August 2014. It was level 1.1 data and the observation mode was full polarimetry high beam quad (HBQ). The azimuth and range resolution of this model were 4.3 and 5.1 m, respectively. The coverage of the data (Figure 5, red rectangle) was 42 km wide (east–west) and 70 km long (north–south). The pixel spacing of the azimuth and range were 2.86 and 2.84 m, respectively. The centre incidence angle was 36.5°. Figure 6 shows the Pauli RGB display of the PolSAR data (multi-looked). The front slopes were very bright.The green polygon area was covered by airborne LiDAR data acquired in August to September 2012 (Figure 5). The forest AGB product of 30-m resolution shown in Figure 7 was estimated from airborne LiDAR and field forest plot data. The plot setting strategies of the area take topography into consideration to avoid biased estimates, with a total of 60 plots. A step-wise multivariate regression model was established to determine the relationship between field plot biomass and LiDAR-derived features (i.e., LiDAR metrics). We divided all 60 plots into a training dataset (70%) and a validation dataset (30%) to establish and test the model. The final regression model is:





l
n
W
=
8.466
+
1.323
×
l
n
(
H
25
)
+
0.904
l
n
(
D
70
)
,





(15)


where H25 is the height at the 25th percentile and D70 is the number of all points returned at the 70th height percentile divided by all points returned; these two variables were shown to be good indicators of biomass in previous studies in this region [18]. The validation results yield a root mean square error (RMSE) of 23.1 t/hm2 and a coefficient of determination (R2) of 0.78. This region has been classified as a nature reserve since 2005. As a result, the forests of this region were not greatly affected by human activities between 2012 and 2014. For example, there were no large forest disturbances, such as forest fires, during these two years. Thus, the LiDAR-derived forest AGB may be used as reference data to evaluate the effectiveness of terrain correction, despite an interval of two years for PolSAR data. The ASTER DEM (30 m) shown in Figure 8 was used for GTC and to derive local slope information.", 3. Experiments, 3.1.2. PolSAR and Reference Data,3
361,"The first pre-processing step was multi-look; the SLC PolSAR data were multi-looked with eight looks in the azimuth direction and four looks in the range direction. The size of the resulting PolSAR image was 3245 × 2176 (Figure 6).Based on precise satellite orbit information, a look-up table (GTC model) was constructed using multi-look PolSAR data (Figure 6, slant range space of SAR image) and DEM data (Figure 8, geographic space). Figure 9 shows the Pauli RGB of PolSAR data following the geocoding process using the GTC model. The resolution of the PolSAR data was resampled to 30 × 30 m and the geocoding accuracy levels of azimuth and range directions were 0.45 and 0.37 pixels, respectively. Simultaneously, we obtained the projection angle (Figure 10) and the local incidence angle (Figure 11) for each pixel. The projection angle values were large in the front slope area and small in the back slope area. Conversely, the local incidence angles were large in the back slope area and small in the front slope area.Figure 12 shows the geocoded results of the POA shift angle calculated by Formula (3) in SAR slant range image space. The changing trend of pixel values in this image was consistent with the terrain undulations, showing that topographic information is implicit in the POA shift angle. This fact has been used in some studies to derive DEM information from the POA shift angle [19]. Comparing Figure 10, Figure 11 and Figure 12, we see that Figure 12 displays mainly the terrain information for the azimuth direction, and Figure 10 and Figure 11 mainly display the terrain information for the range direction. POA correction mainly compensates for the radiometric influence of terrain in the azimuth direction. However, the ESA and AVE corrections mainly compensate for the radiometric influence of terrain in the range direction.", 3. Experiments, 3.2. Pre-Processing and Geocoding Results,3
362," 3.3.1. The Procedure of Terrain CorrectionThe PolSAR image terrain correction includes three steps: POA, ESA, and AVE corrections. Among these, POA correction can be completed in the slant-range space of PolSAR images before the geocoding process. The two remaining correction processes can be completed in geographic space with the GTC model. For convenient comparison, we present all of our results in geographic coordinate space.The integrated three-step terrain correction method can be described by:


CRTC = (VCVT)·cosψ ⊙K.


(16)

First, the POA correction is completed based on the POA shift angle (Figure 12). The ESA correction is then performed based on the projection angle ψ (Figure 10). Finally, the AVE correction is implemented based on the correction coefficient matrix K.AVE correction requires the ability to distinguish land cover types. At our test site, forest is the dominant land cover, and it grows on areas with complex topography (Figure 9), whereas non-forest areas are mainly distributed on the flat terrain (Figure 8). Based on the PolSAR data following POA and ESA corrections, the forest cover map (Figure 13) may easily be obtained by unsupervised classification using polarimetric decomposition and the complex Wishart classifier [20]. Using the forest cover map as a mask file, we may then calculate the correlation coefficients between the AVE corrected backscattering values and the local incidence angle for various values of n (Equation (10)). The results are shown in Figure 14.Figure 14 shows the correlation coefficients for the AVE corrected backscattering values for different polarisations and the local incidence angle as a function of n. The correlation coefficients for different polarisations corresponding to the same value of n are different, such that we should use different n values for different polarisations during the AVE correction. In general, the effective range of n is 0–1 [13]. Using an iterative method at the effective range, we may easily determine the optimum value of n when the correlation coefficient (Equation (12)) converges to a minimum value. In this study, the optimum values of n for different polarisations were nhh = 0.30, nhv = 0.45, and nvv = 0.63. With these values of n, we may obtain the final correction matrix K as:





K
=

[





k

(

0.30

)







k

(

0
.
75

)









k

(

0
.
93

)











k

(

0
.
75

)







k

(

0.45

)







k

(

1
.
08

)











k

(

0
.
93

)









k

(

1
.
08

)







k

(

0.63

)






]

.





(17)

If n equals 1 for different polarisations, the result of the AVE correction is a standard backscatter coefficient γ0 [10], which is frequently used in research on forest areas [4]. The γ0 is essentially a special case of the AVE correction model. Therefore, it may be not suitable in all situations. An analysis of n based on Figure 14 shows that a uniform and fixed value of n is not an ideal choice for PolSAR data. 3.3.2. Analysis of Terrain Correction ResultsFigure 15a presents the Pauli RGB image of PolSAR data after POA correction. Compared to the uncorrected case (Figure 9), there appears to be no significant difference. This is because visual terrain effects on PolSAR image results are mainly due to the difference between front and back slopes in the range direction. In contrast, the impact of azimuth terrain is relatively weak in the case of an entire scene PolSAR image. Thus, there are no obvious visual changes after POA correction. Figure 15b shows further results after ESA correction. The radiometric distortions due to terrain relief were strongly reduced compared to the PolSAR images shown in Figure 9 and Figure 15a. However, there are still subtle topographic effects on local details of the PolSAR image. The final result after AVE correction is shown in Figure 15c. Topographic effects have effectively been removed from Figure 15b, and there is no obvious visual difference between the pixels on the front and back slopes.Because the range of the PolSAR image is large, Figure 15 appears small. Details in the PolSAR images are not easy to observe. Therefore, we display an enlarged area in Figure 15 (black polygon) for more detailed demonstration (Figure 16). Enlarged images of GTC PolSAR, POA shift angle, and local incidence angle are shown in the area. In the enlarged images, greater detail of different correction steps may be seen, particularly when compared to the enlarged images of POA shift angle and local incidence angle. For example, in the regions where the POA shift angle is larger (Figure 16e, red), the PolSAR image of GTC (Figure 16a) is greener than the PolSAR image for the POA correction (Figure 16b). This means that cross-polarisation was overestimated in these regions. Compared with the middle regions of Figure 16c,d,f, improvements made by the AVE correction may be seen more clearly.To evaluate the effectiveness of the three-step correction method, we conducted a deeper analysis. For the POA correction, the relationships between the POA shift angle and the differences between corrected and uncorrected PolSAR data were analysed.As shown in Figure 17, ΔHH, ΔHV, and ΔVV were the differences between the corrected and uncorrected backscattering coefficients for different polarisations (corrected − uncorrected pixel values). With increasing POA shift angle, the numerical ranges of ΔHH, ΔHV, and ΔVV increased. The values of ΔHH and ΔVV may be positive or negative, and the proportion of positive values was relatively large; however, the value of ΔHV may only be less than zero. These patterns indicate that a POA shift will cause overestimation of the backscattering coefficient of HV polarisation. Because of the conservation of polarimetric span, HH and VV polarisation cannot be overestimated simultaneously; that is, ΔHH and ΔVV cannot be negative at the same time (Figure 17d). Additionally, the POA shift exerted more influence on HV polarisation than HH and VV. For example, when the POA shifted by approximately 20°, the maximum biases of HH and VV polarisation were approximately 0.5 dB, while that of HV polarisation was greater than 1 dB. This also indicates that POA correction is an indispensable step for terrain correction of PolSAR data. These different behaviours can be explained by the physical basis of the POA shift. When polarimetric radar images a horizontal surface, the horizontal polarisation electric field of transmitted and received data is parallel to the surface. For a tilted surface, however, the horizontal electric field of transmitted data is no longer parallel to the horizontal surface. However, the horizontal electric field of received data is parallel to the tilted surface. Therefore, there is a shift in angle between the transmitted and received electromagnetic wave vectors. Consequently, the horizontal-transmitting and vertical-receiving (HV) components are increased and horizontal-transmitting and horizontal-receiving (HH) components are decreased, due to the tilted slope. In the case of a vertical polarisation wave, a similar phenomenon occurs. Therefore, the basic rule is that cross-polarisation (HV) will be overestimated and co-polarisation (HH + VV) will be underestimated due to the POA angle shift.We then analysed the relationship between backscattering coefficients of different polarisations and the local incidence angles at different correction steps. Figure 18 presents the backscattering coefficients of different polarisations as a function of the local incidence angle (θloc). And we divided PolSAR data into three groups according to the 33.3th and 66.6th percentile of θloc, the statistical characteristics of each group were calculated and are displayed in Figure 19. For the PolSAR data without ESA correction (Figure 18a,d,g), clear linear relationships were found between the backscattering coefficient and θloc for each polarisation channel. We observe higher backscattering values for the small θloc of front slopes, and lower values for the large θloc of back slopes. The difference of backscattering value between large θloc group and small θloc group is about 3 dB (Figure 19). Following ESA correction (Figure 18b,e,h), this phenomenon was effectively relieved. And the difference of backscattering value between large θloc group and small θloc group is reduced to about 0.5 dB (Figure 19). However, as θloc increased, backscattering values continued to decrease. Complex terrain effects on the corrected PolSAR data clearly remain (Figure 15b and Figure 16c). However, as shown in Figure 18c,f,i, the residual terrain effect was further removed by AVE correction. And the difference of backscattering value between large θloc group and small θloc group is reduced to about 0.1 dB (Figure 19). These behaviours are due to the scattering mechanism of the actual forest; it cannot be pure surface scattering or ideal volume scattering. In the case of an ideal surface scattering target, ESA correction was sufficient. For an ideal volume scattering target, γ0 was more suitable, in that it remained approximately constant for all incidence angles [21]. Therefore, this may be the reason why ESA correction is insufficient and AVE correction is required.Using the Yamaguchi four-component decomposition as an example [22], we also analysed the relationship between polarimetric decomposition parameters and the local incidence angle at the different correction steps (Figure 20). These four polarisation parameters can be obtained from PolSAR matrix data at different correction steps by Yamaguchi four-component decomposition, which includes surface scattering power (Odd), double-bounce scattering power (Dbl), volume scattering power (Vol) and helix scattering power (Hlx). As shown in Figure 20a,e,i,m, the decomposition parameters derived from GTC PolSAR data and also as a function of the local incidence angle exhibit linear behaviour, with higher decomposition parameter values for low θloc, and lower values for the high θloc. ESA correction also plays a major role in determining all decomposition parameters. This is because a larger ESA value corresponds to larger decomposition components. Comparing the scatter plots for the different correction steps, the behaviour at different correction steps is similar to that shown in Figure 18. For the Odd and Hlx components, the terrain effect was relieved only at the ESA correction step. In the case of the Vol component, the terrain effect was relieved mostly at the ESA correction step, whereas AVE correction can further remove the residual terrain effect. However, for the Dbl component, all three correction steps were useful. The POA correction significantly reduced the dispersion of the points (Figure 20f), and ESA and AVE corrections further removed terrain effects (Figure 20g,h). This result may be due to the correction of not only the principal diagonal elements but also non-diagonal elements of the polarisation covariance matrix. Overall, the RTC results indicate that the best correction results were due to the Dbl and Vol components, which were the dominant scattering mechanism for the forest. ESA correction was still the most important correction step, but only ESA correction fails to remove the terrain effects completely. 3.3.3. Effectiveness of the Three-Step RTC for Forest AGB EstimationOne of the key applications of RTC in forest areas is to reduce biomass estimation error caused by uneven topography. For further verification of the effectiveness of the three-step RTC method for forest AGB estimation, we analysed the relationship between the LiDAR-derived forest AGB data and the backscattering coefficients of the uncorrected (GTC) and corrected (POA, POA + ESA, POA + ESA + AVE) PolSAR data at the test site (Figure 5, green rectangle; Figure 7), as shown in Figure 21. Black lines indicate the regression curve of a logarithmic equation. The correlation coefficient (R) of regression model was calculated and displayed in each plot. The method of statistical regression is least squares can refer to [23]. There were 518 points in each plot, which were extracted from LiDAR-derived AGB data and PolSAR data for different correction steps. To ensure the reliability of the results, non-forest points were masked and the points at the forest edge were also excluded. The spatial interval between two points is 90 m, and the value for each point was a mean value of the surrounding pixels. Thus, the influence of geographical coordinate error between LiDAR data and PolSAR data was reduced.Figure 21a–c shows the scatter plots of LiDAR-derived forest AGB and backscattering coefficients before three-step RTC processing, and Figure 21d–l shows the same result after processing at each correction step. This shows that three-step RTC can significantly reduce the dispersion of the points. All of the correlations between the backscattering coefficients of each of the three polarisations and the forest AGB were improved; the lowest R value in the POA + ESA + AVE correction step (Figure 21j–l, VV polarisation) was larger than the highest R value in the uncorrected case (Figure 21a–c, HV polarisation). The backscattering coefficients for HV polarisation after RTC processing (Figure 21k) had the best correlation with forest AGB, whose R value was 0.8083, while the corresponding R value for HV polarisation before RTC processing was only 0.5391. The contributions of POA, ESA and AVE to correlation coefficient were 0.05, 0.16 and 0.06, respectively. In the case of co-polarisation, similar phenomena were observed.To evaluate the robustness of the regression results, we conducted an uncertainties analysis of LiDAR forest AGB and backscattering coefficients of different correction steps. For the former, the uncertainty is mainly due to the estimation error of forest AGB. For the latter, the uncertainty is mainly due to the accuracy of the DEM data. First of all, an additional error term of Gaussian distribution (Mean: 0; Standard deviation: 23.1 t/hm2) was added in the LiDAR forest AGB. The standard deviation of error term is equal to the RMSE of LiDAR forest AGB. Based on this error term, simulated forest AGB data can be generated and used for regression. We calculated the correlation coefficients for each regression, as shown in Figure 22. Overall, the correlation coefficient of different polarisation and different correction step decreased due to the additional error terms. However, the proportion of the contribution of different correction steps to correlation coefficient is consistent with Figure 21. In HV polarisation, for example, the mean contributions of POA, ESA and AVE were 0.04, 0.15 and 0.05, respectively.Secondly, it is the uncertainty caused by DEM. In this respect, we re-verified the results using SRTM DEM (30m). Figure 23 shows the validation results. In repeated experiments, the geocoding accuracy of azimuth and range directions were 0.17 and 0.22 pixels in the GTC process. This is slightly higher than the accuracy based on ASTER DEM. And the optimum values of n for different polarisations were nhh = 0.31, nhv = 0.49, and nvv = 0.61. This is basically consistent with the ASTER DEM-based parameters. Figure 23a shows the correlation between ψ of ASTER DEM and ψ of SRTM DEM, whose R value was 0.9281. And Figure 23b shows the correlation between θloc of ASTER DEM and θloc of SRTM DEM, whose R value was 0.9257. This shows that similar imaging geometric angles were achieved by SRTM DEM compared with ASTER DEM. Figure 23c shows the correlation coefficient between backscattering coefficients of different correction steps and LiDAR forest AGB. We can see that similar results were obtained based on SRTM DEM compared with ASTER DEM. In HV polarisation, for example, the R value of GTC, POA, ESA and AVE were 0.5768, 0.6275, 0.7834 and 0.8497, respectively. The contributions of POA, ESA and AVE to correlation coefficient were 0.05, 0.16 and 0.07, respectively. Overall, the R value of SRTM DEM were slightly higher than that of ASTER DEM. The reason may be that higher geocoding accuracy and more reliable imaging geometric angles can be obtained by SRTM DEM compared with ASTER DEM. However, this requires further and more detailed researches to confirm.Thus, we conclude that the three-step RTC method improves the power of PolSAR data to estimate forest AGB in uneven topography conditions. There is no doubt that ESA correction is the most important correction for improving biomass estimation, although POA and AVE corrections are also important. Additionally, the method developed in this study is fully suitable for PolSAR data in a matrix format, for example, covariance or coherency matrices. We can also extract the most sensitive polarisation parameters from the matrix data after RTC processing to construct a forest AGB inversion model, which will further improve model performance.", 3. Experiments, 3.3. Terrain Correction Results,3
363,"The PolSAR image terrain correction includes three steps: POA, ESA, and AVE corrections. Among these, POA correction can be completed in the slant-range space of PolSAR images before the geocoding process. The two remaining correction processes can be completed in geographic space with the GTC model. For convenient comparison, we present all of our results in geographic coordinate space.The integrated three-step terrain correction method can be described by:


CRTC = (VCVT)·cosψ ⊙K.


(16)

First, the POA correction is completed based on the POA shift angle (Figure 12). The ESA correction is then performed based on the projection angle ψ (Figure 10). Finally, the AVE correction is implemented based on the correction coefficient matrix K.AVE correction requires the ability to distinguish land cover types. At our test site, forest is the dominant land cover, and it grows on areas with complex topography (Figure 9), whereas non-forest areas are mainly distributed on the flat terrain (Figure 8). Based on the PolSAR data following POA and ESA corrections, the forest cover map (Figure 13) may easily be obtained by unsupervised classification using polarimetric decomposition and the complex Wishart classifier [20]. Using the forest cover map as a mask file, we may then calculate the correlation coefficients between the AVE corrected backscattering values and the local incidence angle for various values of n (Equation (10)). The results are shown in Figure 14.Figure 14 shows the correlation coefficients for the AVE corrected backscattering values for different polarisations and the local incidence angle as a function of n. The correlation coefficients for different polarisations corresponding to the same value of n are different, such that we should use different n values for different polarisations during the AVE correction. In general, the effective range of n is 0–1 [13]. Using an iterative method at the effective range, we may easily determine the optimum value of n when the correlation coefficient (Equation (12)) converges to a minimum value. In this study, the optimum values of n for different polarisations were nhh = 0.30, nhv = 0.45, and nvv = 0.63. With these values of n, we may obtain the final correction matrix K as:





K
=

[





k

(

0.30

)







k

(

0
.
75

)









k

(

0
.
93

)











k

(

0
.
75

)







k

(

0.45

)







k

(

1
.
08

)











k

(

0
.
93

)









k

(

1
.
08

)







k

(

0.63

)






]

.





(17)

If n equals 1 for different polarisations, the result of the AVE correction is a standard backscatter coefficient γ0 [10], which is frequently used in research on forest areas [4]. The γ0 is essentially a special case of the AVE correction model. Therefore, it may be not suitable in all situations. An analysis of n based on Figure 14 shows that a uniform and fixed value of n is not an ideal choice for PolSAR data.", 3. Experiments, 3.3.1. The Procedure of Terrain Correction,3
364,"Figure 15a presents the Pauli RGB image of PolSAR data after POA correction. Compared to the uncorrected case (Figure 9), there appears to be no significant difference. This is because visual terrain effects on PolSAR image results are mainly due to the difference between front and back slopes in the range direction. In contrast, the impact of azimuth terrain is relatively weak in the case of an entire scene PolSAR image. Thus, there are no obvious visual changes after POA correction. Figure 15b shows further results after ESA correction. The radiometric distortions due to terrain relief were strongly reduced compared to the PolSAR images shown in Figure 9 and Figure 15a. However, there are still subtle topographic effects on local details of the PolSAR image. The final result after AVE correction is shown in Figure 15c. Topographic effects have effectively been removed from Figure 15b, and there is no obvious visual difference between the pixels on the front and back slopes.Because the range of the PolSAR image is large, Figure 15 appears small. Details in the PolSAR images are not easy to observe. Therefore, we display an enlarged area in Figure 15 (black polygon) for more detailed demonstration (Figure 16). Enlarged images of GTC PolSAR, POA shift angle, and local incidence angle are shown in the area. In the enlarged images, greater detail of different correction steps may be seen, particularly when compared to the enlarged images of POA shift angle and local incidence angle. For example, in the regions where the POA shift angle is larger (Figure 16e, red), the PolSAR image of GTC (Figure 16a) is greener than the PolSAR image for the POA correction (Figure 16b). This means that cross-polarisation was overestimated in these regions. Compared with the middle regions of Figure 16c,d,f, improvements made by the AVE correction may be seen more clearly.To evaluate the effectiveness of the three-step correction method, we conducted a deeper analysis. For the POA correction, the relationships between the POA shift angle and the differences between corrected and uncorrected PolSAR data were analysed.As shown in Figure 17, ΔHH, ΔHV, and ΔVV were the differences between the corrected and uncorrected backscattering coefficients for different polarisations (corrected − uncorrected pixel values). With increasing POA shift angle, the numerical ranges of ΔHH, ΔHV, and ΔVV increased. The values of ΔHH and ΔVV may be positive or negative, and the proportion of positive values was relatively large; however, the value of ΔHV may only be less than zero. These patterns indicate that a POA shift will cause overestimation of the backscattering coefficient of HV polarisation. Because of the conservation of polarimetric span, HH and VV polarisation cannot be overestimated simultaneously; that is, ΔHH and ΔVV cannot be negative at the same time (Figure 17d). Additionally, the POA shift exerted more influence on HV polarisation than HH and VV. For example, when the POA shifted by approximately 20°, the maximum biases of HH and VV polarisation were approximately 0.5 dB, while that of HV polarisation was greater than 1 dB. This also indicates that POA correction is an indispensable step for terrain correction of PolSAR data. These different behaviours can be explained by the physical basis of the POA shift. When polarimetric radar images a horizontal surface, the horizontal polarisation electric field of transmitted and received data is parallel to the surface. For a tilted surface, however, the horizontal electric field of transmitted data is no longer parallel to the horizontal surface. However, the horizontal electric field of received data is parallel to the tilted surface. Therefore, there is a shift in angle between the transmitted and received electromagnetic wave vectors. Consequently, the horizontal-transmitting and vertical-receiving (HV) components are increased and horizontal-transmitting and horizontal-receiving (HH) components are decreased, due to the tilted slope. In the case of a vertical polarisation wave, a similar phenomenon occurs. Therefore, the basic rule is that cross-polarisation (HV) will be overestimated and co-polarisation (HH + VV) will be underestimated due to the POA angle shift.We then analysed the relationship between backscattering coefficients of different polarisations and the local incidence angles at different correction steps. Figure 18 presents the backscattering coefficients of different polarisations as a function of the local incidence angle (θloc). And we divided PolSAR data into three groups according to the 33.3th and 66.6th percentile of θloc, the statistical characteristics of each group were calculated and are displayed in Figure 19. For the PolSAR data without ESA correction (Figure 18a,d,g), clear linear relationships were found between the backscattering coefficient and θloc for each polarisation channel. We observe higher backscattering values for the small θloc of front slopes, and lower values for the large θloc of back slopes. The difference of backscattering value between large θloc group and small θloc group is about 3 dB (Figure 19). Following ESA correction (Figure 18b,e,h), this phenomenon was effectively relieved. And the difference of backscattering value between large θloc group and small θloc group is reduced to about 0.5 dB (Figure 19). However, as θloc increased, backscattering values continued to decrease. Complex terrain effects on the corrected PolSAR data clearly remain (Figure 15b and Figure 16c). However, as shown in Figure 18c,f,i, the residual terrain effect was further removed by AVE correction. And the difference of backscattering value between large θloc group and small θloc group is reduced to about 0.1 dB (Figure 19). These behaviours are due to the scattering mechanism of the actual forest; it cannot be pure surface scattering or ideal volume scattering. In the case of an ideal surface scattering target, ESA correction was sufficient. For an ideal volume scattering target, γ0 was more suitable, in that it remained approximately constant for all incidence angles [21]. Therefore, this may be the reason why ESA correction is insufficient and AVE correction is required.Using the Yamaguchi four-component decomposition as an example [22], we also analysed the relationship between polarimetric decomposition parameters and the local incidence angle at the different correction steps (Figure 20). These four polarisation parameters can be obtained from PolSAR matrix data at different correction steps by Yamaguchi four-component decomposition, which includes surface scattering power (Odd), double-bounce scattering power (Dbl), volume scattering power (Vol) and helix scattering power (Hlx). As shown in Figure 20a,e,i,m, the decomposition parameters derived from GTC PolSAR data and also as a function of the local incidence angle exhibit linear behaviour, with higher decomposition parameter values for low θloc, and lower values for the high θloc. ESA correction also plays a major role in determining all decomposition parameters. This is because a larger ESA value corresponds to larger decomposition components. Comparing the scatter plots for the different correction steps, the behaviour at different correction steps is similar to that shown in Figure 18. For the Odd and Hlx components, the terrain effect was relieved only at the ESA correction step. In the case of the Vol component, the terrain effect was relieved mostly at the ESA correction step, whereas AVE correction can further remove the residual terrain effect. However, for the Dbl component, all three correction steps were useful. The POA correction significantly reduced the dispersion of the points (Figure 20f), and ESA and AVE corrections further removed terrain effects (Figure 20g,h). This result may be due to the correction of not only the principal diagonal elements but also non-diagonal elements of the polarisation covariance matrix. Overall, the RTC results indicate that the best correction results were due to the Dbl and Vol components, which were the dominant scattering mechanism for the forest. ESA correction was still the most important correction step, but only ESA correction fails to remove the terrain effects completely.", 3. Experiments, 3.3.2. Analysis of Terrain Correction Results,3
365,"One of the key applications of RTC in forest areas is to reduce biomass estimation error caused by uneven topography. For further verification of the effectiveness of the three-step RTC method for forest AGB estimation, we analysed the relationship between the LiDAR-derived forest AGB data and the backscattering coefficients of the uncorrected (GTC) and corrected (POA, POA + ESA, POA + ESA + AVE) PolSAR data at the test site (Figure 5, green rectangle; Figure 7), as shown in Figure 21. Black lines indicate the regression curve of a logarithmic equation. The correlation coefficient (R) of regression model was calculated and displayed in each plot. The method of statistical regression is least squares can refer to [23]. There were 518 points in each plot, which were extracted from LiDAR-derived AGB data and PolSAR data for different correction steps. To ensure the reliability of the results, non-forest points were masked and the points at the forest edge were also excluded. The spatial interval between two points is 90 m, and the value for each point was a mean value of the surrounding pixels. Thus, the influence of geographical coordinate error between LiDAR data and PolSAR data was reduced.Figure 21a–c shows the scatter plots of LiDAR-derived forest AGB and backscattering coefficients before three-step RTC processing, and Figure 21d–l shows the same result after processing at each correction step. This shows that three-step RTC can significantly reduce the dispersion of the points. All of the correlations between the backscattering coefficients of each of the three polarisations and the forest AGB were improved; the lowest R value in the POA + ESA + AVE correction step (Figure 21j–l, VV polarisation) was larger than the highest R value in the uncorrected case (Figure 21a–c, HV polarisation). The backscattering coefficients for HV polarisation after RTC processing (Figure 21k) had the best correlation with forest AGB, whose R value was 0.8083, while the corresponding R value for HV polarisation before RTC processing was only 0.5391. The contributions of POA, ESA and AVE to correlation coefficient were 0.05, 0.16 and 0.06, respectively. In the case of co-polarisation, similar phenomena were observed.To evaluate the robustness of the regression results, we conducted an uncertainties analysis of LiDAR forest AGB and backscattering coefficients of different correction steps. For the former, the uncertainty is mainly due to the estimation error of forest AGB. For the latter, the uncertainty is mainly due to the accuracy of the DEM data. First of all, an additional error term of Gaussian distribution (Mean: 0; Standard deviation: 23.1 t/hm2) was added in the LiDAR forest AGB. The standard deviation of error term is equal to the RMSE of LiDAR forest AGB. Based on this error term, simulated forest AGB data can be generated and used for regression. We calculated the correlation coefficients for each regression, as shown in Figure 22. Overall, the correlation coefficient of different polarisation and different correction step decreased due to the additional error terms. However, the proportion of the contribution of different correction steps to correlation coefficient is consistent with Figure 21. In HV polarisation, for example, the mean contributions of POA, ESA and AVE were 0.04, 0.15 and 0.05, respectively.Secondly, it is the uncertainty caused by DEM. In this respect, we re-verified the results using SRTM DEM (30m). Figure 23 shows the validation results. In repeated experiments, the geocoding accuracy of azimuth and range directions were 0.17 and 0.22 pixels in the GTC process. This is slightly higher than the accuracy based on ASTER DEM. And the optimum values of n for different polarisations were nhh = 0.31, nhv = 0.49, and nvv = 0.61. This is basically consistent with the ASTER DEM-based parameters. Figure 23a shows the correlation between ψ of ASTER DEM and ψ of SRTM DEM, whose R value was 0.9281. And Figure 23b shows the correlation between θloc of ASTER DEM and θloc of SRTM DEM, whose R value was 0.9257. This shows that similar imaging geometric angles were achieved by SRTM DEM compared with ASTER DEM. Figure 23c shows the correlation coefficient between backscattering coefficients of different correction steps and LiDAR forest AGB. We can see that similar results were obtained based on SRTM DEM compared with ASTER DEM. In HV polarisation, for example, the R value of GTC, POA, ESA and AVE were 0.5768, 0.6275, 0.7834 and 0.8497, respectively. The contributions of POA, ESA and AVE to correlation coefficient were 0.05, 0.16 and 0.07, respectively. Overall, the R value of SRTM DEM were slightly higher than that of ASTER DEM. The reason may be that higher geocoding accuracy and more reliable imaging geometric angles can be obtained by SRTM DEM compared with ASTER DEM. However, this requires further and more detailed researches to confirm.Thus, we conclude that the three-step RTC method improves the power of PolSAR data to estimate forest AGB in uneven topography conditions. There is no doubt that ESA correction is the most important correction for improving biomass estimation, although POA and AVE corrections are also important. Additionally, the method developed in this study is fully suitable for PolSAR data in a matrix format, for example, covariance or coherency matrices. We can also extract the most sensitive polarisation parameters from the matrix data after RTC processing to construct a forest AGB inversion model, which will further improve model performance.", 3. Experiments, 3.3.3. Effectiveness of the Three-Step RTC for Forest AGB Estimation,3
366,"The first step of terrain correction is to geocode the SAR data with DEM data of sufficient resolution. For most users, free, globally shared DEM data, for example, ASTER DEM, SRTM DEM and ALOS 3D DSM, are the only data sources that may be employed. However, these DEM data are not actually digital elevation models, but digital surface models. Therefore, the RTC process proceeds under the assumption that the top of the forest canopy follows the underlying topography. In the case of medium or coarse resolution (multi-looked, >25 m) SAR data, this is not a serious limitation. However, when high resolution is required, this assumption may not hold. We are looking forward to the development of “real” DEM products created by the application of PolInSAR technology.The highest resolution of these globally shared DEMs is only 30 m, which is relatively low compared to PolSAR data (spaceborne or airborne), even taking into account the multi-look process. Therefore, the proposed method is based on projection angle [8], rather than the area integration method, which has been proposed in recent years [9]. If we have a high-resolution DEM, where the resolution is equal to or better than that of SAR data, then the ESA method can easily be replaced by the integration method under the heteromorphic assumption. However, for AVE correction, it is not yet possible to make corrections under this assumption owing to the limitation of the local incidence angle cannot be integrated from different geometry as the scattering area can. This remains an avenue for future research.", 4. Discussion, 4.1. Limitations of DEMs for Geocoding and ESA Correction,4
367,"Assuming a reflective, symmetrical medium, the POA shift value can be estimated by the circular polarisation method. After POA correction, PolSAR data will satisfy reflection symmetry. However, the performance of this method is greatly affected by the presence of forests in high-frequency SAR (L-, C-band) data [24]. The forest area POA shift angle is influenced not only by topography, but also by the forest canopy [19,25]. Between these effects, the former type of interference information should be removed; however, the latter should be retained. Therefore, over-correction will occur if the effects of the forest canopy cannot be separated. However, POA shifts in multilayer forests are complex and it is difficult to estimate the POA shift due to topography over vegetated terrain; this remains an open issue that should be studied in the future.", 4. Discussion, 4.2. The Influence of Forest Canopy on POA Correction,4
368,"As mentioned in previous sections, the key point for AVE correction is the value of n, which depends on terrain cover type, frequency, and polarisation, among other factors. The correction process should be completed for different land cover types. Thus, land cover map data are a critical requirement for AVE correction. We can obtain land cover map data from the globally shared products, such as the Finer Resolution Observation and Monitoring of Global Land Cover (FROM-GLC) dataset and the Global 25 m Resolution PALSAR-2/PALSAR Mosaic and Forest/Non-Forest Map dataset [26,27]. If there are no suitable land cover data, these can also be acquired directly through the classification of PolSAR data after POA and ESA correction. Early studies have shown that the influence of terrain in classification is very small if ESA correction is performed [15]. However, even if we consider a specific cover type such as forest, there must be more subclasses within this type, such as low-biomass forests and high-biomass forests. Since the value of n is determined through statistical optimisation, some assumptions are required for the proposed method. First, the slope angle and slope direction should be of fairly uniform distribution for the same type of coverage area. Second, the subclasses of a specific cover type should be of fairly uniform distribution for different slopes.In addition, although the basic model used for AVE correction in this article is a widely accepted correction model [3,4,12,13], it is the fact that only the local and the reference incidence angles are considered in the model. This may be a limitation of AVE correction. If more angles in the imaging geometry or the 3D components of local incidence angles are considered in the AVE basic model, it is possible to achieve better correction results. However, more angles mean that more unknown parameters will also appear in the model, such as the model proposed by Hoekman [15]. Taking into account the local incidence angle and the slope angle in azimuth, the model contains four unknown parameters [15]. How to adaptively determine these parameters will be worthwhile to research.", 4. Discussion, 4.3. The Semi-Empirical Method in AVE Correction,4
369,"In this study, we proposed a three-step semi-empirical approach for radiometric terrain correction of PolSAR data. The modulation of PolSAR data by complex terrain is described by the POA shift, variation in local ESA, and the AVE phenomenon. Unlike conventional correction methods, the proposed method can be carried out for polarisation matrix data, and can correct not only intensity information, but also polarisation state information. At the AVE correction step, we proposed a novel approach to determine adaptively the “n” value for different polarisation channels based on a statistical optimisation method, which can be directly applied to PolSAR matrix data.This three-step RTC scheme was verified by PALSAR-2 HBQ (L-band, quad-polarisation) data and the correction results of different steps were analysed and evaluated based on qualitative and quantitative methods. Experimental results showed that (1) after three-step correction, the visual image intensity contrast between front and back slopes was significantly reduced. The results of different correction steps showed that the three correction steps are all effective for PolSAR data. Among these, ESA correction is the most important and necessary step for radiometric terrain correction; (2) At the POA correction step, HV polarisation was more greatly influenced by the POA shift than the other polarisation channel. The backscattering coefficient modification effected by the POA correction is greater than 1 dB for HV polarisation, but about 0.5 dB for HH or VV polarisation at an intermediate shift angle (±20°); (3) Based on LiDAR-derived forest AGB data, we analysed the relationship between forest AGB and the backscattering coefficient. RTC processing can significantly improve the correlation between forest AGB and the backscattering coefficient for different polarisations. Among these, HV polarisation has the highest correlation coefficient with the forest AGB (R = 0.81) and the correlation coefficient increased by approximately 0.3 compared to uncorrected data.The PolSAR terrain correction method proposed in this paper has advanced features in systematic comprehensive correction and self-adaptive parameter settings. It is suitable for PolSAR matrix data. However, some limitations remain. For POA correction, how to separate the POA shift angle component caused by the canopy and the terrain under canopy remains an open issue. Moreover, the resolution of the RTC product of PolSAR data is limited by the relatively low resolution of available DEMs; this is another area for future research. Furthermore, the conclusions obtained in this study are under some constraints. There were no extreme slopes in our test area. The minimum local incidence angle was greater than 10°. Therefore, in the case of extreme terrain, the conclusions of this study must be verified. Second, the coverage of LiDAR-derived forest AGB was a small area compared to that of the PolSAR data. Thus, the relevant conclusions can represent only the smaller data range (LiDAR data), rather than the larger area (PolSAR data). The level of biomass in our test site was relatively low (<150 t/hm2). For forests with high levels of biomass, the backscattering coefficient of high-frequency SAR may be saturated and the corresponding conclusions may not be consistent with this study. However, for low-frequency PolSAR data, we believe that the three-step semi-empirical radiometric terrain correction method could play an important role in forest applications.", 5. Conclusions,None,5
370,"Bamboo forests occur extensively in tropical and subtropical regions, playing important roles in improving economic conditions by providing construction materials and food (bamboo shoots) and influencing carbon cycling due to their unique characteristics of rapid growth and short harvest rotation [1,2,3]. The continuous increase of bamboo forest area in the world and its important role in carbon sequestration make mapping its distribution and modeling aboveground biomass (AGB) urgent tasks [4,5,6,7]. The ability to repeatedly capture land surface features makes remote sensing a major data source for quickly updating spatial distribution of bamboo forests and estimating AGB [1,2,3,8]. However, compared to broadleaf and coniferous forests, bamboo forests have some unique characteristics during growth stages [9] that result in challenges when using remote sensing techniques to model AGB in large areas [10,11].As shown in Figure 1, bamboo forests can change quickly in a short time and have some unique characteristics: (1) On-year and off-year phenomena: An “on-year bamboo forest” represents many bamboo shoots growing during spring (Figure 1a), whereas in an “off-year bamboo forest” almost no bamboo shoots grow (Figure 1b). (2) Rapid growing period of bamboo shoots to fully developed trees (Figure 1c): In the on-year bamboo forest, bamboo shoots emerge between mid-March and mid-April, then take about 40 to 60 days to attain full size (usually until May), depending on soil conditions, and the leaves develop completely in June [9]. (3) Visibility of bamboo canopy: The boundary between on-year and off-year bamboo forest canopy is very clear from April to September (Figure 1d). (4) Intensive management of bamboo forests: In a typical site, forest owners may remove some bamboo shoots in early spring and cut old bamboo trees during fall and early winter; they also remove tree crowns (about 2 to 3 m) of the newly grown bamboo trees in November to make brooms and to avoid tree falls due to snow in the winter. (5) On-year and off-year bamboo forests have different stand structures between April and November but are similar after removal of crowns (Figure 1d), mainly between December and March. Due to the unique growth stages resulting in a change in stand structure within one year [9], on-year and off-year bamboo forests display different or similar colors on the images, depending on the season (Figure 2). The on-year and off-year bamboo forests in April and May have clear color differences (Figure 2a,b), implying that they can be easily separated, while in July such differences almost disappear (Figure 2c) and they are difficult to distinguish based on spectral signatures. In particular, the difference of on-year and off-year bamboo forests in color composites disappear after summer and before spring seasons (Figure 2d–f). The color changes in the true color composites from Sentinel-2 images at different dates throughout a year imply the importance of selecting suitable image acquisition dates for separation of on-year and off-year bamboo forest distribution and for AGB estimation, which previous research has not explored. When remote sensing data and sample plots are determined, selection of suitable variables and use of proper modeling algorithms are two critical steps for AGB studies in a given region [12,13]. Many studies have examined the mapping of bamboo forest distribution and modeling AGB using remote sensing data such as Landsat [2,14]. In addition to spectral bands, vegetation indices, image transform algorithms such as principal component analysis (PCA), and textures are often used, and stepwise regression is used to identify the variables for AGB modeling [2,14,15,16]. Meanwhile, radar data such as ALOS (Advanced Land Observing Satellite) PALSAR (Phased Array type L-band Synthetic Aperture Radar) are also used for AGB estimation, but the estimation accuracy is not much better than with Landsat images [11]. Since different remote sensing (e.g., optical, radar, lidar) data with various spectral and spatial resolutions are available, a large number of potential variables may be used [12,17]. However, properly identifying key variables is critical for accurately estimating AGB, and the selected variables may vary considerably depending on the characteristics of forest types under investigation and remotely sensed data itself [10,11,18]. The impacts of forest phenology, growth conditions, and external factors such as moisture on remotely sensed data in representing forest canopy structure make AGB model transfer difficult [19]. Due to the intensive management (e.g., fertilization, selective logging) and the short growth period from bamboo shoots to fully developed bamboo trees [9], remote sensing-based AGB estimation for bamboo forests becomes especially challenging. In addition to the selection of suitable variables, another critical step is to determine which algorithm should be used for developing the AGB estimation model [12]. Lu et al. [12] summarized the major characteristics of common algorithms used for AGB modeling, including parametric-based algorithms (e.g., regression-based methods) and non-parametric algorithms (e.g., k-nearest neighbor (kNN), artificial neural network (ANN), support vector regression (SVR)). The regression-based modeling approach is often used for developing AGB estimation; in particular, stepwise regression can automatically identify the variables for AGB modeling [13,14]. However, regression-based approaches require the assumption that the selected variables have linear relationships with AGB. In reality, the relationships between AGB and remote sensing-derived variables may be nonlinear, resulting in poor estimation accuracy, for example, the relative root mean squared error can be over 40% [13]. Therefore, in recent years, many studies have explored the use of machine learning algorithms such as kNN, ANN, SVR, and random forest (RF) for bamboo AGB estimation [5,13,20,21]. In particular, RF can provide the importance ranking of the variables [13] and is extensively employed for AGB modeling [22,23,24,25]. RF is a nonparametric ensemble modeling approach that can effectively construct numerous small regression trees for predictions [26]. Compared with other machine learning algorithms such as ANN and kNN, one key advantage of using RF is its ability to provide the importance ranking of the variables. This characteristic is especially valuable when key variables need to be identified from many potential variables. Another advantage is RF’s ability to deal with noise and large datasets [27,28] because it is insensitive to noisy data in training datasets.In remote sensing-based AGB estimation, one important factor influencing AGB estimation accuracy is the data quality, including ground-truth and remotely sensed data [12]. The dates of sample collection and image acquisition are often inconsistent due to the variable availability of remotely sensed data in frequently cloud-covered tropical and subtropical regions [10,29]. Most previous studies assumed that different dates between sample collection and image acquisition would not significantly influence the relationships between AGB and remote sensing-derived variables [30]. This assumption may be valid for some forest types because forest growth in a short time period will not significantly change the forest stand structure, thus the spectral signature should be similar too. However, this assumption may not be valid for bamboo forests because of the completely different growth stages of bamboo forests (see Figure 1) and broadleaf or coniferous forests [10].Although studies for modeling bamboo forest AGB have gained increasingly attention, some critical questions remain to be answered. For example, how do different bamboo growth stages affect AGB estimation performance? How do the unique features of on-year and off-year bamboo forests affect AGB estimation? Can the increase of spectral bands in red edge and NIR wavelengths in Sentinel-2 data compared to the common Landsat data improve AGB estimation? In subtropical regions, acquiring cloud-free Landsat images is often difficult due to the cloud-cover problem and relatively low re-visit frequency. The higher spatial and temporal resolutions and more spectral bands in red edge and NIR wavelengths in Sentinel-2 data than in Landsat may provide new insights in bamboo forest AGB studies, but they have not been examined yet. The overall goals of this research are to explore the impacts of on-year and off-year bamboo forests on AGB modeling effects and the potential role of increased spectral bands in Sentinel-2 data in improving AGB estimation. Specifically, the objectives of this research are to (1) better understand the impacts of on-year and off-year bamboo forests on AGB estimation, (2) understand the impacts of suitable image acquisition dates for AGB estimation, (3) examine AGB saturation in Sentinel-2 data, and (4) better understand the mechanism of bamboo forest AGB estimation using optical sensor data. The new contribution of this research is to better understand the impacts of the unique characteristics of bamboo growing stages on AGB estimation, the impacts of on-year and off-year bamboo forests on AGB estimation, and the roles of multi-seasonal Sentinel-2 images in mapping on-year and off-year bamboo forest distribution and AGB estimation.", 1. Introduction,None,1.
371,"The study area is located in northwest Zhejiang Province, China (Figure 3), covering about 538.06 km2. The terrain is undulating with elevations between 20 and 846 m and average slope of 16 degrees. Five soil types—red, yellow, lithologic, fluvoaquic, and paddy—were found [31]. The climate in this region is subtropical monsoon that has abundant illumination and precipitation with four distinct seasons: Warm in spring, hot and humid in summer, cool in fall, cold and damp in winter. The average annual temperature is 15 °C with the lowest temperature of 2 °C in winter and the highest temperature of 37 °C in summer. Annual rainfall is 1400 mm with the highest rainfall in June and lowest rainfall in December [32]. This study area is in subtropical evergreen forests, including coniferous evergreen, broadleaf evergreen, and bamboo. There are also other plantations such as pines, Chinese fir, and agroforestry. Moso bamboo forest (Phyllostachys pubescens) is the most widely distributed bamboo forest type in this study area, accounting for 86% of the total bamboo forests [31]. Moso bamboo trees are taller and have larger diameter at breast height (DBH) than any other bamboo forests such as Phyllostachy snuda [32]. The average height of Moso bamboo is between 9 and 12 m and the average DBH is between 8 and 11 cm. In addition, Moso bamboo forests have single species and stand structure, but stand densities may vary greatly in sites and different seasons because of their on-year and off-year growth characteristics and intensive management, such as selective logging of trees 3 du or older in the on-year bamboo forests during winter [33].", 2. Materials and Methods, 2.1. Study Area,2
372,"The datasets used in our research are summarized in Table 1, including field survey data, multitemporal Sentinel-2 multispectral images, and digital elevation model (DEM) data. The fieldwork was conducted between 2016 and 2018. A total of 517 sample plots covering different land-cover types, especially forest types, were collected during this period. The coordinates of each plot were recorded. Of these sample plots, about 300 were bamboo forests, including on-year and off-year bamboo forests. These sample plots were used to support mapping of on-year and off-year bamboo forest distribution. Meanwhile, 62 20 × 20 m sample plots of bamboo forests (31 each for on-year and off-year) were measured in May to August 2018. Within each plot, the DBH and age were measured for each tree. The age of a bamboo tree was determined by visually checking the stem colors: White ring in the bamboo joint, cyan in stem, and un-dropped shell in the stem bottom indicate 1 du (Figure 1a,c); powder ring in the bamboo joint and green in stem indicate 2 du; yellow-green in stem and lignified stem indicate 3 du; tan in stem and sparsely scattered because of selective logging indicate 4 du and older [9].The bamboo AGB is often calculated using an allometric equation based on DBH and age [28] because the special physiological characteristics in bamboo tree species have high relationships between age and AGB. In this research, the AGB for a single bamboo tree was calculated using Equation (1) [34]:

M = 747.787 D2.771 [0.148 A/(0.028 + A)]5.555 + 3.772,


(1)

where M is the dry aboveground biomass for a single bamboo tree in kg, D is the DBH in cm, and A is the bamboo tree age in du. In each plot, all bamboo tree AGBs were totaled to produce the AGB density in Mgha−1. Table 2 summarizes the AGB statistical results for all collected sample plots. According to the statistical results, off-year samples have wider AGB ranges than on-year samples, but the mean AGB in on-year samples is significantly higher than in off-year samples (64.4 vs. 48.6 Mgha−1). Three scenes of Sentinel-2 multispectral images with acquisition dates closest to field collection dates were selected for AGB estimation (Table 3). Four spectral bands with 10 m spatial resolution and six spectral bands with 20 m spatial resolution were used, but another three spectral bands with 60 m spatial resolution were not used because of their coarse spatial resolutions. The atmospheric calibration was implemented using the Sen2Cor software, which is specific for Sentinel-2 data [35]. Due to the different spatial resolutions in the Sentinel-2 spectral data, this research used the nearest neighbor resampling approach to resample the Sentinel-2 spectral data into a cell size of 10 × 10 m. Meanwhile, the ALOS global digital elevation model (GDEM) data with spatial resolution of 12.5 m was also resampled to a cell size of 10 m, and was used for topographic correction of the Sentinel-2 data using the C-correction model [36].The framework for modeling AGB using Sentinel-2 data is illustrated in Figure 4, including three major steps: (1) Mapping on-year and off-year bamboo forest distribution using multitemporal Sentinel-2 data; (2) extraction of variables from multi-seasonal Sentinel-2 images and selection of key variables using the RF approach; and (3) development of AGB estimation model and evaluation of the modeling results. ", 2. Materials and Methods, 2.2. Data Preparation,2
373,"Accurately mapping bamboo forest distribution is required for bamboo AGB estimation. In order to identify suitable variables for quickly extracting bamboo forests, spectral analysis of on-year and off-year bamboo forests and other forest types was examined based on multitemporal Sentinel-2 images. Compared to Landsat multispectral bands, the Sentinel-2 multispectral bands provide two red edge bands and one NIR band with improved spatial resolution. It is necessary to examine how the newly added spectral bands can separate land-cover types, especially on-year and off-year bamboo forests, which previous research has not examined, probably due to unavailable data sources in the spring season. As shown in Figure 2, the images acquired in the spring season have obviously different colors for on-year and off-year bamboo forests. Based on the analysis of spectral curves among different dates, a new index based on seasonal images was proposed and a decision tree classifier was then used to map the distribution of on-year and off-year bamboo forests. The Normalized Difference Vegetation Index (NDVI) for winter was first used to mask non-vegetation (e.g., impervious surface, bare soil, croplands, and water) and deciduous forest in the Sentinel-2 image; that is, when NDVI(winter) was less than 0.5, those pixels were masked and the remaining pixels indicated evergreen forests, such as evergreen broadleaf and needle-leaf forests and bamboo forests. The proposed seasonal index was then applied to discriminate on-year and off-year bamboo forests from other evergreen forest types (e.g., teagarden, evergreen broadleaf forest, coniferous forest). The index value of bamboo forests and other forest types is greater than 1 because their spectral values began to increase during the growth season, but the index value of teagarden is less than 1 because teagarden is pruned in May and its spectral value decreases between April and May. In addition, because the spectral value of off-year bamboo forest changes more obviously than other forest types between April and May while the spectral values of on-year bamboo forests are almost unchanged, thresholds can be used to discriminate on-year bamboo, off-year bamboo, and other forest types based on training samples. Validation sample plots were collected during fieldwork and used to evaluate the classification image. A total of 600 sample plots, including 150 on-year and 150 off-year bamboo forest samples, and 300 other land-cover samples were collected from the field survey data and Google Earth images. The traditional error matrix approach was used to evaluate the classification image [37,38]. Overall accuracy and kappa coefficient were used to evaluate the overall classification performance, and user’s and producer’s accuracies were used to evaluate on-year and off-year bamboo forest classification accuracy.", 2. Materials and Methods, 2.3. Analysis of Spectral Signature and Mapping of Bamboo Forest Distribution,2
374,"Selection of suitable variables is one of the critical steps in AGB modeling. The most common variables from optical sensor data are spectral responses and textures [12]. Previous research has indicated that the relationships between AGB and spectral responses (spectral bands, vegetation indices) varied, depending on the complexity of forest stand structure and composition of tree species [30]. Spectral bands are fundamental variables for AGB modeling, and proper use of vegetation indices can improve their relationships with AGB [12,30] because external factors such as soil moisture and atmospheric conditions have various impacts on spectral signatures while vegetation indices can reduce these kinds of impacts [39]. Considering the extra red edge spectral bands in the Sentinel-2 data, this research included some vegetation indices that used the red edge wavelength of 750 nm (see Table 4 for the vegetation indices used in this research), because previous research indicated that this wavelength is more sensitive to vegetation health and chlorophyll contents than other red edge wavelengths [40]. The Pearson’s correlation analysis was used to examine relationships between AGB and these variables. Spatial feature is another important factor used in AGB modeling. Textural images are often used through a combination of spectral responses [10,11,17]. For effective extraction of a texture image, the spectral band, texture measure, and moving window size must be determined [49]. The GLCM (gray-level co-occurrence matrix) is often used to calculate textural images [10]. Based on our previous research [10,11,17], the textural images were extracted from the first component based on a principal component analysis (PCA) of the Sentinel-2 multispectral images and GLCM measures with a window size of 9 × 9 pixels. After extraction of variables using vegetation indices and texture measures, another important step is to determine which variables should be used for AGB modeling [13]. Previous research usually used stepwise regression to automatically select variables based on the assumption that the selected variables have no or weak correlation to each other and have a linear relationship with the dependent variable, AGB here. In reality, the remote sensing variables may not have linear relationships with AGB. Thus, we used RF to identify key variables because it can provide the importance ranking of the variables [26]. Some previous studies explored the use of RF for AGB estimation [13] and provided a detailed description of this approach. Therefore, the theory of RF is not described here. According to the importance ranking of selected variables, Pearson’s correlation analysis was used to examine the relationships between these variables. The backward feature elimination method was used to remove the less important variables while keeping the minimum of root mean squared error (RMSE). By repetitively implementing the RF procedure, we can identify the minimum number of variables but produce the most accurate AGB estimation. A detailed description of the RF-based variable selection and modeling is provided in Gao et al. [13].After optimization of the parameters in RF, this RF-based model with the finally selected variables was used to estimate bamboo forest AGB for the entire study area. The RF optimization procedure was conducted based on the following scenarios separately: Individual Sentinel-2 data in April, May, and July and combination of all images based on non-stratification (all bamboo forests as one population) and stratification (on-year and off-year groups) for AGB modeling. For non-stratification, 40 samples were used for AGB modeling and 22 samples for validation. For stratification, 20 samples were used for on-year bamboo AGB modeling and 11 samples for AGB estimation validation; the same numbers of samples were used for off-year AGB study. The common evaluation approach with RMSE, relative RMSE (RMSEr), and MAE (mean absolute error) was used, in addition to R2. System error (SE) was calculated to examine whether the results were under- or over-estimated. In order to compare the AGB estimation results using different scenarios, Akaike’s Information Criterion (AIC) and Bayesian Information Criterion (BIC) [50,51] were calculated, in which the lowest AIC or BIC value represents the best modeling result.






R
2

=




∑

i
=
1

n





(

y

e
i

−


y
m

¯


)


2







∑

i
=
1

n





(

y

m
i

−
y
m

)


2










(2)





R
M
S
E
=






∑

i
=
1

n





(

y

e
i

−
y

m
i


)


2




n







(3)

 



R
M
S
E
r
=


R
M
S
E




y
m

¯







(4)

 



M
A
E
=

1
n



∑

i
=
1

n



|

y

e
i

−
y

m
i


|







(5)

 



S
E
=

1
n



∑

i
=
1

n



(

y

e
i

−
y

m
i


)







(6)

 



A
I
C
=
n
∗
log

(



S
S
E

n


)

+
2
K




(7)

 



B
I
C
=
n
∗
log

(



S
S
E

n


)

+
log

(
n
)

∗
K




(8)

 where 

y

e
i


 is the estimated AGB value from the model, 

y

m
i


 is the measured AGB value, 
n
 is the number of sampling plots, 



y
m

¯


 is the mean value of the measured AGB value, 

S
S
E

 is the sum of square errors, 
K
 is the number of parameters, and 

K
=
p
+
1

 where 
p
 is the number of predictors. Meanwhile, the scatterplots between AGB reference data and estimates and the residual images were used to examine the AGB modeling performance.", 2. Materials and Methods, 2.4. Selection of Variables for Development of Biomass Estimation Models,2
375,"Different spectral signatures of on-year and off-year bamboo forests over time provide the possibility to effectively separate them (Figure 5). In particular, the spectral signatures of on-year and off-year bamboo forests in RedEdge2, RedEdge3, NIR1, and NIR2 (between 740 and 865 nm) have considerably different values in May, indicating that on-year and off-year bamboo forests can be separated, and vegetation indices based on RedEdge2, RedEdge3, NIR1, and NIR2 with visible bands may further improve the separability. The different spectral curves among the dates indicate the value of using the combination of different dates in classification of on-year and off-year bamboo forests, which previous research had not examined. Based on this idea, a seasonal bamboo index is proposed here: 

SBI = (NIR1S5 + NIR2S5 + RedEdge3S5)/(NIR1S4 + NIR2S4 + RedEdge3S4),


(9)

where S5 and S4 represent Sentinel-2 data in May and April. The on-year and off-year bamboo forests in April and May have obvious forest stand structure change, resulting in high variation of SBI compared to other forest types. Therefore, the thresholds of SBI were used to separate on-year and off-year bamboo forests; that is, when SBI > 1.35, the pixels were grouped as off-year bamboo forest, and when SBI < 1.1, the pixels were grouped as on-year bamboo forest. The final results were classified as three classes: On-year bamboo, off-year bamboo, and others, as illustrated in Figure 6. In 2018, the on-year bamboo forests were mainly distributed in the central part of this study area, while off-year bamboo forests were in the southeast, west, and north. The accuracy assessment result (Table 5) indicates that on-year and off-year bamboo forests can be accurately extracted from the bi-seasonal images with producer’s accuracy of 90% to 93% and user’s accuracy of 91% to 93%.", 3. Results, 3.1. Spectral Analysis of On-Year and Off-Year Bamboo Forests and Mapping of Bamboo Distribution,3
376,"The correlation coefficients indicate that AGB has different relationships with spectral bands, depending on dates (Table 6). For example, in April, visible, RedEdge1, and SWIR bands have significant correlations with AGB, but RedEdge2, RedEdge3, NIR1, and NIR2 bands do not. In May, all spectral bands except blue have significant correlations with AGB; in particular, the red edge and NIR bands have stronger correlation with AGB than visible and SWIR bands; however, in July, only green and RedEdge1 have a significant correlation with AGB. One interesting thing is in the on-year bamboo forests, no spectral bands have a significant correlation with AGB, whether in April, May or July, while in off-year bamboo forests, only red and SWIR2 bands have a significant correlation with AGB in April, but none do in May. On the other hand, in July, the spectral bands from RedEdge1 to SWIR1 (705–1610 nm) have a significant correlation with AGB. The correlation coefficients in Table 6 show that the on-year bamboo forests do not have linear relationships with AGB, implying that traditional linear regression models are not suitable for on-year bamboo AGB estimation; however, with proper selection of seasonal image and spectral bands, linear regression may be suitable for off-year bamboo AGB estimation. In contrast, if both on-year and off-year bamboo forests are combined as one population, the high correlation coefficients (0.52–0.59) between AGB and red, RedEdge1, and SWIR in the April image may imply that the April image provides the most accurate AGB estimation. The relationships between spectral bands and AGB are illustrated in scatterplots (Figure 7). For on-year bamboo forests, the correlation results in Table 6 show that spectral bands have no relationships with AGB, and Figure 7 confirms that even as AGB increases from about 40 to about 90 Mgha−1, their spectral values remain almost the same, implying that spectral bands cannot be used for on-year bamboo AGB estimation. For off-year bamboo forests, as AGB increases, spectral values in green, red, and RedEdge1 decease to AGB values of about 50 Mgha−1 in April and May. In contrast, as AGB increases, spectral values of green and red bands in July increase, while spectral values in NIR and SWIR bands are almost the same in April, May, and July, even as AGB increases. This implies that visible bands may be used for off-year bamboo AGB estimation, but because of data saturation (when AGB is greater than about 50 Mgha−1) spectral values cannot be effectively used for AGB estimation.Figure 7 also indicates that with the combination of on-year and off-year bamboo forest as one population, the linear relationships between AGB and spectral bands in green, red, and RedEdge1 in April, green, RedEdge1, and NIR1 in May, and green and RedEdge1 in July have obviously linear relationships until AGB reaches about 60 Mgha−1. The better linear relationships and higher AGB saturation values in the combination of on-year and off-year bamboo forest than in on-year or off-year alone imply that stratification of on-year and off-year bamboo forests may not be necessary. ", 3. Results, 3.2. Correlation Analysis and Identification of Biomass Saturation in Sentinel-2 Data,3
377,"The key variables identified using RF (Table 7) indicate that spectral responses (spectral bands and vegetation indices) are more important than textures in bamboo AGB modeling according to the importance ranking. Under the non-stratification condition, one texture in May and two textures in April were selected, but no textures were selected in July or in the combination of multiple seasons. With stratification of on-year and off-year bamboo forests, no textures were selected for on-year bamboo AGB modeling, and only one texture was selected in off-year bamboo AGB modeling using the May or July imagery. Table 7 implies that texture may not be a critical variable in bamboo AGB modeling. Although Figure 7 indicates that AGB has weak linear correlation with most of the spectral bands, especially for the on-year bamboo forests, the high R2 and relatively low MAE and RMSE values in Table 7 imply that the RF-based approach may be valuable for bamboo AGB estimation. For example, in non-stratification, the April image provides the best overall AGB estimation performance, the May image provides the best performance for on-year bamboo forest, and the combination of April and July imagery provides the most accurate estimation for off-year bamboo forest.", 3. Results, 3.3. Identification of Key Variables for Biomass Modeling,3
378,"The accuracy assessment results (Table 8) show that under the non-stratification condition, the April image provides the best estimation performance with the highest R2 value and lowest values of other evaluation parameters (e.g., RMSE, RMSEr, MAE, AIC and BIC). The overall estimation results based on this stratification condition using the July image slightly improved the AGB estimation over the best estimation with non-stratification using the April image. On the other hand, the highest R2 value (0.46) and the lowest error evaluation parameter values imply that the stratification-based AGB estimation model using the July image can predict the best AGB estimates When this non-stratification-based AGB model was used to map the entire study area, the April image also provided the lowest errors for both on-year or off-year bamboo AGB estimations. The combination of April and July images did not improve AGB estimation performance compared to the April image alone. Although the RMSE, RMSEr, and MAE for on-year and off-year bamboo forests in April have small values using the non-stratification-based AGB model, the low R2 values (0.05 for on-year and 0.03 for off-year) may imply poor estimation results because the estimates and reference data do not have a good linear relationship. With stratification of on-year and off-year bamboo forests, the AGB modeling using the July image based on either on-year or off-year bamboo samples, the RMSE and RMSEr are the lowest values compared to the April and May images, and combination of multiple dates of images cannot improve AGB estimation performance. The off-year bamboo AGB estimation based on the stratification indeed considerably improved estimation performance, with RMSE of 7.75 Mgha−1 and RMSEr of 17.88% using the July image, compared to non-stratification with RMSE of 10.0–14.6 Mgha−1 and RMSEr of 23.1% to 33.7%. For on-year bamboo AGB estimation, the estimation results between stratification and non-stratification did not differ much; for example, RMSE was 13–14.1 Mgha−1 and RMSEr was 18.9% to 20.6% for stratification, and 12.7–15.1 Mgha−1, 18.5% to 22.1% for non-stratification, implying the difficulty of AGB estimation for on-year bamboo forest using the Sentinel-2 data. The scatterplots in Figure 8 indicate that the off-year bamboo forests are more prone to be overestimated, especially when AGB is less than 40 Mgha−1, while on-year bamboo forests are more apt to be underestimated. This situation is especially serious when AGB is greater than 70 Mgha−1 because of the data saturation problem as illustrated in Figure 7. Comparing the residual results between non-stratification and stratification models, the under- or over-estimation problems were slightly reduced but still very obvious in the stratification-based models. For example, when AGB is greater than 80 Mgha−1, the underestimation value can be over 30 Mgha−1 (Figure 8).The spatial distributions of the predicted AGB using the most accurate AGB models under non-stratification and stratification conditions are illustrated in Figure 9. Comparison of Figure 9 and Figure 6 indicates that the lower right region in Figure 9a2 has many more AGB pixels with high AGB values than the same region in Figure 9b2, confirming more accurate estimation using the stratification-based AGB model for off-year bamboo forest AGB estimation, which is confirmed in Table 9. Based on analysis of system errors, on-year bamboo AGB is underestimated, and off-year bamboo AGB is overestimated (Table 10). The stratification-based AGB modeling approach is especially valuable in reducing the on-year underestimation problem.", 3. Results, 3.4. Analysis of Bamboo Forest Biomass Estimation Results ,3
379,"In general, broadleaf and coniferous forests have relatively stable stand structures month to month or even year to year if no serious disturbance is inflicted by external factors, such as selective logging or serious drought. Therefore, previous studies often collected AGB field measurements and remotely sensed data for AGB modeling on different dates due to the difficulty of acquiring data sources during the same year [10,11,17]. However, bamboo forests change their canopies and structures rapidly, especially in spring due to the rapid growth from shoots to fully developed trees, and during fall and winter seasons due to selective logging of old trees (3 du or older). Therefore, the spectral values at different image acquisition dates have high variation due to the bamboo phenological characteristics, as shown in Figure 2 and Figure 5. Thus, the inconsistency of dates between field measurements and image acquisition for AGB calculation may considerably affect the relationships between the spectral bands and AGB, and even produce spurious relationships [13]. Another big difference between bamboo and other forest types is that bamboo forests have on-year and off-year growth features (see Figure 1), while other forest types do not. As shown in this research, the on-year bamboo forests can seriously affect AGB modeling effects due to the low AGB data saturation problem; that is, on-year bamboo forests may have high AGB variation, but their spectral signatures are very similar, and there are no significant relationships between on-year bamboo AGB and spectral responses, as shown in Table 6. This implies that the spectral bands are not suitable for on-year bamboo AGB modeling, especially the traditional linear regression models. More research is needed to use high spatial resolution images (e.g., QuickBird, WorldView) with better than 2 m to examine how changes in stand structure of on-year bamboo forests influence the relationships between AGB and spectral signatures. ", 4. Discussion, 4.1. Impacts of Phenological Features of Bamboo Forests on Biomass Estimation Performance,4
380,"Many previous studies have indicated that the combination of spectral responses and textures is valuable to improve AGB estimation performance, either in tropical or subtropical forest types [11,13,14,15]. However, our research indicates that textures are not critical variables for AGB estimation in bamboo forests. This may be due to the fact that bamboo forests have a single tree species with similar DBH, height, and stand structure. Thus, in bamboo AGB, the tree age and density caused by on-year and off-year phenology play important roles. The challenge in bamboo AGB estimation is the difficulty in modeling on-year bamboo AGB because of the serious data saturation problem. Previous studies [1,2,10,11,14,20] as well as this study confirm the difficulty of using optical sensor data, and the RMSEr can be over 20%. Incorporation of remotely sensed data and ancillary data such as soil and topographic factors may improve AGB estimation if proper modeling algorithms, such as support vector machine, are used [17]. The common approaches, such as machine learning algorithms, that are valid for broadleaf and coniferous AGB modeling may not be suitable for bamboo AGB modeling due to their completely different growth characteristics. Researchers need to develop new algorithms that can effectively incorporate the bamboo forest’s growth stage information, such as how shoots grow quickly to fully developed trees causing a rapid increase in AGB within two to three months.Optical sensor data can only provide land surface information and cannot provide vertical forest stand structure information. Previous research using optical or radar data for AGB modeling has indicated that data saturation is an important factor resulting in poor estimation performance [10,11,17]. This research also indicates that when bamboo forest AGB is greater than 70 Mgha−1, Sentinel-2 data cannot effectively estimate off-year bamboo forest and yield very high underestimation values, especially for on-year bamboo forests. Previous research has shown that incorporating tree height can solve the data saturation problem; thus, using lidar or satellite stereo images can considerably improve AGB estimation [52]. However, bamboo forests have very different growth characteristics from other forest types, as described in the Introduction. The AGB in different bamboo forest sites may be considerably different, but their average DBH and canopy height can be similar. The difference in AGB is mainly caused by different bamboo ages and tree densities. Therefore, use of lidar or stereo images for bamboo AGB estimation may not be as helpful as for other forest types. Researchers need to develop new approaches to extract from bamboo forests the ages and densities of the trees. Bamboo age is related to tree density, because the increase in tree density is due to new bamboo shoots in the on-year bamboo forests. The Sentinel-2 or Landsat images with spatial resolution of 10 or lower cannot effectively capture the subtle difference in tree densities. Higher spatial resolution images such as QuickBird, WorldView, and Pleiades with sub-meter spatial resolution may be needed. To date, there are no such studies for bamboo AGB modeling. In the near future, we need to explore how the very high spatial resolution images can be used for bamboo forest AGB estimation. The available high-speed computers and sub-meter resolution satellite images provide a new opportunity for improvements. In particular, use of the Unmanned Aerial Vehicle (UAV) may provide a new way to estimate bamboo AGB. ", 4. Discussion, 4.2. The Potential to Improve Biomass Estimation Performance,4
381,"Remote sensing-based bamboo AGB estimation has been extensively explored, but the estimation accuracy often has been very poor due to poor understanding of the impacts of the bamboo forest growth characteristics on remote sensing spectral signatures. This research examined using multiple dates of Sentinel-2 multispectral images in bamboo forest classification and AGB estimation based on stratification of on-year and off-year bamboo forests. This research identified the major problems that affect bamboo AGB estimation performance: Mismatch of dates of AGB sample collection and acquisition of remotely sensed data, the high variation of the bamboo stand structures within one year caused by rapid growth from shoots to full-size trees and selective logging, the on-year and off-year bamboo growth features, and the AGB saturation in optical sensor data, especially for the on-year bamboo forest. The on-year bamboo forests have a serious data saturation problem, thus, optical sensor data such as Landsat and Sentinel-2 are not suitable for on-year bamboo AGB estimation. The off-year bamboo forests had obviously linear relationships with AGB, especially when the July Sentinel-2 data were used; the estimation RMSE can be as low as 7.75 Mgha−1. If an insufficient number of samples is available for on-year and off-year bamboo forests, the non-stratification-based AGB model using the April image can provide the most accurate estimation results. This research indicates the difficulty in using optical sensor data alone for bamboo forest AGB estimation. More research should be explored to incorporate multiple data sources such as lidar, optical sensor multispectral data, and ancillary data into AGB modeling. An alternative is to use very high spatial resolution images such as Pleiades and WorldView with sub-meter resolution for extraction of tree density that can be incorporated into the AGB estimation models.", 5. Conclusions,None,5
382,"Windthrows are associated with strong downdrafts produced during severe convective storms [1,2,3,4]. In the Amazon, windthrows are a frequent natural disturbance that influences regional tree mortality and has the potential to regulate regional biomass/carbon stocks and balance [5,6,7,8,9,10]. The geographic distribution of windthrows generally follows the pattern of rainfall across the Amazon Basin, though there are large variations in the size and frequency of occurrence [7,11,12]. Windthrows are more frequent in the Northwestern Amazon than in the Central Amazon [12].Windthrows create changes in forest composition and forest dynamics [13,14]. Consequently, windthrows provide niches for maintaining a diverse cohort of species [6,8,15,16]. In old-growth tropical forests, species with limited competition strategies are eventually eliminated from the community [17]. Therefore, understanding the drivers of structural and compositional change in tropical forests is important for predicting the future composition of these ecosystems [18,19], especially since the frequency and intensity of convective storms are being affected by climate change [7,12]. This knowledge is crucial for better planning initiatives of forest management and climate adaptation [20]. Numerous studies have examined the impacts of climate variability [21,22], soils, nutrient availability, geomorphological variation [23], hydrological regimes [24,25], and productivity [26] on forest structure and dynamics, but the effects of large-scale windthrows have received less attention and remain unassessed for most of the Amazon. Research in the Central Amazon has demonstrated that the recovery of biomass and functional composition depends on the size and severity of the disturbance [5,8,27]. Understanding how wind disturbances impact standing biomass and influence subsequent succession through tree establishment, growth, and mortality is an enduring task in forest ecology [28].In this study, we investigate rates of forest recovery from windthrows in the Northwestern Amazon. We compare our results with a similar study carried out in the Central Amazon, which is characterized by a lower frequency of windthrows, poorer soils and slower turnover rates than our study region. We address the following questions: (a) Which forest structural attributes are most affected following windthrows? and (b) How rapidly do these attributes recover to old-growth conditions? This is the first assessment of forest recovery after windthrow events in the Northwestern Amazon, and provides insight into the different regional patterns of forest dynamics and vulnerability to natural disturbances.", 1. Introduction,None,1.
383,"The study area is located within ~50 km of Iquitos, Peru, in a region covered with old-growth lowland forest (no flooded areas and less than 500 m a.s.l.) (Figure 1). Iquitos is characterized by its lack of dry season (no consecutive months with rainfall ≤ 100 mm) [29]. The mean annual rainfall is 3000 mm, and mean annual temperature is 25.9 °C. Precipitation is lowest from June to August with a mean and standard deviation of 183 mm and ±10 mm month−1, respectively [12]. The study sites are managed by the National University of the Peruvian Amazon (UNAP). Because we want to study the timing of recovery after windthrow disturbances of differing severity, we identified a chronosequence of study sites that were affected by windthrow disturbances at different times in the past. The old-growth forests at the study sites have similar climatic, edaphic and floristic compositions. None of our study sites have experienced any major, recent or direct human impacts such as logging.Windthrow events were identified via Landsat imagery using changes in non-photosynthetic vegetation (NPV) between sequential years [3,30]. This revealed that disturbances at the three study sites (Nauta, Napo and Oroza), occurred in a chronosequence of 2, 12 and 22 years, respectively, prior to transect installation. Oroza (named after the closest town) was windthrown in 1988, has a disturbed area of 662 ha and was surveyed in 2010 (i.e., 22 years after windthrow). Napo experienced a windthrow event in 1998, has a disturbed area of 188 ha, and was also surveyed in 2010 (12 years after windthrow). The windthrow in Nauta occurred in 2009. This site has a disturbed area of 189 ha and was surveyed in 2011 (2 years after windthrow).Given that a chronosequence study substitutes space for time [8,31], our study sites are not strictly replicates, and there are differences in forest structure in the undisturbed parts of the transects. We acknowledge that additional temporal measurements would be needed to assess the degree to which this influences our results, and we have, in most cases, normalized our data to the respective undisturbed forest when making comparisons across sites.", 2. Materials and Methods, 2.1. Study Area,2
384,"Landsat 5 TM images processed with LEDAPS (Landsat Ecosystem Disturbance Adaptive Processing System) [32] were used to detect the occurrence of windthrows. For Oroza, Landsat image P063R03 from 17 April 1988 (prior to disturbance) and 24 September 1988 (after disturbance) were used; for Napo, P062R03 from 19 August 1998 and 22 October 1998; and for Nauta, P063R03 from 2 September 2009 and 7 December 2009. Landsat 5 imagery with Ecosystem Disturbance Adaptive Processing System (LEDAPS) is available in the Google Earth Engine https://earthengine.google.com, (accessed on 24 February 2020) [33], which is the platform used for our imagery analysis and Landsat imagery processing. Windthrows were identified by their spectral characteristics (endmembers) and their distinctive shape diverging from a central area with radiant corridors separated by forest [1]. We used spectral mixture analysis (SMA) [34] to quantify the fraction of distinct endmembers. Specifically, we used image-derived endmembers: green photosynthetic vegetation (GV), non-photosynthetic vegetation (NPV), and shadows. The fractions of NPV and GV were then normalized without shadows as NPV/(GV + NPV) and GV/(GV + NPV) [3,30,34]. Metrics of the windthrow area and damage are derived from ∆NPV [3,6,15,30,35].Using the ∆NPV, we estimated the percentage of trees directly toppled or killed in the studied windthrows by using a locally adjusted predictive windthrow tree-mortality model (Equation (1)) [12]:







M

(

mortality
,

 
in
 
%


)

=
99.86
·
Δ
NPV








(1)

To assign the mortality value by subplot (10 × 30 m), we resampled the image at a greater spatial resolution (from 30 × 30 m to 3 × 3 m), and extracted weighted ∆NPV values based on the pixels comprising subplots using the Zonal statistics tool available in QGIS 3.10.3. The ∆NPV values were used to classify windthrow severity at the subplot level, complementing previous studies in the CA [8].", 2. Materials and Methods, 2.2. Assessing Windthrow Severity,2
385,"At each site, we installed 10 m wide transects of varying lengths, with a total area of three hectares for Napo and Oroza, and 3.09 ha for Nauta. In Napo and Oroza, the transects were subdivided into 100 subplots of 300 m2 each (i.e., 30 m × 10 m), and 103 subplots for Nauta, yielding a total of 303 subplots for our analysis. The transects encompassed the entire gradient of windthrow tree-mortality derived from our remote-sensing metric [6,12]. In each subplot we measured the diameter of trees > 10 cm DBH (diameter at breast height, 1.3 m). Combining all sites, we recorded 4889 living trees. A botanical sample was collected from each recorded species for tree identification. A summary of forest floristics characteristics by severity is shown in Appendix A. Tree locations were determined using a local reference system (UTM 18S) and the following procedure. First, a handheld GPS receiver (Global Position System, Garmin Map76 CSx, Olathe, Kansas, U.S.A) was used to locate the start point of each transect, then the “x” and “y” coordinates of each tree were measured using a rangefinder laser (Trimble Laserace 1000, Sunnyvale, CA, USA) based on their distance and angle from the transect’s starting position.", 2. Materials and Methods, 2.3. Forest Inventory,2
386,"The basal area (BA) of recorded trees m2 ha−1 was estimated from the diameter at breast height assuming a circular trunk shape [36]. As there are no locally adjusted allometries, we estimated individual tree aboveground biomass (AGB) using references from other Amazon regions (Models 1, 2 and 3, Table 1). The AGB at the subplot level was calculated by summing the individual biomass of trees recorded in each subplot.Since Models 1 and 2 include wood density as a predictor, we compiled wood density values of recorded species from previous studies conducted in the Amazon Basin [5,8,38]. Values were assigned using data at the species, genus, or family level (in order of preference), depending on the availability and geographical proximity of our study region. Model 3 was applied to individual trees from species for which wood density was not reported.Forest structural attributes such as biomass can be over- and/or underestimated due to spatial variations in small plots containing relatively large individual trees [5,6,39]. Previous studies from the Central Amazon suggest that robust estimates of biomass require sample units with areas between 0.08 ha to 0.12 ha [8,39]. Therefore, to reduce intrinsic spatial variations in biomass estimates, we binned subplots from our study sites based on their windthrow severity. The final area of our binned plots ranged between 0.09–0.12 ha.", 2. Materials and Methods, 2.4. Data Processing and Analysis,2
387,"A chi-square test at the 5% significance level was used to compare the diameter distribution of trees in old-growth plots. A Student’s t-test was used to assess whether differences in mean DBH, basal area, and average AGB were statistically significant between disturbed and old-growth forest. To compare tree size, basal area, and AGB among successional stages, we used a one-way ANOVA. For reporting forest recovery, we assumed a 10% uncertainty around the respective undisturbed reference, i.e., a subplot was considered ‘recovered’ if it attained 90% of the old-growth value for a given attribute. We estimated the time required to recover old-growth levels of basal area and AGB by fitting linear regressions to the subplot-level data using the time since windthrow as the predictor. We further calculated 90% confidence bands of the response in order to visualize uncertainties. Although our high number of subplots (total of 303) allows for calculating confidence intervals and p-values independent of data distribution, these may be overly optimistic as they do not account for site-level autocorrelation. The statistical analyses were carried out in the statistical software package R 4.0.3 [40].", 2. Materials and Methods, 2.5. Statistical Analysis,2
388,"Estimates of windthrow tree-mortality (Equation (1)) and the locations of transects at respective sites allowed us to calculate the number of plots and the area occupied by each severity class (Table 2). These classes encompass the range of disturbance severity from old-growth forest to low, moderate, high, and extreme severity, and are given in Table 2.", 3. Results, 3.1. Subplot Distribution by Disturbance Severity Class,3
389,"Old-growth forest subplots at our study sites had a mean (± standard deviation) trees per hectare (TPH) of 562 ± 87 trees ha−1, BA of 24.8 ± 2.3 m2 ha−1 and AGB of 380 ± 156 Mg ha−1. We assessed possible pre-disturbance differences among old-growth forests by assessing the mean diameter of trees, the basal area and the AGB across old-growth plots. The results of the ANOVA indicated a significant difference in forest structure among the study sites for BA (p = 0.003) and AGB (p = 0.002), but no significant differences for mean DBH (p = 0.079). A post-hoc T-test (p-adjust using the Benjamin–Hochberg method) indicated that there is no statistical evidence of differences in mean DBH (p = 0.31), BA (p = 0.55), and AGB (p = 0.71) at the Napo and Nauta sites. The Oroza site showed significant differences from the Napo site for BA (p = 0.02) but no difference from the Nauta site (p = 0.06). For AGB, Oroza was significantly different from Nauta and Napo (p = 0.007 and p = 0.004, respectively). For mean DBH, Oroza did not differ significantly from Napo (p = 0.07) or Nauta (p = 0.3).", 3. Results, 3.2. Structural Attributes of Old-Growth Forests,3
390," 3.3.1. Mean Diameter, Tree Density and Basal AreaWe did not find significant differences in the size distribution of trees recorded at varying windthrow severities. However, mean DBH was significantly reduced in extremely disturbed plots 2 years after windthrow (t-test p = 0.03), but differences were not significant 12 years (t-test p = 0.1) and 22 years (t-test p = 0.16) after windthrow. We therefore suggest that in extremely disturbed areas, DBH has recovered to old-growth levels by year 12. For moderate and high severities, no significant differences were observed 22 years after windthrow, with t-test values of p = 0.58 and p = 0.50, respectively.The three sites, spanning 2 to 22 years after disturbance, show clear recovery of structural attributes in the decades following the respective windthrow events. Figure 2a shows the number of trees per hectare as a function of windthrow severity and recovery time. Two years after windthrow disturbance, the number of trees per hectare was 382 (± 35) trees ha−1 in extremely disturbed areas. This rapidly increased to 599 (± 55) trees ha−1 and 578 (±112) trees ha−1 12 and 22 years after windthrow disturbance, respectively. This apparently fast recovery of TPH was also observed for high and moderate windthrow severities. Figure 2b shows the basal area (BA) as a function of windthrow severity and recovery time. Comparing the BA of extremely disturbed forest 2 years following the windthrow event (12.46 ± 4.5 m2 ha−1) with that of extremely disturbed forest after 12 years (23.52 ± 4.51 m2 ha−1) and 22 years (24.46 ± 5.03 m2 ha−1) yields a gradual increase over time. Similar recovery patterns are observed for the high, moderate and low severity categories. 3.3.2. Aboveground Tree BiomassOut of the 4889 trees recorded in our study, 2171 (44.5%) were assigned wood density values at the species level, 1554 (31.7%) at the genus level and 523 (10.7%) at the family level. We did not assign wood density values for 641 (13.1%) trees. We used 95 binned plots distributed over 4 severities and 3 measured years (ranging from 0.09 ha. to 0.12 ha.). Estimates of AGB differed when using Model 1 [37] versus Model 2 [5], mainly due to the relatively higher values given for trees larger than 50 cm DBH by Model 1. However, regardless of which model was used, the overall trajectory of AGB recovery did not change (Appendix B).Extreme disturbance (>60% mortality) reduced the mean AGB to 163 ± 68 Mg ha−1 (2 years after windthrow). AGB increased to 323.4 ± 138.7 Mg ha−1 and 327.5 ± 86.2 Mg ha−1, 12 and 22 years after disturbance, respectively. This AGB recovery process was also observed for sites with high severity. Although AGB loss was considerably lower at low and moderate severity, these areas showed an increased biomass compared to old-growth levels 12 years after windthrow. AGB values differed among studied old-growth areas (see details in Appendix C). For these reasons, AGB recovery in disturbed areas was analyzed relative to old-growth values. Thus, a relative sequence of AGB recovery was made (Figure 3A, bottom panel). As suggested by a linear model (Figure 4-Iquitos), AGB stocks at all windthrow severities will recover to ~90% of that observed in contiguous old-growth forest over a time span of 22 years.", 3. Results, 3.3. Recovery Patterns of Structural Attributes,3
391,"We did not find significant differences in the size distribution of trees recorded at varying windthrow severities. However, mean DBH was significantly reduced in extremely disturbed plots 2 years after windthrow (t-test p = 0.03), but differences were not significant 12 years (t-test p = 0.1) and 22 years (t-test p = 0.16) after windthrow. We therefore suggest that in extremely disturbed areas, DBH has recovered to old-growth levels by year 12. For moderate and high severities, no significant differences were observed 22 years after windthrow, with t-test values of p = 0.58 and p = 0.50, respectively.The three sites, spanning 2 to 22 years after disturbance, show clear recovery of structural attributes in the decades following the respective windthrow events. Figure 2a shows the number of trees per hectare as a function of windthrow severity and recovery time. Two years after windthrow disturbance, the number of trees per hectare was 382 (± 35) trees ha−1 in extremely disturbed areas. This rapidly increased to 599 (± 55) trees ha−1 and 578 (±112) trees ha−1 12 and 22 years after windthrow disturbance, respectively. This apparently fast recovery of TPH was also observed for high and moderate windthrow severities. Figure 2b shows the basal area (BA) as a function of windthrow severity and recovery time. Comparing the BA of extremely disturbed forest 2 years following the windthrow event (12.46 ± 4.5 m2 ha−1) with that of extremely disturbed forest after 12 years (23.52 ± 4.51 m2 ha−1) and 22 years (24.46 ± 5.03 m2 ha−1) yields a gradual increase over time. Similar recovery patterns are observed for the high, moderate and low severity categories.", 3. Results," 3.3.1. Mean Diameter, Tree Density and Basal Area",3
392,"Out of the 4889 trees recorded in our study, 2171 (44.5%) were assigned wood density values at the species level, 1554 (31.7%) at the genus level and 523 (10.7%) at the family level. We did not assign wood density values for 641 (13.1%) trees. We used 95 binned plots distributed over 4 severities and 3 measured years (ranging from 0.09 ha. to 0.12 ha.). Estimates of AGB differed when using Model 1 [37] versus Model 2 [5], mainly due to the relatively higher values given for trees larger than 50 cm DBH by Model 1. However, regardless of which model was used, the overall trajectory of AGB recovery did not change (Appendix B).Extreme disturbance (>60% mortality) reduced the mean AGB to 163 ± 68 Mg ha−1 (2 years after windthrow). AGB increased to 323.4 ± 138.7 Mg ha−1 and 327.5 ± 86.2 Mg ha−1, 12 and 22 years after disturbance, respectively. This AGB recovery process was also observed for sites with high severity. Although AGB loss was considerably lower at low and moderate severity, these areas showed an increased biomass compared to old-growth levels 12 years after windthrow. AGB values differed among studied old-growth areas (see details in Appendix C). For these reasons, AGB recovery in disturbed areas was analyzed relative to old-growth values. Thus, a relative sequence of AGB recovery was made (Figure 3A, bottom panel). As suggested by a linear model (Figure 4-Iquitos), AGB stocks at all windthrow severities will recover to ~90% of that observed in contiguous old-growth forest over a time span of 22 years.", 3. Results, 3.3.2. Aboveground Tree Biomass,3
393,"Differences in forest attributes exist across the Amazon Basin [41,42], including tree-mortality predictors [10,43] that can explain different mortality/survival mechanisms when compared across a large region. Winds are an important mechanism of natural disturbance in forests worldwide [44,45,46]. Windthrows produce varying levels of tree damage/mortality that change forest structure [6,20] and can initiate varying successional trajectories [8,15,28]. Our results give further evidence to the importance of wind as a major disturbance mechanism in Amazon forests [9,12,15,47]Forest inventories at windthrow sites in the Northwestern Amazon (our plots) and Central Amazon [5,8,15] followed the same overall sampling and analysis design. The degree of windthrow tree mortality estimated from ∆NPV was higher (up to 95%) in our Northwestern Amazon sites compared to the Central Amazon (up to 70%) [5,12,15]. For that reason, we included one additional severity class to represent extreme windthrow tree-mortality (>60%).The 562 ± 87 trees ha−1 in our old-growth forests is similar to the number reported by other studies conducted in the Northwestern Amazon, for example 608–616 trees ha−1 [48], 559 ± 74 trees ha−1 [41], 589 ± 20 trees ha−1 [49], as well as in the Central Amazon (583 ± 46 trees ha−1) [15]. Our data on stem density (Figure 3A, top panel) shows that 12 years after windthrow, the windthrown forest reaches the same values observed in the adjacent/contiguous old-growth, and maintains this pattern at least until 22 years of recovery. Compared to plots in the Central Amazon, (Figure 3B, top panel) the patterns of forest recovery are similar in terms of TPH and the time required to recover to old-growth values for both regions is between 12 and 14 years, independent of the severity. Tree density was smaller in the Northwestern Amazon indicating that, for a given windthrow severity, mortality was relatively higher in this region than in the Central Amazon. Tree density recovery following disturbances was also faster in Iquitos (NWA) compared to Manaus (CA). In the Northwestern Amazon, tree density was reduced to 377 ± 89 trees ha−1 and 382 ± 35 trees ha−1 2 years after windthrow disturbance in the >40% and > 60% tree-mortality categories, respectively. In the Central Amazon, tree density was 422 ± 121 trees ha−1 4 years after disturbance in the >40% tree-mortality category [15].Basal area in old-growth forests in the Northwestern Amazon was previously reported as ~28 m2 ha−1 [41] and 27.65 (±2.0) m2 ha−1 [49]. These values are similar to those found at our study sites in the Northwestern Amazon (24.8 ± 2.3 m2 ha−1) and those in the Central Amazon (26.8 ± 2.4 m2 ha−1) [15]. In our study, the estimated recovery time for the relative basal area (Figure 3A, middle panel) shows a gradual increase in all the windthrow severities. Compared with the Central Amazon (Figure 3B, top and middle panels), we observed a faster recovery of tree density and basal area in the Northwestern Amazon. This also contributes to a more rapid recovery of biomass [15,50] and may be related to changes in floristic composition and species diversity [15,51].", 4. Discussion, 4.1. Patterns of Recovery after Windthrow,4
394,"In tropical forests, the recovery of biomass following disturbance can vary greatly depending on the latitude, type and severity of the disturbance. In secondary forests created by human disturbances (e.g., slash-and-burn, and clear cut), biomass recovery to old-growth conditions can take from 66 [52] to >100 years [31,53,54,55]. These differences in time reflect, among other factors, the availability of nutrients for regrowth [56]. A hurricane in Puerto Rico reduced biomass by 50% [57]. Moreover, impacts and recovery times for this disturbance depended strongly on the degree of hurricane damage, with biomass recovery taking from 4 to 6 years (F0 damage), and from 50 to 150 years (F3 damage) [58,59]. This pattern was also observed after selective logging in Tapajos, Brazil (Central Amazon). Biomass recovery took ~13 years [60] and minimally affected forest carbon and water exchanges [61].Previous studies in old-growth Amazon forests reported AGB ranging from 303 to 385 Mg ha−1 [62], 155 to 425 Mg ha−1 [63] and ~256 Mg ha−1 [64]. Regional-scale variations in biomass are well documented and likely related to factors such as climate [21,22], soils and nutrient availability, or geomorphological characteristics [23]. The causes of regional variations in vegetation structure across different forest types [64] and the main drivers of tree mortality are not yet fully understood [10]. Our results highlight the importance of large-scale windthrows in shaping forest structure in the Northwestern Amazon.In the Amazon, windthrow distribution extends from the Northwestern Amazon to the Central Amazon [12], showing a spatial and temporal variability in gap sizes [11,65] and mortality rates [6,8,9,12]. In our study, the estimated time to recover AGB increased slightly with windthrow severity. In our study, the recovery to old-growth levels occurred after 22 years (Figure 3A, bottom panel), whereas in the Central Amazon, 24 years were only enough to recover the old-growth levels of attributes observed in forests exposed to low-severity windthrow, and showed a slower growth increment for moderate and high severities even 27 years after windthrow (Figure 3B, bottom panel).We described the trajectories of biomass recovery in the Northwestern and Central Amazon using linear models (Figure 4). For the Northwestern Amazon, we estimated recovery to be at least > 90% of the old-growth condition after 14 years, 15 years, 18 years, and 20 years since windthrow for low, moderate, extreme, and high windthrow tree-mortality, respectively. For the Central Amazon we estimated ~10 years, ~30 years, and ~37 years for low, high, and moderate windthrow tree-mortality, respectively (details in Supplementary Material SM1, SM2). Differences in the width of confident intervals between the Northwestern and Central Amazon in Figure 4 reflect the number of binned plots used for each site and the numbers of measured years. In the Central Amazon, more complex models such as the generalized additive model (GAM) were used for estimating how biomass recovered to pre-disturbance levels (from 27 to 40 years, maximum) [8].Our study indicated a faster recovery of biomass in the Northwestern Amazon than in the Central Amazon, which may be explained by the higher productivity in this region [26], and potentially related geographic variations in community attributes, including larger tree diversity [42] which can influence tree mortality patterns [12]. In addition, high competition in combination with water availability [25,66] promotes high productivity, and species that sacrifice defenses in favor of the competitive advantage obtained by rapid growth and low wood density may be favored in regions with severe disturbance regimes [43]. Thus, faster recovery could be the result of adaptation to more frequent windthrow disturbance in the Northwestern Amazon [12], which provides supporting evidence for the growth-defense hypothesis [67].Ecologists have long recognized that disturbances and recovery processes overlap in spatial and temporal dimensions [68]. In our study sites, the density and size distribution of trees had returned to old-growth levels only 12 years after windthrow. Furthermore, basal area and biomass recovered to pre-disturbance levels within 20 years of the disturbance. This is ~50% faster than the recovery from windthrows observed in the Central Amazon. Future research on forest recovery from windthrows should include a component of geospatial analysis to help explain individual tree response [8].", 4. Discussion, 4.2. Time Span of Biomass Recovery,4
395,"This study demonstrated rapid recovery of tree density, basal area, and AGB in the two decades following windthrow events that caused mortality rates >60% in forests near Iquitos, Peru. The observed recovery rates are nearly twice as fast as those reported for a comparable study conducted in the slower-growing forests of the Central Amazon. The variations in forest damage and the recovery dynamics across this geographical and climatic gradient emphasize the effect that extreme wind and rain associated with convective storms can have on the spatial variability of forest structure across the Amazon Basin.", 5. Conclusions,None,5
396,"Forested ecosystems are spatially dynamic and continuously changing and therefore comprise complex and heterogeneous forest structures [1,2]. Forest structure, defined as the spatiotemporal arrangement of structural components in specific vertical and horizontal spatial patterns within a forest stand [3,4,5], is recognized as both a product and driver of forest biophysical processes [6] and represents important forest information, which is useful for guiding multi-functional forest management [7]. Forest structural parameters (e.g., tree height, volume, biomass or stem density etc.) provide considerable information on the spatial and temporal distribution of forests as well as structural properties, and are considered critical components of forest inventory [8] and reliable diversity indicators across forest successional stages [3]. So obtaining spatially continuous estimates of forest structural parameters is valuable for supporting long-term sustainable forest management [9].Subtropical forests are distributed in a transition zone between tropical and temperate zones, i.e., the region lying largely from 23.5° to 40° latitude in the northern or southern hemispheres [10]. Subtropical forests consist of both subtropical humid and subtropical dry forests, which have unique ecological characteristics when compared to tropical and temperate regions [11]. Subtropical forests, which account for approximately 9% of the world’s forest area [12], are considered a carbon sink contributing to global forest carbon sequestration, and have high species richness, complex structure of forest, high biodiversity and high net ecosystem productivity (NEP) [11]. Quantitative measurements of forest structural parameters of subtropical forests are required to understand forest ecological mechanisms, promote regional ecological developments, maintain biodiversity and enhance regional carbon balance [13].Traditionally, forest structural parameters are assessed by conventional field inventories, which is time-consuming, costly and limited in spatial extent [2,14]. As a promising earth observation technique, remote sensing has shown great potential for providing multi-scale, multi-dimensional and multi-temporal earth surface information [15] for instantaneous, quantificational and accurate measurements of spatially continuous wall-to-wall properties of forest structure over large-scale areas in lieu of time-consuming and labor-intensive inventory [16]. Furthermore, integrating information from remotely sensed data with a high level of precision and temporal consistency has been recognized as having the ability to describe forest biophysical properties and effectively enhance the performance of forest structure estimations [17].Estimates of forest stand structural parameters have been derived from optical remote sensing data for several decades [17,18]. However, passive remote signals are generally reflected or absorbed in the uppermost canopy layers and tend to “saturate”, especially in dense forest(i.e., high canopy closure), limiting the ability to characterize vertical structure [19,20]. Similarly, Radar (Radio Detection and Ranging) technology also reveals the aforementioned data saturation problems, due to noise introduced by terrain, surface moisture and other factors [20,21]. Conversely, as a promising active remote sensing technology, Light Detection and Ranging (LiDAR) can be used to directly estimate a spatially explicit three-dimensional (3D) canopy structure with submeter accuracy by transmitting short laser pulses and receiving returned signals [22,23]. Furthermore, LiDAR systems have the ability to overcome the data saturation problems in optical or Radar remote sensing, as a laser beam can strongly penetrate through even dense and multilayered forest canopies to the earth’s surface [24].Means et al. (2000) [25] estimated forest structural parameters, i.e., tree height, basal area, and volume, using airborne LiDAR data over a Douglas-fir-dominated temperate forest in the Western Cascades of Oregon. They found that the estimation of tree height predicted by the metrics of height percentiles and resulted in R2 values of 0.93–0.98. The R2 values were 0.94–0.95 and 0.95–0.97 for basal area and volume, which were predicted using the metrics of height percentiles and canopy densities as independent variables. Silva et al. (2016) [26] predicted and mapped volume using LiDAR metrics in Eucalyptus plantations in tropical forests (located in São Paulo, Brazil), and found that volume (Adj-R2 = 0.84) was well predicted by the coefficient of variation of return height and the 99th height percentile from LiDAR. Tesfamichael and Beech (2016) [27] used height-related metrics (e.g., height percentiles, maximum height) and canopy density metrics to estimate plot-level structural attributes (i.e., mean height, maximum height, crown diameter and aboveground biomass) over a savanna ecosystem region located in the south western part of Zambia, and resulted in R2 values of 0.48–0.95. However, these studies often include height and density predictors with little physical justification for model formulation. Moreover, they usually neglected a mechanism to summarize complex canopy characteristics into simple parameters, which can potentially be used for estimates of forest structural parameters in different forest conditions [14,28], and the standard metrics (i.e., height-based and density-based metrics) tend to be strongly inter-correlated, and depend on forest conditions, plot sizes, point cloud density and geometrical distributions of point clouds etc. [29,30,31,32,33], and a large subset of these metrics are linked to only a few forest stand characteristics. Thus, these metrics generally have a relatively low transferability and are limited in describing the vertical heterogeneity of forest structure [24].Canopy vertical profiles, defined as the distributed curves about the characteristic of forest structural components as a function of height above ground, are intimately linked to the vertical distributions of forest structural elements (e.g., foliage, branches, trunks etc.), and have strong potential in enhancing the theoretical explanations of vertical forest structure [4,34,35]. Canopy vertical profiles are important descriptors of forest structure. Lefsky et al. (1999) [36] developed an approach termed “canopy volume models (CVM) ” to characterize three-dimensional (3D) volumetric structure of forest canopies by quantifying the differences in the total volume and spatial organization of the tree foliage, and this approach is beneficial to distinguish specific volumetric canopy architecture. They found relatively high accuracies (R2 = 0.52–0.91) for estimating forest structural parameters using the metrics derived from canopy vertical profiles (i.e., canopy volume profiles (CVP) and canopy height profiles (CHP)). Lovell et al. (2003) [37] used airborne and terrestrial LiDAR data to derive foliage profiles (FP) and estimated effective leaf area index (LAI) in temperate forests located in southern Australia. They found that results compared with LAI derived from classified hemispherical photographs with agreement within 8%. Coops et al. (2007) [38] refined the CVM approach to adapt discrete return LiDAR data. In addition, a Weibull fitting approach was conducted to fit FP profiles and further obtain relevant LiDAR metrics, and finally a number of forest structural parameters (i.e., mean height, basal area) (R2 = 0.65–0.85) were estimated. Hilker et al. (2010) [39] assessed and compared canopy metrics derived from canopy vertical profiles using airborne and terrestrial LiDAR data. The results showed that airborne and terrestrial LiDAR were both able to accurately determine canopy height (absolute error of height was less than 2.5 m) and LAI (R2 = 0.86–0.90). However, most previous studies that estimate forest structural parameters using canopy metrics derived from canopy vertical profiles were conducted in temperate, tropical and boreal forests, and published studies of the subtropical forests are few.In this study, the standard metrics and canopy metrics derived from airborne LiDAR data are used to estimate plot-level forest structural parameters (i.e., mean diameter at breast height, Lorey’s mean height, stem density, basal area, volume, and aboveground biomass) individually and in combination over a north subtropical secondary forest in southern Jiangsu Province, China. The objectives of this study are: (1) to derive two suites of canopy metrics, i.e., canopy volume (CV) metrics and Weibull-fitted (WF) metrics, using voxel-based CVM and Weibull fitting approaches separately; and (2) to assess the capability of standard metrics and canopy metrics based models and combination models for estimating forest structural parameters and to evaluate the accuracies of the models; and (3) to explore the optimal horizontal and vertical resolution of voxels for the predictive models.", 1. Introduction,None,1.
397,"This study was conducted in Yushan Forest, a state-operated forest and national park located near the town of Changshu in Jiangsu Province, southeastern China (120°42′9.4″E, 31°40′4.1″N). The total site area is approximately 1260 ha, which covers approximately 1140 ha of forests. Topographically, the site’s mountain terrain extends from northwest to southeast and the ridge line is more than 6500 m, with the elevation range between approximately 20 and 261 m above sea level. This site is situated in the north-subtropical monsoon climatic region with an annual mean temperature of 15.4 °C, and precipitation of 1047.7 mm, and annual mean relative humidity of approximately 80%. The highest monthly precipitation occurs from June to September. The soil type in Yushan is composed mainly of mountain yellow-brown earth. The forest in Yushan belongs to the north-subtropical mixed secondary forest with three main forest types: conifer-dominated, broad-leaved dominated and mixed forests. The dominant broad-leaved tree species include Oriental oak (Quercus variabilis Bl.), Chinese sweet gum (Liquidambar formosana Hance) and Sawtooth oak (Quercus acutissima Carruth.) of deciduous broad-leaved trees species, mixed with other evergreen broad-leaved tree species including Camphorwood (Cinnamomum camphora (L.) Presl.) and Chinese holly (Ilex chinensis Sims.). The primary coniferous forests are dominated by evergreen coniferous tree species, including Masson pine (Pinus massoniana Lamb.), Chinese fir (Cunninghamia lanceolata (Lamb.) Hook.), slash pine (Pinus elliottii Engelm.) and Japanese Blackbark Pine (Pinus thunbergii Parl.). Figure 2 shows an overview of the study site and distribution of sample plots and Figure 3 shows the field photos of three forest types.", 2. Materials and Methods, 2.1. Study Area,2
398," 2.2.1. LiDAR DataSmall footprint airborne LiDAR data were acquired on 17 August 2013 using a Riegl LMS-Q680i sensor flown at 900 m above ground level, with a flight speed of 55 m·s−1 and a flight line side-lap of ≥60%. The sensor recorded returned waveforms of laser pulse with a temporal sample spacing of 1 ns (approximately 15 cm). The LiDAR system was configured to emit laser pulses in the near-infrared band (1550 nm) at a 360 kHz pulse repetition frequency and a 112 Hz scanning frequency, with a scanning angle of ±30° from nadir and a swath of 1040 m. The dataset had an average beam footprint size of 0.45 m (nadir) in diameter. The average ground point distances of the dataset were 0.49 m (flying direction) and 0.48 m (scanning direction) in a single strip, with pulse density of approximately 5.06 pulse m−2. The final extracted point clouds and associated waveforms were stored in LAS 1.3 format (American Society for Photogrammetry and Remote Sensing, Bethesda, MD, USA).In order to obtain the relative height of trees, raw point cloud data were first filtered by removing outliers. The data were filtered to remove non-ground points using an algorithm adapted from Kraus and Pfeifer (1998) [40], which was based on a method of linear least-squares interpolation, and then the data were smoothed by the median filter (moving square windows of size 5 × 5 m). After filtering the non-ground points, a 1-m Digital terrain model (DTM) was created by calculating the average elevation from the ground points within a cell (cells that contain no points were filled by interpolation using neighboring cells). Then, the point cloud was then normalized against the ground surface height and extracted for each plot. Point clouds for all plots (n = 51) were finally extracted using the coordinates of the lower left and upper right corners. 2.2.2. Field DataThe field data for the study site were collected from June to August in 2012 and in August of 2013. Throughout the Yushan study region, a total of 51 square sample plots (30 × 30 m) were established, covering the forest type, dominant species compositions, age classes, and site indices, according to an historical forest resource inventory data (2012). All plots were divided into broad-leaved forest (n = 14), coniferous forest (n = 14), and mixed forest (n = 23). The centers of each plot and plot corners were located using Trimble GeoXH6000 Handheld GPS (Trimble, Sunnyvale, CA, USA) units equipped with a dual frequency GNSS antenna, and corrected with high precision real-time differential signals received from the Jiangsu Continuously Operating Reference Stations (JSCORS), resulting in a submeter positional of accuracy of less than 0.5 m [41]. The plot directions and inclined angles were recorded by forest compass, and the border lengths were measured by PI tape. For all live trees with a diameter at breast height (DBH) over 5 cm, tree type, diameter, height, height to crown base, crown width in both cardinal directions, crown class, and crown transparency were measured. DBH was measured on all trees using a diameter tape. Heights of all trees were measured using a Vertex IV hypsometer (Haglöf, Långsele, Sweden). Crown widths were obtained by measuring the average of two values measured along two perpendicular directions from the location of the tree top. In addition, small trees (DBH < 5 cm) and dead wood were also tallied for total stem density, but not used in biomass calculations.Several forest structural parameters were assessed in this study, including mean DBH, Lorey’s mean height (i.e., the basal area weighted height), stem density, basal area, volume and aboveground biomass. In addition, aboveground biomass of each tree was calculated by means of the species specific allometric equations from local or nearby province [42,43,44,45,46,47] (Appendix A (Table A1)), and the tree-based calculation results were summed within each plot to determine plot-level forest aboveground biomass. Plot-level volume was similarly calculated using provincial species specific volume equations of individual trees, which were based on DBH as predictor variables. A summary of plot-level forest structural parameters data is presented in Table 1.", 2. Materials and Methods, 2.2. Data Acquisition and Pre-Processing,2
399,"Small footprint airborne LiDAR data were acquired on 17 August 2013 using a Riegl LMS-Q680i sensor flown at 900 m above ground level, with a flight speed of 55 m·s−1 and a flight line side-lap of ≥60%. The sensor recorded returned waveforms of laser pulse with a temporal sample spacing of 1 ns (approximately 15 cm). The LiDAR system was configured to emit laser pulses in the near-infrared band (1550 nm) at a 360 kHz pulse repetition frequency and a 112 Hz scanning frequency, with a scanning angle of ±30° from nadir and a swath of 1040 m. The dataset had an average beam footprint size of 0.45 m (nadir) in diameter. The average ground point distances of the dataset were 0.49 m (flying direction) and 0.48 m (scanning direction) in a single strip, with pulse density of approximately 5.06 pulse m−2. The final extracted point clouds and associated waveforms were stored in LAS 1.3 format (American Society for Photogrammetry and Remote Sensing, Bethesda, MD, USA).In order to obtain the relative height of trees, raw point cloud data were first filtered by removing outliers. The data were filtered to remove non-ground points using an algorithm adapted from Kraus and Pfeifer (1998) [40], which was based on a method of linear least-squares interpolation, and then the data were smoothed by the median filter (moving square windows of size 5 × 5 m). After filtering the non-ground points, a 1-m Digital terrain model (DTM) was created by calculating the average elevation from the ground points within a cell (cells that contain no points were filled by interpolation using neighboring cells). Then, the point cloud was then normalized against the ground surface height and extracted for each plot. Point clouds for all plots (n = 51) were finally extracted using the coordinates of the lower left and upper right corners.", 2. Materials and Methods, 2.2.1. LiDAR Data,2
400,"The field data for the study site were collected from June to August in 2012 and in August of 2013. Throughout the Yushan study region, a total of 51 square sample plots (30 × 30 m) were established, covering the forest type, dominant species compositions, age classes, and site indices, according to an historical forest resource inventory data (2012). All plots were divided into broad-leaved forest (n = 14), coniferous forest (n = 14), and mixed forest (n = 23). The centers of each plot and plot corners were located using Trimble GeoXH6000 Handheld GPS (Trimble, Sunnyvale, CA, USA) units equipped with a dual frequency GNSS antenna, and corrected with high precision real-time differential signals received from the Jiangsu Continuously Operating Reference Stations (JSCORS), resulting in a submeter positional of accuracy of less than 0.5 m [41]. The plot directions and inclined angles were recorded by forest compass, and the border lengths were measured by PI tape. For all live trees with a diameter at breast height (DBH) over 5 cm, tree type, diameter, height, height to crown base, crown width in both cardinal directions, crown class, and crown transparency were measured. DBH was measured on all trees using a diameter tape. Heights of all trees were measured using a Vertex IV hypsometer (Haglöf, Långsele, Sweden). Crown widths were obtained by measuring the average of two values measured along two perpendicular directions from the location of the tree top. In addition, small trees (DBH < 5 cm) and dead wood were also tallied for total stem density, but not used in biomass calculations.Several forest structural parameters were assessed in this study, including mean DBH, Lorey’s mean height (i.e., the basal area weighted height), stem density, basal area, volume and aboveground biomass. In addition, aboveground biomass of each tree was calculated by means of the species specific allometric equations from local or nearby province [42,43,44,45,46,47] (Appendix A (Table A1)), and the tree-based calculation results were summed within each plot to determine plot-level forest aboveground biomass. Plot-level volume was similarly calculated using provincial species specific volume equations of individual trees, which were based on DBH as predictor variables. A summary of plot-level forest structural parameters data is presented in Table 1.", 2. Materials and Methods, 2.2.2. Field Data,2
401," 2.3.1. Canopy Volume Model ApproachA voxel-based CVM approach was applied for point cloud data to derive metrics in this study. The canopy spaces were first organized as a matrix composed of voxels (5 × 5 × 0.5 m3), and these voxels were classified as either “filled” or “empty” volume depending on the presence or absence of LiDAR points within each voxel. “Filled” voxels were further classified as either “euphotic“ zone, if they were located in the uppermost 65% of all filled voxels, or as “oligophotic” zone if they were located below the point, whereas “empty” voxels were located either below (“closed gap”) or above the canopy (“open gap”) [38]. Open gap, euphotic, oligophotic and closed gap were determined as four canopy structure classes, with units defined as the volume of each class per unit area. All volume elements (Open gap, Oligophotic, Euphotic, Closed gap, Filled, Empty) were derived as canopy volume (CV) metrics using the CVM method and canopy volume profile (CVP) was visualized. Figure 4 shows the illustration of voxel-based CVM approach. Point clouds of a plot (30 × 30 m2) were voxelized, and divided into 36 vertical columns of voxels, and each column was further stratified with four canopy structure classes. All columns of a plot were expanded in a panel and the canopy volume distribution (CVD) was presented (Figure 4c). Finally, the volume percentages of canopy structure classes of each height interval (0.5 m) were calculated, resulting in CVP (Figure 4d).Notably, an appropriate voxel volume size for CVM in this study was been considered because various voxel sizes likely change the distributions and proportions of canopy structure classes. Thus, this study also investigated the influence of various voxel sizes on the accuracies of the models. Given the average beam footprint size of 0.45 m, average ground point distances of 0.49 m (flying direction) and 0.48 m (scanning direction) and pulse density of approximately 5.06 pulse·m−2, horizontal resolutions of 1 m to 10 m were chosen (which were multiples of the footprint size and average ground point distances). Vertical resolutions of 0.5 m and 1 m were chosen to correspond to roughly three and six sampling intervals of the returned waveform. A sensitivity analysis was performed using CV-metrics (i.e., Open gap, Oligophotic, Euphotic, Closed gap, Filled, Empty). 2.3.2. Weibull Fitting ApproachCanopy height distributions (CHD), which describe vertical distributions of foliage elements and non-photosynthetic tissues within canopy spaces, were used to measure the distribution of laser returns within the 0.3-m bins (i.e., a 30 × 30 × 0.3 m3 rectangular section) from the ground to canopy top [48,49]. In this study, a two-parameter Weibull density function (PDF) was used to describe CHD on each plot. As a Weibull model is highly adaptive, ranging from an inversed J-shape to unimodal skewed and unimodal symmetrical curve, the Weibull model has flexibility in characterizing distributions of a range of forest attributes [50,51]. The two parameters, i.e., Weibull scale (α1) and Weibull shape (β1), were derived by the maximum likelihood estimation method. Weibull scale determines the basic shape of the distribution density curve and Weibull shape controls the breadth of the distribution [52]. Foliage profile (FP) can delineate the vertical distribution of canopy phytoelement (e.g., leaf, stem, twig, etc.) density above the ground within a forest stand [37]. FP is defined as the total one-sided leaf area that is involved in photosynthesis per unit canopy volume at canopy height z, and describes changes in the leaf area distribution with increasing height [53]. FP is highly related to leaf area index (LAI), which was demonstrated in previous studies [35,54], and the relationship between FP and LAI is: 




L

(
z
)

=



∫


z
1




z
2





F
P

(
z
)

d
z


,





(1)


where L(z) is the cumulative leaf area index (LAIc) from the ground to a given height z; FP(z) represents the foliage area volume density at height z (is the vertical foliage profile in a thin layer or “slice” through a canopy as a function of height z); z1 and z2 are different canopy height. A height interval or each vertical “slice” was 0.3 m. Meanwhile, we assumed that foliage elements in a thin “slice” were very small so that occlusion can be neglected, and leaves presented Poisson random distribution. Because airborne LiDAR is incapable of resolving foliage angle distribution, clumping and non-foliage elements, the foliage profiles derived from airborne LiDAR are referred to here as “apparent” foliage profiles and effective LAI [37]. In this study, LAI can be indirectly determined from LiDAR by estimating the derived gap probability in the canopy [37,38], and the gap probability be estimated as the total number of laser hits up to a height z relative to the total number of LiDAR shots as follows:




L

(
z
)

=
−
l
n

(


P

g
a
p



(
z
)


)

=
−
l
n

(

1
−



(

#

z
j

|

z
j

>
z

)


N


)

,





(2)


where Pgap (z) is a gap probability measurement at height z, #z is the number of hits down to a height z above the ground, and N is the total number of shots emitted up to the sky. Previous studies have showed that Weibull distribution function can also delineate vertical foliage profiles distributions [37,55]. In this study, the Weibull fitted scale parameter (α2) and shape parameter (β2) were derived from the apparent FP by linking Weibull cumulative function to cumulative projected foliage area index [37,38]:




L
(
z
)
=
1
−

(


e

−



(



1
−
z
/

H

max





α
2




)




β
2






)

,





(3)


where α2 and β2 are fitted parameters, z is the height, and H is the maximum height in a plot.Moreover, another suite of standard metrics were calculated, including height-based (HD) metrics (h25, h50, h75, h95, hmean, hcv, hskewness and hkurtosis) and density-based (DB) metrics (d1, d3, d5, d7, d9, CC2m). A summary of these metrics with corresponding descriptions is shown in Table 2.", 2. Materials and Methods, 2.3. Derived Metrics,2
402,"A voxel-based CVM approach was applied for point cloud data to derive metrics in this study. The canopy spaces were first organized as a matrix composed of voxels (5 × 5 × 0.5 m3), and these voxels were classified as either “filled” or “empty” volume depending on the presence or absence of LiDAR points within each voxel. “Filled” voxels were further classified as either “euphotic“ zone, if they were located in the uppermost 65% of all filled voxels, or as “oligophotic” zone if they were located below the point, whereas “empty” voxels were located either below (“closed gap”) or above the canopy (“open gap”) [38]. Open gap, euphotic, oligophotic and closed gap were determined as four canopy structure classes, with units defined as the volume of each class per unit area. All volume elements (Open gap, Oligophotic, Euphotic, Closed gap, Filled, Empty) were derived as canopy volume (CV) metrics using the CVM method and canopy volume profile (CVP) was visualized. Figure 4 shows the illustration of voxel-based CVM approach. Point clouds of a plot (30 × 30 m2) were voxelized, and divided into 36 vertical columns of voxels, and each column was further stratified with four canopy structure classes. All columns of a plot were expanded in a panel and the canopy volume distribution (CVD) was presented (Figure 4c). Finally, the volume percentages of canopy structure classes of each height interval (0.5 m) were calculated, resulting in CVP (Figure 4d).Notably, an appropriate voxel volume size for CVM in this study was been considered because various voxel sizes likely change the distributions and proportions of canopy structure classes. Thus, this study also investigated the influence of various voxel sizes on the accuracies of the models. Given the average beam footprint size of 0.45 m, average ground point distances of 0.49 m (flying direction) and 0.48 m (scanning direction) and pulse density of approximately 5.06 pulse·m−2, horizontal resolutions of 1 m to 10 m were chosen (which were multiples of the footprint size and average ground point distances). Vertical resolutions of 0.5 m and 1 m were chosen to correspond to roughly three and six sampling intervals of the returned waveform. A sensitivity analysis was performed using CV-metrics (i.e., Open gap, Oligophotic, Euphotic, Closed gap, Filled, Empty).", 2. Materials and Methods, 2.3.1. Canopy Volume Model Approach,2
403,"Canopy height distributions (CHD), which describe vertical distributions of foliage elements and non-photosynthetic tissues within canopy spaces, were used to measure the distribution of laser returns within the 0.3-m bins (i.e., a 30 × 30 × 0.3 m3 rectangular section) from the ground to canopy top [48,49]. In this study, a two-parameter Weibull density function (PDF) was used to describe CHD on each plot. As a Weibull model is highly adaptive, ranging from an inversed J-shape to unimodal skewed and unimodal symmetrical curve, the Weibull model has flexibility in characterizing distributions of a range of forest attributes [50,51]. The two parameters, i.e., Weibull scale (α1) and Weibull shape (β1), were derived by the maximum likelihood estimation method. Weibull scale determines the basic shape of the distribution density curve and Weibull shape controls the breadth of the distribution [52]. Foliage profile (FP) can delineate the vertical distribution of canopy phytoelement (e.g., leaf, stem, twig, etc.) density above the ground within a forest stand [37]. FP is defined as the total one-sided leaf area that is involved in photosynthesis per unit canopy volume at canopy height z, and describes changes in the leaf area distribution with increasing height [53]. FP is highly related to leaf area index (LAI), which was demonstrated in previous studies [35,54], and the relationship between FP and LAI is: 




L

(
z
)

=



∫


z
1




z
2





F
P

(
z
)

d
z


,





(1)


where L(z) is the cumulative leaf area index (LAIc) from the ground to a given height z; FP(z) represents the foliage area volume density at height z (is the vertical foliage profile in a thin layer or “slice” through a canopy as a function of height z); z1 and z2 are different canopy height. A height interval or each vertical “slice” was 0.3 m. Meanwhile, we assumed that foliage elements in a thin “slice” were very small so that occlusion can be neglected, and leaves presented Poisson random distribution. Because airborne LiDAR is incapable of resolving foliage angle distribution, clumping and non-foliage elements, the foliage profiles derived from airborne LiDAR are referred to here as “apparent” foliage profiles and effective LAI [37]. In this study, LAI can be indirectly determined from LiDAR by estimating the derived gap probability in the canopy [37,38], and the gap probability be estimated as the total number of laser hits up to a height z relative to the total number of LiDAR shots as follows:




L

(
z
)

=
−
l
n

(


P

g
a
p



(
z
)


)

=
−
l
n

(

1
−



(

#

z
j

|

z
j

>
z

)


N


)

,





(2)


where Pgap (z) is a gap probability measurement at height z, #z is the number of hits down to a height z above the ground, and N is the total number of shots emitted up to the sky. Previous studies have showed that Weibull distribution function can also delineate vertical foliage profiles distributions [37,55]. In this study, the Weibull fitted scale parameter (α2) and shape parameter (β2) were derived from the apparent FP by linking Weibull cumulative function to cumulative projected foliage area index [37,38]:




L
(
z
)
=
1
−

(


e

−



(



1
−
z
/

H

max





α
2




)




β
2






)

,





(3)


where α2 and β2 are fitted parameters, z is the height, and H is the maximum height in a plot.Moreover, another suite of standard metrics were calculated, including height-based (HD) metrics (h25, h50, h75, h95, hmean, hcv, hskewness and hkurtosis) and density-based (DB) metrics (d1, d3, d5, d7, d9, CC2m). A summary of these metrics with corresponding descriptions is shown in Table 2.", 2. Materials and Methods, 2.3.2. Weibull Fitting Approach,2
404,"All of the LiDAR metrics in Table 2 were used to analyze pair-wise relationships among different forest structural parameters (DBH, Lorey’s mean height, stem density, basal area, volume and AGB) by Pearson’s correlations (r). Then the metrics with low correlations (r < 0.2) were excluded and candidate metrics were used in the regression analysis. In the multiple regression analysis, all of the dependent variables and independent variables were transformed using the natural logarithm to improve linearity and corrected for bias using a bias correction factor (BCF) [56]. Some studies have applied log transformations to both dependent variables and independent variables for estimations of forest parameters [57,58]. Multiple regression models including forest type-specific (coniferous forest, broad-leaved forest, and mixed forest) models and general models of all plots were then established. Both stepwise variable selection and the maximum coefficient of determination (R2) improvement variable selection techniques were applied to select the metrics to be included in the models [59]. Independent variables were left in the model using an F-test with a p < 0.05 significance level. The standard least-squares method was used [60].To ensure that the independent variables were not highly correlated, multicollinearity was evaluated using Principal Component Analysis (PCA) based on the correlation matrix. Models with condition number (k) lower than 30 were accepted to ensure that there was no serious multicollinearity in the selected models [57]. The best fitting models were then selected based on the lowest Akaike information criterion value [61]. The accuracies of predictive models were evaluated using adjusted coefficient of determination (Adj-R2), Root-Mean-Square Error (RMSE), which has been transformed back to original scale, and relative RMSE (rRMSE), which are defined as the percentage of the ratio of RMSE and the observed mean values. In this study, dummy variables (or class variables) were added to the selected models as the dependent variables to assess whether these models differ between forest types [62]. Once the best models were chosen, leave-one-out cross-validation was performed to evaluate the predictive accuracies of the models [63].





Adj
-

R
2

=
1
−


n
−
1


n
−
p
−
1


(
1
−

R
2

)





(4)






R
M
S
E
=



1
n



∑

i
=
1

n




(

x
i

−


x
^

i

)

2










(5)






r
R
M
S
E
=


R
M
S
E


x
¯


×
100
%
,





(6)


where 



x
i



 is the observed value for plot i, 


x
¯


 is the observed mean value for plot i, 




x
^

i



 is the estimated value for plot i, n is the number of plots i, and p is the number of variables.", 2. Materials and Methods, 2.4. Metrics Selection and Statistical Analysis,2
405,"The plots of each forest type were stratified into three groups (low, medium, and high), according to the Lorey’s mean height from low to high. In each group, three plots were selected, and a total of nine typical plots were selected. For the typical plots, CVD, CVP and FP were extracted, as shown in Figure 5, Figure 6 and Figure 7. In addition, Figure 8 shows the mean LAIc for plots in different forest types and mean CVD.Figure 5 shows the spatial arrangements of four canopy structure classes for coniferous, broad-leaved, and mixed forest plots. Generally, Oligophotic zones were larger than euphotic zone in filled volume; coniferous forests had the largest open gap zone and the smallest closed gap zone, whereas broad-leaved forests plots had a larger and wider spread of closed gap zone than mixed forest. Similarly, the percentage of closed gap volume was larger in broad-leaved forests than in mixed forests, and the lowest percentage of closed gap volume was in coniferous forests (Figure 6). The mean CVPs (Figure 6d,h,l) show that the percentages of open gap volume were the highest in coniferous forests, and the differences were not significant between the percentages of open gap volume in broad-leaved forests and mixed forests. The percentages of filled volume in coniferous and mixed forests were significantly higher than in broad-leaved forest, and the differences for the percentage of filled volume between coniferous and mixed forest were not significant.Weibull models were fitted to canopy foliage distribution and matched the shape of foliage profile relatively well (Figure 7). In general, the FP profiles first exhibited a strong increasing trend, followed by a decreasing trend. Particularly, the peaks of FP in coniferous and mixed forests occurred in the lower or middle portions of the canopies whereas the peaks of broad-leaved forests were distributed more toward middle and upper portions of the canopies. Comparing with the mean foliage profiles and Weibull curves of three forest types, the curve showing the spatial distribution of FP values was smoother in broad-leaved forests than those of coniferous or mixed forests. The Weibull shapes of mixed forest canopy were slightly steeper than those of coniferous forest stands, indicating a wider spread of foliage within the canopy (Figure 7d,h,l). This same trend can be seen in the mean CHDs (Figure 8b–d).The mean LAIc values below the threshold of 12 m (approximately middle canopy) were relatively high for mixed forests, followed by coniferous forests and broad-leaved forests (Figure 8a). Above the tree height of 12 m, the increasing slope of the mean LAIc of the broad-leaved forests with increasing tree height was higher than that of coniferous forests, and maintained a relative high increasing trend, whereas the increasing trend of coniferous forests and mixed forests gradually tended to saturate. As a result, the mean LAIc value of broad-leaved forests was eventually higher than that of mixed forests, and lowest for coniferous forests.", 3. Results, 3.1. Profile Analysis,3
406,"The selected metrics and accuracy assessment results of all the multi-regression models (i.e., SM models, CM models, and combination models) are shown in Table A1, Table A2 and Table A3 and Table 3 summarizes their accuracies. All of the forest structural parameters were generally well estimated (Adj-R2 = 0.39–0.88, rRMSE = 5.13–29.86%). Overall, Lorey’s mean height (Adj-R2 = 0.61–0.88, rRMSE = 5.13–12.79%) and AGB (Adj-R2 = 0.54–0.81, rRMSE = 12.19–28.42%) was predicted most accurately. For volume, DBH and basal area, the R2 values were slightly lower and ranged from 0.42 to 0.78, 0.48 to 0.74 and 0.41 to 0.69, respectively. The lowest accuracy was found for stem density (Adj-R2 = 0.39–0.64, rRMSE = 18.68–29.86%). In comparison, most of forest structural parameters in type-specific models (Adj-R2 = 0.44–0.88, rRMSE = 5.13–28.42%) had higher accuracies than in general models (Adj-R2 = 0.39–0.77, rRMSE = 8.54–29.86%), indicating that the accuracies of forest type-specific models were generally improved rather than general models. Furthermore, the fitted models of the forest structural parameters were relatively more accurate for coniferous forests (Adj-R2 = 0.54–0.81, rRMSE = 8.59–26.55%) than broad-leaved forests (Adj-R2 = 0.50–0.88, rRMSE = 6.39–28.42%) and mixed forests (R2 = 0.44–0.84, rRMSE = 5.13–29.52%). Compared with canopy metrics based models (Adj-R2 = 0.39–0.83, rRMSE = 6.94–29.26%), standard metrics based models had a relatively higher performance (Adj-R2 = 0.42–0.84, rRMSE = 5.60–29.86%) and the combination models performed best (Adj-R2 = 0.45–0.88, rRMSE = 5.13–28.96%), indicating the inclusion of canopy metrics potentially improved the estimation performances of structural parameters.For all of the general SM models, the standard metrics that were regressed against for fitting models included most of the standard metrics, indicating those had a relatively strong correlation with forest structural parameters. Overall, h95 (selected by four out of six models), d7 (selected by four out of six models), d3, hcv and d9 (each of them was selected by three out of six models) were the most frequently selected, indicating these metrics are more sensitive and representative to the forest structural parameters. For general CM models, all of CV metrics and WF metrics were selected for estimating forest structural parameters. Within CV metrics, the statistic of Oligophotic (all selected by six models), Empty (selected by four out of six models) and Open (selected by four out of six models) were sensitive to forest structural parameters and these metrics were selected both in the general models and forest type-specific models, suggesting that the three metrics have a strong ability to explain variations. Within WF metrics, α1 was relatively sensitive to structural parameters (selected two out of six models). In six general combination models, most of standard metrics (nine out of 14) and canopy metrics (four out of total 10) were used in combination for parameter estimations. The metrics of Oligophotic, Empty, h95 remained sensitive to structural parameters (selected by 2–4 out of six general combo models). Moreover, h75, d1 and β1 (selected by 2–3 out of 6) became more sensitive for DBH, Lorey’s mean height, and stem density in combination models than SM models.Figure 9 shows the LiDAR estimated versus the field measured forest structural parameters as well as the results for cross-validation in all plots models based on standard metrics and canopy metrics. As indicated, Lorey’s mean height and AGB models were fitted best and resulted in R2 values of 0.79 and 0.66, followed by DBH (R2 = 0.60), volume (R2 = 0.60) and basal area (R2 = 0.52), whereas the accuracy of stem density model was the lowest (R2 = 0.49). For Lorey’s mean height, AGB, DBH, and volume estimations, their relationships were close to the 1:1 line whereas basal area and stem density had a relationship that deviated from the 1:1 line, with a slightly larger deviation in broad-leaved forests.", 3. Results, 3.2. Accuracy Assessments,3
407,"In this study, a sensitivity analysis was performed using different voxel sizes to derive CV metrics based on CVM approach and to quantify their influence on the results. As shown in Figure 10, a quantitative comparison of estimation accuracy for four main forest structural parameters (i.e., DBH, Lorey’s mean height, stem density, and basal area) was performed. In general, the R2 values of the models showed a trend of first increasing and then decreasing when horizontal resolutions of voxels were varied from 1 m to 10 m (Figure 10a,b), and the voxels in horizontal resolution of 5 m had the best performance. Figure 10a was subtracted from Figure 10b to calculate the result of Figure 10c, which demonstrated the difference of rRMSE values of forest structural parameters for various vertical resolutions (0.5 m and 1 m). The values presented were mostly positive, except for some of the differences were negative (e.g., G at 3 m horizontal resolution) (Figure 10c). In particular, DBH and stem density models had all positive values across 1 m to 10 m of horizontal resolutions, indicating the two parameters were strongly influenced by the vertical resolution of the voxels. As a result, the suitable voxel size in this study was 5 × 5 × 0.5 m3.", 3. Results, 3.3. The Selection of Voxel Sizes,3
408,"Canopy is an important constituent of forest structure [64], and canopy structure is critical for estimation of forest structural parameters [65]. Canopy vertical profile is one of the means to quantify and analyze complex forest canopy structure and further characterize the potential heterogeneity of forest spatial structure [66]. A wide range of forest structural parameters can be directly quantified from canopy vertical profiles such as canopy height and canopy vertical distribution [67]. Also, a set of forest structural parameters (aboveground biomass, basal area, volume, LAI, canopy cover, etc.) can be predicted by establishing empirical models from LiDAR data [68]. In this study, a voxel-based CVM and Weibull fitting approach were conducted to extract two key suites of metrics for estimating forest structural parameters and derive correlative canopy vertical profiles including CVD, CVP, CHD, FP, and LAIc. As mentioned above, the CVM approach provides a broad classification approach to categorize the canopy into photosynthetically active and less active zones [39]. Therefore, it can better reflect the spatial heterogeneity of forest structure, which is caused by the difference of light environment in the canopy. Furthermore, the CVP explicitly presented variation in the spatial arrangement of elements (i.e., open gap, euphotic, oligophotic, closed gap) within the vertical forest canopy [38]. As shown in Figure 5 and Figure 6, the broad-leaved forests had the largest closed gap volume and the smallest open gap volume when compared to coniferous forests and mixed forests. The explanations of these phenomena need to take into account the canopy geometry and tree architecture [36]. At our research site, coniferous forests are dominated by Masson pine and slash pine; these species usually consist of a regular and conical crown, demonstrating a heavily thinned upper canopy and a dense sub-canopy (Figure 3). Furthermore, more open upper canopies in coniferous stands allow more light to pass through to the lower canopy strata [69,70], so a shrubby understory may incrementally emerge, resulting in the most open gap and the lowest closed gap zones in coniferous forests. Conversely and notably, broadleaves with elliptical or spherical crown are very tall and have positively skewed canopies with a lower canopy transparency in this study area, as indicated by the large decrease in open gap zones. Additionally, the closed canopy volume generally increased with decreasing stand density [55], hence the broad-leaved forests with a lower stem density (1126.00 ha−1) also had a more closed canopy gap. Although with a much more shrubby understory, mixed conifer–broadleaf forests generally encompass median height broadleaved trees [65] with a high stem density (1431.78 ha−1) and canopy transparency, resulting in a higher amount of closed gap volume than coniferous forests and a slightly higher amount of open gap volume. On the other hand, as Yushan forest is in secondary succession, the forest canopy surface became more uneven, and the competitions among shade-intolerant species (e.g., Masson pine, Chinese sweet gum) were accelerated and further inhibited the establishment and growth of these species [71,72]. As a result, in late-successional stage, the shade-tolerant species (e.g., Oriental oak, camphorwood and Chinese holly) eventually dominated the canopy [69,72,73] and coexisted with other species. This process could cause the transmittance of light through the canopy to decline [74], which may result in an increase the spatial heterogeneity of the light environment [75,76] and a further enhancement of more microsite light availability in lower canopies [70,76,77,78,79]. Thus, for each forest type, the oligophotic zone, which represented a larger proportion of the total filled volume compared to the euphotic zone that represented photosynthetically active tissues (Figure 6). As mentioned above, the canopy architectures of the three forest types can help explain why the distributions of FP and CHD in coniferous forests and mixed forests inclined to the under canopy, whereas the curves of broad-leaved forests were distributed more towards the middle or upper canopy (Figure 7 and Figure 8b–d).In general, due to a thinner upper canopy and dense under canopy for each forest type, the mean LAI increased rapidly and shifted to an infinitesimal increment from the ground up to the top of the canopy (Figure 8a). Below the threshold of 12 m (approximately middle canopy), dense foliage accumulated in the lower canopy of mixed forests and coniferous forests but mixed forests had more understory shrubs and slightly denser canopies than coniferous forests whereas broad-leaved forest had less shrubbery; therefore, there was a dramatically increased LAIc in mixed forests, followed by coniferous forests and broad-leaved forests. Along with still moderate density of foliage near the upper canopy in broad-leaved forests as well as thinned density of foliage in mixed forests and coniferous forests, the mean LAIc increased trend remained relatively stable in broad-leaved forests compared to other forest types. Eventually, broad-leaved forests had the highest mean LAIc, followed by mixed forests and coniferous forests, which is consistent with the findings of previous studies [80,81].", 4. Discussion, 4.1. Canopy Vertical Profiles,4
409,"In comparison, the forest type-specific models had higher accuracies (Adj-R2 = 0.44–0.88, rRMSE = 5.13–28.42%) than the general models (Adj-R2 = 0.39–0.77, rRMSE = 8.54–29.86%). Bouvier et al. (2015) [14] developed a separate model for coniferous, deciduous and mixed stands to estimate forest structural parameters in the Lorraine forests. The results demonstrated that the separate models reduce estimation errors (2.0–5.3%) compared to general models in some complex forests conditions, which was confirmed by our research results. Fu et al. (2011) [82] reported R2 values for AGB of 0.37 of the general model and 0.43–0.68 of forest type-specific models in subtropical forests (located in southern Yunnan province, China). In our study site, the multi-layered forest conditions in subtropical forests contained greater species diversity, making the effects of tree-species composition (classified as forest types) significant. Overall, the models of the forest structural parameters were relatively more accurate for coniferous forests than broad-leaved forests and mixed forests. The relationships between stand structure and the forest structural parameters are species-dependent, and coniferous forests are usually characterized by relatively simple stand structures when compared with broad-leaved or mixed stands. So it is likely that the model prediction accuracy may decrease in multispecies stands [14]. Xu et al. (2015) [83] estimated forest structural parameters (i.e., Lorey’s mean height, stem density, basal area and volume) in the subtropical deciduous mixed forests (on Purple Mountain, located in eastern Nanjing), using canopy height metrics (i.e., height percentile, mean height, maximum height and minimal height) and canopy density metrics. Compared with our results (rRMSE = 5.13–22.28%), theirs showed a relatively lower rRMSE for Lorey’s mean height (6.47%), stem density (27.04%), basal area (16.38%), and volume (6.93%). Compared with canopy metrics-based models (Adj-R2 = 0.39–0.83, rRMSE = 6.94–29.26%), standard metrics-based models had relatively higher performance (Adj-R2 = 0.42–0.84, rRMSE = 5.60–29.86%), except for the volume and AGB (both in forest type-specific models). The combination models performed best (Adj-R2 = 0.45–0.88, rRMSE = 5.13–28.96%), explaining a large amount of the variability for all forest structural parameters and indicating the increased utility of canopy metrics in capturing spatially explicit information describing a heterogeneous forest structure. For DBH, stem density, basal area, and AGB, Lefsky et al. (1999) [36] reported adjusted R2 values of 0.61, 0.52, 0.87, and 0.91 in boreal forests, markedly higher than reported in this study. The cause of the lower performance in this research is likely the complex structure of the subtropical forests, which are typified by multi-layered forests which that encompass some stands with considerable variability in tree height and stem density, especially in old-growth stands, whereas boreal forests have a much higher homogeneous composition and more discernible canopy architecture.When considering the selected frequency of metrics in the fitted models, for CV metrics, Oligophotic, Empty metrics were mostly selected by the combination models. This may be explained by the higher proportions of canopy elements (Figure 5 and Figure 6), which were oligophotic, empty volume zones, revealing the strong sensitivity and representativeness of these two metrics to local forest structures. Previous studies [38,84] found that the Weibull scale and shape parameter were related to canopy attributes (e.g., crown depth and crown length), hence two Weibull parameters were both selected by the CM models of structural parameters (e.g., mean diameter, Lorey’s mean height, basal area, and volume models) linked to canopy attributes. In combination models, the most selected WF metrics were α1 and β1, indicating that both of them are suitable for estimating structure parameters in local forests. The capacity of the Weibull parameters to represent the key attributes of mean crown dimension is important, as it provides a mechanism to summarize complex canopy characteristics into simple parameters that can be empirically analyzed in relation to various forest stand characteristics. The two-parameter Weibull model was applied for characterizing many types of FPs and CHDs in this study. In general, these profiles of single layer canopies corresponded well (Figure 7). However, the unimodal Weibull distribution function applied to the profile is inadequate to describe properly multimodal structure, which may occur in multi-layered, multi-age, complex forest stands [52]. Thus, the relatively poor fit for multi-layered forests could result in errors in estimates of structural parameters, which may explain why the Weibull parameters are not statistically more significant predictors than CV metrics. In this regard, future work could focus on how to apply a multi curve fitting approach in order to further capture the full distributions of canopy vertical profiles. On the other hand, different plot selection strategies could influence the performance of predictive models [85]. The plot selection in this study was only according to forest type, thus our future work could also examine different plot selection strategies of field training plots (e.g., using LiDAR data or geographical factors as a prior information, etc.) and utilize a suitable strategy to improve the estimation accuracy of forest structural parameters.", 4. Discussion, 4.2. Predictive Models,4
410,"Voxels representing canopy elements such as trunks and branches were abstracted by a volume grid and placed in a 3D grid [86]. As a method of volume visualization of LiDAR points, voxels have already been applied to airborne LiDAR data for improving calculations of forest attributes [87,88]. Voxel size is a key parameter pertaining to the scale of forest structural parameter estimates to the physical dimension of canopy components [89]. Thus, a sensitivity analysis was conducted to investigate the influence of various voxel sizes on forest structural estimations. As shown in Figure 10, in very low (i.e., 1 × 1 × 0.5 m3) or high (i.e., 10 × 10 × 1 m3) resolution conditions, the R2 values showed a relatively lower performance. If voxels are too small, a voxel-based CVM approach may produce redundant unfilled voxels of empty volume containing few tree canopy elements, which may lead to the underestimation of forest structural parameters; however, too large voxels may lead to too few voxels and result in statistically insignificant descriptions of canopy features [90]. In these conditions, the voxel approach could become ineffective at characterizing the vertical distribution of various canopy structures and the capability to capture 3D heterogeneity of canopy structure for CV metrics could be constrained, hence resulting in relatively lower performances of the models. After taking into account factors of plot size (30 × 30 m2), point cloud densities (3.74 pts·m−2), etc., Hilker et al. (2010) [39] used a voxel size of 6 × 6 × 1 m3 for discrete airborne LiDAR data to estimate the tree height and LAI in Douglas-fir-dominated forest stands with relatively high tree heights (30–35 m). Concerning a much higher point cloud density (5.06 pts·m−2) of LiDAR data and relatively lower tree heights (4.47–18.52 m) in this study site, a 1 m vertical resolution produced more coarse data than the vertical resolution of 0.5 m (approximately treble the temporal sample spacing of 1 ns (15 cm)), thus, constraining the ability of canopy volume metrics to describe the vertical variability of the forest canopy structures. Moreover, potential tree movement due to wind between laser acquisitions is also considered a source of uncertainty, as laser returns from the same target can be located in different voxels for different laser acquisitions. By using a voxel size larger than the pulse diameter, this issue can be slightly reduced [91]. Overall, the optimal voxel size is a key parameter to determine in order to improve characterizations of forest structure [92,93]. Consequently, the optimal voxel spatial resolution should be determined based on plot size, the characteristics of the LiDAR instrument used (e.g., beam diameter, footprint size, average point density and temporal sample spacing, etc.), and forest structure attributes (e.g., tree height, crown diameter, crown depth, etc.)", 4. Discussion, 4.3. The Selection of Voxel Sizes,4
411,"In this study, a set of canopy metrics derived from canopy vertical profiles, which has the potential to aid in our understanding of the physical characteristics of forest structure, was extracted. The capability of the standard metrics (extracted from the point cloud data) and canopy metrics for estimating forest structural parameters (i.e., DBH, Lorey’s mean height, stem density, basal area, volume, and AGB) was assessed, individually and in combination, over a subtropical forest in southeastern China. Moreover, a sensitive analysis of different voxel sizes was performed to investigate the optimal voxel size for estimating forest structural parameters.The results demonstrated that the forest type-specific models had relatively higher accuracies (Adj-R2 = 0.44–0.88, rRMSE = 5.13–28.42%) compared with the general models (Adj-R2 = 0.39–0.77, rRMSE = 8.54–29.86%). The estimation accuracies of Lorey’s mean height and AGB were the highest, followed by volume, DBH and basal area, whereas stem density was relatively lower. Overall, metrics of Oligophotic, Empty, Open, α1 were the most frequently selected, indicating their potential capability for predicting forest structural parameters in the forest stands within the study site. The results demonstrated the synergistic use of standard metrics and canopy metrics for better predicting forest structural parameters (∆Adj-R2 = 0.01–0.20, ∆rRMSE = −5.71–1.39%), compared with models developed using standard metrics (only) and canopy metrics (only). In addition, the optimal voxel size for estimating forest structural parameters in this study is 5 × 5 × 0.5 m3, and the voxel vertical and horizontal resolutions should be determined based on plot size, the characteristics of the acquired LiDAR data (i.e., beam diameter, footprint size, average point density, and temporal sample spacing) and forest structure attributes (i.e., tree height, crown diameter, and crown depth).", 5. Conclusions,None,5
412,"As an important part of the Earth’s biosphere, forests are a key factor in maintaining the global ecological balance by serving as carbon sources and sinks and removing carbon dioxide (CO2) through Biomass Energy with Carbon Capture and Storage (BECCS) [1,2,3]. Moreover, forests also provide material resources for human survival and development and ecosystem services for local people. According to the current land use classification of China [4,5], forestland refers to land covered with trees, bamboo, shrubs, and coastal mangrove forests. Spatial changes in forestland, such as an increase or decrease in area and the replacement of types, can have great impacts on ecology and human society [6]. Therefore, accurate forestland resource statistics have great realistic and strategic significance [3].Forest resource inventories are traditionally conducted via ground surveys at a high level of detail for relatively small areas. The advantage of this method is that the field data are detailed and accurate [7]. However, the long field survey time means that information is slow to be updated and thus may not reflect the rapid changes caused by development. Additionally, the inconsistent timing of field surveys in different regions of China affects the comparability of data. Therefore, researchers have introduced remote sensing data into forestland statistics due to their high spatial-temporal resolution; however, remote sensing techniques yield the projected area (two-dimensional area, 2D area) instead of the real undulating surface area (three-dimensional area, 3D area), which is an important basic indicator of forestland area [8,9,10,11,12]. Forestland is mainly present in areas with complex topography and large topographic relief in China. Consequently, calculations without height data will cause large bias in subsequent research, such as biomass and carbon sinks [12,13,14,15,16,17]. To solve this problem, it is a feasible way to accurately estimate forestland surface area by overlaying remote sensing and digital elevation model (DEM) data and using algorithms to simulate the area of elements along the surface of the earth based on the actual relief amplitude [17,18,19].Researchers have performed a number of important studies regrading this problem. Some studies have calculated the surface area by combining the slope secant with grid data, which uses each grid of the remote sensing data as a calculation unit, and calculating the secant of the angle of this inclined unit; the surface area of this unit is the product of its secant and its projected area, and the total surface area is the sum of each unit’s surface area [12,20,21,22,23,24]. Additionally, differential methods based on numerical integration are used to approximate the surface. This approximation is generally achieved by constructing the area microelements, which are generally determined by the four vertex positions and the polygonal relationship of the grid data. In this process, the position relationship between the polygon boundary and the grid is frequently determined. There are many decision loops in the determination algorithm that affect the efficiency of the surface area calculation [25,26]. Other scholars have used the relationship between the surface area and ellipsoids to study the surface fitting method [27,28,29,30,31], which mainly employs triangular fitting, using spatial triangulation to fit the topographic relief [1,32,33,34,35]. According to the different methods of dealing with discrete points, triangulation algorithms can be classified into three categories: a growth algorithm that is easy to implement but inefficient [36,37,38,39]; a divide-and-conquer algorithm that has the highest efficiency but frequently calls recursively; and a point-by-point insertion algorithm with a simple process and a small memory requirement [35,40,41,42,43,44,45,46,47]. In addition, most of these studies focus on a single method, and no cross comparison of the advantages and disadvantages of these methods or discussion of the scope of their applications is available. Many studies are concentrated on small ranges, which have limited data and low accuracy [12,19,24,25]. Furthermore, surface area calculation often requires massive computation. When the region of interest is expanded, the surface structure becomes more complex; topographic factors, such as the slope and undulation, change more dramatically; and the data volume increases geometrically. For large-scale applications, the calculation accuracy and efficiency of existing studies cannot handle the complex situations presented by high-precision data with large volumes and cannot meet the application needs.In this study, we attempted to solve these problems based on the above studies. Considering the complex terrain environment, forest fragmentation distribution characteristics, and objective realities of large amounts of data, we overlay DEM data with remote sensing data, use the mean change point and system clustering analysis methods to partition the national-scale region, identify suitable surface area algorithms for every type of geomorphic area, define geomorphic dominance and combine it with a surface area calculation algorithm, and select the appropriate combination for every region. Highly efficient, accurate statistics for forestland areas are obtained, thus providing a theoretical basis for more reasonable carbon emission statistics and climate change research.", 1. Introduction,None,1.
413,"Three types of data are used in this study: Shuttle Radar Topography Mission (SRTM) data, remote sensing interpretation data (Chinese GlobeLand30), and national basic geographic information. Shuttle Radar Topography Mission data are available from the United States Geological Survey (USGS) website (https://earthexplorer.usgs.gov/), which is an international research effort that provides land elevation data for over 80% of the globe. The effort was conducted by the US National Aeronautics and Space Administration (NASA) and the US National Geospatial-Intelligence Agency (NGA). The SRTM 1 Arc-Second Global used in this study provides high-precision terrain grid data with voids filled. Its horizontal datum is WGS84, vertical datum is EGM96, and spatial resolution is 1 arc-second (approximately 30 m) [36].The Chinese GlobalLand30 datasets are high-resolution maps of the Earth’s land cover, including forests and nine other types [37]. The data were extracted from multispectral images with a resolution of 30 m, including the US Earth-observing Landsat satellite sensors, Landsat 5 Thematic Mapper (TM), and Landsat 7 Enhanced Thematic Mapper Plus (ETM+) [38], China’s Environmental Disaster Alleviation Satellite (HJ-1), and a large amount of auxiliary data. GlobalLand30 used a hierarchic method for image classification; the classification scheme of forest is land with greater than 30% vegetation cover, including deciduous and coniferous forests and sparse woodland with 10–30% cover. Its reference ellipsoid is the WGS84 ellipsoid, and the data adopt the UTM projection, the WGS84 coordinate system, and 6-degree zoning. A rule-based workflow and multisource integration were conducted before publication to ensure the quality and consistency of the data. The comprehensive accuracy of the forest data was 89% [38].The national basic geographic information data were obtained from the National Geomatics Center of China (NGCC), which is a government agency that fulfills missions to construct, manage, and distribute national fundamental geo-information data and archives, including national borders, provincial boundaries, and major highways.", 2. Materials and Methods , 2.1. Data Sources,2
414,"We established an integrated multiscale method of calculating forestland area via the optimum combination of geomorphic regionalization and surface area calculation methods; thus, the forestland area of China was calculated. The technical route is shown in Figure 1.", 2. Materials and Methods , 2.2. Research Concepts and Technical Routes,2
415,"Geomorphic regionalization divides a region into different sub-regions according to the similarities and differences of the geomorphic areas based on the principles of relative consistency and geomorphic integrity. Geomorphic aspects mainly include elevation, relief amplitude, etc. The relief amplitude is an important index for quantitatively describing the geomorphology and for classifying geomorphic types [39,40]. This parameter represents the height difference between the highest and lowest points in a certain area. Therefore, relief amplitude is the most relevant to this study, and we selected it as the index for division and used the system clustering analysis method, which combined bottom-up clustering and top-down division (Figure 2), to determine every geomorphic area and the associated boundaries and achieve geomorphic regionalization of large areas. 2.3.1. Relief Amplitude Algorithm“Determined area” is the optimal statistical unit of relief amplitude. The study shows that the topographic relief changes with the area in a logarithmic curve [41,42], and thus the optimal statistical unit is the curve mutation point at which the curve changes from steep to shallow. For this purpose, we introduce the statistical mean change point analysis method by increasing the window used to calculate the relief to obtain that point. The calculation process is as follows:With sample sequence H0, perform the following task:Set i = 2 ... n; for each i, the sample is divided into two sections: X1, X2 ... Xi-1 and Xi, Xi+1 ... Xn. Calculate the arithmetic mean and statistic Si for each sample.





S
i

=


∑


t
=
1


i
−
1




(

X
t

−



X

i
1



¯

)

2

+


∑


t
=
1

N



(

X
t

−



X

i
2



¯

)

2





(1)

Compute statistic S for the original sample.





X
¯

=


∑


t
=
1

N


X
t

/
N




(2)





S
=


∑


t
=
i

N



(

X
t

−

X
¯

)

2





(3)

Calculate the expectation.




E

(

S
−

S
i


)

,
i
=
2
,
3
,
·
·
·
,
N




(4)

The greatest difference between S and Si is the change point, which is the optimal statistical unit in this study.Then, DEM data are traversed in the optimal statistical unit to obtain relief amplitude data. 2.3.2. System Clustering Division MethodConsidering that regionalization takes into account the overall topography and the distribution continuity simultaneously, ""top-down"" division and ""bottom-up"" clustering are commonly used in research. The former operates from the whole region to the unit, and the latter operates from the unit to the whole region [43]. According to the characteristics of area measurement and the precision evaluation requirement, we use the two methods in coordination as follows: first, the region is divided from top to bottom based on the provincial administrative boundaries; and second, the basic geomorphic units in every region are clustered with the iterative clustering algorithm. To ensure geomorphic integrity, the clustering results are manually adjusted, and the boundaries are checked to ensure that each region is a convex polygon and the boundary is complete without broken line segments.We quantified the classification standard of geomorphic type according to the digital landform mapping specification. It is divided into seven levels according to the terrain undulation: plain (<30 m), mesa (30~70 m), hills (70~200 m), low relief amplitude mountain (LRAM) (200~500 m), medial amplitude mountain (MAM) (500~1000 m), high amplitude mountain (HAM) (1000~2500 m), and higher amplitude mountain (HerAM) (>2500 m). The code (GeoID) ranges from 1–7. At the same time, the geomorphic dominance (GeoDominance) is defined for subsequent area calculation. The region’s GeoDominance of a certain geomorphology is the area proportion of that geomorphology in the region. The area proportion is calculated by the projected area to avoid the impact of relief amplitude, and the formula is as follows:



GeoDominance
=




region
′

s
 
projected
 
area
 
of
 
certain
 
geomorphic





region
′

s
 
projected
 
area
 



×
100
%
,




(5)

", 2. Materials and Methods , 2.3. Geomorphic Regionalization,2
416,"“Determined area” is the optimal statistical unit of relief amplitude. The study shows that the topographic relief changes with the area in a logarithmic curve [41,42], and thus the optimal statistical unit is the curve mutation point at which the curve changes from steep to shallow. For this purpose, we introduce the statistical mean change point analysis method by increasing the window used to calculate the relief to obtain that point. The calculation process is as follows:With sample sequence H0, perform the following task:Set i = 2 ... n; for each i, the sample is divided into two sections: X1, X2 ... Xi-1 and Xi, Xi+1 ... Xn. Calculate the arithmetic mean and statistic Si for each sample.





S
i

=


∑


t
=
1


i
−
1




(

X
t

−



X

i
1



¯

)

2

+


∑


t
=
1

N



(

X
t

−



X

i
2



¯

)

2





(1)

Compute statistic S for the original sample.





X
¯

=


∑


t
=
1

N


X
t

/
N




(2)





S
=


∑


t
=
i

N



(

X
t

−

X
¯

)

2





(3)

Calculate the expectation.




E

(

S
−

S
i


)

,
i
=
2
,
3
,
·
·
·
,
N




(4)

The greatest difference between S and Si is the change point, which is the optimal statistical unit in this study.Then, DEM data are traversed in the optimal statistical unit to obtain relief amplitude data.", 2. Materials and Methods , 2.3.1. Relief Amplitude Algorithm,2
417,"Considering that regionalization takes into account the overall topography and the distribution continuity simultaneously, ""top-down"" division and ""bottom-up"" clustering are commonly used in research. The former operates from the whole region to the unit, and the latter operates from the unit to the whole region [43]. According to the characteristics of area measurement and the precision evaluation requirement, we use the two methods in coordination as follows: first, the region is divided from top to bottom based on the provincial administrative boundaries; and second, the basic geomorphic units in every region are clustered with the iterative clustering algorithm. To ensure geomorphic integrity, the clustering results are manually adjusted, and the boundaries are checked to ensure that each region is a convex polygon and the boundary is complete without broken line segments.We quantified the classification standard of geomorphic type according to the digital landform mapping specification. It is divided into seven levels according to the terrain undulation: plain (<30 m), mesa (30~70 m), hills (70~200 m), low relief amplitude mountain (LRAM) (200~500 m), medial amplitude mountain (MAM) (500~1000 m), high amplitude mountain (HAM) (1000~2500 m), and higher amplitude mountain (HerAM) (>2500 m). The code (GeoID) ranges from 1–7. At the same time, the geomorphic dominance (GeoDominance) is defined for subsequent area calculation. The region’s GeoDominance of a certain geomorphology is the area proportion of that geomorphology in the region. The area proportion is calculated by the projected area to avoid the impact of relief amplitude, and the formula is as follows:



GeoDominance
=




region
′

s
 
projected
 
area
 
of
 
certain
 
geomorphic





region
′

s
 
projected
 
area
 



×
100
%
,




(5)

", 2. Materials and Methods , 2.3.2. System Clustering Division Method,2
418," 2.4.1. Slope-Based Calculation AlgorithmThis algorithm calculates the surface area by using each grid as a calculation unit and treats it as an inclined surface to calculate the surface area from its slope. The relationship between the surface area and the projection area is as follows:




S
1

=



S
2




cos
A



=

S
2

×

sec
A

,




(6)

where S1 is the surface area, S2 is the projected area, A is the angle of the slope, and cosA and secA are the cosine and secant of A, respectively. The following formula is used to calculate the secant value of the slope (A) in Equation (6).





sec
A

=
1
/
cos


A
×
3.1415926


180


,




(7)

Using the window differential analysis method to traverse the DEM [24], the slope (A) of the window center point is calculated as follows:



slope
=
arctan




(



(


e
8

+
2

e
1

+

e
5


)

−

(


e
7

+
2

e
3

+

e
6


)



8
×
c
e
l
l
s
i
z
e


)

2

+


(



(


e
7

+
2

e
4

+

e
8


)

−

(


e
6

+
2

e
2

+

e
5


)



8
×
c
e
l
l
s
i
z
e


)

2



,




(8)

The two squared values are the slopes in the x- and y-directions, respectively. If the center point has no data, the slope value of this grid should be set as null. Any adjacent point with no data will be assigned the value of the central point.The projected area obtained from the raster data and the computed secant values are substituted into Equation (6) to obtain the surface area. 2.4.2. Triangular Irregular Network (TIN)-Based Calculation AlgorithmThe TIN algorithm uses spatial triangulation to fit the undulating ground surface and achieves a three-dimensional visualization of the surface details. The sum of the triangle area can be approximately regarded as the surface area [44]. Considering the massive amount of data in this study, we improve the point-by-point insertion algorithm by instituting a directional search and locating the insertion points based on topological relationships followed by a check of the elevation of the insertion points. If two triangles have the same elevation value, they are considered to be in the same plain and are merged into one triangle.After the triangular network is completed, the surface area is the sum of the triangle areas in the network [45]. The area of each triangle is obtained by Heron′s formula (Formula (9)).




S
=


p

(

p
−
a

)


(

p
−
b

)


(

p
−
c

)



,




(9)


where variables a, b, c are the three sides of the triangle and calculated by the vertex elevation, and p is half of the triangle’s circumference. A triangular network has a strong graphic structure and can fit well in regions with undulating terrain. 2.4.3. Simpson-Based Calculation AlgorithmThis method assumes that the surface is composed of several smooth curved surfaces and uses the projection area and integral surface to calculate the surface area (Figure 3).By referring to the calculation method of the polygon ellipsoid area, we modify the original two-dimensional composite Simpson formula (Formula (10)) to three dimensions by two-layer approximation.




S
=


∫

a
b

f

(
x
)

d
x
=


b
−
a

6


[

f

(
a
)

+
f

(



a
+
b

2


)

f

(
b
)


]

,




(10)

(1) The first layer: approximation of the length of the curve:Let f(x) be a secant value representing the angle between the vector in the upward direction of the x-point and the unit vector in the positive direction of the x-axis.The length of the curve is determined as follows:



F

(
x
)

=
 


∫



x
0




x
n



f

(
x
)

d
x




(11)

From Simpson′s formula, the following equation can be deduced:





∫



x
0




x
2



f

(
x
)

d
x
=
 



x
1

−

x
0


6


(

f

(


x
0


)

+
4
f

(


x
1


)

+
f

(


x
2


)


)





(12)







F

(
x
)



=

1
2

(


w
i
d
t
h

6


(

f

(


x
0


)

+
4
f

(


x
1


)

+
f

(


x
2


)


)

+


w
i
d
t
h

6


(

f

(


x
1


)

+
4
f

(


x
2


)

+
f

(


x
3


)


)

+
…





+


w
i
d
t
h

6


(

f

(


x

n
−
2



)

+
4
f

(


x

n
−
1



)

+
f

(


x
n


)


)

)






(13)

Parameter F(x) is determined as follows:



F

(
x
)

=
 


w
i
d
t
h


12



(

f

(


x
0


)

+
f

(


x
n


)

+
5


∑


i
=
1


n
−
1


f

(


x
i


)


)





(14)


where




f

(


x
i


)

=

{










(

h

(


x
1


)

−
h

(


x
0


)


)


2

+
w
i
d
t

h
2



,
 
x
=
0











(

h

(


x
i


)

−
h

(


x

i
−
1



)


)


2

+
w
i
d
t

h
2



,
 
x
>
0
 










(15)

h(xi) is the elevation value at the xi point, and width is the width in the x-direction.(2) The second layer: approximation of the area:The result of the previous step is that F(y) is a function representing the length of the curve at the y point.The surface area can be expressed as follows:



G

(
y
)

=
 


∫



y
0




y
n



F

(
y
)

d
y




(16)

Similar to the length approximation derivation process, the following equation can be deduced:



G

(
x
)

=
 


h
e
i
g
h
t


12



(

F

(


y
0


)

+
F

(


y
m


)

+
5


∑


j
=
1


m
−
1


F

(


y
j


)


)





(17)

where height is the width in the y-direction of the grid.", 2. Materials and Methods , 2.4. Surface Area Calculation Algorithm,2
419,"This algorithm calculates the surface area by using each grid as a calculation unit and treats it as an inclined surface to calculate the surface area from its slope. The relationship between the surface area and the projection area is as follows:




S
1

=



S
2




cos
A



=

S
2

×

sec
A

,




(6)

where S1 is the surface area, S2 is the projected area, A is the angle of the slope, and cosA and secA are the cosine and secant of A, respectively. The following formula is used to calculate the secant value of the slope (A) in Equation (6).





sec
A

=
1
/
cos


A
×
3.1415926


180


,




(7)

Using the window differential analysis method to traverse the DEM [24], the slope (A) of the window center point is calculated as follows:



slope
=
arctan




(



(


e
8

+
2

e
1

+

e
5


)

−

(


e
7

+
2

e
3

+

e
6


)



8
×
c
e
l
l
s
i
z
e


)

2

+


(



(


e
7

+
2

e
4

+

e
8


)

−

(


e
6

+
2

e
2

+

e
5


)



8
×
c
e
l
l
s
i
z
e


)

2



,




(8)

The two squared values are the slopes in the x- and y-directions, respectively. If the center point has no data, the slope value of this grid should be set as null. Any adjacent point with no data will be assigned the value of the central point.The projected area obtained from the raster data and the computed secant values are substituted into Equation (6) to obtain the surface area.", 2. Materials and Methods , 2.4.1. Slope-Based Calculation Algorithm,2
420,"The TIN algorithm uses spatial triangulation to fit the undulating ground surface and achieves a three-dimensional visualization of the surface details. The sum of the triangle area can be approximately regarded as the surface area [44]. Considering the massive amount of data in this study, we improve the point-by-point insertion algorithm by instituting a directional search and locating the insertion points based on topological relationships followed by a check of the elevation of the insertion points. If two triangles have the same elevation value, they are considered to be in the same plain and are merged into one triangle.After the triangular network is completed, the surface area is the sum of the triangle areas in the network [45]. The area of each triangle is obtained by Heron′s formula (Formula (9)).




S
=


p

(

p
−
a

)


(

p
−
b

)


(

p
−
c

)



,




(9)


where variables a, b, c are the three sides of the triangle and calculated by the vertex elevation, and p is half of the triangle’s circumference. A triangular network has a strong graphic structure and can fit well in regions with undulating terrain.", 2. Materials and Methods , 2.4.2. Triangular Irregular Network (TIN)-Based Calculation Algorithm,2
421,"This method assumes that the surface is composed of several smooth curved surfaces and uses the projection area and integral surface to calculate the surface area (Figure 3).By referring to the calculation method of the polygon ellipsoid area, we modify the original two-dimensional composite Simpson formula (Formula (10)) to three dimensions by two-layer approximation.




S
=


∫

a
b

f

(
x
)

d
x
=


b
−
a

6


[

f

(
a
)

+
f

(



a
+
b

2


)

f

(
b
)


]

,




(10)

(1) The first layer: approximation of the length of the curve:Let f(x) be a secant value representing the angle between the vector in the upward direction of the x-point and the unit vector in the positive direction of the x-axis.The length of the curve is determined as follows:



F

(
x
)

=
 


∫



x
0




x
n



f

(
x
)

d
x




(11)

From Simpson′s formula, the following equation can be deduced:





∫



x
0




x
2



f

(
x
)

d
x
=
 



x
1

−

x
0


6


(

f

(


x
0


)

+
4
f

(


x
1


)

+
f

(


x
2


)


)





(12)







F

(
x
)



=

1
2

(


w
i
d
t
h

6


(

f

(


x
0


)

+
4
f

(


x
1


)

+
f

(


x
2


)


)

+


w
i
d
t
h

6


(

f

(


x
1


)

+
4
f

(


x
2


)

+
f

(


x
3


)


)

+
…





+


w
i
d
t
h

6


(

f

(


x

n
−
2



)

+
4
f

(


x

n
−
1



)

+
f

(


x
n


)


)

)






(13)

Parameter F(x) is determined as follows:



F

(
x
)

=
 


w
i
d
t
h


12



(

f

(


x
0


)

+
f

(


x
n


)

+
5


∑


i
=
1


n
−
1


f

(


x
i


)


)





(14)


where




f

(


x
i


)

=

{










(

h

(


x
1


)

−
h

(


x
0


)


)


2

+
w
i
d
t

h
2



,
 
x
=
0











(

h

(


x
i


)

−
h

(


x

i
−
1



)


)


2

+
w
i
d
t

h
2



,
 
x
>
0
 










(15)

h(xi) is the elevation value at the xi point, and width is the width in the x-direction.(2) The second layer: approximation of the area:The result of the previous step is that F(y) is a function representing the length of the curve at the y point.The surface area can be expressed as follows:



G

(
y
)

=
 


∫



y
0




y
n



F

(
y
)

d
y




(16)

Similar to the length approximation derivation process, the following equation can be deduced:



G

(
x
)

=
 


h
e
i
g
h
t


12



(

F

(


y
0


)

+
F

(


y
m


)

+
5


∑


j
=
1


m
−
1


F

(


y
j


)


)





(17)

where height is the width in the y-direction of the grid.", 2. Materials and Methods , 2.4.3. Simpson-Based Calculation Algorithm,2
422,"First, the above surface area algorithms are implemented in one program using the language Python; second, they are applied to typical regions of all geomorphic types and an error analysis is carried out on the calculated results to obtain the optimal combination of surface area algorithms suitable for each geomorphic type.After the above preparations, a kit method that divides the study area into geomorphic regions is used to calculate the surface area by calling the corresponding surface area algorithms according to the region’s geomorphic types. The results are weighted by the dominance of each geomorphic type. The sum of each region’s area is the surface area of the study area.", 2. Materials and Methods , 2.5. Integrated Multiscale Method for the Surface Area Calculation,2
423,"The core of this study is the identification of suitable surface area algorithms for different geomorphic types. For this reason, we selected 210 areas from the typical distribution areas of seven geomorphic types as test areas and 30 areas for each geomorphic type, and the projected area of each test area was approximately 1000 km2. The surface area calculation of each test area was carried out using the three methods presented in Section 2.4. The suitable surface area algorithms were obtained through comparison. The location of each test area is shown in Figure 4.For each test area, a DEM with a resolution of 5 m was generated with contour lines, and the contour interval was 5 m. For the 5 m and 30 m DEMs, all three surface area algorithms were used in the calculations, and the average value of the 5 m DEM was taken as the reference value for the true surface area value. Then, these results were compared with the results from the 30 m DEM, and the absolute and relative errors were calculated. The best surface area algorithm was selected based on the relative error distribution of every geomorphology (Table 1). MinError means that this algorithm had a minimum relative error among the three algorithms, and MinDifference means that the algorithm had a minimum difference with the algorithm of minimum relative error.Generally, the algorithm with the smallest relative error (MinError) was selected. However, in some geomorphic areas, the relative error between two algorithms was similar (with a difference <0.5%), and their differences from other algorithms were large; thus, the mean values of these two algorithms were selected to reduce the random error caused by the samples. The results show that the TIN-based algorithm performs better in areas with large relief and continuous changes, the Simpson-based algorithm is efficient and accurate in mesa areas, and the slope-based algorithm performs better than the first two methods in areas with gentle rolling topography and accurately depicts the topographic details in areas with small relief.Based on the above conclusions, a suitable surface area algorithm was selected for the seven types of geomorphic areas (Table 2).", 3. Data Processing , 3.1. Appropriate Surface Area Algorithm Selection,3
424,"By dividing the national area to obtain the distribution of geomorphic types, we can perform area calculations on the basis of the methods presented below, i.e., Section 3.1. For the convenience of subsequent comparative analysis with statistical data, the top-down division of the national DEM was first carried out according to provincial boundaries. The regions of Hong Kong and Macao are too small to include in the division. Then, the regions were traversed sequentially to calculate the average value of relief amplitude by increasing the rectangular window. The logarithm of the results was taken to establish the sample sequence X (X = {Xi, i = 1, 2, 3 ... 29}). The values of the statistics S and Si of sample series X and the differences between them were calculated. The corresponding window at the maximum difference value was the optimal statistical unit to extract the terrain undulation. The DEM data of each province (excluding Hong Kong, Macao, and the sea area) were traversed at this unit to obtain the relief amplitude data. Using the above classification index to classify the relief degree, Iterative Self-Organizing (ISO) unsupervised clustering was conducted to obtain the national geomorphic distribution.Based on the China Geomorphic Regionalization System [43], the clustering results were adjusted manually. The main principles are that the dominance degree of the main geomorphic types in the region should be greater than 50% and the area should not be less than 9000 km2. Finally, 119 geomorphic sub-regions are obtained, and they are overlain on the national DEM and clipped to obtain the national geomorphic regions (excluding Hong Kong, Macao, and sea areas).For the geomorphic attribution of each region (DivID), GeoDominance was taken as a criterion for judging, and the DivID was the geomorphic type with the highest value. The regionalization distribution is shown in Figure 5. The geomorphic type (GeoID) and GeoDominance information in the area were stored in the region’s attribute table for subsequent calculations.", 3. Data Processing , 3.2. National Geomorphic Regionalization,3
425,The data on forestland cover were extracted from GlobeLand30-2010 data [38]. The DEM data for China were clipped based on the forestland data to obtain the forestland DEM data for the whole country (Figure 6)., 3. Data Processing , 3.3. National Forestland DEM Acquisition,3
426,"The arcpy package is imported into the aforementioned Python program to process the DEM data. Based on Table 3, GeoID is used to call the area algorithm and to embed it in the Python program.Since DivID ignores geomorphic areas with small proportions, such as MAM/HAM/HerAM, and because the area algorithms differ among different geomorphic types, we use multiple GeoIDs for each region to call the corresponding area surface algorithms and sum the calculation results weighted by the GeoDominance to reduce the error. The result of the summation is the national forestland surface area. ", 3. Data Processing , 3.4. Forestland Surface Area Calculation,3
427,"A certain area in Western China was selected as the verification area; its elevation range is 1,354~5,931 m with a standard deviation of 792.14 m (Figure 7). The 5-m DEM was generated with 1:50,000 contour lines of this area, and the surface area calculation results were used as the reference value to evaluate the accuracy of the surface area calculation based on the SRTM DEM. The absolute and relative errors were 24.4 km2 and 0.46%, respectively (Table 3). Therefore, the calculation method used for the surface area calculation in this paper has high accuracy.", 4. Results and Discussion, 4.1. Accuracy Evaluation of the Surface Area Integrated Multiscale Method,4
428,"To verify that the surface area integrated multiscale method is superior to the traditional algorithm in terms of the area calculation accuracy, this paper referred to the example areas of Wang Xiuyun [24], Yuan Weiping [46], and Zeng Zhen [18] (Figure 8) and used the original method and the integrated multiscale method to calculate the surface areas of these regions. The original method used in the study of Xiuyun and Zeng Zhen was a slope-based algorithm based on the projected area and average secant of the slope of the whole region; Yuan Weiping used a Simpson-based method that cuts the grid data into strips in the x- and y-directions. The accuracy was evaluated with the method presented in Section 4.1. The area increment is the difference between the surface area and the projected area. The calculation results are shown in Table 4.The comparison in Table 4 shows that the integrated multiscale method for surface area has the lowest relative error and relatively high area increment in all three areas. The integrated multiscale method reduces the error in many aspects to improve the calculation accuracy, such as the classification of the geomorphology to carry out targeted calculations for better simulations of surface relief and selection of appropriate algorithms for each geomorphology. The mean was used to reduce the error caused by the differences between the algorithms, and GeoDominance was defined to better adapt to the complex topography. In terms of the area algorithm, the integrated multiscale method improves on previous research by performing a comprehensive comparison of seven geomorphic types with three algorithms, clarifies the characteristics and application scopes of the algorithms, defines GeoDominance, and uses it to combine the system clustering division method and three surface area calculation algorithms. As the relief amplitude changes, the appropriate surface area algorithm changes from slope-based to Simpson-based, and finally to TIN. The key of the TIN algorithm is the selection of the starting triangle and the improvement of the search path length. The Simpson-based method simplifies many judgments and loops in the previous process of building the area element via a two-layer approximation and improves the calculation efficiency while ensuring accuracy. GeoDominance can identify geomorphologies with small proportions in the area calculation, and for areas with mixed geomorphologies, it also ensures that the appropriate algorithms for every geomorphology are reflected in the calculation results.Therefore, the integrated multiscale method provides higher precision than the single surface area calculation method under the same positioning coordinate precision.", 4. Results and Discussion, 4.2. Comparative Analysis with the Existing Literature,4
429," 4.3.1. Calculation Results of Forestland Surface Area in ChinaThe sum of the area of all the provinces (i.e., the national forestland surface area) is 2,280,202.76 km2. Table 5 shows the forestland surface area for each province.To perform a more comprehensive analysis of the national forestland surface area calculated by the integrated multiscale method and evaluate the underestimation of forestland area by traditional planar measurements and projected area substitution methods in the statistical process, the surface area was compared between the projected and statistical areas. The statistical data of each province’s forestland were obtained from the website of the Chinese National Bureau of Statistics and generally calculated by ground surveys, which means that the area data are 2D data. 4.3.2. Comparison with the Projected AreaFor the calculation of the projected area, the number of grids in each region was first counted, and the projected area is the product of the grid number and the grid area. The sum of the projected areas of the regions is the projected area of national forestland, which is 2,160,470.47 km2. The difference between the surface area and the projected area, as well as the area increment based on the projected area, were calculated (Figure 9), and the results can be treated as the area increment obtained by the surface area algorithm (Figure 10). The area increment ratio is the area increment percentage of the projected area, which suggests that the national forestland area has increased by 5.54% based on the projected area. Figure 6 shows the relationship between the average relief amplitude and the increment ratio of the projected area of each province. The provinces in the two charts are sorted by their average relief amplitudes.Figure 9 shows that the 3D surface area of forests in each province is greater than the 2D projected area of forestland. The increment ratio of the projected area in Figure 10 is the area increment proportion of the projected area. Figure 10 shows that the area increment has a certain correlation with the average relief amplitude, although the change trend is not completely consistent with the average amplitude and is divided into the following four cases: (1) provinces with large average relief amplitude and concentrated geomorphic distribution of forestland, such as Xizang, Taiwan, and Sichuan, exhibit high area increment ratios consistent with large relief amplitude; (2) the average relief amplitude is large, but the geomorphic distribution of forestland is mixed, such as in Guangdong, Fujian, and Guizhou, and the area increment is not high relative to the larger undulations; (3) the average relief amplitude is small, but the geomorphic distribution of forestland is concentrated, such as in Xinjiang, whose unique geomorphology (i.e., two basins sandwiched among three mountains) results in a high area increment ratio; and (4) in provinces with a small average relief amplitude and decentralized distribution of forestland, such as Ningxia and Hainan, the topographic relief has less influence on the surface area calculation. 4.3.3. Comparison with Statistical DataThe remote sensing images used in this study were from 2010, and the forestland area of each province in 2010 was determined and compared with the surface area (Figure 11 and Figure 12). Compared with the statistical data, the percentage increase in forestland area measured in this paper reached 4.91%, representing a previous underestimation of 106,763.76 km2. Based on the difference and increment ratios of the statistical area and the projected area (12,968.53 km2 and 0.60%, respectively), most of the distribution of forestland used in the calculation of the projected area and the statistical area overlap, and the above number of 106,763.76 km2 can be considered the underestimated area of forestland instead of a calculation error.Provinces in the above charts are sorted by the average relief amplitude. As shown in the analysis in Figure 11 and Figure 12, the change in the statistical area is generally similar to that of the projected area. Some provinces, however, have changed, and we speculate there may be two reasons for the differences: (1) most forests in provinces, such as Henan, are distributed in the plains and low relief amplitudes are correlated with small area increment; (2) urban provinces, such as Shanghai and Jiangsu, along with mainly desert provinces, such as Neimenggu, Ningxia, and Gansu, have small areas of trees that are accounted for in the statistical data but may be underrepresented in the classification of the interpretation of the remote sensing data.To perform the calculations on a large scale, this paper comprehensively considers various geomorphic types that may exist in large areas, such as plains, hills, and mountains, and performs a targeted simplification of the traditional complex and diverse classification methods for the single purpose of area calculation, while considering the classification accuracy and efficiency. This simplification not only is a good fit for surface features of different geomorphic types but also reduces program crashes due to massive data calculations. These advantages indicate the substantial value and broad prospect of this new approach to feature area computation.", 4. Results and Discussion, 4.3. Analysis of the Calculation Results for Forestland Surface Area in China,4
430,"The sum of the area of all the provinces (i.e., the national forestland surface area) is 2,280,202.76 km2. Table 5 shows the forestland surface area for each province.To perform a more comprehensive analysis of the national forestland surface area calculated by the integrated multiscale method and evaluate the underestimation of forestland area by traditional planar measurements and projected area substitution methods in the statistical process, the surface area was compared between the projected and statistical areas. The statistical data of each province’s forestland were obtained from the website of the Chinese National Bureau of Statistics and generally calculated by ground surveys, which means that the area data are 2D data.", 4. Results and Discussion, 4.3.1. Calculation Results of Forestland Surface Area in China,4
431,"For the calculation of the projected area, the number of grids in each region was first counted, and the projected area is the product of the grid number and the grid area. The sum of the projected areas of the regions is the projected area of national forestland, which is 2,160,470.47 km2. The difference between the surface area and the projected area, as well as the area increment based on the projected area, were calculated (Figure 9), and the results can be treated as the area increment obtained by the surface area algorithm (Figure 10). The area increment ratio is the area increment percentage of the projected area, which suggests that the national forestland area has increased by 5.54% based on the projected area. Figure 6 shows the relationship between the average relief amplitude and the increment ratio of the projected area of each province. The provinces in the two charts are sorted by their average relief amplitudes.Figure 9 shows that the 3D surface area of forests in each province is greater than the 2D projected area of forestland. The increment ratio of the projected area in Figure 10 is the area increment proportion of the projected area. Figure 10 shows that the area increment has a certain correlation with the average relief amplitude, although the change trend is not completely consistent with the average amplitude and is divided into the following four cases: (1) provinces with large average relief amplitude and concentrated geomorphic distribution of forestland, such as Xizang, Taiwan, and Sichuan, exhibit high area increment ratios consistent with large relief amplitude; (2) the average relief amplitude is large, but the geomorphic distribution of forestland is mixed, such as in Guangdong, Fujian, and Guizhou, and the area increment is not high relative to the larger undulations; (3) the average relief amplitude is small, but the geomorphic distribution of forestland is concentrated, such as in Xinjiang, whose unique geomorphology (i.e., two basins sandwiched among three mountains) results in a high area increment ratio; and (4) in provinces with a small average relief amplitude and decentralized distribution of forestland, such as Ningxia and Hainan, the topographic relief has less influence on the surface area calculation.", 4. Results and Discussion, 4.3.2. Comparison with the Projected Area,4
432,"The remote sensing images used in this study were from 2010, and the forestland area of each province in 2010 was determined and compared with the surface area (Figure 11 and Figure 12). Compared with the statistical data, the percentage increase in forestland area measured in this paper reached 4.91%, representing a previous underestimation of 106,763.76 km2. Based on the difference and increment ratios of the statistical area and the projected area (12,968.53 km2 and 0.60%, respectively), most of the distribution of forestland used in the calculation of the projected area and the statistical area overlap, and the above number of 106,763.76 km2 can be considered the underestimated area of forestland instead of a calculation error.Provinces in the above charts are sorted by the average relief amplitude. As shown in the analysis in Figure 11 and Figure 12, the change in the statistical area is generally similar to that of the projected area. Some provinces, however, have changed, and we speculate there may be two reasons for the differences: (1) most forests in provinces, such as Henan, are distributed in the plains and low relief amplitudes are correlated with small area increment; (2) urban provinces, such as Shanghai and Jiangsu, along with mainly desert provinces, such as Neimenggu, Ningxia, and Gansu, have small areas of trees that are accounted for in the statistical data but may be underrepresented in the classification of the interpretation of the remote sensing data.To perform the calculations on a large scale, this paper comprehensively considers various geomorphic types that may exist in large areas, such as plains, hills, and mountains, and performs a targeted simplification of the traditional complex and diverse classification methods for the single purpose of area calculation, while considering the classification accuracy and efficiency. This simplification not only is a good fit for surface features of different geomorphic types but also reduces program crashes due to massive data calculations. These advantages indicate the substantial value and broad prospect of this new approach to feature area computation.", 4. Results and Discussion, 4.3.3. Comparison with Statistical Data,4
433,"According to the 2010 forest survey, the total forest carbon storage in China was 7,811,460,800 tons [47] based on the statistical area. Based on a coarse approximation by surface area and the increment ratio of statistical area (4.91%), the total carbon storage of the forestland is 8,195,175,690 tons. The relationship between carbon storage and area of forestland is not linear and could be impacted by many factors; thus, although this approximation may need refinement, our results illustrate the relatively large influence and importance of the forestland surface area increment on carbon storage estimation.", 4. Results and Discussion, 4.4. Carbon Storage Calculation,4
434,"The results show that the surface area (3D area) of national forestland is 2,280,202.76 km2 and that the area has increased by 5.54% compared to the projected area (2D area). The specific comparisons of each region are shown in Section 4.3. This method not only reduces the required manpower but also improves the calculation accuracy and provides technical support for accurate forestland resource statistics.In combination with the advantages of the previous algorithms and the introduction of GeoDominance, the integrated multiscale method can change the shape and calculation method of computational elements flexibly while ensuring the completion of the geomorphic analysis. Additionally, this method resolves the complex situation associated with high precision and large amounts of data, yields small errors, and has a high efficiency. In future studies, hyperparameter optimization and high-performance computing will help accelerate the surface area algorithms selection process [48]. This method enables more accurate forestland area statistics to be obtained and provides a database for accurate assessment of various ecological resources, such as carbon storage. The integrated multiscale method is important for the exploration and evaluation of an ecosystem’s carbon sequestration ability and potential, expansion of the environmental capacity and ecological space, narrowing of the regional ecological quality gradients, and improvement of the ecological carrying capacity. ", 5. Conclusions,None,5
435,"As “the major non-wood forest product and wood substitute”, bamboo is widely distributed in tropical, subtropical, and warm, temperate regions between 46°N and 47°S, which covers a total area of 31.47 million hectares, accounting for 0.78% of the global forest area [1]. In Asian countries, bamboo forests have been expanding rapidly for the past 50 years [2]. China possesses the largest bamboo forest with an area of more than 6.01 million hectares, which accounts for approximately 2.97% of the total forested area nationally [3]. The area of Moso bamboo (Phyllostachys edulis (Carrière) J. Houz., abbreviated as MB) has reached 4.43 million hectares, which is 73.71% of the bamboo forested area in China [3]. Many efforts have been made to quantify ecological properties of MB, such as stand-scale transpiration [4], canopy chlorophyll content [5], and soil respiration of MB forests [6]. Characterized by fast growth and strong carbon sequestration abilities, MB forests show great potential to be a substantial carbon sink and, thus, play a significant role in addressing global climate change [4,7,8,9,10,11]. Carbon exchange between the atmosphere and MB crowns is significantly quantified and explained by leaf area (LA) and leaf angle distribution, which are the two most important crown structure parameters [12,13].Leaf area index (LAI), i.e., projected leaf area per unit surface area of the ground, is generally used to quantify LA in forestry, eco-physiology, and remote sensing communities [14,15]. Recently, much attention has been paid to estimate the LAI of MB canopies based on satellite remote sensing techniques. Xu et al. [5,16] developed empirical and correction models, respectively, to estimate LAI for MB canopies using the Moderate Resolution Imaging Spectroradiometer (MODIS) data. Li et al. [17] and Mao et al. [18] developed assimilation methods to improve the MODIS LAI time series of MB forests. Furthermore, Li et al. [19] estimated aboveground biomasses of MB forests using the MODIS LAI spatiotemporal data and machine learning algorithms. Additionally, Mao et al. [20] analyzed the spatiotemporal pattern and heterogeneity of carbon fluxes of the bamboo forest in Zhejiang Province of China, based on the assimilated LAI. To validate LAIs retrieved from satellite remote sensing images, LAIs indirectly estimated using ground-based digital hemispherical photography (DHP) are taken as surrogate truths [17,18,21] because its field work requirements are more efficient, less expensive, and more user friendly and eco-friendly [22]. However, the DHP-based LAI is always underestimated [23,24,25] because of photographic over exposure [26,27], scattered radiation influences [28], non-random distributed leaves [29,30,31], and high leaf density influences [32]. Direct LA measurements, such as destructive harvesting, litter collection, and allometric equations, are widely accepted as reliable methods and, consequently, important validations for indirect methods such as the DHP method [31,33]. On this issue, allometric methods are more suitable for a large number of forest types because of the relatively stable physical or physiological interrelations among stem dimensions, crown dimensions, LA, and biomass amounts [14,31,34]. Previous studies reported many allometric relationships with accessible tree traits as independent variables to estimate LAs of several specific tree species. These allometries generally relate LA to tree characteristics such as diameter at breast height (DBH) and tree height (H) [13,35,36,37]. However, there are no validation studies to prove the reliability of the estimated LA of MB by indirect methods. Therefore, development of allometric models for estimating the LA of MB is essential to validate LAs retrieved by indirect methods and to facilitate other ecological studies on MB.On the other hand, leaf angle distribution, i.e., the probability density of the leaf angle [38], is also one of the most commonly used structural characteristics of a vegetation canopy. Leaf angle distribution influences the spectral reflectance and radiation transmission properties of vegetation canopies and, hence, interception, absorption, and photosynthesis [39,40,41]. A few leaf angle distribution estimations have been reported for different tree species [42,43,44]. However, little is known about the leaf angle distribution of MB crowns. In general, three types of methods were used for in situ leaf inclination angle measurements, and subsequently for leaf angle distribution modeling, including direct measurements by mechanical inclinometers [45], the indirect photographic method [43,44,46], and indirect three-dimensional digitizing of individual plant elements using specialized instrumentation [42]. The direct mechanical inclinometer measurement has been a traditional and reliable method; however, it is laborious and requires careful measurements of many leaf surfaces [40]. For example, Pisek et al. [44] evaluated canopy non-randomness based on clinometer measurements of 100 leaf angles of three birch trees. For simplification of leaf angle measurements, Ryu et al. [43] developed a photographic method that analyzing leveled digital camera images of canopies consisting of flat leaves. This method allows for a rapid and non-contact estimation of leaf angles and has been applied to several broadleaf canopies. They measured 1200 leaf angles of oak crowns to estimate leaf projection functions, and then the estimated erectophile distribution was used to retrieve LAIs based on a modification of Lambert-Beer’s law. Piayda et al. [47] also determined the leaf angle distribution of a sparse, savannah-type cork oak canopy based on 1561 leaf angle measurements using the photographic method to compare three non-destructive LAI measurement techniques. Another way to obtain leaf angle measurements is to improve inclinometer measurements based on the indirect three-dimensional digitizing method. For example, a leaf angle estimation method based on retrieved Terrestrial LiDAR Scanning (TLS) data was recently developed by Vicari et al. [41]. However, Zou et al. [40] pointed out that with indirect methods, it is almost impossible to differentiate the effects of leaf angles on canopy transmittance from other structural influences.The objectives of this investigation are (1) to develop allometric equations for LA estimations of a MB crown based on DBH or H and (2) to find the leaf angle distribution of MB crowns.", 1. Introduction,None,1.
436,"The study area was in Lin’an city (118°51′–119°52′ E, 29°56′–30°23′ N), southeast of China. Lin’an has an undulating terrain in the east and mountainous regions in the west, with elevation ranging from 10 to 1580 m. Lin’an is in the subtropical monsoon climate zone with a mean temperature of 15.9–17.0 °C and an average annual precipitation of 1614 mm. MB forests are the dominant species in this area. Other vegetation types include coniferous evergreens, broad-leaved evergreens, and mixed coniferous and broad-leaved forests. The primary soil types are red and yellow soils (by Chinese soil taxonomy). A total of 29 healthy and well-formed MB crowns (i.e., there were no signs of defoliation and pest and disease damage) were destructively sampled in late August and early September 2018. We randomly sampled 2, 4, 11, and 12 crowns within four pure MB plots, respectively (Figure 1). The sampled bamboo crowns were away from residential areas, roads, and reservoirs. In addition, the spatial distance between each of the sampled MB crowns was larger than 20 m.Several plant characteristics of the 29 MB crowns were measured and recorded for LA estimation, including DBH, H, total leaf biomass of each crown, and the biomass and area of the sampled leaves in each of the 29 crowns (Table 1). DBHs of the 29 MB crowns were measured using a diameter tape, and H was measured from its trunk base to the top of a crown, using a measuring tape, after cutting down its trunk. Each of the 29 crowns was divided equally into three sections (top, middle, and bottom). About 120 leaves in each section were randomly selected as samples. The sampled leaves were rapidly scanned using an Epson perfection V30 SE scanner (Seiko Epson Corporation, Nagano, Japan) to measure LA to avoid leaf deformation caused by water loss. A white sheet of paper (17 cm × 24 cm) was placed under the sampled leaves during the scanning process as a spatial reference for LA measurements. However, the sampled leaves of some sections were less than 120 pieces because low-quality scanned images were abandoned, such as the contaminated reference paper, and the folded or overlapped leaves. Figure 2 shows an example of the scanned images. The scanned images were classified as leaves and background using MATLAB 2014a software based on digital image processing techniques. Then, the LA of each image was calculated based on the ratio of the leaf pixels and total pixels within the 17 cm × 24 cm rectangle. All sampled leaves of the three sections in each of the 29 MB crowns were separately packed in paper bags and oven-dried at 80 °C for 48 h until their dry weight was constant. Then, the dry mass of sampled leaves was measured using an electronic balance (Wuxin Weighing Apparatus Co., Ltd, Zhejiang, China) with an accuracy of 0.0001 g. The total leaf biomass for each of the 29 crowns was measured in the same way as the sampled leaves.Leaf angle measurements were conducted to estimate the leaf angular distribution. The leaf inclination angle α is defined as the angle between the leaf surface (normal) and the zenith from 0° to 90°. We carefully measured and recorded 312 leaf inclination angles (104 × 3 sections = 312 leaves of a crown) randomly from each of the 29 crowns using a digital obliquity sensor (DXL360S, Jingyan, Inc., Guangdong, China).", 2. Materials and Methods," 2.1. Study Area, Destructive Sampling, and Laboratory Procedures",2
437,"The following three steps were carried out to develop the allometric relationships between the LA of a crown and DBH or H: (1) the specific leaf area (SLA) was calculated based on the sampled LA (Ssampled) and biomass (Bsampled) for each section of the 29 MB crowns [48,49]:



S
L
A
=

S

s
a
m
p
l
e
d


/

B

s
a
m
p
l
e
d


,




(1)


(2) LA of a crown (Scrown) was estimated depending on the total leaf biomass of a crown (Bcrown) and SLA [36]:




S

c
r
o
w
n


=
S
L
A
·

B

c
r
o
w
n


,




(2)


and (3) DBH and H were not used as simultaneous predictors because of the strong linear correlation between DBH and H (R2 = 0.88, p < 0.0001). Linear, exponential, and logarithmic regressions were used for Scrown estimations:



Y
=
a
·
X
+
b
,




(3)





Y
=
a
·

X
b

,




(4)





Y
=
a
·

e

b
·
X


,




(5)


where X is DBH or H, Y is LA of a crown, and a and b are the equation parameters. Because the assumption of the heteroscedasticity was violated for nonlinear regression measurements in our original scale, Equations (4) and (5) were log-transformed [50,51,52]:



ln
Y
=

a
′

·
ln
X
+

b
′

,




(6)





ln
Y
=

a
′

·
X
+

b
′

,




(7)


where a′ and b′ are the log-transformed equation parameters. a′ equals b and b′ equals ln a. The transformation, however, introduced a systematic bias, which can generally be corrected with the following correction factor [52,53,54,55]:



C
F
=

e

S
E

E
2

/
2


,




(8)


where CF is the correction factor, and SEE is the standard error of the estimate, calculated as follows:



S
E
E
=




∑

i
=
1

n




(
ln

Y
i

−
ln


Y
^

i

)

2

/
(
n
−
2
)




,




(9)


where 


Y
i


 and 



Y
^

i


 are observed and predicted biomass values of the ith sample, respectively, and n is the number of samples. Equations (6) and (7) were back-transformed to get LA equations [52]:



Y
=
C
F
·

e


b
′



·

X


a
′



,




(10)





Y
=
C
F
·

e


b
′



·

e


a
′

·
X


,




(11)

The goodness-of-fit of the models were evaluated by the coefficients of determination (R2) and root-mean-square error (RMSE). In addition, leave-one-out cross validation (LOO) was used for model validation [56,57].", 2. Materials and Methods, 2.2. Allometric Equations for LA Estimation,2
438,"The leaf projection function G(θ) is the projection coefficient of a unit area of foliage on a plane perpendicular to the view/solar zenith angle θ. G(θ) is generally used for classifying leaf angle distribution f(α) in the remote sensing community [43,44]. The value of the G-function can be calculated by integrating f(α) over α:



G
(
θ
)
=



∫
0

π
/
2



A
(
θ
,
α
)



f
(
α
)
d
α
,




(12)


where A is the projection coefficient for α and θ according to the theory by Wilson [58]:



A
(
θ
,
α
)
=

{





cos
(
α
)
·
cos
(
θ
)




α
+
θ
≤

90
°







cos
(
α
)
·
cos
(
θ
)
·

[

1
+
2
/
π
·
(
tan
(
γ
)
−
γ
)

]





α
+
θ
>

90
°







,




(13)


where 

γ
=

arccos
(
cot
(

α
)
·

cot
(

θ

)
)


.", 2. Materials and Methods, 2.3. Leaf Angle Distribution and Leaf Projection Function,2
439,"As for the 29 sampled MB crowns, mean SLA values of the top, middle, and bottom sections were 237.76 cm2·g−1 (from 158.62 to 333.52 cm2·g−1), 265.35 cm2·g−1 (from 173.58 to 381.55 cm2·g−1), and 289.54 cm2·g−1 (from 152.21 to 466.37 cm2·g−1), respectively (Figure 3). The SLA values tended to decrease from the bottom to the top of the crown. The negative relationship coincided with the findings of other tree species reported in previous studies [48,59,60]. However, the reason for that phenomenon is still unclear [59]. Potential explanations will be given in the discussion section.Considering SLA varies with height in a MB crown, the LA of a crown should be the sum of LA estimated from the top, middle, and bottom sections, respectively. The estimated LA, which varied from 7.42 to 74.38 m2, showed more than 10 fold divergence among the 29 MB crowns because of the large differences in leaf biomass (Table 1). On the other hand, the average vertical LA distribution of the 29 crowns showed a significant “Muffin top” character (Figure 4). Nearly half of LA grew in the middle section of a crown, about 30% of the LA was in the top section, and the remaining 20% LA was situated in the bottom section of the crown. This type of LA distribution has generally been reported with broad-leaved crowns [15].", 3. Results, 3.1. LA of a MB Crown,3
440,"Both DBH and H are popular structural parameters used to estimate the crown-scale LAs based on allometric equations [14,34,36,61]. In this study, empirical equations with one unknown independent variable, rather than with two unknown independent variables (DBH and H), were used to develop allometric relationships in order to avoid multicollinearity problems, as there was a strong, linear relationship between DBH and H (R2 = 0.88, p < 0.0001). Therefore, six allometric relationships were developed for LA estimations based on three types of regression models, including linear, exponential, and logarithmic regressions, and two predictors, including DBH and H, respectively. Table 2 shows the regression parameters and the goodness-of-fit statistics of the six allometric relationships. R2 values of the six models showed minor differences, from 0.7789 to 0.8211. This indicates no single relationship was significantly outstanding among the six allometric relationships. RMSE estimated based on linear regression cannot be compared to the other nonlinear regressions because Equations (3)–(6) were log-transformed. As for the linear LA models, RMSE did not show a significant divergence between using H and DBH, because of the high correlation of the two predictors. The RMSE values of the nonlinear allometric relationships also had no big differences. The highly reliable relationships among H, DBH, and LA of MB crowns can be explained by the species-specific branching pattern that depends on genetic and environmental influences [62].The six allometric relationships in Table 2 were validated based on the leave-one-out cross validation (Figure 5). LOO validations confirm the similar and highly reliable relationships between predicted and observed LA data for the six models. The results indicate that any one of the three types of regression methods can be used for the estimation. Both DBH and H are also suitable for the LA estimations of a MB crown.", 3. Results, 3.2. Allometric Equations for LA Estimation,3
441,"Figure 6 is the leaf angle distribution f(α) of MB crowns with a 10° leaf angle interval. It can be found that: (1) The average leaf angle proportion decreased significantly with increasing α; and (2) the differences of f(α) among the top, middle, and bottom sections were not significant. Therefore, it is not necessary to specify sampling positions in the MB crown for leaf angle measurements. The estimated f(α) using total leaf angle data of a MB crown is shown in Figure 6d.G(θ) of MB crowns was simulated based on f(α) according to Equation (12) (Figure 7). Compared to the five typical leaf angle distributions, including the erectophile, planophile, plagiophile, spherical, and uniform cases [63], G(θ) of MB crowns tends to be planophile.", 3. Results, 3.3. Leaf Angle Distribution f(α) and Leaf Projection Function G(θ),3
442,"SLA is an important conversion factor for estimating LA [37,60]. This study found that SLA values increased from top to bottom of a MB crown (Figure 3). This relationship is consistent with most previous studies with varied tree species [48,59,60] and is generally explained by the following two main possible reasons, which refer to different leaf strategies in response to environmental pressure and constrains [64]. One reason concerns the fall in water potential [59]. With a tree stem growing taller, the stem conductance reduces [61,65]. A further reduction in water potential may induce a reduction in turgor pressure. Then, stomata would potentially close, and cell expansion would likewise be reduced. Furthermore, such water stress might be associated with the development of xeromorphic features, including thick cuticles and lignified cell walls, both of which would tend to reduce SLA. Another reason is related to the expression of the plant species’ ability to cope with changing light [66,67,68,69,70]. Light conditions for leaves in the lower crown are shadier and worse compared to that of the leaves in the upper crown; therefore, a larger SLA is likely an adaptation to more efficiently intercept light in low-light conditions [60,71,72]. Certainly, both the hydraulic limitations of greater branch height and light availability may combine to impact SLA [70]. Although these two explanations have been accepted by previous studies to a certain extent, detailed physiology studies for the MB species are worth exploring further to uncover more potential reasons.Previous studies found that the higher SLA in broad-leaved trees, relative to evergreen conifers, fit the trend of a decreasing SLA with increased leaf lifespan [73,74,75,76]. As expected, the SLA value of MB, ranging from 152 cm2·g−1 to 466 cm2·g−1, is a typical example of broadleaf trees when compared with several published SLA cases (Table 3 and Table 4). Because of the unique biological rhythm of MB’s leaf growth, new bamboo usually grows leaves in June of its first year; these initial leaves fall in the next spring, and new leaves quickly emerge. The new leaves have a life span of 2 years, thus, replacement occurs biennially [77,78,79]. Therefore, the short lifespan of MB leaves results in a high SLA value.", 4. Discussion, 4.1. Specific Leaf Area,4
443,"To quantify total LA in the field, this study indicates that DBH is a reliable and easy scalar to measure, and validation proves that the empirical relationships between the LA of MB and its DBH are highly significant. On the contrary, in many cases of forest inventories, H of MB is obtained through eye estimations by skilled workers under complicated forest conditions, including tree tops that are hidden by the canopy layer, bending growth of crowns, and a sloping background. This can be a source of error that needs to be considered. On the other hand, the strong, linear relationship between the DBH and H of MB agrees with the results by previous studies for other tree species, which indicate that DBH is also used as a reliable crown trait for H estimations [11,55,88,89], and using both DBH and H as independent variables to estimate LA cannot significantly improve, or even reduce, the accuracy of estimations [13,90,91]. Therefore, DBH is a better predictive variable for the allometry of LA of MB crowns.The linear, allometric equations showed as good of a performances as those of the nonlinear equations, including the exponential and logarithmic regressions. This means that the nonlinear models do not explain more of the variation and do not fit the data better than the linear models. Therefore, a linear, allometric relationship is preferred for estimating the LA of MB because it is easy to use. In addition, it should be kept in mind that, when using the developed allometric equations of this study, regression should not be applied beyond the range of observations used to develop the model.Does the LA of a MB crown change with the invariant DBH and H? And does the developed allometry of LA lose efficacy if LA changes within a MB crown? The “pipe model” theory [92] potentially explains this problem. It indicates that a given LA is supplied with water from a respective quantity of conducting pipes. Different from other tree species, MB, which belongs to the Poaceae family, usually can reach its maximum DBH and H in only 40–60 days. Once it enters the second growth stage (strength increase and biomass accumulation), DBH and H will not increase anymore because of the lack of cambium [8]; hence, no new conducting pipes are produced as the tree ages. On the other hand, as on the tree ages, a part of the conducting pipes might be clogged. Therefore, the potential decrease in water supply theoretically leads to the reduction of the LA of a MB crown according to the “pipe model” theory. However, this reduction was not found in the 29 sampled crowns at various ages, from 1 to 5 years. That was because a MB crown is harvested usually at 6–8 years, and variations of its conducting pipes do not significantly influence the quantity of LA in such a short lifespan. In addition, the LAs of this study were not sampled at the leaf replacement stage (field work was conducted during late August and early September). Therefore, all developed allometric relationships are applicable, except during the leaf replacement stage of MB.", 4. Discussion, 4.2. LA Estimation of MB,4
444,"A simple LAI inversion case, using an inappropriate G(θ), was taken as an example to show the influence of leaf angle distribution on ecological studies of MB. In the remote sensing community, G(θ) is one of the critical canopy structure parameters used for LAI estimation and is based on the modified Lambert–Beer’s law:



P
(
θ
)
=

e

−
G
(
θ
)
·
L
A
I
·
Ω
(
θ
)
/
cos
(
θ
)


,




(14)


where P(θ) is the gap fraction of a canopy, which is generally obtained by hemispherical optical instruments such as in DHP [93,94]; and Ω(θ) is the clumping index, which is used for quantifying leaf spatial distribution within a canopy. Here, Ω(θ) is assumed as 1 to represent a random spatial distribution of leaves. Generally, a spherical leaf angle distribution (G(θ) ≈ 0.5) is considered as the surrogate truth of G(θ) in Equation (14) when f(α) is unavailable [95,96]. However, this study found that the G(θ) of MB was far from the spherical case and was close to the planophile case. Based on Equation (14), the error for the LAI estimation of MB using the spherical case can be estimated (Figure 8). The results show that the LAI of a MB canopy is overestimated with view/solar zenith angles from 0 to 57.5°, and the overestimation reaches up to 2. However, LAI is underestimated with view/solar zenith angles from 57.5° to 90°, and the maximum underestimation is 0.62 at a 77° view/solar zenith angle. With a decreasing gap fraction at the same view/solar zenith angle, the error of the LAI estimation increases. However, the error of the estimation is at a minimum and close to 0 at 57.5° for all gap fractions. This is also the reason why many previous LAI estimations used a 57.5° view/solar zenith angle when f(α) is unavailable [97,98,99]. Considering the significant error using inappropriate leaf angle distributions, we suggest using the modeled G(θ) in this study to estimate LAI of MB, especially for the cases with large gap fractions.", 4. Discussion, 4.3. Leaf Angle Influence on LAI Estimation,4
445,"This study represents the first attempt to report species-specific allometric equations for the crown-scale LA estimations of MB and its leaf angle distribution. The simplest and most efficient linear regression uses the predictor DBH, which is easy to measure in the field, and is recommended for LA estimations of MB. On the other hand, the leaf angle distribution of MB was found to be close to the planophile distribution. Use of the modeled leaf angle distribution of this study potentially benefits LAI retrieval of MB forests based on remote sensing techniques.Although the results showed strong correlations between the LA of a MB crown and DBH or H, and a reliable species-specific leaf angle distribution of MB, there is also the need to evaluate and improve the developed relationships based on more widespread fieldwork data in future studies. In addition, SLA variation within a MB crown is also worth exploring to uncover more potential reasons in further physiology studies.The findings of this study provide crucial parameters to quantitatively estimate the carbon sequestration of MB forests. Therefore, these findings will serve in understanding MB’s contribution to global climate change and to meet other biophysical study requirements in vegetation remote sensing, biology, and forestry communities.", 5. Conclusions,None,5
446,"Tropical forest plantations play a major role in global timber markets. In 2012, 231 million m3 (41% of the global total) of industrial roundwood from plantations was produced in tropical countries [1]. In addition to timber, national and international institutions are looking to plantations for ecosystem services such as carbon sequestration, water filtration, and soil conservation [2,3,4,5]. Countries and multilateral organizations such as the United Nations are implementing vegetation carbon accounting programs to integrate carbon stores, including those in plantations, into national and global budgets. These mechanisms are increasingly making funding available to landowners and organizations that can track changes in biomass and quantify carbon stored.Performing accurate inventories of plantations is critical for any land manager [6]. Diameter at breast height is often measured in the field to estimate height, which can then be used to inform harvest schedules and derive biomass [7]. However, assessing height directly is often cost and time-prohibitive [8].One alternative to measuring height by hand is offered by remote sensing techniques [9]. Light Detection and Ranging (LiDAR), which records 3D structure based on emitted laser pulses, is often employed for characterizing 3D vegetation structure [10]. While LiDAR can accurately measure forest, plantation, and individual tree structure in 3D [11,12,13,14], it is prohibitively-expensive for smallholders in tropical and developing nations [8]. A typical commercial aerial LiDAR acquisition costs at least US $20,000 per flight [15], significantly more than low-income smallholders can afford.However, new developments with unmanned aerial vehicles (drones) have significantly lowered the cost and time needed to conduct inventories [16,17,18]. Because of this, drones offer the possibility of empowering landowners or small organizations to conduct forest inventories more frequently. Nowadays, one can buy a high-quality drone and equip it with an RGB digital camera, thereby creating a homemade remote sensing tool [19,20]. Photos taken from these cameras can be processed with open-source software (e.g., Ecosynth) to construct a 3D model using structure from motion algorithms [21,22]. These algorithms identify features (e.g., trees, buildings) on overlapping photos taken from different angles and reconstruct the features’ 3D structure [23,24]. The resulting data is a collection of RGB points that represent the 3D surface of the objects imaged by the drone. This method has been used to produce LiDAR-like results in measuring canopy heights, structure, roughness, and biomass [18,21,22,25].While drones have been used in connection with estimation of height and biomass in mixed plantations and secondary forest [18], they have never been tested for their ability to support estimation of height, aboveground biomass (AGB), and total biomass (TB) on a per-species basis in monoculture plantations in the steepland tropics. Characterized by slopes that average more than 12% in grade, the steepland tropics provide critical land for smallholders and watersheds for communities and cities [26]. Because the slopes are too treacherous for industrial cultivation, forestry and agriculture are often practiced by smallholders and are thus an ideal place to test this approach [26,27,28,29].Additionally, past forestry-relevant drone studies have largely focused on the use of drones in monitoring forest variables and temperate plantation management [17,30,31]. Few of these studies have been performed for tropical timber plantations and none have been performed on the species that we studied. As interest in operationalizing drones for forest inventories proliferates, it is critical to determine the appropriate conditions and purposes for using these tools [32].In this study, we compare estimates of canopy height and biomass (aboveground and total) of five different species derived from drone-based models and LiDAR-based models. The study was performed in the steeplands that surround the Panama Canal. We applied this method to 56–1754 m2 plantations of five different species, and evaluated its performance by comparing height with field-based measurements and biomass with estimates derived from locally-generated allometric equations.", 1. Introduction,None,1.
447,"This study was performed at the site of the Smithsonian Tropical Research Institute’s Agua Salud Project in the Panama Canal Watershed (9°13′ N, 79°47′ W). The site receives 2700 mm of annual rainfall, experiences a dry season from mid-December through early May [33] and is characterized by short, steep, and highly variable slopes (range of 0–75°, mean of 24°) that range from 52 to 343 m above sea level in elevation. Agua Salud is a mosaic of pastures, successional forests, and plantations (both native and exotic) and is surrounded by a diverse landscape of agriculture, human settlements, and forest [34]. The Agua Salud native species plantations consist of 21 treatments of different combinations of monocultures and mixtures and totals 267 plots, 56 of which are monocultures of native species [35].This study was carried out in the 56–1754 m2 (45 m × 39 m) monoculture native species plantations (termed ‘plots’) located in two different blocks (termed ‘Block 1’ and ‘Block 2’) within the Agua Salud Project area (see Figure 1). Thirty plots are located in Block 1 and 26 plots are in Block 2, all of which were established in 2008. Five different species were randomly assigned to the plots and stratified across slope classes—Terminalia amazonia, Dalbergia retusa, Pachira quinata, Tabebuia rosea, and Anachardium excelsum. Each plot contained a 27 m × 23.4 m ‘core zone’ of 81 trees (nine rows of nine trees each), and was surrounded by a buffer zone of three rows of trees on every side—resulting in a total of 225 trees in each plot. All plots were 7 years old at the time of measurement.", 2. Materials and Methods, 2.1. Study Site,2
448," 2.2.1. Field Measurements Canopy HeightHeights were measured with a 15-meter extendable pole between June and July 2015 for all trees in each core zone. Heights were measured at the tallest stem. If no tree was present, the record was marked as null and the entry was omitted from further analysis. Average field height per core zone was then calculated, termed ‘field height,’ which was assumed to represent the average height of the entire plot. BiomassAboveground biomass (AGB) and total biomass (TB) were calculated for each core zone using species-specific allometric equations that were derived in a separate study [36]. In their study, Sinacore et al. measured and destructively-harvested 41 trees from six species, five of which are included in this study. They further excavated, dried, and weighed all roots down to 2 mm thus providing accurate measures of belowground biomass.The best species-specific allometric equations from the Sinacore et al. paper, used in this study, take basal diameter as input parameters [33]. Basal diameters were measured at the same time as tree heights and were recorded for each stem in the multi-stemmed trees. Out of the 3955 trees that were present, 351 were multi-stemmed (59% of which were D. retusa). From the 351 multi-stemmed trees, 271 had two stems, 62 had three stems, 15 had four stems, two had five stems, and one had six stems. Both AGB and TB were calculated for individual stems using basal diameter values. Biomass was then summed for all the trees in a core zone and divided by the area to get the final dimensions (Mg/Ha). Since height has been found to predict biomass [18,37], field-estimated AGB and TB were compared to remotely-sensed height measurements (see below) to determine how well height measurements from drones could be used to model AGB and TB estimates of these species. 2.2.2. Remote Sensing Measurements LiDAR CollectionLiDAR data was collected for the study areas in August 2009 by Blom (a surveying company) using an Optech sensor (Optech Incorporated, ALTM 3100, Toronto, Canada) on board a fixed wing manned aircraft traveling at 457.2 m above the ground at a flight speed of 66.9 m·s−1 (scanning frequency of 48 Hz and pulse repetition rate of 70 kHz). Blom then created a model of the terrain, a DTM, from this data using TerraScan 9.0 (TerraSolid, Helsinki, Finland), with spatial resolution of 1 × 1 m. LiDAR horizontal and vertical accuracy was evaluated at 36 control points within the flight area, resulting in a horizontal root mean square error (RMSE) of 7.6 cm, and a vertical RMSE of 6.9 cm. Due to the age of the LiDAR data relative to the current study (2009 vs. 2015), no surface measurements of canopy height from the LiDAR were used. Instead, it is expected that there would be little change in topography over this time, making the 2009 LiDAR DTM a valid dataset for the current work. This DTM was used in all LiDAR analysis in this study, referred to as the LiDAR DTM, or the LiDAR terrain model. Image CollectionImagery was collected using a multirotor drone following the methods and equipment specifications of Dandois and Ellis [21], from 16 April 2015 to 19 April 2015. Digital images were taken with a Canon ELPH 520 (Canon Inc., Tokyo, Japan) HS point and shoot digital camera, which shot continuously at two frames per second (f·s−1) throughout the flights. Seven flights were required to capture both Block 1 (five flights) and Block 2 (two flights). Drone flight altitude was fixed to 400 m above the launch location, which was set at a nominal location and elevation within each flight area. The drone flew autonomously along a predetermined flight path at roughly 7 m·s−1, resulting in an average image resolution of 14 cm GSD. In general, flights were conducted between 09:00 and 14:00 local time to minimize the effects of sun angle and to avoid high winds and rain. Point Cloud GenerationSeveral processing steps were required prior to creating point clouds from drone images. GPS and altitude telemetry from the drone were used to provide an initial estimate of the XYZ location of each image. Due to the relatively high frame rate of the camera and high altitude, images were collected with very high forward overlap (≥ 98%), resulting in more image data than is needed so image sequences were subsampled to every 10th frame [25]. Even though image white balance and contrast were fixed before each flight to an 18% gray card in full sun, there were still differences in image quality between flights over the same locations and within flights due to passing clouds and cloud shadows. A histogram matching technique was used to minimize these effects [38]. Briefly, images were converted to the HSV (hue-saturation-value) color space, then for each image, the histogram of the value channel was normalized to that of an exemplar image manually identified to have good contrast and exposure with no cloud shadows.Normalized images were then transformed back to the RGB color space. Normalized and georeferenced images from each flight were then imported into the photogrammetry, structure from motion software Agisoft Photoscan (version 1.1.6, 64-bit) for each flight area (Block 1 and Block 2) to create 3D point clouds. This software uses computer vision photogrammetric algorithms to recognize similar features in multiple images and to simultaneously solve for their locations as well as the location and orientation of the camera at the time of image capture in 3D space ([21] for further details). After initial processing, a GeoTIFF orthomosaic (14 cm GSD) was exported from Photoscan.Additional georeferencing was performed in ArcGIS and Photoscan on the drone orthomosaic by extracting XYZ data from the LiDAR DTM for ground control points (e.g., building corners, distinct marks in the roads, small shrubs, etc.). The resulting DTM had a positional RMSE of 1.30 m for Block 1 and 1.89 m for Block 2, relative to the LiDAR DTM error. After this stage, a sparse point cloud was exported for each block for additional analysis. This point cloud, produced from drone imagery, is referred to as the Ecosynth point cloud, based on the name of the methodology used [21,22]. Digital Terrain and Canopy Height ModelsDigital terrain models were created from the Ecosynth point clouds by refining the data and then filtering the terrain. The referenced point clouds were clipped to the study area, filtered to remove any noisy points, and converted into a 1 × 1 m grid of median height values. Terrain filtering algorithms were then applied to each point cloud using MCC-LiDAR software to produce the DTMs [39]. This software applies a filter to the point cloud at different scales to estimate whether any given data point is a local low point—thus classified as ‘terrain’. The terrain points were then interpolated into a 1 m gridded raster DTM using natural neighbor interpolation in ArcGIS 10.1 (ESRI, Redlands, CA, USA). Canopy height models (CHM) were created from the Ecosynth DTM and LiDAR DTM by subtracting the underlying DTM value from the elevation of each point in the Ecosynth point cloud. These canopy height models are hereafter referred to as Ecosynth CHM and LiDAR CHM. As noted above (Section 2.2.2), due to the age of the LIDAR data, no canopy heights were obtained from LIDAR canopy surface measurements—the LiDAR CHM refers to the model derived from subtracting the Ecosynth canopy height measurements from the LiDAR DTM.A Trimble R8 differential GPS unit was used to record the locations of all the corners of the study plots via FastStatic. This was done to enable accurate plot-level spatial analysis of the canopy height models. Coordinates were processed and exported with Trimble Business Center with a median precision of 7 cm horizontal and 10 cm vertical in Block 1 and 12 cm horizontal and 7 cm vertical in Block 2. 2.2.3. Data Analysis Canopy Height and BiomassCanopy height metrics—mean, minimum, maximum, median, 25th percentile, 75th percentile, and 95th percentile height—were calculated using points from each CHM with height >0 m on a per-treatment per-plot basis (N = 56, see Supplementary Materials). These metrics were then plotted against all field heights, AGB, and TB from each CHM using both simple linear regression and linear mixed-effect models to determine which metric and model could best predict field-derived values based on Akaike information criterion (AIC). Using mixed-effect models allowed us to test whether treating the species as a random variable improved the model. The same canopy metrics were then linearly regressed against field heights, AGB, and TB for each species separately to find the best metric for species-specific predictions, again using AIC as the means for model selection. The best models were tested for significance by analyzing their p values.Visual inspection of the imagery and CHMs revealed that the maps of the plots did not capture crowns that extended outside the plot borders. To include these points in the height analysis, the plot borders were manually adjusted to include the overhanging crowns, as determined by visual inspection. Trees that crowded into the plots were similarly excluded (see Figure 2). While this process was made easier by the clear outline of plantation-style crowns, there is a corresponding level of error from manual tracing of tree crowns. Vertical Canopy ProfilesCanopy profiles were made for each CHM on a per-species basis by plotting a vertical histogram of point heights. This was done to visualize and compare each CHM’s ability to characterize the vertical canopy distributions of the studied species.", 2. Materials and Methods, 2.2. Data Collection and Analysis,2
449," Canopy HeightHeights were measured with a 15-meter extendable pole between June and July 2015 for all trees in each core zone. Heights were measured at the tallest stem. If no tree was present, the record was marked as null and the entry was omitted from further analysis. Average field height per core zone was then calculated, termed ‘field height,’ which was assumed to represent the average height of the entire plot. BiomassAboveground biomass (AGB) and total biomass (TB) were calculated for each core zone using species-specific allometric equations that were derived in a separate study [36]. In their study, Sinacore et al. measured and destructively-harvested 41 trees from six species, five of which are included in this study. They further excavated, dried, and weighed all roots down to 2 mm thus providing accurate measures of belowground biomass.The best species-specific allometric equations from the Sinacore et al. paper, used in this study, take basal diameter as input parameters [33]. Basal diameters were measured at the same time as tree heights and were recorded for each stem in the multi-stemmed trees. Out of the 3955 trees that were present, 351 were multi-stemmed (59% of which were D. retusa). From the 351 multi-stemmed trees, 271 had two stems, 62 had three stems, 15 had four stems, two had five stems, and one had six stems. Both AGB and TB were calculated for individual stems using basal diameter values. Biomass was then summed for all the trees in a core zone and divided by the area to get the final dimensions (Mg/Ha). Since height has been found to predict biomass [18,37], field-estimated AGB and TB were compared to remotely-sensed height measurements (see below) to determine how well height measurements from drones could be used to model AGB and TB estimates of these species.", 2. Materials and Methods, 2.2.1. Field Measurements,2
450,"Heights were measured with a 15-meter extendable pole between June and July 2015 for all trees in each core zone. Heights were measured at the tallest stem. If no tree was present, the record was marked as null and the entry was omitted from further analysis. Average field height per core zone was then calculated, termed ‘field height,’ which was assumed to represent the average height of the entire plot.", 2. Materials and Methods, Canopy Height,2
451,"Aboveground biomass (AGB) and total biomass (TB) were calculated for each core zone using species-specific allometric equations that were derived in a separate study [36]. In their study, Sinacore et al. measured and destructively-harvested 41 trees from six species, five of which are included in this study. They further excavated, dried, and weighed all roots down to 2 mm thus providing accurate measures of belowground biomass.The best species-specific allometric equations from the Sinacore et al. paper, used in this study, take basal diameter as input parameters [33]. Basal diameters were measured at the same time as tree heights and were recorded for each stem in the multi-stemmed trees. Out of the 3955 trees that were present, 351 were multi-stemmed (59% of which were D. retusa). From the 351 multi-stemmed trees, 271 had two stems, 62 had three stems, 15 had four stems, two had five stems, and one had six stems. Both AGB and TB were calculated for individual stems using basal diameter values. was then summed for all the trees in a core zone and divided by the area to get the final dimensions (Mg/Ha). Since height has been found to predict biomass [18,37], field-estimated AGB and TB were compared to remotely-sensed height measurements (see below) to determine how well height measurements from drones could be used to model AGB and TB estimates of these species.", 2. Materials and Methods, Biomass,2
452," LiDAR CollectionLiDAR data was collected for the study areas in August 2009 by Blom (a surveying company) using an Optech sensor (Optech Incorporated, ALTM 3100, Toronto, Canada) on board a fixed wing manned aircraft traveling at 457.2 m above the ground at a flight speed of 66.9 m·s−1 (scanning frequency of 48 Hz and pulse repetition rate of 70 kHz). Blom then created a model of the terrain, a DTM, from this data using TerraScan 9.0 (TerraSolid, Helsinki, Finland), with spatial resolution of 1 × 1 m. LiDAR horizontal and vertical accuracy was evaluated at 36 control points within the flight area, resulting in a horizontal root mean square error (RMSE) of 7.6 cm, and a vertical RMSE of 6.9 cm. Due to the age of the LiDAR data relative to the current study (2009 vs. 2015), no surface measurements of canopy height from the LiDAR were used. Instead, it is expected that there would be little change in topography over this time, making the 2009 LiDAR DTM a valid dataset for the current work. This DTM was used in all LiDAR analysis in this study, referred to as the LiDAR DTM, or the LiDAR terrain model. Image CollectionImagery was collected using a multirotor drone following the methods and equipment specifications of Dandois and Ellis [21], from 16 April 2015 to 19 April 2015. Digital images were taken with a Canon ELPH 520 (Canon Inc., Tokyo, Japan) HS point and shoot digital camera, which shot continuously at two frames per second (f·s−1) throughout the flights. Seven flights were required to capture both Block 1 (five flights) and Block 2 (two flights). Drone flight altitude was fixed to 400 m above the launch location, which was set at a nominal location and elevation within each flight area. The drone flew autonomously along a predetermined flight path at roughly 7 m·s−1, resulting in an average image resolution of 14 cm GSD. In general, flights were conducted between 09:00 and 14:00 local time to minimize the effects of sun angle and to avoid high winds and rain. Point Cloud GenerationSeveral processing steps were required prior to creating point clouds from drone images. GPS and altitude telemetry from the drone were used to provide an initial estimate of the XYZ location of each image. Due to the relatively high frame rate of the camera and high altitude, images were collected with very high forward overlap (≥ 98%), resulting in more image data than is needed so image sequences were subsampled to every 10th frame [25]. Even though image white balance and contrast were fixed before each flight to an 18% gray card in full sun, there were still differences in image quality between flights over the same locations and within flights due to passing clouds and cloud shadows. A histogram matching technique was used to minimize these effects [38]. Briefly, images were converted to the HSV (hue-saturation-value) color space, then for each image, the histogram of the value channel was normalized to that of an exemplar image manually identified to have good contrast and exposure with no cloud shadows.Normalized images were then transformed back to the RGB color space. Normalized and georeferenced images from each flight were then imported into the photogrammetry, structure from motion software Agisoft Photoscan (version 1.1.6, 64-bit) for each flight area (Block 1 and Block 2) to create 3D point clouds. This software uses computer vision photogrammetric algorithms to recognize similar features in multiple images and to simultaneously solve for their locations as well as the location and orientation of the camera at the time of image capture in 3D space ([21] for further details). After initial processing, a GeoTIFF orthomosaic (14 cm GSD) was exported from Photoscan.Additional georeferencing was performed in ArcGIS and Photoscan on the drone orthomosaic by extracting XYZ data from the LiDAR DTM for ground control points (e.g., building corners, distinct marks in the roads, small shrubs, etc.). The resulting DTM had a positional RMSE of 1.30 m for Block 1 and 1.89 m for Block 2, relative to the LiDAR DTM error. After this stage, a sparse point cloud was exported for each block for additional analysis. This point cloud, produced from drone imagery, is referred to as the Ecosynth point cloud, based on the name of the methodology used [21,22]. Digital Terrain and Canopy Height ModelsDigital terrain models were created from the Ecosynth point clouds by refining the data and then filtering the terrain. The referenced point clouds were clipped to the study area, filtered to remove any noisy points, and converted into a 1 × 1 m grid of median height values. Terrain filtering algorithms were then applied to each point cloud using MCC-LiDAR software to produce the DTMs [39]. This software applies a filter to the point cloud at different scales to estimate whether any given data point is a local low point—thus classified as ‘terrain’. The terrain points were then interpolated into a 1 m gridded raster DTM using natural neighbor interpolation in ArcGIS 10.1 (ESRI, Redlands, CA, USA). Canopy height models (CHM) were created from the Ecosynth DTM and LiDAR DTM by subtracting the underlying DTM value from the elevation of each point in the Ecosynth point cloud. These canopy height models are hereafter referred to as Ecosynth CHM and LiDAR CHM. As noted above (Section 2.2.2), due to the age of the LIDAR data, no canopy heights were obtained from LIDAR canopy surface measurements—the LiDAR CHM refers to the model derived from subtracting the Ecosynth canopy height measurements from the LiDAR DTM.A Trimble R8 differential GPS unit was used to record the locations of all the corners of the study plots via FastStatic. This was done to enable accurate plot-level spatial analysis of the canopy height models. Coordinates were processed and exported with Trimble Business Center with a median precision of 7 cm horizontal and 10 cm vertical in Block 1 and 12 cm horizontal and 7 cm vertical in Block 2.", 2. Materials and Methods, 2.2.2. Remote Sensing Measurements,2
453,"LiDAR data was collected for the study areas in August 2009 by Blom (a surveying company) using an Optech sensor (Optech Incorporated, ALTM 3100, Toronto, Canada) on board a fixed wing manned aircraft traveling at 457.2 m above the ground at a flight speed of 66.9 m·s−1 (scanning frequency of 48 Hz and pulse repetition rate of 70 kHz). Blom then created a model of the terrain, a DTM, from this data using TerraScan 9.0 (TerraSolid, Helsinki, Finland), with spatial resolution of 1 × 1 m. LiDAR horizontal and vertical accuracy was evaluated at 36 control points within the flight area, resulting in a horizontal root mean square error (RMSE) of 7.6 cm, and a vertical RMSE of 6.9 cm. Due to the age of the LiDAR data relative to the current study (2009 vs. 2015), no surface measurements of canopy height from the LiDAR were used. Instead, it is expected that there would be little change in topography over this time, making the 2009 LiDAR DTM a valid dataset for the current work. This DTM was used in all LiDAR analysis in this study, referred to as the LiDAR DTM, or the LiDAR terrain model.", 2. Materials and Methods, LiDAR Collection,2
454,"Imagery was collected using a multirotor drone following the methods and equipment specifications of Dandois and Ellis [21], from 16 April 2015 to 19 April 2015. Digital images were taken with a Canon ELPH 520 (Canon Inc., Tokyo, Japan) HS point and shoot digital camera, which shot continuously at two frames per second (f·s−1) throughout the flights. Seven flights were required to capture both Block 1 (five flights) and Block 2 (two flights). Drone flight altitude was fixed to 400 m above the launch location, which was set at a nominal location and elevation within each flight area. The drone flew autonomously along a predetermined flight path at roughly 7 m·s−1, resulting in an average image resolution of 14 cm GSD. In general, flights were conducted between 09:00 and 14:00 local time to minimize the effects of sun angle and to avoid high winds and rain.", 2. Materials and Methods, Image Collection,2
455,"Several processing steps were required prior to creating point clouds from drone images. GPS and altitude telemetry from the drone were used to provide an initial estimate of the XYZ location of each image. Due to the relatively high frame rate of the camera and high altitude, images were collected with very high forward overlap (≥ 98%), resulting in more image data than is needed so image sequences were subsampled to every 10th frame [25]. Even though image white balance and contrast were fixed before each flight to an 18% gray card in full sun, there were still differences in image quality between flights over the same locations and within flights due to passing clouds and cloud shadows. A histogram matching technique was used to minimize these effects [38]. Briefly, images were converted to the HSV (hue-saturation-value) color space, then for each image, the histogram of the value channel was normalized to that of an exemplar image manually identified to have good contrast and exposure with no cloud shadows.Normalized images were then transformed back to the RGB color space. Normalized and georeferenced images from each flight were then imported into the photogrammetry, structure from motion software Agisoft Photoscan (version 1.1.6, 64-bit) for each flight area (Block 1 and Block 2) to create 3D point clouds. This software uses computer vision photogrammetric algorithms to recognize similar features in multiple images and to simultaneously solve for their locations as well as the location and orientation of the camera at the time of image capture in 3D space ([21] for further details). After initial processing, a GeoTIFF orthomosaic (14 cm GSD) was exported from Photoscan.Additional georeferencing was performed in ArcGIS and Photoscan on the drone orthomosaic by extracting XYZ data from the LiDAR DTM for ground control points (e.g., building corners, distinct marks in the roads, small shrubs, etc.). The resulting DTM had a positional RMSE of 1.30 m for Block 1 and 1.89 m for Block 2, relative to the LiDAR DTM error. After this stage, a sparse point cloud was exported for each block for additional analysis. This point cloud, produced from drone imagery, is referred to as the Ecosynth point cloud, based on the name of the methodology used [21,22].", 2. Materials and Methods, Point Cloud Generation,2
456,"Digital terrain models were created from the Ecosynth point clouds by refining the data and then filtering the terrain. The referenced point clouds were clipped to the study area, filtered to remove any noisy points, and converted into a 1 × 1 m grid of median height values. Terrain filtering algorithms were then applied to each point cloud using MCC-LiDAR software to produce the DTMs [39]. This software applies a filter to the point cloud at different scales to estimate whether any given data point is a local low point—thus classified as ‘terrain’. The terrain points were then interpolated into a 1 m gridded raster DTM using natural neighbor interpolation in ArcGIS 10.1 (ESRI, Redlands, CA, USA). Canopy height models (CHM) were created from the Ecosynth DTM and LiDAR DTM by subtracting the underlying DTM value from the elevation of each point in the Ecosynth point cloud. These canopy height models are hereafter referred to as Ecosynth CHM and LiDAR CHM. As noted above (Section 2.2.2), due to the age of the LIDAR data, no canopy heights were obtained from LIDAR canopy surface measurements—the LiDAR CHM refers to the model derived from subtracting the Ecosynth canopy height measurements from the LiDAR DTM.A Trimble R8 differential GPS unit was used to record the locations of all the corners of the study plots via FastStatic. This was done to enable accurate plot-level spatial analysis of the canopy height models. Coordinates were processed and exported with Trimble Business Center with a median precision of 7 cm horizontal and 10 cm vertical in Block 1 and 12 cm horizontal and 7 cm vertical in Block 2.", 2. Materials and Methods, Digital Terrain and Canopy Height Models,2
457," Canopy Height and BiomassCanopy height metrics—mean, minimum, maximum, median, 25th percentile, 75th percentile, and 95th percentile height—were calculated using points from each CHM with height >0 m on a per-treatment per-plot basis (N = 56, see Supplementary Materials). These metrics were then plotted against all field heights, AGB, and TB from each CHM using both simple linear regression and linear mixed-effect models to determine which metric and model could best predict field-derived values based on Akaike information criterion (AIC). Using mixed-effect models allowed us to test whether treating the species as a random variable improved the model. The same canopy metrics were then linearly regressed against field heights, AGB, and TB for each species separately to find the best metric for species-specific predictions, again using AIC as the means for model selection. The best models were tested for significance by analyzing their p values.Visual inspection of the imagery and CHMs revealed that the maps of the plots did not capture crowns that extended outside the plot borders. To include these points in the height analysis, the plot borders were manually adjusted to include the overhanging crowns, as determined by visual inspection. Trees that crowded into the plots were similarly excluded (see Figure 2). While this process was made easier by the clear outline of plantation-style crowns, there is a corresponding level of error from manual tracing of tree crowns. Vertical Canopy ProfilesCanopy profiles were made for each CHM on a per-species basis by plotting a vertical histogram of point heights. This was done to visualize and compare each CHM’s ability to characterize the vertical canopy distributions of the studied species.", 2. Materials and Methods, 2.2.3. Data Analysis,2
458,"Canopy height metrics—mean, minimum, maximum, median, 25th percentile, 75th percentile, and 95th percentile height—were calculated using points from each CHM with height >0 m on a per-treatment per-plot basis (N = 56, see Supplementary Materials). These metrics were then plotted against all field heights, AGB, and TB from each CHM using both simple linear regression and linear mixed-effect models to determine which metric and model could best predict field-derived values based on Akaike information criterion (AIC). Using mixed-effect models allowed us to test whether treating the species as a random variable improved the model. The same canopy metrics were then linearly regressed against field heights, AGB, and TB for each species separately to find the best metric for species-specific predictions, again using AIC as the means for model selection. The best models were tested for significance by analyzing their p values.Visual inspection of the imagery and CHMs revealed that the maps of the plots did not capture crowns that extended outside the plot borders. To include these points in the height analysis, the plot borders were manually adjusted to include the overhanging crowns, as determined by visual inspection. Trees that crowded into the plots were similarly excluded (see Figure 2). While this process was made easier by the clear outline of plantation-style crowns, there is a corresponding level of error from manual tracing of tree crowns.", 2. Materials and Methods, Canopy Height and Biomass,2
459,Canopy profiles were made for each CHM on a per-species basis by plotting a vertical histogram of point heights. This was done to visualize and compare each CHM’s ability to characterize the vertical canopy distributions of the studied species., 2. Materials and Methods, Vertical Canopy Profiles,2
460,"When modeling height using all treatments from the Ecosynth CHM, we found that the most parsimonious model (see Figure 3a) is a linear mixed effect model with the median height metric as the independent variable (AIC: 194.5, see Table 1). This model took species as the random effect and assessed the model using random slopes. Median canopy height was also the best predictor of field height with the LiDAR CHM (see Table 1) but with a simple linear model (R2: 0.906, see Figure 3b). The LiDAR CHM produced significantly better models of height compared to the Ecosynth CHM, as seen by the AIC values.Again, the median canopy height metric was the best predictor of field height on a per-species basis for both canopy height models. When species-specific linear models were created, both LiDAR and Ecosynth CHMs exhibited the same order of predictive ability for species, as judged from the R2 and RMSE values (see Table 2). In order of decreasing predictability, the species are T. amazonia, D. retusa, A. excelsum, T. rosea, and P. quinata. The LiDAR CHM improved the prediction of height for each species compared to Ecosynth CHM (see Table 2).", 3. Results, 3.1. Canopy Height,3
461,"The median canopy height metric was the best predictor for both AGB and TB when examining the species together using the Ecosynth CHM. The strongest model was a linear mixed effect model that took species as the random effect and accounted for random y-intercepts (see Figure 4a,b). Using data from a LiDAR terrain model, via the LiDAR CHM, the median canopy height metric best models AGB and TB with a simple linear regression (AIC: 347.6 and 379.1 respectively, see Figure 4c,d). The LiDAR CHM improved the prediction of AGB and TB compared to the Ecosynth CHM (see Table 1).When linear models were created to predict AGB and TB for individual species, we found that the optimal height metric depended on the species and terrain model. For the drone terrain model, AGB and TB of most species were best estimated with mean and 25 percentile height metrics, and for the LiDAR terrain model, maximum and median height metrics most accurately predicted biomass. The LiDAR CHM more accurately predicted AGB and TB for every species compared to the Ecosynth CHM; except for when modeling TB for T. amazonia (see Table 2). Unlike the height models, the species-specific biomass regressions from drone and LiDAR data did not exhibit the same order of predictive ability (see Table 2).", 3. Results, 3.2. Aboveground and Total Biomass,3
462,"The vertical canopy profiles correctly capture the distinction in vertical stature between species but the LiDAR profiles better reflect the known vertical structure distribution of the species. This was determined by comparing the mean heights from the profiles of the different species to the mean heights of each species from the field data (see Figure 5a,b). For every species except for T. amazonia, the Ecosynth CHM profile overestimated field height while the LiDAR CHM provided a much closer approximation to field height.", 3. Results, 3.3. Vertical Canopy Profiles,3
463,"As expected, drone-derived point clouds more accurately predicted canopy heights during the dry season when used with a LiDAR DTM than with an Ecosynth DTM. When surveying multiple species at a time, drone point clouds, combined with LiDAR DTM, can predict plot-level height comparably to what has been measured with LiDAR point clouds and LiDAR DTMs [37,40]. Comparing the species-specific height models demonstrates that while the LiDAR CHM more accurately predicts height for all species than the Ecosynth CHM, both CHMs demonstrate the same order of predictive ability (see Table 1). Height of T. amazonia and D. retusa were predicted most accurately—with the T. amazonia models performing significantly better than any other, regardless of which terrain model was used.In terms of biomass, the LiDAR CHM more accurately predicted AGB and TB than the Ecosynth CHM for every species except for T. amazonia. The LiDAR CHM most strongly predicted A. excelsum while the Ecosynth CHM most strongly predicted T. amazonia. The species with the lowest predictive ability for AGB and TB for both models were D. retusa and P. quinata. The results also demonstrate that the Ecosynth CHM and the LiDAR CHM could predict TB with nearly identical regression coefficients to AGB models. This is an important step in carbon measurement studies because many remote sensing studies up to this point have focused primarily on AGB, disregarding a significant portion of a forest’s carbon—that which is below ground [9,41,42,43,44,45,46]. By incorporating belowground biomass into calculations, we can produce more accurate carbon estimates, and with the aid of drones, do so faster and cheaper in monoculture plantations.Both the species-specific height and biomass models demonstrate a significant difference in predictive ability between species. The Ecosynth CHM and LiDAR CHM most accurately predicted height and biomass for T. amazonia and A. excelsum, and least accurately predicted both metrics for D. retusa, T. rosea, and P. quinata. The two species with the most accurate models are both single-stemmed evergreen trees while the other three are deciduous, and one of them is multi-stemmed. These results suggest that in the steepland tropics, drone point clouds can be used to accurately measure the plot-level height of tall evergreen trees but not small deciduous ones during the dry season. This difference is likely because the structure from motion algorithms is not as effective when the drone photos contain less visible features (i.e., leaves) to identify. While other researchers have shown a distinction between leaf-on and leaf-off drone accuracy [22], this is the first study to isolate the experiments on a per-species basis using tropical timber species. This is important because many plantations in the tropics are either subdivided into mono-specific patches or are entirely monocultures [47].In every case, the LiDAR CHM produced more accurate models than the Ecosynth CHM, although the Ecosynth CHM acceptably predicted height and biomass for certain species. The most likely explanation for this discrepancy is the terrain-filtering algorithm which is used to create the Ecosynth CHM. The point cloud creation and terrain filtering processes both work best on flat ground and in areas with visible terrain [21,48,49]. In this study, many areas of the terrain were covered by ground vegetation, likely causing elevation overestimation and a source of error in both the Ecosynth and LiDAR terrain filtering algorithms [39]. As described elsewhere, accuracy can be improved by placing ground control markers, such as bright targets, to be referenced in the drone imagery [18]. In the steepland tropics, for future studies, we recommend either using ground control markers, LiDAR-derived terrain models, or GPS-based terrain models.", 4. Discussion,None,4
464,"Data collected by drones, when used with accurate terrain models, can accurately measure biomass and heights of select species in monoculture plantations. Because they are small and easy-to-operate, drones can be used in hard-to-reach locations as a field tool in mapping and monitoring plantation growth, given the right species and time of year. Because of their low cost and potential for rapid deployment, drones overcome the cost and time barriers often associated with LiDAR and field inventories. However, as we have shown, drone measurements must be used in conjunction with field-derived biomass equations, high accuracy terrain models, and GPS data collected from the field to improve survey accuracy.Canopy height metrics from drone measurements, regardless of the DTM used, can predict total biomass as well as aboveground biomass. This finding opens the door to further research into drone-based total biomass estimation, a metric that has too often been overlooked by biomass studies. Accurately calculating both above and belowground biomass of plantations and forests is a critical step in improving local and national carbon budgets.This study also demonstrates that drone point cloud data can be used with LiDAR terrain models to acquire accurate models of height and biomass for select species. In places where LiDAR terrain models are already available, drones can be used to cost-effectively re-survey plantation growth and biomass accumulation.While Ecosynth shows promise for plantation assessments, it has its limitations. The Ecosynth methodology requires a high degree of skill to process the data. New user-friendly applications though, such as ESRI’s Drone2Map (ESRI, Redlands, CA, USA) are lowering this barrier to entry. Additionally, variables such as wind, light, and camera settings can change the quality of the data (see [25] for an outline of optimal conditions).Drones, especially when used with existing DTMs, can accurately measure monoculture plantation heights but their ability to characterize all species’ heights and biomass in tropical steeplands depends on phenology, architecture, and terrain variability. The methodology can be employed rapidly and holds great promise for measuring small-scale plantations. To realize the full potential of drones, researchers should continue to test the limitations of the technology. These studies will allow resource managers to make informed decisions about the use of this technology and identify areas for future research and development. With continued study, drones can be used to deliver a degree of timeliness and cost-efficiency to plantation assessments not seen before in forestry.", 5. Conclusions,None,5
465,"Light Detection and Ranging (LiDAR) is an active remote sensing system whose output consists of a three-dimensional point cloud representing the Earth’s surface and all the objects standing on it.Starting from the 1990s, LiDAR became commercially available, thus allowing for an acceleration of its technical improvement and field applications [1,2]. Nowadays, applications involve terrestrial, airborne, and spaceborne systems and concern agriculture [3,4], geomatics [5,6], and forestry [7,8], to mention just a few. The ability of LiDAR systems to capture the complex structure of trees and forests is related to the different returns provided by the surfaces when they are intercepted by the LiDAR signal. Vegetation partially reflects and transmits the signal, so multiple returns from a single shot may occur before the last one from the ground is received. Therefore, the vertical characterization of the vegetation structures is possible [2,8,9] and LiDAR-derived data can be efficiently used to determine forest inventory parameters [10].Thanks to its features, LiDAR is complementary to or more advantageous than other methods, such as photogrammetry and ground-based data collection, for the characterization of some forest attributes. Monoscopic photogrammetry allows for coarse-scale investigations but does not provide three-dimensional information. Stereoscopy can return a three-dimensional point cloud, but this cloud just describes the upper surface of the canopy in forested areas, thus avoiding the investigation of the under-canopy vegetation structures [11]. Ground-based methods, despite providing numerous information about individual trees and tree plots, are time-consuming, labour-intensive, expensive, and circumscribed to relatively small areas [8].Forest inventories are fundamental for natural resources management. For instance, a record of the past and present status of forests can be generated on the basis of inventory parameters, and used to evaluate forest damage [12,13], plan environmental and commercial activities, and model future forest evolution [14]. Furthermore, data of forest inventory are essential for carbon accounting and fire-related risk assessment [15,16], and for the development of a sustainable bio-economy that grounds on renewable resources [2]. Forest information can be derived by LiDAR data according to two main approaches, namely the area-based and the individual tree-based approaches (see [16,17,18] for detailed information about the features, advantages, and disadvantages of the two approaches). The former approach generally predicts the mean features at the stand level (e.g., mean tree height diameter, basal area, volume, and biomass) from the percentiles of the LiDAR-derived height distribution [19,20]. The individual tree-based approach, instead, aims to collect specific information from which deriving other attributes, such as the biomass and the diameter-at-breast height, of each tree by means of existing models [21]. When the estimation parameters (area-based) or the LiDAR-derived metrics (individual tree-based) are calibrated on the basis of ground data, both of the methods generate accurate forest structural information that can support forest inventory over large areas [22,23].Within the frame of individual tree-based forest inventories, the identification of trees and the assessment of their height and position play a fundamental role as they constitute the basis to derive other tree attributes [24]. Although the literature provides a large number of works dedicated to the identification of individual trees from LiDAR data, most of the proposed methodologies rely on the adoption of similar approaches, which can be roughly classified into two families, namely the canopy height models-based (CHM) and the cloud-based approaches.Canopy Height Model (CHM)-based approaches identify the treetops by applying algorithms to the canopy height model, namely the surface model representing the top layer of canopies through its relative height with respect to the ground. This family of approaches can be further divided into classes according to their underlying algorithm: (i) the local maxima methods, which are the most frequently found in literature [12,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40]; (ii) the local curvature methods [41]; (iii) the watershed methods, which find the tree crowns through a pouring mechanism [42,43,44]; (iv) the morphological methods, which apply opening operations to isolate the tree crowns within the CHM [13,14,45], and (v) other methods, which delineate potential crown material so that the individual trees can be distinguished [18,46,47,48]. The main difference among these classes is that the former two carry out the crown segmentation after the treetop identification, whereas the latter three perform the tree identification by looking for the treetop within the segmented crown boundaries. The CHM-based approach has proven to be quite effective in very regular vegetation pattern, especially when only one layer of the tree canopy is present, and in coniferous stands. Nevertheless, this approach may provide lower-accuracy results when applied under particular conditions [37,49,50,51,52,53]: the interpolated surfaces can be affected by the noise of the LiDAR data they derive from and by the complexity of the terrain and canopy geometry so that the tree counting process can be misleading; moreover, the presence of mixed-species forests, random tree patterns, and shade-tolerant species can affect the identification process.As reported by Richardson and Moskal [50], some attempts have been made to overcome the aforementioned intrinsic weaknesses of the CHM-based approaches. For instance, the CHM has been used together with full-waveform LiDAR datasets [54], combined to a new inventory index [15] or improved by computing correlation surfaces [55,56]. Since these improvements have not led to a satisfactory rise of the accuracy [50,57], at the beginning of the 2010s, a new paradigm for treetop detection promoted the rise of the second family of approaches, labeled as cloud-based. These methods do not just work on the CHM, but on the entire three-dimensional point cloud and are further classified in: (i) the top-bottom methods, where treetops are firstly detected and then all the points belonging to the same tree are identified on the basis of tree spacing [24,50,51,52,58,59,60,61,62,63], and (ii) the bottom-top methods, where the stems are firstly detected from the lower layer and then all the points belonging to the same tree are identified while moving upwards [53,57]. To our knowledge, the only cloud-based methods that cannot be listed in the aforementioned classes were provided by Rahman and Gorte [64], Rahman et al. [65], Ferraz et al. [66], Paris et al. [67] and work either on point density or point clustering. Although the cloud-based approach generally achieves higher accuracy than the CHM-based [57], it requires a greater computational effort. Therefore, the CHM-based approach is still the most commonly adopted [44,48].The described classification is summarized by Figure 1. It grounds on the extensive, albeit not exhaustive, literature review that is reported in Table S1 of the Supplementary Material. The review begins from the 2000s, when active remote sensing devices began to be widely used in forestry [59,68], and only considers the applications of the traditional airborne discrete-return LiDAR systems, neglecting the multi-spectral e.g., [69] and the full-waveform ones e.g., [54,70,71]. Furthermore, it does not include the recent branch of Terrestrial Laser Scanning (TLS) systems. While Airborne Laser Scanning (ALS) systems provide complementary information for forest inventory in terms of tree number, areal stem density, and tree height over large areas (up to the regional scale), TLSs give high point density data and allow for three-dimensional tree reconstruction but can investigate relatively small areas (see [72,73,74,75] for further details).The tools and algorithms that have been proposed so far for the individual tree identification usually lead to more accurate results when applied to coniferous stands than to deciduous ones. This is mainly due to the particular features of coniferous trees since their conical shape makes their tops easy to identify [12,50], but it is also due to the regular pattern of coniferous stands that avoids the inaccuracies related to the presence of understory trees. Conversely, deciduous trees assume an umbrella-like shape so that their crowns are usually very rounded and tend to overlap each other. Moreover, except for the regular spatial configuration of plantations, trees in natural deciduous stands are usually located according to random patterns with a strong presence of understory vegetation, thus affecting the tree detection [30,50,57,76].Aiming to improve the individual tree detection for the case of deciduous stands, this work provides a novel, flexible, and simple tool that falls into the category of point cloud-based approaches and relies on a density-based algorithm.In the following, we describe the structure of the algorithm and assess its accuracy by applying it to twelve deciduous stands along the Orco River (Italy). Seven of these areas show regularly-arranged trees, whereas the others are characterized by trees that are randomly located. Therefore, the algorithm is tested for, respectively, more and less favorable tree configurations. The performance of the algorithm is evaluated both in terms of tree count and stem position by comparing its outcome with a tree census that was carried out by the authors in February 2019. The influence of input parameters on the presented algorithm is then investigated through a sensitivity analysis and its results are discussed. Finally, the algorithm is applied to the datasets that have undergone a re-sampling process. The evaluation of the outcome accuracy at different re-sampling rates is then used to define the minimum point density that is required for the input datasets in order to meet an overall accuracy higher than 0.70.", 1. Introduction,None,1.
466,"The study areas are located in the Orco River floodplain (Northwestern Italy, 45


°

14


′

 22.2



″


N–7


°

48


′

45.2



″


E), as shown in Figure 2a–c.The Orco River is 89.57 km long and has a catchment area of 930 km2, bounded by the Gran Paradiso National Park, the Stura di Lanzo Valley, the Vanoise National Park, and the Canavese Valley at the Northern, Southern, Western, and Eastern side, respectively. The Orco River floodplain is characterized by a low degree of anthropic activities so that the river channels and meanders can migrate over time. The study sites are located between the town of Cuorgnè and the confluence with the Po River and are occupied by stands of deciduous trees, mainly poplars (Populus alba, Populus nigra), willows (Salix alba), black locusts (Robinia pseudoacacia), oaks (Quercus robur), and hornbeams (Carpinus betulus). Some of these stands belong to commercial plantations and are characterized by well-separated trees of similar age and size and organized according to a regular pattern, such as at the study area hereinafter called 

D
2

 (Figure 2e). Nevertheless, the majority of vegetation follows the natural life cycle of the riparian forests, being populated by trees of different sizes and ages, randomly arranged, often with partially-overlapping crowns. An example of this latter case is shown by the study area hereinafter called 

D
1

 (Figure 2d). Table 1 reports the main features of the twelve study areas. No significant topographic variations are reported for the selected areas since they are generally flat or with very gentle slope (average slope range from 1 to 5 degrees except for 

D
7

, which is close to the river banks).The LiDAR data associated with these study areas were acquired on 28 February 2019 by the Italian National Council of Research—Research Institute for Geo-Hydrological Protection (CNR-IRPI) with a LiteMapper 6800 installed on a POD DART certificated by EASA with a minor/STC approval for Eurocopter AS350 Heliwest. The scanning process was designed to guarantee: (i) a raw coverage of the twelve surveyed areas equal to nine points·m



−
2


 on average; (ii) a minimal stereoscopic coverage equal to 60% and 30% for the forward and sideward overlap between adjacent swaths, respectively, and (iii) an average ground sampling distance equal to 10 cm/pixel. The scan frequency was 400 KhZ, whereas the flight height ranged between 675 and 794 m above sea level. The scan angle ranges from 4


°

 to 19


°

, approximately, for the study areas. The trajectories of the flight are shown in Figure 2f. The dataset was provided as two separate clouds for the ground and the vegetation, respectively.During the LiDAR data acquisition, the authors carried out a tree census within the study areas. The tree coordinates were taken by means of a Real-Time Kinematic Global Positioning System (RTK-GPS), model ROVER LEICA 1250, and GNSS smart antenna. The error position of this device is approximately 1.0 m when performing measurements within the tree stands because of the reduced availability of satellites for the GNSS-based positioning and the low signal from the reference station for the kinematic corrections. After the survey, the acquired tree positions were double-checked with a visual inspection of the orthophotos deriving from the LiDAR campaign.", 2. Data and Method, 2.1. Study Site and Available Data,2
467,"The algorithm is provided in Matlab® code and freely available in the supplementary material. Unlike most of the other existing methods, it does not look for local height maxima but local point density maxima, after having defined the point density as the number of the points’ projections on the plane z = 0 per unit area. The underlying assumption is that the point cloud becomes denser in correspondence with the tree center. Thus, the principles upon which the algorithm is based are that: (i) in the lower layers, LiDAR systems tend to record the highest number of returns when the signal intercepts tree trunks unless too thick understory vegetation is present, and (ii) above a certain reference height the density of tree branches is higher at the center of the crown, decreasing towards its edges. Whereas the former statement is intuitive, the latter has been confirmed by previous studies e.g., [49,64,65], which have also reported that this feature does not depend on the crown shape. Accordingly, this assumption holds for LiDAR data acquired in leaf-off conditions, such as the ones used in this work. We further checked the validity of this hypothesis, by projecting all the points of the cloud on the plane 

z
=
0

 and computing their areal density. As it can be observed in Figure 3, the density is maximum at the tree center and gradually decreases towards the tree edges.The adoption of a density-based approach allows the algorithm to overcome the limitations of the other approaches when applied to deciduous stands. The upper panels of Figure 4 provide a graphical explanation of the influence that the spatial distribution of the trees has on their detection when the local height maxima are looked for, whereas the lower panels highlight the intrinsic advantage of the density-based approaches. 2.2.1. Pre-ProcessingThe required input is a text file containing the 

{
x
,
y
,
z
}

 coordinates of the elements constituting the LiDAR point-cloud, where the vertical coordinate z must be expressed as relative height with respect to the ground. The generation of the ground surface model and the computation of the relative heights is required prior to the use of the algorithm. 2.2.2. WorkflowFirstly, the algorithm removes the outliers from the point cloud that are associated with unrealistic vertical coordinates, as well as the points lower than 1.4 m, which may be associated with shrubs, bushes, and grasses. In this way, the computational time is reduced.Secondly, for each point of the ‘cleaned’ cloud, the algorithm computes the most frequent radius, which is a proxy of the crown radius. To this aim, it sorts the inverse distances from all the surrounding points, applies the periodogram method to obtain the Fourier transform of the inverse distance signal, and switches from the space to frequency domain. The computation of the power spectral density of this signal leads to the identification of the mean spatial frequency of the points, which is the inverse of the most frequent radius.As the computation of the most frequent radius can be time-consuming for large clouds, the input file is clipped around the i-th considered point, at a distance equal to 

R
i

. Then, the algorithm determines the areal density 

D
i

 according to





D
i

=


N
i


4

R
i
2







(1)

For the i-th considered point, 

N
i

 is the number of the points’ projections on the plane z = 0 that are contained in an area of radius 

R
i

. Finally, the algorithm selects the point associated with the maximum density for each 

A
i

, and generates a list of the coordinates of the detected stems. The outcome is further refined by applying a filter that eliminates double-counting, based on the typical spacing of stems.The highest point density corresponds to the stem location, but it does not always coincide with the location of the treetop. Optionally, the algorithm detects the closest local height maximum for each stem and creates a new list of coordinates for the treetops’ location and heights. Another (optional) filter identifies trees with an apparent height close to that of other objects (e.g., fences) and decides whether to remove them on the basis of statistical considerations about the surrounding trees (i.e., comparing the mean and standard deviation of the tree heights).The algorithm’s output can be imported in Geographic Information Systems (GIS) and compared to field data, as shown in Figure 5.As further discussed in Section 4.3, the present algorithm requires two parameters to be set, namely the radius of the circular area that is used to clip the input file (i.e., 

R
i

), and the critical length for the double-counted stem filter. In this work, we set the clipping radius equal to 20 m, whereas we used an optional function, included in the algorithm, to automatically compute the latter: the critical length can be interpreted as a proxy of the typical stem spacing that can be observed in the study area; therefore, for each detected stems, the function computes the most frequent spacing with respect to the surrounding trees and then sets the critical length as the median of the resulting spacing values.The conceptual workflow of the algorithm is reported in Figure 6, whereas the technical details about the algorithm setup are reported in Appendix A.", 2. Data and Method, 2.2. Presentation of the Algorithm,2
468,"The required input is a text file containing the 

{
x
,
y
,
z
}

 coordinates of the elements constituting the LiDAR point-cloud, where the vertical coordinate z must be expressed as relative height with respect to the ground. The generation of the ground surface model and the computation of the relative heights is required prior to the use of the algorithm.", 2. Data and Method, 2.2.1. Pre-Processing,2
469,"Firstly, the algorithm removes the outliers from the point cloud that are associated with unrealistic vertical coordinates, as well as the points lower than 1.4 m, which may be associated with shrubs, bushes, and grasses. In this way, the computational time is reduced.Secondly, for each point of the ‘cleaned’ cloud, the algorithm computes the most frequent radius, which is a proxy of the crown radius. To this aim, it sorts the inverse distances from all the surrounding points, applies the periodogram method to obtain the Fourier transform of the inverse distance signal, and switches from the space to frequency domain. The computation of the power spectral density of this signal leads to the identification of the mean spatial frequency of the points, which is the inverse of the most frequent radius.As the computation of the most frequent radius can be time-consuming for large clouds, the input file is clipped around the i-th considered point, at a distance equal to 

R
i

. Then, the algorithm determines the areal density 

D
i

 according to





D
i

=


N
i


4

R
i
2







(1)

For the i-th considered point, 

N
i

 is the number of the points’ projections on the plane z = 0 that are contained in an area of radius 

R
i

. Finally, the algorithm selects the point associated with the maximum density for each 

A
i

, and generates a list of the coordinates of the detected stems. The outcome is further refined by applying a filter that eliminates double-counting, based on the typical spacing of stems.The highest point density corresponds to the stem location, but it does not always coincide with the location of the treetop. Optionally, the algorithm detects the closest local height maximum for each stem and creates a new list of coordinates for the treetops’ location and heights. Another (optional) filter identifies trees with an apparent height close to that of other objects (e.g., fences) and decides whether to remove them on the basis of statistical considerations about the surrounding trees (i.e., comparing the mean and standard deviation of the tree heights).The algorithm’s output can be imported in Geographic Information Systems (GIS) and compared to field data, as shown in Figure 5.As further discussed in Section 4.3, the present algorithm requires two parameters to be set, namely the radius of the circular area that is used to clip the input file (i.e., 

R
i

), and the critical length for the double-counted stem filter. In this work, we set the clipping radius equal to 20 m, whereas we used an optional function, included in the algorithm, to automatically compute the latter: the critical length can be interpreted as a proxy of the typical stem spacing that can be observed in the study area; therefore, for each detected stems, the function computes the most frequent spacing with respect to the surrounding trees and then sets the critical length as the median of the resulting spacing values.The conceptual workflow of the algorithm is reported in Figure 6, whereas the technical details about the algorithm setup are reported in Appendix A.", 2. Data and Method, 2.2.2. Workflow,2
470,"The accuracy for the tree count was assessed by following the same criteria adopted in the literature: the algorithm-detected trees were classified as true positive 

T
P

 if correctly identified, and false positive 

F
P

 if they do not correspond to the field-mapped ones; the trees omitted by the algorithm were instead classified as false negative 

F
N

 e.g., [51,57]. The rate of tree detection is represented by the recallr metric, its correctness by the precisionp, and the overall accuracy by the F-score F [77] that were computed as follows:





r



=


T
P


T
P
+
F
N





p



=


T
P


T
P
+
F
P





F



=
2


r
·
p


r
+
p









(2)

All of these metrics range from 0 to 1.The position error, expressed in m, was calculated as the average distance between the field-measured trees and the algorithm-detected ones.The correct shift from the stem position to the closest height maxima to define the treetops was checked by comparing the resulting stem-to-top distances with the typical values of the crown radius.", 2. Data and Method, 2.3. Accuracy Assessment,2
471,"As said above, the algorithm requires the setting of two input parameters: (i) the radius of the area to clip the input file around each element, and (ii) the critical length to detect the double-counted stems. We performed an analysis to assess the parameter sensitivity in the outcomes of the algorithm. For this purpose, we tested 10 values of the clipping radius in the range 10–100 m, and twenty values of the critical length in the range 0.5–10.0 m. In case the clipping radius exceeded the extent of the study areas, all of the input points were considered.As we mentioned in the previous paragraphs, the algorithm can optionally compute the critical length as a proxy of the typical stem spacing on the basis on the statistics of the distances among the identified stems. We tested the effectiveness of this automatic function by comparing the real spacing, obtained by site-specific observations, with the optimal spacing that emerges from the sensitivity analysis and that leads to the highest accuracy, and the values computed by the algorithm.", 2. Data and Method, 2.4. Sensitivity Analysis and the Parameter Setting,2
472,"Finally, we re-tested the presented algorithm on the same study cases but using lower resolution input data. The new datasets were obtained through the random re-sampling of the vegetation point clouds by employing the free software CloudCompare. The rate of point reduction was of 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, and 90%, corresponding to an average density of 8.1, 7.2, 6.3, 5.4, 4.5, 3.6, 2.7, 1.8, and 0.9 points·m



−
2


. This additional test allowed us to understand the influence of point density on the achieved accuracy and to define a minimum requirement for the resolution of the input LiDAR data.", 2. Data and Method, 2.5. Application to Re-Sampled Point Clouds,2
473,"Table 2 compares the real tree count with the algorithm-derived one for all the twelve areas and shows the accuracy metrics, the position error, and the main statistics of the stem-to-top distance.A scatter plot reporting algorithm detected versus field-detected is displayed in Figure 7a, with a fairly good agreement. The accuracy metrics are also reported in Figure 7b.The algorithm provided a successful tree count in eight of the twelve sites (

D
3

, 

D
5

–

D
9

, 

D
11

–

D
12

,), where the percentage error of the tree count did not exceed the 20%. The recall and precision indices were generally higher than 0.80. The mean overall accuracy of the algorithm outcomes (F-score) is 0.91. This performance is equal to or higher than the existing methods (see [57] for a summary about the achieved accuracy).In more detail, the lowest recall value was recorded for 

D
2

 (r = 0.58), where many trees are missed because of a local decrease of LiDAR points representing the bare young vegetation in the area. Some trees are represented, in fact, by very few points in the cloud (see Figure 8), therefore precluding the identification of the point density maxima. In 

D
1

 (r = 0.78), some trees were likely lost because of the intense crown interlacing, which misled the detection of local density maxima. As it will be better explained in Section 3.2, the low recall of 

D
10

 (r = 0.79) is due to the presence of two kinds of tree spatial distributions, regular and random that affected the computation of the spacing parameter and the related double-stem removal, leading to an excessive reduction of the tree number.The lowest precision value was found for 

D
3

 (p = 0.84) and 

D
4

 (p = 0.75). In 

D
3

, this is likely due to the features of the tree pattern. One portion of 

D
3

 is indeed regular, with equispaced trees that are relatively far between each other. The other portion is characterized by a random tree distribution, with very short and variable stem spacing. This aspect likely altered the algorithm’s assessment of the stem spacing that resulted in being shorter than the effective one in the former portion, thus leading to double-counting some trees. Similarly, the presence of trees of very different size in 

D
4

 affected the stem spacing computation, so that a too short stem spacing led to impair the double-stem removal.The position error of the algorithm-detected trees is similar to the error of the instrumentation used to perform the tree mapping. The largest error is recorded for 

D
1

 (1.25 m) and is likely due to the intense interlacing of the tree crowns that can move the density maxima from the stem towards the crown edges.The algorithm can detect the treetops associated with the identified stems. As Table 2 shows, the mean stem-to-top shift is always in the range [0.5–0.8 m] that is lower or close to the minimum crown radius that the literature reports for the species found in the study areas, as well as the maximum shift is largely lower than the average crown radius [78,79]. The minimum shift is equal to 0 for all the areas, meaning that there is always at least one treetop perfectly centered over the stem. These values indicate that the stem-to-top shift worked properly by identifying treetops that effectively belong to the detected stems, as also a visual inspection of results confirmed.", 3. Results, 3.1. Algorithm Performance,3
474,"The clipping radius affects the computational times, as the higher the clipping radius, the larger the analyzed area (and the number of considered points). Table 3 highlights the direct proportionality between the elapsed time and the number of points that constitute the input point cloud, where elapsed time values refer to the use of a personal computer (RAM 16 GB, processor i7-7700HQ), and the clipping radius is set equal to 20 m.Figure 9a shows the percentage time reduction of the elapsed time with the increasing of the clipping radius. A lower bound of the clipping radius must be around 10–20 m, since at least one tree must be included in the analysis. Since the accuracy is poorly affected by this quantity (see Figure 9b), a value of approximately 20 m is a fair compromise between high accuracy and low computational times for both regular and random stands.The setting of the critical length allows the algorithm to eliminate false double detection, namely the stems that are too close to each other to belong to two different plants. Therefore, it is defined as the typical spacing between stems within a stand. Figure 9c shows that the accuracy is highly dependent on this parameter. High accuracy is met for critical lengths between 2 and 6 m, which is consistent with the values observed in the study areas, as shown in columns 2 and 3 of Table 4.This result highlights that the algorithm can achieve high accuracy when the correct tree spacing is set, thus suggesting a significant site-dependency and the need for field surveys to measure it. In order to overcome this limitation, we included an optional function that allows the algorithm to quantify this parameter in the case that the average stem spacing is not known. Table 4 highlights an overall agreement between real, optimal, and computed values. A few exceptions are: (i) 

D
2

 for which computed and real spacing perfectly agree although they are not associated with the best accuracy (albeit higher than 0.80); 

D
4

 and 

D
5

, which are both characterized by a large minimum spacing (5 and 8 m, respectively). In this latter case, both the optimal and computed spacing do not match the actual spacing but the tree crown radius, nevertheless giving F-score values higher than 0.80.", 3. Results, 3.2. Sensitivity Analysis Results,3
475,"The elapsed time is directly proportional to the number of points that constitute the input point cloud (see Table 3). Consequently, the point cloud re-sampling leads to the proportional reduction of the elapsed time, as Figure 10a highlights.The F-score remains almost steady up to a re-sampling of the 80%, as Figure 10b shows. Within this range of the re-sampling rate, the slight fluctuations (never exceeding 0.1) of the F-score are related to the randomness that drives the re-sampling process. F-score increments indicate that the re-sampling led to a cleaning of the point cloud with respect to the overlapping crown, thus making the stems more evident. Analogously, F-score reductions indicate that the random point removal jeopardizes the stem identification by reducing the point density closer to the stem than at the crown edges. When the re-sampling rate exceeds 80%, the F-score drastically reduces for eight of the twelve investigated areas, whereas it increases for 

D
3

, 

D
4

, 

D
9

, and 

D
11

, which presents extremely interlaced crowns both for regular (

D
4

, and part of 

D
3

) and random (

D
9

, 

D
11

) tree patterns. In terms of point density, these results translate into accuracy larger than 0.70 for cloud as dense as (or denser than) 2 points·m



−
2


.As the F-score reduces the position error increases, therefore, the more intense the re-sampling the higher the position error, as Figure 10c shows.", 3. Results, 3.3. Re-Sampling Results,3
476,"The presented algorithm was designed to process ALS-derived point clouds. Although photogrammetry can also be used for the generation of point clouds, its products are not suitable for the algorithm’s application. Photogrammetric point clouds derive from image processing and represent the top layer of the objects that stand on the ground surface. In case of forested areas, they can be used to interpolate the canopy surface but do not provide information about the under-canopy vegetation structures and the topography [11,80,81,82], which are instead necessary for the correct implementation of the algorithm.The algorithm was not tested on Terrestrial Laser Scanning (TLS) point clouds because of the non-availability of that kind of data for the study area. However, we presume that the application to TLS may not be convenient: although the underlying hypothesis may hold (e.g., the areal point density of the cloud’s projection of the 

z
=
0

 axis is higher at the stem locations and decrease towards the crown edges), the extremely high point density of the TLS datasets could remarkably increase the computational time. For these reasons, we encourage the use of one of the method that the literature provides e.g., [72,73,74,75] when dealing with TLS data.", 4. Discussion, 4.1. Data for the Algorithm’s Application,4
477,"The presented algorithm provided a high accuracy tree count both in regular-patterned plantation and stands where the trees naturally established according to a random spatial distribution. The detection of individual trees is easier for regular stands, as the point cloud itself already indicates the potential individual elements, as occurs in 

D
12

-like areas. Nevertheless, the algorithm demonstrated good performance also in random areas, where the point cloud itself does not provide any indication of the individual trees and the visual inspection of orthophotos can be misleading, as for 

D
1

-like areas.The count error has a slight correlation to the areal extent of the study stands. In addition, the recall and precision metrics often reduce when the algorithm deals with heterogeneous areas (both in terms of spatial tree distribution and tree size or age). These results suggest that the individual tree detection may be improved by previously subdividing the study site into areas of homogeneous features according to field observations or visual inspection of satellite images and orthophotos.The mean shift from the stem to the treetop location is usually lower than the minimum crown radius of the tree species that can be found within the study areas, indicating that the algorithm correctly associates the stems with their corresponding treetops.The position error of the detected trees is generally similar to that of the instrumentation used to map the trees within the stand (1.0 m). However, it must be noted that, because of the nadir or small off-nadir scan angle and the flight conditions, the available cloud consists of point arranged almost regularly according to a three-dimensional grid. As Figure 3 clearly shows, the top view of the acquired LiDAR point clouds results in a linear pattern where the lines, perpendicular to the flight trajectory, have an average distance of 0.5 m. Therefore, an additional error of ±0.25 m should be considered in this case.The influence of the scan angle in LiDAR-derived tree structures is still debated in the literature. Some studies have indeed demonstrated that the accuracy of canopy height and other vegetation parameters decreases with off-nadir angle [83]. Large scan angles also result in shadow areas where the pulses do not penetrate adjacent tree crowns [84,85], and, generally, the higher the scan angle the lower the returns from the ground because of an increment of the tree crown projection to the near nadir crown area [83,84,86,87]. The influence of scan angle is related to the spatial configurations of the trees: it becomes stronger as the crown height exceeds the crown width (e.g., in coniferous stands) and when the number of stems per unit area decreases [87].With respect to the presented algorithm, the nadiral signal may provide fewer returns than those obtained in off-nadir conditions, as the literature suggests [88]. Although our data indicate no correlation between scan angle and point density, we note that an overall point density reduction is not expected for the performance of the algorithm unless the point density becomes lower than 2 points·m



−
2


, as shown in Section 3.3. Not even the three-dimensional point pattern seems to impact the tree count since the algorithm looks for local maxima of the areal point density by inspecting areas whose radius largely exceeds the distance between the pattern’s lines.The stand features (e.g., rounded-shaped crowns and high stems per unit areas) and the nadir or small off-nadir acquisition suggest a low influence of the scan angle in the study areas for what concerns the height accuracy. However, it is known that the LiDAR tends to underestimate the tree height [17,89], especially when the point density decreases [90,91]. The laser beam may not be intercepted by the highest branches, and this effect may be exacerbated by leaf-off conditions [92,93]. Moreover, the trees often lean while growing, thus aggravating the height underestimation. Because of the aforementioned reasons, the LiDAR-derived treetop heights that our algorithm provides should be calibrated on the basis of field measurements prior to their use, as it is common practice for LiDAR applications in forestry e.g., [17].As mentioned in Section 2, the available LiDAR data already consisted of separated point clouds for the ground and the vegetation, respectively. Moreover, the topographic flatness of the study site allowed for a straightforward interpolation of the ground surface that is necessary to compute the relative heights of the vegetation cloud. Complex topographies do not directly hamper the algorithm, which just works on the vegetation point cloud, but can indirectly impair the tree identification by affecting the classification of vegetation and ground points and the following ground surface interpolation [94]. However, despite the potential inaccuracy of ground interpolation in complex topographies, the methods to be adopted for the surface interpolation are not the object of this work and have been extensively discussed in other research e.g., [89,94].", 4. Discussion, 4.2. Achieved Accuracy and the Influence of Data Quality,4
478,"The CHM methods are highly influenced by the parameter setting. For instance, Chen et al. [32] describes their extreme sensitivity to the size of the cell window that is used to inspect the CHM and detect the height maxima. The window size, indeed, represents the main and most critical parameter to achieve satisfactory accuracy. A large window smooths the variations of canopy height and drastically reduces the detected peaks, whereas a small one can dramatically increase the number of peaks. The literature does not provide robust criteria for the window size setting and, therefore, the CHM-methods require site-specific measurements and calibration [28,30,36].The cloud-based methods need a proper parameter setting too. For instance, the tools that ground on the works of Ayrey et al. [62], Rahman and Gorte [64] identify the crown center by inspecting the point density within vertical cylinders of arbitrary size and generating a density raster that shows the density peaks e.g., [95]. The cylinder radius has to be close to the typical tree spacing, whereas the issue of the cell size setting resembles that of the CHM-based methods. Large cells excessively smooth the density raster and small ones overestimate the peaks so that the literature suggests values of the same order of magnitude of 1/(point density)0.5 [32].Similarly to the other methods, the proposed algorithm requires a set of input parameters. Nevertheless, it has the advantage to achieve satisfying accuracy (F-score > 0.70) also with the default setting. This setting comprises a clipping radius equal to 20 m that, as the sensitivity analysis highlights, does not affect the results but strongly speeds up the tree identification process. Moreover, it comprises the automatic estimation of the typical stem spacing from the point cloud features, which reduces the dependency from costly and time-consuming site-specific surveys.The default setting also includes a threshold to remove outliers above 40 m from the input point cloud. This threshold was not considered for the sensitivity analysis as its influence is negligible if realistic values are used (e.g., 40 m is the height limit for the species found in the study area). We refer the reader to Appendix A for further details.", 4. Discussion, 4.3. The Influence of the Parameter Setting,4
479,"The results shown in Section 3.3 highlight the linear relationship between computational time and input point number. The performance refers to the features of a personal computer without the implementation of parallelization techniques, and the order of magnitude of the elapsed time is that of minutes due to the relatively small size of the investigated areas. The use of the algorithm for input clouds characterized by millions of points would require long computation time. Therefore, future works will focus on its parallelization and application to large domains.The results shown in Section 3.3 suggest that the algorithm can be applied also to very low-resolution input clouds since it is able to provide F-scores higher than 0.70 also for point densities of 2.0 points·m



−
2


. This means that, in the case of large datasets, the user can re-sample the original point cloud to create one of lower density and, consequently, drastically reduce the computational effort.The chance to effectively work with low-density point clouds allows the algorithm’s user to carry out analyses of data provided by a wide range of LiDAR devices, therefore avoiding the use of expensive and advanced equipment. In addition, although LiDAR measurements for forestry purposes are often scheduled under leaf-on conditions, topographic surveys are often carried out in leaf-off conditions. This implies a few points representing deciduous trees. It is clear that, for this particular case, the capability of the presented algorithm to deal with low-density clouds becomes very important. The proposed algorithm can, therefore, analyze old point-clouds, whose density is usually lower than the most recent ones, thus providing time series of tree position and features. This information can constitute a valuable contribution to forest modeling and management.It is worth mentioning that the results indicate an increment in the position error as the point density reduces. Thus, although the re-sampling could speed up the algorithm’s computation without impairing the tree count, it should be avoided when an accurate localization of the detected trees is the main target of the LiDAR data processing.", 4. Discussion, 4.4. Cloud Re-Sampling and Low-Resolution Data,4
480,"In this work, we proposed a novel algorithm for the identification of individual trees in forest stands from three-dimensional point clouds. The algorithm is designed to process airborne LiDAR point clouds and grounds on the detection of stems according to local maxima of the areal point density. It can give the stem coordinates and the treetop height as output.The algorithm achieves high accuracy when applied to stands with both regular and random spatial tree distribution. The achieved F-score is higher than 0.70 and position error close to 1.0 m, if the input point cloud has a density of at least 2 points·m



−
2


. Thanks to its capability to deal with relatively low-density clouds, old LiDAR datasets can be also accurately analyzed, while very dense clouds can be sub-sampled to speed up the process.A sensitivity analysis highlighted the influence that the parameter describing the critical stem spacing has on the achieved accuracy. However, the algorithm demonstrated to be able to automatically compute it on the basis of statistical considerations about the geometric configuration of the detected trees. This feature allows the algorithm to also be adopted with little information about the study area.The main advantages and limitations of the algorithm are summarized in Table 5 along with the precautions that may be taken to obtain better results.Despite its simplicity, the algorithm can constitute the basis for more complex tools, such as those for crown segmentation. In addition, it may allow for the biomass estimation if coupled to GIS information about the spatial distribution of tree species and site-dependent allometric laws. There are many applications for such a coupled methodology, ranging from forest inventories e.g., [25,96] to the characterization of riparian vegetation for hydrodynamic modeling e.g., [97,98,99].Our results suggest that the accuracy of tree identification relies on the quality of the input point clouds. Although this is not a limitation of the algorithm itself, it must be considered when analyzing the region of interest. It is worth noting that the algorithm performs better in plantations and forest stands with mature vegetation since the mature trees are better represented in the point clouds and generally more spaced apart from each other. The application of the algorithm to natural stands is generally good unless the stem spacing is excessively variable or the crown is very interlaced. We also point out that the presence of high and thick brambles, as often occurs in the riparian zone, can decrease the algorithm accuracy since they may be wrongly identified as trees.Finally, we note that the algorithm was tested on LiDAR data acquired during leaf-off conditions. Because of a density-based approach, the algorithm is expected to work well in leaf-on conditions too, if applied to coniferous stands (see Figure 4). In that specific case, indeed, the underlying hypothesis (i.e., the correspondence between the maximum point density and the tree center) still holds thanks to the conical shape of these species. Future works should verify whether this hypothesis holds for point clouds acquired in deciduous stands with leaf-on conditions and whether the presence of interlacing branches or their non-symmetric distribution can mislead the stem identification, as is suggested by some authors e.g., [64] and the large position error of 

D
1

.", 5. Conclusions,None,5
481,"Forest vegetation is a major terrestrial ecosystem and can provide low-cost options to mitigate climate change. However, climate change, especially temperature change [1], has significantly influenced the distribution [2], structure and ecology [3] of forest vegetation. Understanding the distribution of forest vegetation and assessing the present and future carbon balance of forest ecosystems are of scientific and policy interest.Studies have explored the carbon storage and sequestration potential of forest vegetation in China with different models. Some used mature forests to estimate the carbon sequestration potential (CSP) of forest vegetation as a reference for the forests in China [4]. Some utilized logistic equations to estimate the biomass carbon storage at a species level in China [5,6]. Some used the data from the forest resource inventory to predict the forest vegetation carbon storage from 2005 to 2050 with a stage-classified matrix model [7]. However, these approaches cannot be used to predict future whole-forest CSP, especially under climate change. In addition, the prediction results at the national scale are not suitable for prediction at smaller scales. Therefore, other studies have been performed to focus on the regional scale in China. There had researchers used the TRIPLEX model to simulate the forest growth and carbon dynamics of the boreal and temperate forest in Northeast China [8]; however, this model is limited for modeling vegetation succession and future dynamics. Some studies have explored the carbon storage and carbon sequestration in Yunnan Province [9,10,11]. However, those studies have assumed that all forests are mature, and they have not considered the succession and distribution changes of forest vegetation. In addition, climate change causes high uncertainty, which is a key factor that regulates carbon sequestration in a forest.Bioclimatic classification schemes are commonly used to predict changes in forest vegetation distribution caused by climate change [12]. The most popular method is the Holdridge Scheme [13], but this scheme does not provide a biological interpretation of the influences of plant life forms and attributes [14]. The dynamic vegetation model [15] considers the succession and physiological responses of forest vegetation to climate change but requires abundant data and many physiological parameters [16]. General linear models (GLM), general addition models (GAM) and classification and regression (CART) [17] models have been extensively used to assess climate-vegetation relationships. Researchers compared these three types of predictive models for Fagus crenata forests (Fagus crenata Blume) in Japan and concluded that when accounting for the interactions of predictor variables, CART could explain the relationships between climate and forest vegetation distribution with greater accuracy than GLM and GAM [18]. CART models are a practical technology that can be used to explore the relationships between environmental variables and vegetation [19], and they have been used to predict plant habitat distributions [20].The Paris climate agreement aims to hold the global average temperature increase to well below 2 °C and pursues efforts to limit the temperature increases to 1.5 °C above preindustrial levels [21]. Some previous studies have suggested that the global temperature will reach the 2 °C increase between 2026 and 2060 [22]. Increasing temperatures affect forests by changing their geographical distributions [23] and exhibit dominant control over the natural distribution of forest ecosystems [24]. Temperature increases will change the regeneration capacities [25] of species and therefore alter the area of suitable habitat of forest vegetation. Changes in the forest distribution area entail changes in the forest biomass and hence changes in the CSP. Predicting how forest distributions respond to ongoing and anticipated global warming is a challenge with great ecological relevance [26]. Forest vegetation is characterized by large biomass carbon stocks that are vulnerable to both biological and non-biological factors [27]. Temperate and high-latitude forests have been shown to be carbon sinks; however, the carbon balance of subtropical forests has been less well studied [28]. Achieving an understanding of the current and potential future role of forest sequestration is required by international negotiations and is very important for both managed and unmanaged forests [29]. However, to date, few studies have investigated the potential impacts of further temperature increases on the distribution and carbon sequestration of natural vegetation. Yunnan Province is one of the most climatically and biologically diverse areas in the world and has been noted to be sensitive to climate changes [2]. The landform, climate, ecosystem, and species diversity of the province are higher than in any comparably sized region in China. In this study, the space-for-time method based on climax theory was adopted, which hypothesizes that forest vegetation ultimately reaches a climax status by succession [30]. A spatial modeling approach based on a statistically derived bioclimatic factor is used to predict and understand the vegetation distribution and CSP of projected temperature increases within Yunnan Province. Our objectives are as follows: (1) determine the changes in forest vegetation distribution with temperature increases in Yunnan Province and (2) evaluate the responses of carbon storage and sequestration potential in forest vegetation in Yunnan Province to temperature increases.", 1. Introduction,None,1.
482,"Yunnan Province is located in Southwest China between 21°08′32″–29°15′08″ N and 97°31′39″–106°11′47″ E. It is situated at the meeting point of three geographic regions: the eastern Asia monsoon region, the Tibetan Plateau region and the tropical monsoon region of southern Asia and Indo-China. The province has topographic complexity, with a large altitudinal range of 76 to 6740 m. Yunnan Province spans only 8° in latitude but exhibits all of the climate zones and land ecosystem types of China [31]. The climate is generally mild with a long growing period. There are cold winters at the higher elevations in the northwestern mountain regions, moderate temperatures in the middle plateau region, and tropical, hot and humid conditions at the lower elevations and valley bottoms in the southern region [32]. Yunnan’s rich ecosystems comprise over 30 ecosystem types according to the Chinese classification, which span from the lower tropical valleys and basins in the southern part to the barren high peaks and deep valleys in the northwestern part [33]. The ecosystems of Yunnan Province are sensitive to environmental change and are less stable than those in temperate zones [34].", 2. Materials and Methods, 2.1. Study Area,2
483,"We selected six bioclimatic factors from the WorldClim dataset: annual mean temperature (TMA, °C), mean temperature of the warmest quarter (TMS, °C), minimum temperature of the coldest month (TMW, °C), annual precipitation (PRA, mm), precipitation of the warmest quarter (PRS, mm) and precipitation of the coldest quarter (PRW, mm). The resolution of all datasets is 1 × 1 km. TMS is a measure of the effective heat required for plant growth. TMW is a measure of extreme cold, which controls the altitudinal and northern range limit of evergreen broad-leaved forests [35]. PRS and PRW are measures of water supply during the growing and winter seasons, respectively. By performing paired samples t-tests, we confirmed that there were no significant differences between the WorldClim dataset and the dataset derived from 134 climate observation stations in Yunnan [36].In this study, we investigated different climate change scenarios of air temperature due to anthropogenic influences based on the current climate background. Precipitation has not changed significantly over the past several decades in southwestern China [37]. As the temperature increases in the future, the change in precipitation is not sure [38]. Therefore, we considered the influence of temperature increases only. Here, we considered temperature (TMA, TMS and TMW) increases from 0 to 2 °C at 0.5 °C intervals with no changes in precipitation in each scenario.We set up a vegetation database by combining field investigations with remote sensing identification. We drew a vegetation map based on remote sensing images from the Advanced Land Observing Satellite (ALOS) from 2008 to 2011 (Table 1), in the Albers equal-area conic projection and Krasovsky datum. We used the 1:50,000 topographic map for geometric correction of remote sensing images.We were building the 1 × 1 km grid to resample vegetation data which was drawn from ALOS remote sensing by ArcGIS 10.2 (ESRI Inc., Redlands, CA, USA). The longitude and latitude records of the cells were taken from this map, which yielded the same spatial resolution as the climate data. A 10 × 10 km grid and global positioning system (GPS) point layer were built for accuracy tests. The Beijing 54 coordinates were adopted in all layers and subsequent processes. The 1 × 1 km spatial resolution was used to combine these data. The accuracy of the two methods was tested using the 10 × 10 km geographic grid point and the GPS point that was recorded in the field investigation and not used for interpretation. When assessing the accuracy by using the 10 × 10 km grid, we evaluated whether the altitude and image characteristics of the point matched the vegetation type. When testing the accuracy by using the GPS point, we determined whether the vegetation type was consistent with that recorded within a 0.25 km buffer area of the point. The validation results indicated that the vegetation map was highly accurate [39,40]. Thus, the vegetation map was used for the geographic distribution of vegetation data in Yunnan Province. In this study, we chose 7 dominant vegetation types, which are shown in Table 2.", 2. Materials and Methods, 2.2. Climate and Forest Vegetation Data,2
484,"A CART model is built using the binary recursive partitioning method, and the results are a simple binary tree structure. Each branch of the binary tree represents a test result. CART models are a practical technology that can be used to explore the relationships between environmental variables and vegetation [41] and have been widely used to predict the distribution of plant habitat [20]. Minimum Gini coefficient values are used to evaluate the attributes of the model. A smaller Gini value indicates a higher “purity” of the samples and better divided results. The CART algorithm builds a tree before pruning, and the accuracy is often higher than that of the multi-tree algorithms because the binary tree cannot easily generate data fragments. Therefore, the CART model uses binary recursive partitioning and utilizes Boolean tests at the branch nodes. If a condition is met, then the sample is divided into the left branch; otherwise, the sample is divided down the right branch, and a binary decision tree is eventually formed.We obtained the spatial vegetation data by encoding the forest vegetation and 1 × 1 km grid samples. We established the CART model by using the “Tree” program in R3.3.3 software (University of California, Berkeley, CA, USA). All climate-vegetation sampling data were divided into two data sets, one for validation and another for testing. The model was built using 70% of the data that was randomly selected; the rest of the data were used for pruning. Overfitting may occur during the modeling process; therefore, we used cross-validation rules to eliminate the least important tree using the “prune tree” function on the final model.The area under the curve (AUC) derived from receiver operating characteristic (ROC) analysis was calculated to validate the performance of the CART model. The AUC values were interpreted for model accuracy using the following standards: 0.90–1.00: excellent, 0.8–0.90: good and 0.7–0.80: fair [42]. We divided the habitats into three categories: non-habitats, marginal habitats and suitable habitats, and the occurrence probability thresholds were obtained from the ROC analysis [43]. The areas where the predicted probability of occurrence was less than a low occurrence probability (0.01) were defined as non-habitats; the areas where the probability was equal to or greater than 0.01 but smaller than the optimal threshold were defined as marginal habitats; and the areas where the probability was greater than the optimal threshold were defined as suitable habitats. In this study, we selected the suitable habitats as potential habitats. It has been proved that climate factors can be used to build CART models [36].", 2. Materials and Methods, 2.3. Description of the CART Model,2
485,"Using the Forest Identity concept [44], the area of forest vegetation (S, ha), the mean aboveground biomass (Wa, Mg/ha) (Table 3) and the forest vegetation biomass (W, TgC) can be linked using Equation (1).


W = Wa × S


(1)

The forest carbon storage was based on the biomass in the study area and was calculated according to the different forest carbon sequestration rates. We used a conversion coefficient of 0.5 [52] (the carbon content of per gram of dry matter) to calculate the forest carbon storage. We obtained the forest carbon storage by multiplying the carbon density by the forest vegetation distribution area. Suitable habitat and actual carbon storage were calculated by the following formula:

Wc = 0.5W


(2)


where Wc is forest carbon storage (TgC), W is the vegetation biomass of the forest (TgC), and 0.5 is the conversion coefficient.We simulated the habitat area suitable for forest vegetation by using the CART model. We obtained the carbon sequestration potential (CSP) by subtracting the carbon storage of suitable habitat from the actual carbon storage:

Wp = Wsui − Wact


(3)


where Wp is the CSP (TgC), Wsui is the carbon storage of suitable habitat (TgC), and Wact is the actual carbon storage (TgC).", 2. Materials and Methods, 2.4. Calculation of CSP,2
486,"The AUC values are greater than 0.8 and less than 0.9 for all simulation scenarios. Deviance-weighted scores (DWS) were applied to evaluate the contributions of each predictor variable to the model (Table 4). TMW was an overwhelmingly potent factor among the six climate variables, indicating that extremely cold temperatures in a year play a decisive role in the broad-scale distribution of the forest vegetation in Yunnan Province. TMS, PRS and PRW also affected the distribution to a small extent. TMA and PRA showed no contribution; thus, these variables are not shown in Table 4.", 3. Results, 3.1. Prediction Accuracy and Contribution of Climate Variables,3
487,"The map of the vegetation in Yunnan Province (Figure 1) shows that the main forest vegetation area in Yunnan Province was 1.86 × 107 ha and that the forest coverage was 48.63%. The TCC and CTC types had small distribution areas and coverage. They were mainly distributed in northwestern Yunnan. The areas of TCC and CTC were 7.10 × 105 ha and 1.35 × 106 ha, respectively, and accounted for 1.85% and 3.52% of Yunnan’s land area, respectively. WHC was mainly distributed in Pu’er District and had an area of 1.94 × 106 ha. MHEB had the smallest area (3.79 × 105 ha) among the forest vegetation types and was mainly distributed in mountainous areas with higher elevations in Yunnan; MHEB accounted for 0.99% of Yunnan’s total land area. MEB was mainly distributed in southern Yunnan and had an area of 3.16 × 106 ha. The SEB and WTC forests were intermixed and had the largest distributions, being spread throughout the central region of Yunnan. The areas of SEB and WTC were 1.47 × 106 ha and 9.62 × 106 ha, respectively, and accounted for 3.84% and 25.11% of the land area, respectively.", 3. Results, 3.2. Distribution Area of Current Forest Vegetation,3
488,"Under the T0.0 scenario, the forest vegetation ultimately reaches a climax status by succession. The entire forest area in Yunnan Province increased by 130.42% compared with the current forest vegetation distribution area. The vegetation distribution areas of the 7 selected forest types all increased under this scenario, especially WHC, which increased by 572.30%. As the temperature increased, the distribution area of all forest vegetation types (except WTC) decreased to varying extents (Table 5). The distribution area of WTC increased by approximately 30% in all of the simulation scenarios. When the temperature increased from 0.5 °C to 1.0 °C, the distribution area of MHEB decreased significantly. When the temperature increased from 1.5 °C to 2.0 °C, the distribution area of WHC decreased significantly. SEB was the forest type most sensitive to temperature, with its distribution area decreasing by more than half with a temperature increase of 0.5 °C (Figure 2). In general, the mean forest distribution area first increased and then decreased with increasing temperature. When the temperature increased by 2 °C, the mean forest distribution area in Yunnan decreased by 11% (Table 5).", 3. Results, 3.3. Potential Forest Vegetation Distribution,3
489,"The total current actual carbon storage of the seven types of forest vegetation in Yunnan Province was 871.14 TgC. Among the forest types, MEB and WTC had the highest levels of actual carbon storage due to their large distribution areas, with values of 205.42 TgC and 172.72 TgC, respectively. Although MHEB has the highest mean biomass, it had lower actual carbon storage, with a value of 75.93 TgC. TCC had a high mean biomass, but because of its small distribution area and coverage, it had the lowest value (56.40 TgC) of actual carbon storage among the forest types. In contrast, WTC had a low mean biomass but a wide distribution, resulting in a high value of actual carbon storage. SEB, WHC and CTC had intermediate levels of actual carbon storage, which were 99.91 TgC, 137.78 TgC and 122.98 TgC, respectively. The total actual carbon storage in coniferous forests was 489.88 TgC, accounting for 56.23% of the total.Overall, the CSP of the seven types of forest vegetation in Yunnan Province increased and then decreased as the temperature increased. In particular, the CSP decreased sharply from 1059.19 TgC to 647.24 TgC when the temperature increased by 2 °C. On the whole, the forest vegetation exhibited the largest CSP (1114.82 TgC) when the temperature increased by 0.5 °C. The different forest vegetation types in Yunnan Province showed varying increases in carbon sink ability as the temperature increased except SEB, which exhibited a negative CSP value. Among the forest types, WHC and WTC exhibited the largest CSP values when the temperature increased. The results show that incremental warming of 2 °C will sharply decrease forest carbon sequestration in Yunnan Province. Much of the observed decrease was due to WHC, which showed a decrease in CSP from 734.52 TgC to 234.96 TgC (Table 6).", 3. Results, 3.4. Carbon Storage and CSP,3
490,"The AUC values of all models were greater than 0.8 and less than 0.9 in all simulation scenarios (Table 5). The high accuracy of the model suggested that the distribution of vegetation at the province scale can be explained by climatic variables. The accuracy of the carbon density estimate is very important and should be discussed. Although future vegetation distributions were predicted by the CART model under a rising temperature scenario, the present carbon density values were used to calculate the future carbon storage in Yunnan Province in this study. However, this method is not entirely accurate because carbon density in the future will change under future climate conditions [53,54]. Carbon sequestration depends on both vegetation composition and the climate [53]. Although the past and future vegetation compositions may be similar to the present composition, they may have different carbon densities under different future climate conditions [55]. Hence, the application of the modern carbon density database [56] might underestimate or overestimate past and future terrestrial carbon storage values. Thus, changes in carbon density under future climate conditions could have a significant impact on the estimates of carbon storage in Yunnan Province. In this sense, new approaches, such as dynamic global vegetation models (DGVMs) that couple biogeography and biogeochemistry models are encouraging [57] because they consider the effects of changes in both the climate and atmospheric CO2 concentrations on both vegetation redistribution and carbon density [53]. ", 4. Discussion, 4.1. Model Accuracy Test,4
491,"The carbon density of the forest vegetation in Yunnan Province was 84.69 Mg/ha, which was twice the average carbon density in China (41.32 Mg/ha) [58], similar to the worldwide average carbon density (86.00 Mg/ha) [59] and greater than the subtropical forest carbon density (66–77 Mg/ha) [60]. These results can be interpreted as follows. First, the forest cover in Yunnan Province is high and mostly consists of mature coniferous forest vegetation [4]. Furthermore, the International Biosphere Project (IBP) may have overestimated worldwide forest carbon storage because of an insufficient number of sampling sites [61]. The vegetation carbon storage in the forests of Yunnan Province was approximately 871.14 TgC, which was 14.9% of the total forest vegetation carbon storage in China (5.85 PgC; Fang et al., 2007) and 0.24% of the worldwide forest vegetation carbon storage (360 PgC; Pan et al., 2011). The main reason for this difference was that the other studies used the national forest inventory data to estimate carbon storage, which led to the underestimation of the forest vegetation distribution area. In addition, differences in vegetation classification schemes and estimation methods result in different carbon storage estimates. The forest vegetation in Yunnan Province is a large carbon sink in China and plays an important role in the world.", 4. Discussion, 4.2. The Status of Forest Vegetation Carbon Storage in Yunnan,4
492,"The successful simulation of the distribution of forest vegetation under different climate conditions achieved here is partly attributable to the accurate simulation of the relative distribution of forest carbon. Previous studies have indicated that temperature is the main factor that affects forest vegetation carbon storage in China, the Midwestern United States [62], Russia [63], Canada, and the Netherlands [64], among other places. The effect of temperature differs among places and vegetation types. Temperature increases have been found to increase forest carbon storage in colder and wetter ecoregions [65] but reduce the rates of net above-ground biomass increases in the Amazon rainforest [66] and the growth rates of mature rainforests [67]. Rising temperatures affect forest carbon storage in two ways. First, rising temperatures alter vegetation types [68] and vegetation boundaries [69] and can transform coniferous forest regions into broad-leaved forest regions [68]. Second, rising temperatures increase species diversity [70], which reduces the sensitivity to temperature and influences CO2 and energy exchange [71]. A temperature increase of 4 °C will increase the absorption and saturation of CO2 in forest vegetation [72]. Forests respond positively to the influences of rising temperatures [73,74], and temperature increases have positive effects on forest growth and wood production in the short-to-medium term [75]. In turn, stand age has an influence on forest carbon storage. With increasing stand age, the carbon storage of forest increases quickly, then reaches a maximum value [76]. At last, the carbon storage of forest decreases to a relatively stable level because of the limit of hydraulic resistance [77], and the growth of wood becomes extremely slow or is almost not change [78]. Future studies can consider further the effect of stand age.In Yunnan Province, the forest distribution area changed by 5.74%, 3.30%, 5.31% and −11.10% when the temperature increased by 0.5, 1.0, 1.5 and 2.0 °C, respectively. The total amount of carbon sequestration in the worldwide forest is approximately 360 PgC [32], and the CSP of mature forest constitutes 49.32 to 58.37% of total forest CSP [78]. Among forest types, subtropical forests have higher CSP [4] but are more sensitive to temperature changes. The carbon sequestration rate of coniferous forests is more impacted by climate change than is that of deciduous forests [79] in subtropical regions. Much of the coniferous forest vegetation in Yunnan Province is mature vegetation [4] and is easily affected by rising temperatures (Table 5). Temperature increases from 0 °C to 1.5 °C did not have severe impacts on the CSP of the forests in Yunnan Province. However, a temperature increase of 2 °C resulted in sharp decreases in the CSP of coniferous forest vegetation (Table 6). This result indicated that the CSP of mature forest vegetation was more easily influenced by temperature increases than broad-leaved forest vegetation. Mature coniferous forests are mainly distributed in the Hengduan Mountains of northwestern Yunnan Province. In this region, the mean annual temperature over the last two decades has increased at a rate of 0.6 °C/10 year, and the vegetation distribution has changed in the past [80]. In conclusion, rising temperature has impacted the CSP in Yunnan Province by affecting the mature forest vegetation, especially coniferous forest vegetation. In this paper, we hypothesize only that the forest is balanced with current climate conditions, and the forest will develop to the climax. At last, the places where are uitable for forest growth will full of this kind of forest vegetaiton in turn. With the development of forest vegetation, the CO2 will increase and have fertilization effects [81], revealing underestimates of forest carbon storage in our projections. However, nitrogen limitation is a driving factor of the forest carbon storage responses to elevated CO₂ [82]. It suppresses the positive vegetation response to enhanced CO2 fertilization [83], and this same limitation effect has been observed in a grassland ecosystem [84]. Other problems are anthropogenic effects, because the need for cropland will lead to over-estimates of the carbon sink and coupling effects of temperature with other climate factors. In this study, the influence of temperature change was taken into consideration, and there was a gap between it and the actual effect. Future studies can consider the comprehensive effect.", 4. Discussion, 4.3. The Effects of Temperature Increases on Forest Vegetation Carbon Storage and CSP,4
493,"The warm-hot coniferous forest had the highest CSP in Yunnan Province under each simulation scenario except the temperature increase of 2 °C (Table 6). These results are similar to those obtained in India, that noted that the total forest biomass and carbon pool of Pinus kesiya forest were greater than those of other pine forests studied in other regions of the world [85]. In the present study, the forest distribution area was found to change by −5.83%, −4.89%, −5.83% and −59.76% when the temperature increased by 0.5, 1.0, 1.5 and 2.0 °C, respectively. The main species composition was P. kesiya which can occupy a variety of habitats and is mainly distributed in Southwestern Yunnan Province [86]. In the distribution area, the annual precipitation ranges from 1000 to 1500 mm, the relative humidity reaches 80%, and the elevation ranges from 600 to 1950 m [87]. P. kesiya trees have rapid growth [88] and strong natural regeneration ability. The average carbon sequestration rate of P. kesiya is 12.7 Mg C ha−1 yr−1 in the Philippines [88]. If P. kesiya and Pinus yunnanensis share the same habitat, the two species exhibit converging development [87]. The emission-reduction effect of the P. kesiya afforestation project in Yunnan Province has been pronounced [89]. ", 4. Discussion, 4.4. The CSP of Warm-Hot Coniferous Forest,4
494,"Classification and regression tree models are capable of modeling the distribution of forest vegetation, especially suitable habitat and the carbon sequestration potential under changing climatic conditions. Based on the simulated results, several conclusions can be drawn. The carbon sequestration potential of coniferous forests is more strongly influenced by temperature increases than the carbon sequestration potential of deciduous forests. Temperature increases can influence the carbon storage and carbon sequestration potential in Yunnan Province. Warm-hot coniferous forests have a large current carbon storage and carbon sequestration potential, and this vegetation type is especially sensitive to temperature increases of 2 °C compared with other forest vegetation types. However, warm-temperate coniferous forests have the largest distribution area, and the carbon sequestration potential will increase when temperatures increase by 2 °C. The carbon sequestration of semi-humid evergreen broad-leaved forests is most sensitive to temperature increases, and it will decrease when temperatures increase by 0.5 °C. Overall, the forest vegetation in Yunnan Province has high carbon density, carbon storage and carbon sequestration potential. Temperature increases of 2 °C will sharply decrease the carbon sequestration potential of the forests in Yunnan Province.", 5. Conclusions,None,5
495,"Global climate change has been projected to reduce global net primary production (NPP) and carbon stocks from soil [1], and has become a global threat to humans. To date, tremendous efforts have been made to reduce the impact of global climate change, for which the control of greenhouse gases (GHGs) emissions has become a popular solution [2]. Such an effort could be more effective if supported by increased reforestation, as tree species and all chlorophyll plants are important for mitigation purposes, since leaves capture CO2 from the atmosphere, and combine it with water and energy from the sun to produce carbohydrates, a well-known process called photosynthesis that is critical for the carbon cycle [3,4].To understand the role of photosynthesis in the carbon cycle, a comprehensive study of the dynamics of photosynthesis parameters is necessary. The proposed model by Farquhar et al. [5] has become a basic tool for assessing the photosynthetic capacity of each species [6]. Its two critical parameters, the maximum rate of rubisco carboxylation (Vcmax), and the maximum rate of photosynthesis electron transport (Jmax), are essential to the model, and are, thus, important to understand the exchange of carbon between the atmosphere and the terrestrial ecosystem [7].Conventional approaches to obtain information on these two parameters usually involve long-term field work, even for one leaf sample [8,9], and can only be done on a small scale due to the time-consuming and highly labor-intensive work required. Alternatively, the approach of utilizing remote sensing information has increasingly attracted attention, and may potentially be used for estimating plant physiological, biochemical, and biophysical properties [10,11].The utilization of remote sensing information generally involves two common approaches: empirical ways based on multispectral or hyperspectral information obtained from satellites, such as Hyperion, TianGong-1, EnMAP (Environmental Mapping and Analysis Program) and HyspIRI (Hyperspectral Infrared Imager) [12], or a radiative-transfer-model-based inversion like using SCOPE (Soil Canopy Observation, Photochemistry and Energy fluxes) [13], 4-Scale [14], or ProSAIL (Prospect + Scattering by Arbitrarily Inclined Leaves) [15]. However, most of the currently available radiative transfer models (RTMs) have not included photosynthesis parameters, especially Vcmax and Jmax, as input variables, meaning that they are impossible to retrieve inversely. As an exception, the SCOPE model incorporated both radiative transfer and physiological processes, with Vcmax as one of the dozens (more than 30) inputting parameters [13,16]. Recent work by Camino et al. estimated Vcmax in wheat phenotyping trials using airborne hyperspectral-based solar-induced chlorophyll fluorescence (SIF) retrievals through SCOPE model inversions [17]. Their work involved the determination of numerous parameters, including the meteorological, leaf biophysical and structural parameters, leaf inclination angle distribution function (LIDF) parameters, and the broadband incoming shortwave radiation. As SCOPE is a very complex model, which has integrated different modules, the parameterization complexities can induce large errors in its application [16,18]. In addition, rather than obtained directly from reflectance, Vcmax used for the model was estimated from a previously established relationship with SIF. Therefore, directly remote sensing retrieval of physiological parameters to date has relied more on empirical approaches.Since Rouse et al. proposed the popularly applied normalized difference vegetation index (NDVI) [19], the empirical approach has been widely followed and a number of indices have been developed for diverse purposes, including Gamon et al.’s photochemical reflectance index (PRI) [20] for physiological parameters [21,22,23,24,25]. To date, a large number of indices have been developed to fulfill the needs for monitoring and assessing plant structural and biochemical aspects [26,27,28], and most of the well-known indices reported were developed in multispectral information but with certain adjustments, such that these indices could potentially be used for hyperspectral reflectance. However, even though the use of vegetation indices for a quick assessment of photosynthesis or photosynthetic parameters has been attempted in several previous works [29,30,31,32,33], no consensus has yet been reached [34], and is dramatically behind the indices for structural or biochemical parameters. Furthermore, the few reported indices are generally only applicable to a specific area and specific forest stands depending on the condition for the index developed, or for specific leaf groups [35]. Our previous efforts to filter a universal index to trace photosynthetic parameters failed and no hyperspectral index has ever been applicable, especially for trees in alpine deciduous forests.The aim of this study, therefore, is to develop a robust index for tracing photosynthetic parameters using hyperspectral information for alpine deciduous forests. We used a dataset composed of six species that dominate in the habitat of the alpine temperate forest in Japan. The dataset includes synchronous measurements of photosynthetic parameters (Vcmax and Jmax) and reflectance from two distinctive leaf groups, sunlit leaves, and shaded leaves of each species. A downscaled dataset is also attempted to investigate the possibilities of using satellite-borne hyperspectral data for future assessment.", 1. Introduction,None,1.
496,"The study site is located in Nakakawane, one of the forestry research facilities of Shizuoka University (35°04′ N and 138°06’ E, Shizuoka Prefecture, Japan). The land cover in this study site is a deciduous temperate forest, dominated by Acer shirasawanum Koidz. The elevations vary from 390 to 1560 m with an annual precipitation of approximately 2153 mm. Meanwhile, the annual mean temperature is around 17 °C [36]. The location of this site is shown in Figure 1.", 2. Materials and Methods, 2.1. Study Site,2
497,"A detached leaf sampling strategy has been followed in this study [37,38]. Leaf samples were collected in the years 2014, 2015, 2016, and 2018. All samples were taken pre-dawn by cutting the leaves from the branches and re-cutting underwater and were transported as soon as possible from the field to the laboratory under dark conditions. Measurements were taken with the dark-adapted leaves as soon as possible (no later than three days maximum) after the leaf samples were collected.Gas exchange measurements were made for each sample following the standard method [8]. The LI-6400 (LI-COR Bioscience Inc., Lincoln, NE, USA) equipped with a leaf chamber was used. For dark-adapted samples, we took light response curves first in 2018, starting from a PAR (Photosynthetically Active Radiation) level of 0 μmol·m−2·s−1 and an ambient CO2 (Ca) concentration of 400 μmol mol−1. After all the graphs became stable, we gradually tuned the PAR to 100, 200, 400, 700, 850, 950, and 1000 μmol·m−2·s−1 for about two minutes each to reach stably. The A/Ci curve (net CO2 assimilation rate, A, versus calculated substomatal CO2 concentration, Ci) measurements were made after having obtained the light saturation points from the light response curves. However, for the years from 2014 to 2016 light response curves were not taken regularly, the A/Ci curve measurements were made with the PAR set to 1000 μmol·m−2·s−1, a light-saturated point as determined from previous light response curves. Then we decreased the Ca concentrations gradually from 400 μmol·mol−1 to 300, 200, 100 (but to 300, 250, 200, 150, 100 in 2018), and then finally to 50. Each step took about 2 minutes to stabilize. After that, we gradually increased the Ca back to 400 μmol mol−1, and then to 1200, 1500, 1800 in 2014-2016 while to 550, 650, 750, 850, 1000, 1200, 1500, 1700 in 2018, before finally reaching 2000 μmol·mol−1. The A/Ci curves were fitted using the plantecophys package [39] in R software [40] for Vcmax and Jmax.For each sample, once the gas exchange measurements finished, leaf scale reflectance was immediately taken using a field spectrometer (Analytical Spectral Devices Inc., Boulder, CO, USA) equipped with a leaf clip. Reflectance measurements were done with both white and dark backgrounds, repeated three times for each measurement. The average values of the three repeats were used for further analysis.The dominant species in our study site is A. shirasawanum, which has unique leafy periods. This species comes into leaf earlier than other species but matures at the almost same time as the others and has a longer leaf senescence period. On the other hand, one of the target species in this study is Fagus crenata. This species is native to Japan and is categorized as an endemic Fagus species from Japan together with Fagus japonica. The species is usually widespread and even the dominant tree of Japanese deciduous forest. In total, six species were used for this study. The list of species is presented in Table 1. These species were all easy-to-access trees surrounding the towers. Shaded and sunlit leaves were taken from each species separately, and their positions were recorded. Only mature leaves were used for this study (from June to the middle of September in each year). This is also to eliminate outliers, since a typhoon hit the study site at the end of September 2018. An exception was only found for A. shirasawanum since the species has a longer leaf senescence period and suffered more serious stress from the typhoon than the other species. Therefore, we excluded all September data from each year of measurements for this species. However, for the year 2017 only F. crenata was measured. The dataset used in this study finally contained 170 leaf samples (Table 1). Besides F. crenata and A. shirasawanum, the other four species have a small number of leaf samples due to the small number of trees within our study site.", 2. Materials and Methods, 2.2. Measurements and the Dataset,2
498,"We collected a number of reported indices to validate their applicability for estimating photosynthetic parameters. The results were also compared with the new indices developed in this study. We tested a series of well-known vegetation indices of hyperspectral remote sensing. The formulae of the reported indices are shown in Table 2.The wavelengths used for the Moderate Resolution Imaging Spectroradiometer (MODIS)-like indices were 858 nm for NIR (near infrared) and 645 nm for red. We also tried another combination of using the center Sentinel 2A wavelengths, in which the NIR was 833 nm and the red was 741 nm (vegetation red edge, Band 6). The reported indices were examined for their original reflectance form only.", 2. Materials and Methods, 2.3. Reported Indices,2
499,"Several reported index types were used in this study for developing new indices, including the given wavelength (R), simple ratio (SR), wavelength difference (D), a normalized difference (ND), and inverse differences (ID). Besides these five types, we also included the double differences (DDn), modified simple ratio 1 (mSR1), modified simple ratio 2 (mSR2), modified normalized difference (mND) and modified inverse differences (mID) to the list (Table 3). Furthermore, all types using original reflectance, first-order derivatives spectra and apparent absorption were screened to identify the best index and the best type of reflectance forms. The first-order derivatives and apparent absorption spectra were used to reduce background noise and the possibilities of overlapping spectral features [45,46]. The calculations of the first-order derivatives and the apparent absorption spectra are listed in Equation (1) and Equation (2), respectively.





1

st




Der



λ
n




=


(


R


λ
n
+
1






−
R




λ
n
−
1




)

/
2




(1)






 
Abs
=
log


(


1


R


λ
n






)





(2)

The value of Rλn was the original reflectance value at wavelength λn.In addition, we also examined the consistency of the developed indices with different spectral resolutions. This was done by downscaling the original spectral resolution to 5 nm, 10 nm, 20 nm, and 50 nm, with the purpose of investigating the possibilities of applying the developed indices using airborne or satellite-borne data. The screening was done using the MATLAB software (The MathWorks, Inc.).", 2. Materials and Methods, 2.4. New Indices Development,2
500,"The premier criterion used in this study to evaluate the performance of an index is the ratio of performance to deviation (RPD) (Equation (3)) to observe the goodness of fit. It is expressed as a ratio of the standard error in prediction to the standard deviation of the samples. The RPD is calculated as follows:




RPD
=



SD


SEP






(3)


where SEP is the standard error prediction and SD is the standard deviation of photosynthetic capacity (Vcmax or Jmax).Based on the RPD results, the indices are then categorized into three different groups (A, B, or C). The category of each group refers to Chang et al. [47]. Category A means the indices can be used, while category B means the indices can be used with several improvements. Category C means the indices cannot be reliably applied.However, the Akaike’s information criterion corrected (AICc) (Equation (4)) served as the determinative criterion for the final selection of the candidates especially when several different indices give the same RPD value. The AICc is used due to its capability to address potential overfitting caused by a small sample size.




AIC
c
=
(
2
k
−
2
ln
(

L
^

)
)
+


2

k
2

+
2
k


n
−
k
−
1






(4)


where 

L
^

 is the maximum value of the likelihood function, n is the sample size, and k is the number of parameters. In addition, the coefficient of determination (R2) and the root mean square error (RMSE) were also calculated.", 2. Materials and Methods, 2.5. Statistical Criteria,2
501,"Six species from Nakakawane were measured for photosynthesis activities from 2014 until 2018. The mean value of Vcmax was estimated to be 33.48 μmol m−2 s−1, ranging from 10.01 μmol m−2 s−1 to 61.21 μmol m−2 s−1, with a median of 31.95 μmol m−2 s−1. Meanwhile, the Jmax data varied from 26.15 μmol m−2 s−1 to 160.80 μmol m−2 s−1, with the mean of 71.80 μmol m−2 s−1 and the median of 67.61 μmol m−2 s−1. Descriptive statistical results revealed that the Vcmax had a skewness of 0.284, a kurtosis of –0.851, and a standard deviation of 12.18 μmol m−2 s−1. On the other hand, the Jmax had 0.668 for skewness, –0.369 for kurtosis, and 29.98 μmol m−2 s−1 for the standard deviation. The distributions of every photosynthetic parameter are shown in Figure 2.Species-based descriptive statistics for photosynthetic parameters are shown in Figure 3. The highest values for Vcmax and Jmax were both found in Fagus crenata, of 61.21 μmol m−2 s−1 and 160.80 μmol m−2 s−1, respectively. In contrast, the lowest value for Vcmax was observed in Acer shirasawanum (10.01 μmol m−2 s−1), while the lowest value for Jmax was found in Betula grossa (26.15 μmol m−2 s−1). The highest variance of Vcmax was found in B. grossa, which reached 146.41 μmol m−2 s−1 (14 samples). This was followed by Carpinus tschonoskii (135.09 μmol m−2 s−1; 11 samples), and F. crenata (112.73 μmol m−2 s−1; 84 samples). However, different trends were noted for the Jmax, for which F. crenata had the highest variance of 780.98 μmol m−2 s−1, followed by C. tschonoskii (713.10 μmol m−2 s−1) and B. grossa (668.18 μmol m−2 s−1).On the other hand, the reflectance data also varied among different species (Figure 4). The S. monadelpha had the highest standard deviations of reflectance spectra at the range of red-edge to NIR. Nevertheless, F. crenata had the highest mean reflectance in most wavelengths, especially for the domain of short-wave infrared (SWIR). For different leaf groups, there is no significant variation of reflectance from 400 to 1400 nm. However, the standard deviations of sunlit leaves were higher at 700 nm (red edge) to 1100 nm (NIR area), while shaded leaves were higher at 1400 to 2500 nm (SWIR area). The result is presented in Figure 5.", 3. Results, 3.1. Properties of Leaf Photosynthetic Parameters and Hyperspectral Reflectance,3
502,"The results from indices screening based on the original reflectance for both parameters using the reported indices are shown in Table 4. The reported indices used for this study gave poor performance, judged from their low RPD values and coefficients of determination (R2).", 3. Results, 3.2. Performance of Reported Indices,3
503," 3.3.1. All DataWe developed new indices based on the original reflectance, the first-order derivatives, and the apparent absorption for both parameters. The screening of all indices using the original spectra suggested that the double difference (DDn) type of indices gave the best performance for quantifying both Vcmax and Jmax. The best index of this type used the first wavelength at 1652 nm and had an interval of 9 nm for Vcmax, which had an RPD of 1.42 and an R2 of 0.50. It also had the minimum AICc (=5.34) among all index types. In comparison, the best index identified for Jmax of this type used the nearby wavelength of 1644 nm with an interval of 16 nm and had an RPD of 1.75. Furthermore, its R2 reached 0.67.Similar analysis on the indices calculated from the first-order derivatives spectra again suggested that the DDn type index performed best for predicting Vcmax (R2 = 0.51 and RPD = 1.43), with the central wavelength at 1831 nm and an interval of 419 nm. However, the wavelength difference (D) type index performed best for Jmax, which used the wavelengths of 1629 nm and 1658 nm. This index also had an R2 of 0.68 and its RPD was estimated as 1.78. The DDn type index with the central wavelength at 1600 nm and an interval of 65 nm was also effective to trace Jmax with an R2 of 0.64 and RPD of 1.68.Furthermore, indices based on the apparent absorption spectra were also examined for their performance. The results suggested the mID type indices performed best for Vcmax while the DDn type for Jmax. The R2 between the mID index and Vcmax was higher than the SR, ND, and mSR1 indices (0.514 versus 0.513 for the other three indices, not shown in Table 5). The best mID index (R2 = 0.51, RPD = 1.44) used the wavelength of 2199 nm with an interval of 9 nm, while the best DDn index (R2 = 0.65, RPD=1.68) used 1651 nm with an interval of 11 nm for wavelengths before and after that.Further, for all indices based on the different types of spectral forms, the indices based on first-order derivatives spectra gave the best performance, which had the highest RPD values for first-order derivatives of both Vcmax and Jmax. 3.3.2. Different leaf groupsWe also explored the best indices for different leaf groups (sunlit and shaded) based on the original reflectance spectra, the first-order derivatives spectra and the apparent absorption spectra as well. The results for sunlit and shaded leaves are shown in Table 6. The bold type indicates the best RPD and coefficient of determination (R2).As illustrated in Table 6, for sunlit leaves, the best performance indices based on the original reflectance form for Vcmax and Jmax are both the DDn type. Similarly, the best indices based on the first-order derivatives spectra are also the DDn type of indices for Jmax and for Vcmax. Further, the DDn type index using the apparent absorption spectra also performed best for Jmax. Although the SR type index based on apparent absorption performed best for Vcmax (with maximum RPD value, not shown in Table 6), the R2 values of SR, ND, DDn, mSR1, and mID were very similar (0.47 for SR, ND, mSR1 and mID indices, while 0.46 for DDn index). In addition, we also found that the RPD values generally increased from the indices based on original reflectance to indices based on first-order derivatives spectra.For shaded leaves, the performance of indices based on the original reflectance mimicked that of sunlit leaves. The DDn type of indices were effective to trace both Vcmax and Jmax of shaded leaves. Although the D type index based on the original reflectance performed best for Vcmax, the DDn type index gave similar R2 values (0.55 versus 0.57). Similarly, the D type of index based on the first-order derivatives spectra performed best for Jmax and the DDn type index gave similar R2 values (0.62 versus 0.65). For apparent absorption spectra based indices, the performance of the DDn type index to trace Vcmax was comparable with the identified best index mID (R2 = 0.56 versus 0.57). Overall, the DDn type of indices based on all three spectra forms were effective to trace Vcmax and Jmax of both sunlit and shaded leaves. 3.3.3. Different SpeciesWe also investigated the best indices for each species in this study, to determine whether it is necessary to trace photosynthetic parameters for each species individually or for species groups instead. The results indicated that the indices based on the first-order derivative spectra performed better in quantifying the photosynthetic capacity parameters for all species. For most species, except F. crenata and A. shirasawanum, the indices based on the first-order derivative spectra have RPD values > 2.00 (irrespective of index type) for Vcmax and even better for Jmax. For both F. crenata and A. shirasawanum, most index types have RPD values within 1.4 and 2.0 with Vcmax (except for R type for A. shirasawanum, RPD = 1.31). In comparison, all index types have RPD values within the range of 1.4 and 2.0 with Jmax for the two species.In general, the DDn type of indices based on the original reflectance had a respectable performance for all species when quantifying Vcmax. However, each species has its own specific best-fitting index. For example, for quantifying the Vcmax of A. shirasawanum, F. crenata, S. monadelpha and S. pseudocamellia, the DDn type of index should be chosen. For the other two species (B. grossa and C. tschonoskii), the best-performing indices type were the D and mSR2, respectively. In contrast, for Jmax, the DDn type of index performed best with only two species (A. shirasawanum and S. monadelpha).Due to the small sample sizes, the RPD values for S. monadelpha and S. pseudocamellia were higher than the other species and may, thus, provide misleading RPD results. The sample size was an important factor in ensuring accurate indices’ predictions.", 3. Results, 3.3. Development of New Indices,3
504,"We developed new indices based on the original reflectance, the first-order derivatives, and the apparent absorption for both parameters. The screening of all indices using the original spectra suggested that the double difference (DDn) type of indices gave the best performance for quantifying both Vcmax and Jmax. The best index of this type used the first wavelength at 1652 nm and had an interval of 9 nm for Vcmax, which had an RPD of 1.42 and an R2 of 0.50. It also had the minimum AICc (=5.34) among all index types. In comparison, the best index identified for Jmax of this type used the nearby wavelength of 1644 nm with an interval of 16 nm and had an RPD of 1.75. Furthermore, its R2 reached 0.67.Similar analysis on the indices calculated from the first-order derivatives spectra again suggested that the DDn type index performed best for predicting Vcmax (R2 = 0.51 and RPD = 1.43), with the central wavelength at 1831 nm and an interval of 419 nm. However, the wavelength difference (D) type index performed best for Jmax, which used the wavelengths of 1629 nm and 1658 nm. This index also had an R2 of 0.68 and its RPD was estimated as 1.78. The DDn type index with the central wavelength at 1600 nm and an interval of 65 nm was also effective to trace Jmax with an R2 of 0.64 and RPD of 1.68.Furthermore, indices based on the apparent absorption spectra were also examined for their performance. The results suggested the mID type indices performed best for Vcmax while the DDn type for Jmax. The R2 between the mID index and Vcmax was higher than the SR, ND, and mSR1 indices (0.514 versus 0.513 for the other three indices, not shown in Table 5). The best mID index (R2 = 0.51, RPD = 1.44) used the wavelength of 2199 nm with an interval of 9 nm, while the best DDn index (R2 = 0.65, RPD=1.68) used 1651 nm with an interval of 11 nm for wavelengths before and after that.Further, for all indices based on the different types of spectral forms, the indices based on first-order derivatives spectra gave the best performance, which had the highest RPD values for first-order derivatives of both Vcmax and Jmax.", 3. Results, 3.3.1. All Data,3
505,"We also explored the best indices for different leaf groups (sunlit and shaded) based on the original reflectance spectra, the first-order derivatives spectra and the apparent absorption spectra as well. The results for sunlit and shaded leaves are shown in Table 6. The bold type indicates the best RPD and coefficient of determination (R2).As illustrated in Table 6, for sunlit leaves, the best performance indices based on the original reflectance form for Vcmax and Jmax are both the DDn type. Similarly, the best indices based on the first-order derivatives spectra are also the DDn type of indices for Jmax and for Vcmax. Further, the DDn type index using the apparent absorption spectra also performed best for Jmax. Although the SR type index based on apparent absorption performed best for Vcmax (with maximum RPD value, not shown in Table 6), the R2 values of SR, ND, DDn, mSR1, and mID were very similar (0.47 for SR, ND, mSR1 and mID indices, while 0.46 for DDn index). In addition, we also found that the RPD values generally increased from the indices based on original reflectance to indices based on first-order derivatives spectra.For shaded leaves, the performance of indices based on the original reflectance mimicked that of sunlit leaves. The DDn type of indices were effective to trace both Vcmax and Jmax of shaded leaves. Although the D type index based on the original reflectance performed best for Vcmax, the DDn type index gave similar R2 values (0.55 versus 0.57). Similarly, the D type of index based on the first-order derivatives spectra performed best for Jmax and the DDn type index gave similar R2 values (0.62 versus 0.65). For apparent absorption spectra based indices, the performance of the DDn type index to trace Vcmax was comparable with the identified best index mID (R2 = 0.56 versus 0.57). Overall, the DDn type of indices based on all three spectra forms were effective to trace Vcmax and Jmax of both sunlit and shaded leaves.", 3. Results, 3.3.2. Different leaf groups,3
506,"We also investigated the best indices for each species in this study, to determine whether it is necessary to trace photosynthetic parameters for each species individually or for species groups instead. The results indicated that the indices based on the first-order derivative spectra performed better in quantifying the photosynthetic capacity parameters for all species. For most species, except F. crenata and A. shirasawanum, the indices based on the first-order derivative spectra have RPD values > 2.00 (irrespective of index type) for Vcmax and even better for Jmax. For both F. crenata and A. shirasawanum, most index types have RPD values within 1.4 and 2.0 with Vcmax (except for R type for A. shirasawanum, RPD = 1.31). In comparison, all index types have RPD values within the range of 1.4 and 2.0 with Jmax for the two species.In general, the DDn type of indices based on the original reflectance had a respectable performance for all species when quantifying Vcmax. However, each species has its own specific best-fitting index. For example, for quantifying the Vcmax of A. shirasawanum, F. crenata, S. monadelpha and S. pseudocamellia, the DDn type of index should be chosen. For the other two species (B. grossa and C. tschonoskii), the best-performing indices type were the D and mSR2, respectively. In contrast, for Jmax, the DDn type of index performed best with only two species (A. shirasawanum and S. monadelpha).Due to the small sample sizes, the RPD values for S. monadelpha and S. pseudocamellia were higher than the other species and may, thus, provide misleading RPD results. The sample size was an important factor in ensuring accurate indices’ predictions.", 3. Results, 3.3.3. Different Species,3
507,"Indices based on downscaled spectra were also examined in this study, in order to investigate the possibility of expanding their applications from hyperspectral to multispectral data. We downscaled the original 1 nm spectra into several different resolutions, namely, 5 nm, 10 nm, 20 nm, and 50 nm. The screening results proved that the RPD values for indices based on original reflectance did not change significantly, and that the type of indices used to quantify the photosynthetic parameters remained consistent for all resolutions except for 50 nm.The results indicated that the RPD values of each type of index were relatively constant even when the resolutions were changed. The DDn type of indices based on either original reflectance or apparent absorption spectra showed a non-significant decrease of the RPD values for tracing Jmax. However, for the first-order derivatives spectra-based indices, the D type index performed better than the DDn type. Nevertheless, the RPD for the DDn index type was still respectable for different spectral resolutions. On the other hand, Vcmax can be traced better using the DDn type of indices based on the first-order derivatives and apparent absorption spectra. The RPD values of DDn type indices for Vcmax decreased with the spectral resolution of the original reflectance.", 3. Results, 3.4. Evaluation of Developed Indices With Downscaled Resolutions,3
508,"Hyperspectral remote sensing, as a promising technique, has already been widely used for retrieving structural and biochemical parameters [11,48,49,50] Unfortunately, few studies have ever succeeded with physiological parameters [29,31,51,52]. Sensitivity analysis results of the newly developed model of soil-canopy spectral radiances, photosynthesis, fluorescence, temperature, and energy balance (SCOPE) [13] indicated that recognizable contributions of the physiological parameters (such as Ball–Berry stomatal conductance parameter, roughness length for the momentum of the canopy) were identified to reflectance [16]. What’s more, Vcmax showed a great contribution to the full broadband sun-induced chlorophyll fluorescence (SIF) flux and calculating total fluorescence yield [53]. These results laid the possibility of using hyperspectral remote sensing to trace photosynthetic capacity parameters.In this study, we tried to reveal the possibility of using hyperspectral information to detect and to quantify photosynthetic capacity parameters, namely, the maximum rate of rubisco carboxylation (Vcmax) and maximum rate of photosynthesis electron transport (Jmax). We investigated the possibilities of using hyperspectral vegetation indices, the most popular applied empirical approach in current remote sensing activities. We first investigated the feasibility of using the reported indices based on our specific dataset containing synchronous data of gas exchange and reflectance. In total, ten well-known indices were validated, including the PRI and RVSI that are usually used for physiological trait assessment, and some for predicting biochemicals such as pigments (SIPI, CARI, mCARI) and nitrogen content (NDNI), as well as several (e.g., NDVI and EVI2 for structural assessment, such as LAI (leaf area index) and green biomass). These ten reported indices are in widespread use and are related, more or less, to photosynthetic capacity [54,55,56].None of the reported indices could be recommended, as clearly indicated by their RPD values (all below 1.4). Although NDVI and EVI2 performed slightly better using the range of the central wavelength of Sentinel 2A, their RPD values were still below 1.4. Similar results were also found for other indices, such as PRI and RVSI. Surprisingly, although both the PRI and RVSI indices have frequently been used to quantify physiological parameters, they performed poorly with both photosynthetic parameters. Furthermore, several indices that are usually used to quantify pigments also gave poor results.Possibly, the main reason for the poor performance of the reported indices may be the range of wavelengths used for calculations. All of the reported indices were developed using specific wavelengths to fit their specific purposes. For example, PRI was developed using green wavelengths at 531 nm and 570 nm, both of which are useful to detect chlorophyll fluorescence [57,58]. As such, a number of previous researches have already proved the feasibility of PRI for tracing other plant physiological activities related to chlorophyll pigment [24,59,60], but apparently not for photosynthetic parameters. The other reported indices are largely based on the red and NIR wavelengths that are sensitive to trace the change of vegetation, except for NDNI using the SWIR range. However, the wavelengths used were not feasible to trace other physiological changes, especially photosynthetic capacity.Clearly, new indices for quantifying photosynthetic capacity need to be developed. When using first-order derivatives spectra, we found DDn(1831,419) and D(1629,1658) to be the best indices for tracing Vcmax and Jmax based on our dataset. The RPD values of both indices are 1.43 and 1.78 for Vcmax and Jmax, respectively. Although this type of index is not the best on Jmax, the performance of DDn(1600,65) is still acceptable (RPD = 1.68, R2 = 0.64). We suggest that the DDn type of indices could be used as a general form for tracing photosynthetic parameters. We looked through the wavelengths and identified several negative coefficients of correlation (troughs) between the reflectance spectra and photosynthetic parameters. We found that our identified DDn index used a wavelength from the second trough and other troughs of first-order derivatives spectra, as shown in Figure 6. Meanwhile, the useful wavelengths for all of the indices based on original reflectance, first-order derivatives, and apparent spectra are presented in Figure 7. Most of the useful wavelengths for both parameters are from the peak regions or troughs region.The indices based on the first-order derivatives spectra were found to perform better than those based on the original or apparent absorption spectra. The first-order derivatives spectra are known to be able to reduce noise between spectral data [45,46] and this is the probable reason. Another possible reason is that these identified indices all used wavelengths in the SWIR region (1300 nm to 2500 nm). The SWIR domain is known to be very informative for detecting physiological or chemical activity due to the wavelengths being absorbed or reflected by the object [61,62]. These SWIR wavelengths have properties that are more similar to visible light compared with the other infrared range. Based on Figure 7, we extracted six different wavelengths used by the DDn type of indices based on the first-order derivatives spectra. Wavelengths 1412 nm, 1831 nm, and 2250 nm were selected for Vcmax and wavelengths 1535 nm, 1600 nm, and 1665 nm were selected for Jmax. The wavelength 1412 nm used in the DDn index for Vcmax estimation was within the most sensitive domain of Vcmax. The first-order derivative spectra at 1412 nm were significantly related to Vcmax (the coefficient of correlation r = -0.62). Similarly, the wavelength 1600 nm used in the DDn index for Jmax estimation was also within the most sensitive domain of Jmax. The first-order derivative spectra at 1600 nm were significantly and positively related to Jmax (the coefficient of correlation r = 0.68). According to Figure 8, there were no significant differences between species in this range of wavelengths. However, the value range of the wavelengths differed in each case. The value of each wavelength is presented in Figure 8.Furthermore, we investigated the robustness of the developed indices with different leaf groups. The difference in leaf groups (sunlit and shaded) used in this study is due to differences in their response to the photosynthesis process [63]. This leaf stratification also contributed to model accuracy when upscaling the leaf photosynthesis model to the canopy scale [64]. While in several vegetation indices that have already been developed, the sunlit leaves usually contain a higher ratio of chlorophyll A and are thicker than shaded leaves, the shaded leaves have more chlorophyll per dried leaf weight and emit the maximum chlorophyll fluorescence, higher than sunlit leaves [65].We found that the DDn type of indices consistently traced Jmax well, even when the wavelengths used were slightly different. For the shaded leaf group, the best DDn index used the 1664 nm for λ1with a Δλ of 54 nm, while for the sunlit leaf group the 1609 nm was used for λ1 with the Δλ of 45 nm. Meanwhile, the RPD values of the DDn type indices for tracing Vcmax decreased, especially in the sunlit leaves group. The sunlit leaves and shaded leaves have different physical and pigment conditions, where the shaded leaves usually emit higher chlorophyll fluorescence compared with sunlit leaves [65]. Furthermore, the sunlit leaves mostly represent the lowest quantum yield of electron transport and lowest pigment content [66] while the shaded leaves generally obtain only one-third of the canopy carbon gain [67].In addition to leaf groups, the screening results for different species also confirmed that the DDn type of indices performed best for B. grossa and F. crenata. However, the RPD value of the DDn index for A. shirasawanum was also respectable. As mentioned before, A. Shirasawanum and F. crenata have a large number of samples, being the dominant and targeted species in our study, while for other species, the DDn performed respectably in comparison with the other types of index and when using different forms of spectra also performed better than the original reflectance spectra.Further, we tested the indices with downscaled datasets to check the possibility of using airborne or satellite-borne data that generally have coarse spectral resolutions. The DDn type of indices kept their good performance for tracing Jmax and even Vcmax, although the Vcmax results were slightly inferior to those of Jmax. We also tried to use different types of spectral forms to test the consistency of the DDn index, and the performance for the DDn type of indices was found to be acceptable even for different spectral resolutions.We concluded that the best type of index for quantifying photosynthetic parameters is the DDn type, which proved to be robust even for different species. The index also performed stably for downscaled resolution spectra, suggesting that it could also be used for airborne or satellite-borne coarse spectral data.However, we realize that the indices have several shortcomings that must be resolved before they can be applied widely, such as that the number of species needs to be increased, as the sensitivity of hyperspectral indices is often considered to be species-dependent [68,69]. Furthermore, the sample sizes for several specific species were too small and could possibly therefore be overfitted, since it has been claimed that the sample size could influence the value of statistical indicators [70]. The first-order derivatives spectra are the best type of spectra for quantifying photosynthetic parameters, as hyperspectral indices based on the spectra show a certain balance between accuracy and robustness on retrieving plant properties [71]. Even though we are confident that this type of index could work for the alpine deciduous forest, much more study is still needed in order to provide generally applicable indices for tracing photosynthetic parameters. However, we foresee that such indices could be developed and we have taken an important step towards this objective.", 4. Discussion,None,4
509,"New hyperspectral vegetation indices have been developed for tracing photosynthetic parameters in an alpine deciduous forest containing six species. The results demonstrated that the DDn type of indices performed best in tracing photosynthetic capacity. The DDn type of indices used the first-order derivatives spectra in the SWIR region wavelength at 1831 nm with Δλ 419 nm for Vcmax and 1600 nm with Δλ 65 nm for Jmax. The result from this index type was relatively stable even for the downscaled resolution of 50 nm. The first-order derivatives spectra have been proven to be the best spectral form for tracing photosynthetic capacity. The DDn type of indices and first-order derivatives spectra have already demonstrated possibilities for tracing photosynthetic capacity using hyperspectral indices. The results obtained can contribute to the development of the vegetation index to assess photosynthetic capacity, especially for the alpine deciduous forest.", 5. Conclusions,None,5
510,"Accurate estimates of above ground biomass (AGB) of vegetation in forests are fundamental for quantifying and monitoring forest conditions and trends. AGB and other forest structure metrics provide baseline information required to derive estimates of available wood supply, habitat quality for wildlife, and fire threat, among other ecosystem attributes [1,2,3,4]. Such information can help guide, for example, national policies on forest management, carbon sequestration, and ecosystem health [5]. While in-situ measurements can provide a direct local-scale quantification of forest structure attributes, they can also be cost prohibitive, time consuming, and limited in spatial extent [6]. Therefore, utilization of widely available remotely sensed data with new modeling methods have become an essential approach for estimating AGB and other forest metrics in recent decades [7].In recent years, advanced methods utilizing satellite or airborne sensor technology have resulted in regional and global-scale estimates of forest structure [8,9,10,11,12]. These sensors range from very high spatial resolution optical/laser datasets (Quickbird and airborne LiDAR) to moderate or low spatial resolution datasets (Landsat, radar, and MODIS), each with their own advantages and disadvantages [7,13]. Airborne LiDAR is currently the most advanced platform and has recently become ubiquitous in the literature. This is due to the high accuracy in forest structure metrics estimation produced by its very high spatial resolution (sub 1-m), and its ability to represent three-dimensional structure with point clouds [14]. However, despite its growing usage, airborne LiDAR acquisitions are costly, limited in spatial and temporal coverage, and can contain fly-over data gaps, thus limiting their utility for large continuous regional analyses of forest structure [7].Landsat has been the most widely used sensor to measure forest structure due to its free availability, medium temporal resolution (16-day return interval), and effective global spatial coverage [15]. The wall-to-wall access of data globally has led to advancements in understanding not only of the patterns and dynamics of AGB, but also of net primary productivity and forest canopy cover change dynamics [9,16]. Yet, its moderate spatial resolution (30-m) has led to issues of “data saturation,” in which a single pixel’s reflectance has high uncertainty and/or underestimates at AGB values above 150 Mg/ha [1,17,18]. This is due to mature forests often containing a complex mixed age structure, resulting in canopy layering, which can be difficult to discern at a 30-m spatial resolution [19]. One data source that has the potential to resolve issues with Landsat’s data saturation and LiDAR’s limited coverage is the USDA National Agriculture Imagery Program (NAIP) [20]. Since 2002, the NAIP program has provided freely accessible, 1-m resolution aerial photography, approximately every two years and for each state in the conterminous US [20]. Using texture/pattern recognition software, such high resolution imagery can help to overcome data saturation issues and provide better estimates of forest structure metrics [21,22].In the past couple of decades, development of newer machine learning methods, including deep learning, have led to an explosion of computer vision research, lending itself to the creation of complex and computationally efficient relationship models in the field of remote sensing [23,24,25,26,27,28,29]. One application for which deep learning is particularly well-suited is image interpretation and pattern recognition with spatial data through use of convolutional neural networks (CNN) [30]. CNNs have proven to outperform all other existing methods when applied to these tasks [31,32,33]. Yet, this method has not been readily adopted for forest metric estimation, such as AGB [1]. Predictions of forest structure metrics have been shown to improve when including image textures as predictors, e.g., gray level co-occurrence matrix (GLCM), standard deviation of gray levels (SDGL). However, these, and other more complex textural features require laborious hand-crafting to identify and implement in model fitting [34,35,36]. CNNs have the ability to identify similar relevant image textures from the data alone without human assistance, which allows them to be applied to solve generalized image feature detection problems [32,37]. Additionally, the advancement of recurrent CNNs (RCNN), convolutional neural networks that include a time dependent layer, allows identified image texture spaces to be ordered in sequence [38,39]. The ability of RCNNs to recognize patterns in multi-dimensional domains that have both time and space components demonstrates promise with object recognition in a wide range of remote sensing problems, from classification to segmentation [40,41,42].With the rapid adoption of CNNs for solving computer vision problems, additional advanced approaches have been developed to improve predictive accuracy, which include multi-task learning and ensembling. Multi-task learning is a method in which a neural network is trained to perform two or more similar tasks, such as identifying road characteristics while predicting steering direction for an automated driving system [43]. This shared task method of learning has been demonstrated to increase predictive ability for each individual task [44]. Ensembling, the technique of using multiple models together to make a single prediction, has also been demonstrated to increase predictive ability of many machine learning approaches, by reducing the bias of any single model prediction [45]. These technical advancements and characteristics present an opportunity to apply them in an ensemble of multi-task RCNNs as a case study, and test the ability of such an architecture to classify forest cover and predict AGB and other forest structure metrics against more conventional approaches.In this study, we introduce an ensemble of individual RCNN models called “Chimera” (together called the Chimera ensemble, or CE) to perform a data fusion of high resolution NAIP imagery, moderate resolution time-varying Landsat, and ancillary climate and terrain (ANC) variables, and to build prediction tiles which can then be reassembled for spatially explicit mapping of larger areas. We present performance metrics based on field plots collected from the USDA forest service forest inventory and analysis (FIA) program dataset. ObjectivesThe main objective of this study is to measure the performance of a novel multi-task RCNN architecture which simultaneously classifies forest and land cover (‘conifer’, ‘deciduous’, ‘mixed’, ‘dead’, or ‘none’) and estimates forest structure metrics (AGB, quadratic mean diameter (QMD), basal area, and canopy cover). Our performance experiments will involve: (1) comparing the different combinations of input datasets, specifically, the impact of including high resolution (1-m) imagery; (2) comparing the RCNN architecture with more commonly used random forest (RF) and support vector machine (SVM) models, with similar inputs; (3) assessing the potential improvement with ensembling of RCNN models compared to an individual best fit model. It is hoped that these objectives (Figure 1) will better inform the application of deep learning approaches in forest structure and type estimation, and present a potential architecture upon which future modeling efforts might improve.", 1. Introduction,None,1.
511,"California and Nevada were chosen as the region of analysis for data sampling and modeling (Figure 2). The California–Nevada region embodies a wide gradient of elevation from −86 m in Death Valley to 4421 m at the summit of Mt. Whitney. In California, about 40% of the area (approx. 13.35 million hectares) is covered by forests [46], while Nevada contains the largest national forest in the lower 48 states, the 6.3-million acre Humboldt–Toiyabe National Forest [47]. Both states contain a wide variety of ecosystems including alpine, montane and subalpine forests, coastal forests, mixed conifer-deciduous forests, chaparral, pinyon-juniper woodlands, and desert scrub. This variety of forest ecotypes make these states an excellent case study for forest structure estimation over an extensive, heterogeneous region.", 2. Materials and Methods, 2.1. Region of Analysis,2
512,"Our input variables for the RCNN architecture are formed from a combination of four different, open-source remote sensing datasets available in the Google Earth Engine (GEE) [48]. These datasets (NAIP imagery, LANDSAT imagery, PRISM climate data, and USGS NED terrain data) are combined across different spatial and temporal resolutions to form individual tensors (i.e., multi-dimensional array), each approximating a single 120 × 120-m FIA field measured sample for each of our predictor variables (Figure A3). We chose the 120 × 120-m size to maximize the inclusion of the sampled area while allowing for any potential mismatches in either imagery georeferencing, or FIA plot location [49]. 2.2.1. NAIP (National Agricultural Imagery Program)USDA NAIP images are mostly cloud-free image tiles collected across the continental United States during the summer months by aerial fly-over in frequencies ranging from 5 years (in some rural areas) to 1 year [20]. NAIP image tiles are sized at 3.75 × 3.75 arc-minutes (approx. 6 km × 6 km) in GEE, with either three (red, green, blue; RGB) or four (red, green, blue, and near-infrared starting in 2007; RGBN) spectral bands, with a target of 1 m or smaller pixel size. NAIP is available across the entire time range of FIA inventory samples that we considered (2005–2017). In order to limit the cases of non-representative samples, locations without NAIP imagery available within a three year time window (one year forward, two years back from the date of FIA sampling) were not included in the training dataset. The image collected closest to the date of FIA field data collection was chosen and resampled to 1 meter resolution either through mean aggregation, or nearest neighbor resampling. Only RGB bands were used due to lack of uniform availability of RGBN images across the two states in our case study region. 2.2.2. Landsat 7Landsat 7 is one of a series of satellites providing open-source imagery for scientific purposes through a joint effort by the USGS and NASA [15]. Landsat 7 imagery is collected at 16-day intervals through the entire period of interest for this study. For training purposes, we produced a 4 × 4-pixel image at the native 30-m resolution of all but the thermal bands, resampling the panchromatic band to 30 m from 15 m via mean aggregation, and utilizing the quality assessment (QA) band codes to mask noisy pixels and all but the lowest confidence cloudy pixels. This was accomplished using only tier 1, top-of-atmosphere (TOA) reflectance data. As a result of gaps in surface reflectance data and reduced efficacy of data correction over arid/snow covered regions in GEE, we used TOA to maintain the highest possible number of continuous temporal samples [50]. We gathered a three year time series (one year forward, two years back from FIA sampling) and produced a monthly average for each of the 12 calendar months of reflectance values with only high quality pixels to represent a single year. This method provided the best chance at capturing the distinct patterns produced by deciduous and mixed stands, as well as dead stands through an annual cycle.", 2. Materials and Methods, 2.2. Predictor Variables—Optical Data,2
513,"USDA NAIP images are mostly cloud-free image tiles collected across the continental United States during the summer months by aerial fly-over in frequencies ranging from 5 years (in some rural areas) to 1 year [20]. NAIP image tiles are sized at 3.75 × 3.75 arc-minutes (approx. 6 km × 6 km) in GEE, with either three (red, green, blue; RGB) or four (red, green, blue, and near-infrared starting in 2007; RGBN) spectral bands, with a target of 1 m or smaller pixel size. NAIP is available across the entire time range of FIA inventory samples that we considered (2005–2017). In order to limit the cases of non-representative samples, locations without NAIP imagery available within a three year time window (one year forward, two years back from the date of FIA sampling) were not included in the training dataset. The image collected closest to the date of FIA field data collection was chosen and resampled to 1 meter resolution either through mean aggregation, or nearest neighbor resampling. Only RGB bands were used due to lack of uniform availability of RGBN images across the two states in our case study region.", 2. Materials and Methods, 2.2.1. NAIP (National Agricultural Imagery Program),2
514,"Landsat 7 is one of a series of satellites providing open-source imagery for scientific purposes through a joint effort by the USGS and NASA [15]. Landsat 7 imagery is collected at 16-day intervals through the entire period of interest for this study. For training purposes, we produced a 4 × 4-pixel image at the native 30-m resolution of all but the thermal bands, resampling the panchromatic band to 30 m from 15 m via mean aggregation, and utilizing the quality assessment (QA) band codes to mask noisy pixels and all but the lowest confidence cloudy pixels. This was accomplished using only tier 1, top-of-atmosphere (TOA) reflectance data. As a result of gaps in surface reflectance data and reduced efficacy of data correction over arid/snow covered regions in GEE, we used TOA to maintain the highest possible number of continuous temporal samples [50]. We gathered a three year time series (one year forward, two years back from FIA sampling) and produced a monthly average for each of the 12 calendar months of reflectance values with only high quality pixels to represent a single year. This method provided the best chance at capturing the distinct patterns produced by deciduous and mixed stands, as well as dead stands through an annual cycle.", 2. Materials and Methods, 2.2.2. Landsat 7,2
515,"Kane et al. [51] were able to demonstrate that forest structure patterns such as canopy cover percentage, could be predicted based on water balance and topographic position information. This follows the intuition that specific forest species with unique structural attributes can be delimited based on abiotic factors [52]. Therefore, we included ancillary (ANC) climate and terrain data to provide the CE with additional information for land cover classification and forest structure estimation. 2.3.1. PRISM (Parameter-Elevation Regressions on Independent Slopes Model)In order to provide long term climate trend information to the CE for each sample, we utilized PRISM from Oregon State University [53]. PRISM aggregates continuous data from weather stations across the United States and uses sophisticated interpolation methods to produce gridded data for the entire United States on multiple time scales. We utilize AN81m, a monthly curated and quality-controlled dataset which provides dewpoint, vapor pressure deficit, temperature, and precipitation data at a coarse 2.5 arc-minute (approx. 4 km) scale. This dataset was resampled to a single 120-m pixel for each sample using the nearest neighbor method, and a mean/standard deviation across the 30-year period prior to the FIA inventory year associated with each training or test sample. 2.3.2. USGS NED (National Elevation Dataset)The National Elevation Dataset (NED) provides gridded elevation at a 1/3 arc-second (approx. 10–15 m) resolution for the entire continental U.S. [54]. NED was produced from multiple individual datasets as a national aggregation and has been shown to have an RMSE ≈ 1.63 m from truth in vertical accuracy across the continental U.S. [55]. Terrain features including elevation, slope, and aspect, have been shown to be correlated with forest structural attributes [56,57]. We use elevation, slope, and aspect (which we calculate and apply a cosine transform on the fly directly from the NED) in the training process, represented as a single, 3-band, 120 m mean aggregated pixel for each sample.", 2. Materials and Methods, 2.3. Predictor Variables—Ancillary Data,2
516,"In order to provide long term climate trend information to the CE for each sample, we utilized PRISM from Oregon State University [53]. PRISM aggregates continuous data from weather stations across the United States and uses sophisticated interpolation methods to produce gridded data for the entire United States on multiple time scales. We utilize AN81m, a monthly curated and quality-controlled dataset which provides dewpoint, vapor pressure deficit, temperature, and precipitation data at a coarse 2.5 arc-minute (approx. 4 km) scale. This dataset was resampled to a single 120-m pixel for each sample using the nearest neighbor method, and a mean/standard deviation across the 30-year period prior to the FIA inventory year associated with each training or test sample.", 2. Materials and Methods, 2.3.1. PRISM (Parameter-Elevation Regressions on Independent Slopes Model),2
517,"The National Elevation Dataset (NED) provides gridded elevation at a 1/3 arc-second (approx. 10–15 m) resolution for the entire continental U.S. [54]. NED was produced from multiple individual datasets as a national aggregation and has been shown to have an RMSE ≈ 1.63 m from truth in vertical accuracy across the continental U.S. [55]. Terrain features including elevation, slope, and aspect, have been shown to be correlated with forest structural attributes [56,57]. We use elevation, slope, and aspect (which we calculate and apply a cosine transform on the fly directly from the NED) in the training process, represented as a single, 3-band, 120 m mean aggregated pixel for each sample.", 2. Materials and Methods, 2.3.2. USGS NED (National Elevation Dataset),2
518," Training Data Targets: FIA Sampling and Database Parameter UsageContinuous response variables were generated from the forested and non-forested 27,966 FIA Phase 2 plots inventoried from 2005–2017 within California and Nevada state boundaries. The FIA program applies a nationally consistent quasi-systematic sampling protocol [58] with a nominal sampling intensity of approximately one sample location per 2400 ha, to provide a source of information about the extent, condition, status, and trends of forests across the United States [8,59]. In Phase 2, field crews visited permanent plots that contain a forested land use (areas that have at least 10% tree canopy cover, are at least 0.4 ha in size, and at least 36.6 m wide) and collect information on individual trees and site variables [60]. In each plot, trees were sampled at the subplot (four 24 foot (7.31 m) diameter circles) or macroplot (58.9 foot (17.95 m)) level in a consistent orientation. Only larger trees are measured outside the subplots in the case of macroplot measurements by FIA field crews. We considered all live trees above 1 inch (2.54 cm) in diameter when calculating our response variables. Dry biomass components for each live tree were calculated via the national standard method (the component ratio method (CRM)) detailed in the current FIA handbook [60]. We summed the total above ground components of each tree together to represent the dry biomass of a sample plot, accounting for the variations of the CRM for woodland species, timber species, and saplings. These values were then converted to a density value using recorded plot geometry information. Basal area metrics were taken directly from FIA field measurements within the database. Canopy cover measurements were taken from the live canopy cover attribute of the database, which can be measured differently (in-situ or remotely sensed image interpretation) depending on the region and year of survey [61]. Plot-level QMD was given by the equation:



Q
M
D
=



∑


d
b

h
i


2


n






(1)


where 

d
b
h

 is the diameter at breast height of each tree, i, for all measured live trees, 

i
=
1
,
…
,
n

 on the plot.For the land cover classification task of this study, we classified plots based on an 80% tree count threshold as ‘conifer’ or ‘deciduous’. If there was not 80% trees of conifer or deciduous type, plots were labeled as ‘mixed’. A label of ‘dead’ was given to plots where 80% of the trees were recorded as standing dead. Plots where no trees were present were labeled as ‘none’. It should be noted that these classification labels are different from FIA definitions, which are land-use labels and not land cover labels. We additionally utilized FIA non-forested plots (20,660 plots of the 27,966). These plots provide a valuable baseline for image feature recognition of urban areas, bare land, and water. However, since these plots are non-forested by definition, these locations are not-visited and have no tree attributes recorded but may still have tree cover (e.g., urban and residential areas) [61]. Following the methods of Hogland et al. [35], who visually inspected plot locations against the corresponding reference NAIP image, we manually inspected images corresponding to these non-visited plots. For locations where there were clearly no trees visible in the imagery, we labeled them as ‘none’ and attributed them with AGB, QMD, basal area, and canopy cover values of zero.After all manual inspections of plot-to-image correspondence were completed, plots were further filtered to those containing all four corresponding predictor variable data, leaving n = 9967 samples (Table 1). The data were then randomly subdivided into training, validation, and test samples. We first set aside 500 plots for testing (5% of the total data) and then used the remaining data at a 4:1 ratio of training to validation data for fitting each individual Chimera model (7724 training samples, 1743 withheld validation samples, and 500 test samples). Training, validation, and test samples followed similar distributions for each response metric, and across all k-fold cross-validation subsets as discussed in the Model Ensembling section below (Figure A1).", 2. Materials and Methods, 2.4. Response Variables,2
519,"Continuous response variables were generated from the forested and non-forested 27,966 FIA Phase 2 plots inventoried from 2005–2017 within California and Nevada state boundaries. The FIA program applies a nationally consistent quasi-systematic sampling protocol [58] with a nominal sampling intensity of approximately one sample location per 2400 ha, to provide a source of information about the extent, condition, status, and trends of forests across the United States [8,59]. In Phase 2, field crews visited permanent plots that contain a forested land use (areas that have at least 10% tree canopy cover, are at least 0.4 ha in size, and at least 36.6 m wide) and collect information on individual trees and site variables [60]. In each plot, trees were sampled at the subplot (four 24 foot (7.31 m) diameter circles) or macroplot (58.9 foot (17.95 m)) level in a consistent orientation. Only larger trees are measured outside the subplots in the case of macroplot measurements by FIA field crews. We considered all live trees above 1 inch (2.54 cm) in diameter when calculating our response variables. Dry biomass components for each live tree were calculated via the national standard method (the component ratio method (CRM)) detailed in the current FIA handbook [60]. We summed the total above ground components of each tree together to represent the dry biomass of a sample plot, accounting for the variations of the CRM for woodland species, timber species, and saplings. These values were then converted to a density value using recorded plot geometry information. Basal area metrics were taken directly from FIA field measurements within the database. Canopy cover measurements were taken from the live canopy cover attribute of the database, which can be measured differently (in-situ or remotely sensed image interpretation) depending on the region and year of survey [61]. Plot-level QMD was given by the equation:



Q
M
D
=



∑


d
b

h
i


2


n






(1)


where 

d
b
h

 is the diameter at breast height of each tree, i, for all measured live trees, 

i
=
1
,
…
,
n

 on the plot.For the land cover classification task of this study, we classified plots based on an 80% tree count threshold as ‘conifer’ or ‘deciduous’. If there was not 80% trees of conifer or deciduous type, plots were labeled as ‘mixed’. A label of ‘dead’ was given to plots where 80% of the trees were recorded as standing dead. Plots where no trees were present were labeled as ‘none’. It should be noted that these classification labels are different from FIA definitions, which are land-use labels and not land cover labels. We additionally utilized FIA non-forested plots (20,660 plots of the 27,966). These plots provide a valuable baseline for image feature recognition of urban areas, bare land, and water. However, since these plots are non-forested by definition, these locations are not-visited and have no tree attributes recorded but may still have tree cover (e.g., urban and residential areas) [61]. Following the methods of Hogland et al. [35], who visually inspected plot locations against the corresponding reference NAIP image, we manually inspected images corresponding to these non-visited plots. For locations where there were clearly no trees visible in the imagery, we labeled them as ‘none’ and attributed them with AGB, QMD, basal area, and canopy cover values of zero.After all manual inspections of plot-to-image correspondence were completed, plots were further filtered to those containing all four corresponding predictor variable data, leaving n = 9967 samples (Table 1). The data were then randomly subdivided into training, validation, and test samples. We first set aside 500 plots for testing (5% of the total data) and then used the remaining data at a 4:1 ratio of training to validation data for fitting each individual Chimera model (7724 training samples, 1743 withheld validation samples, and 500 test samples). Training, validation, and test samples followed similar distributions for each response metric, and across all k-fold cross-validation subsets as discussed in the Model Ensembling section below (Figure A1).", 2. Materials and Methods, Training Data Targets: FIA Sampling and Database Parameter Usage,2
520,"We constructed a deep learning model architecture called Chimera, for estimating forest structure using the Keras (v2.1.3) package [62] for building TensorFlow (v1.3.0) CNNs in Python. We implemented a multi-task learning (MTL) neural network architecture that merges climate, terrain, Landsat, and NAIP imagery datasets as predictors to perform two tasks: (1) classification of land cover type (‘none’ (non-forested), ‘deciduous’, ‘conifer’, ‘mixed’, ‘dead’) and (2) regression of four continuous forest metrics (AGB, quadratic mean diameter (QMD), basal area, and canopy cover) simultaneously [44] (Figure 3). Multi-task learning is a technique that has been demonstrated to improve accuracy by allowing convolutions to fit parameters more efficiently through understanding “easier” tasks [43,63,64]. This follows the intuition from another popular model called “you only look once” (YOLO) [65], that performs both object detection and classification simultaneously. In the YOLO architecture, a single trained CNN takes an image as an input and then performs discrete object identification (classification task) and draws a box around the object, thus performing an estimate of the box width, height, and center coordinates (regression tasks). Our architecture, similarly performs two tasks, but also allows the neural network to learn multiple differing input feature parameters simultaneously. To perform the classification and regression tasks, Chimera minimizes two loss functions in a single model; a cross-entropy loss function (H):



H

(
y
,

y
^

)

=
−

∑
i


y
i

log

(


y
^

i

)

,




(2)


where 

y
i

 is the ground truth label of ith training sample instance and 


y
^

i

 is the ith model prediction, and the L2 (mean squared error; MSE) loss function:



MSE

(
y
,

y
^

)

=

1
n


∑

i

n



(


y
^

i

−

y
i

)

2

.




(3)

Chimera’s architecture utilized a five block DenseNet structure to serve as the shared layer that will identify features within a three channel NAIP image. The DenseNet architecture [66] allows improved information flow between sequential convolutional composite layers 

F
j

 composed of a batch normalization, rectified linear units (ReLU), convolution, dropout, and pooling. We denoted the output of the j-th layer as 

x
j

 by direct concatenation of the feature maps produced from proceeding layers:




x
j

=

F
j


(

[

x
0

,

x
j

,
…
,

x

(
j
−
1
)


)

]

,




(4)


where 

[

x
0

,

x
j

,
…
,

x

(
j
−
1
)


]

 refers to the concatenation of the j previous layer outputs. This improved information flow additionally allows for higher performance, reduced parameter space, and faster model fitting compared to other well known architectures (e.g., ResNet, GoogLeNet, AlexNet) [32,37,67].A three layer convolutional long short-term memory (LSTM) block was applied to time sequenced Landsat scenes to summarize temporal changes that would be conducive to identifying deciduous, conifer, and mixed forest stands [38,68,69]. The output of the LSTM layer was concatenated to the dense layer of the DenseNet for classification.We concatenated the ancillary climate and DEM data to the output of the final DenseNet layer and LSTM layer. We then forked the concatenated layer in two for each task and run each fork through four fully connected layers with five outputs for the classification task and four outputs for the regression task. This is an example of a hard parameter sharing architecture, in which the same final concatenated layer is used for both tasks [44]. This allows the classification loss to influence regression parameters, and the regression loss to influence the classification parameters. For example, where classification was ‘none’, forest structure metrics were low to zero, indicating a strong relationship between the two tasks.NAIP and Landsat image samples were augmented randomly using image rotation and mirroring during model training to increase robustness of the RCNN and to allow varying forest image feature geometries to represent the same forest structure metric values across different training epochs. Furthermore, to compensate for training sample class count imbalance, we applied the Eigen and Fergus [70] class weighting method to adjust the final cross-entropy loss layer.Each individual Chimera RCNN was trained for 90 epochs at an 80 sample batch size using a stepped learning rate Adam optimizer [71] (learning rate stepped by a factor of 0.1 at every 30 epochs) to increase speed of model convergence during gradient descent. Average training time was 1h30m on a Microsoft Azure NC6 instance using a Intel (R) Xeon (R) [email protected] CPU with 56 GB of RAM and a NVIDIA Tesla K80 GPU with 24 GB of GDDR5 memory.Additionally, to understand if contributions of each input dataset improve performance, we fit seven different independent models with the complete training dataset, using all possible combinations of input data with the Chimera architecture (ANC only; NAIP only; NAIP and ANC; Landsat only; Landsat and ANC; NAIP and Landsat; all inputs).", 2. Materials and Methods, 2.5. Chimera RCNN Architecture,2
521,"Using the same training and test data sets, we built inputs for random forest and support vector machine models with the Scikit-learn package implemented in Python to compare results [72]. Data were subsetted to accomplish each regression task (four models), and the classification task separately (one model), resulting in five models for each algorithm. Two forms of data aggregation were tested: one used a single Landsat pixel time series of aggregated arrays resulting in 84 features, while the other used the same full 4 × 4 Landsat image time series as the Chimera ensemble, resulting in 1344 features. In both cases, textural extraction of NAIP was performed identically: one layer of 4 × 4 standard deviation gray level (SDGL) and one layer of 4 × 4 mean-downsampled images were concatenated, resulting in 96 features. Climate and DEM inputs were kept in the same shape and all data were normalized through the same process as the Chimera Ensemble. The final shapes of the resultant flattened vectors were 197 and 1457 features. The RF models were parameterized with 


n

e
s
t
i
m
a
t
o
r
s


=
150

 and the SVM models were parameterized with 

c
=
250
,
γ
=
0.5

 after employing a grid search methodology and finding the best output RMSE values across all tasks.", 2. Materials and Methods, 2.6. Chimera Comparisons with RF and SVM,2
522,"We used a k-fold cross-validation methodology to divide the data into a 4:1 ratio training versus validation samples. Five separate Chimera models 

(
k
=
5
)

 were fit with each fold of the training data. We performed diagnostics on each model to ensure all had converged on their loss functions and accuracy metrics (Figure 4). A super learner [45] approach was used to ensemble the five models weighted by the design matrix 
A
 in the form:





Y
^


e
n
s
e
m
b
l
e


=
A


Y
^


s
t
a
c
k


,




(5)


where 


Y
^


s
t
a
c
k


 is a matrix of stacked column vectors 


Y
^

k

, for each fitted model k. We solved for 
A
 using a multiple linear regression as the meta-learning algorithm and applied these final weights to combine models for prediction. The stacking methodology has been demonstrated to increase prediction accuracy metrics over a single model alone, or a simple unweighted averaging of models [73].", 2. Materials and Methods, 2.7. Model Ensembling,2
523,"Both the batch-level classification and regression loss functions converged for training and validation data for all k-folds within 60 epochs for a total of 1,353,593 parameters. Low differences in loss values between training and validation suggested that no individual Chimera model was overfit (Figure 5). Experiments of differing Chimera model input combinations (Table 2) demonstrated that all data types on their own (ANC only, NAIP only, Landsat only), did not perform as well as models with two input types. NAIP + ANC data outperformed Landsat models in classification (+0.01 overall F1-score) and similarly to Landsat + ANC in regression performance (

R
2

 = 0.76). The full model case (NAIP + Landsat + ANC) had the best overall performance (overall classification F1-score = 0.90; overall regression 

R
2

 = 0.81, normalized RMSE = 0.076) for the combined task of classification and regression simultaneously compared to each input combination considered separately, however the imagery-only model (NAIP + Landsat) performed slightly better in land use cover plot classification (overall classification F1-score = 0.92; overall regression 

R
2

 = 0.78, normalized RMSE = 0.080). 3.1.1. Classification Task DiagnosticsWe used accuracy metrics of precision, recall, and F1-scores to assess Chimera’s classification abilities. Precision refers to number of true positives divided by total true and false positives, while recall refers to true positives divided by the sum of true positives and false negatives. The F1-Score is a combination of the precision and recall, defined by, 

(
2
∗
precision
∗
recall
)
/
(
precision
+
recall
)

. Classification diagnostics on the test set reported an overall average precision, recall, and F1-score of 0.92, 0.92, and 0.92, respectively (Table 3) (Figure 6). Class-wise F1-scores were high for ‘none’ (0.99) and ‘conifer’ (0.86) classes. This indicated that the ensemble model was able to distinguish between forested and non-forested plots. The CE had difficulty accurately distinguishing the ‘deciduous’ class and ‘mixed’ class, with moderate F1-scores of 0.6 and 0.74 respectively. This difficulty emerged as a result of class label imbalance in the training data. The ‘dead’ class samples were insufficiently assessed due to the low sample number within the test samples (

n
=
1

). Due to this limited number of dead samples in the test set, we assessed each individual k-fold Chimera model in CE for their predictive ability on their respective k-fold validation subset. F1-scores for these k-fold validations were as follows: (k



1

=
0.222

, k



2

=
0.182

, k



3

=
0.0

, k



4

=
0.0

, k



5

=
0.133

), demonstrating a weak predictive ability for the dead class. Comparisons to SVM and RF reported higher levels of performance from the CE in all classes (except ‘dead’ class), with the largest difference occurring with the CE versus the SVM in classifying the ‘deciduous’ (F1-score difference of 0.26) and ‘mixed classes’ (F1-score difference of 0.13) (Table 3). 3.1.2. Regression Task DiagnosticsThe CE presented a strong ability to predict forest structure metrics, with all metrics reporting 

R
2

’s above 0.8 on the independent test data (n = 500) (Figure 7). Scores for the single best individual model (BIM) and ensemble were similar, but with the ensemble consistently outperforming the BIM at all forest structural metrics. Canopy cover was the best performing metric (


R
2

=
0.89
,

 RMSE 

=
8.01

 percent), followed by basal area (


R
2

=
0.87
,

 RMSE 

=
25.88

 ft


2

/ac), AGB (


R
2

=
0.84
,

 RMSE 

=
37.28

 Mg/ha), and finally QMD being the lowest (


R
2

=
0.81
,

 RMSE 

=
3.74

 inches) (Table 4). This was expected, as elements of forest structure such as QMD underneath the canopy are hidden and can be difficult to estimate based on optically sensed spatial feature detection alone, whereas canopy cover features can often be recognized based on imagery alone.Similarly, in spatially explicit prediction, plots demonstrated the ability for the model to be able to distinguish dense forest canopy cover and provided representative estimates of large and small diameter tree stands reflected with low QMD and basal area estimates (Figure 8 and Figure 9)", 3. Results, 3.1. Model Diagnostics and Input Experiments,3
524,"We used accuracy metrics of precision, recall, and F1-scores to assess Chimera’s classification abilities. Precision refers to number of true positives divided by total true and false positives, while recall refers to true positives divided by the sum of true positives and false negatives. The F1-Score is a combination of the precision and recall, defined by, 

(
2
∗
precision
∗
recall
)
/
(
precision
+
recall
)

. Classification diagnostics on the test set reported an overall average precision, recall, and F1-score of 0.92, 0.92, and 0.92, respectively (Table 3) (Figure 6). Class-wise F1-scores were high for ‘none’ (0.99) and ‘conifer’ (0.86) classes. This indicated that the ensemble model was able to distinguish between forested and non-forested plots. The CE had difficulty accurately distinguishing the ‘deciduous’ class and ‘mixed’ class, with moderate F1-scores of 0.6 and 0.74 respectively. This difficulty emerged as a result of class label imbalance in the training data. The ‘dead’ class samples were insufficiently assessed due to the low sample number within the test samples (

n
=
1

). Due to this limited number of dead samples in the test set, we assessed each individual k-fold Chimera model in CE for their predictive ability on their respective k-fold validation subset. F1-scores for these k-fold validations were as follows: (k



1

=
0.222

, k



2

=
0.182

, k



3

=
0.0

, k



4

=
0.0

, k



5

=
0.133

), demonstrating a weak predictive ability for the dead class. Comparisons to SVM and RF reported higher levels of performance from the CE in all classes (except ‘dead’ class), with the largest difference occurring with the CE versus the SVM in classifying the ‘deciduous’ (F1-score difference of 0.26) and ‘mixed classes’ (F1-score difference of 0.13) (Table 3).", 3. Results, 3.1.1. Classification Task Diagnostics,3
525,"The CE presented a strong ability to predict forest structure metrics, with all metrics reporting 

R
2

’s above 0.8 on the independent test data (n = 500) (Figure 7). Scores for the single best individual model (BIM) and ensemble were similar, but with the ensemble consistently outperforming the BIM at all forest structural metrics. Canopy cover was the best performing metric (


R
2

=
0.89
,

 RMSE 

=
8.01

 percent), followed by basal area (


R
2

=
0.87
,

 RMSE 

=
25.88

 ft


2

/ac), AGB (


R
2

=
0.84
,

 RMSE 

=
37.28

 Mg/ha), and finally QMD being the lowest (


R
2

=
0.81
,

 RMSE 

=
3.74

 inches) (Table 4). This was expected, as elements of forest structure such as QMD underneath the canopy are hidden and can be difficult to estimate based on optically sensed spatial feature detection alone, whereas canopy cover features can often be recognized based on imagery alone.Similarly, in spatially explicit prediction, plots demonstrated the ability for the model to be able to distinguish dense forest canopy cover and provided representative estimates of large and small diameter tree stands reflected with low QMD and basal area estimates (Figure 8 and Figure 9)", 3. Results, 3.1.2. Regression Task Diagnostics,3
526,"We explored two versions of SVM and RF models with a single-pixel seven-channel representation of Landsat data, and a 4 pixel × 4 pixel × seven-channel input. We found the single pixel variation resulted in the highest accuracy. RF outperformed SVM in all response variable estimates except basal area. The largest improvements by the Chimera ensemble were observed for AGB and basal area with a 0.08 increase in 

R
2

’s respectively when compared to RF AGB and SVM basal area. Both the BIM k-fold and CE were superior to SVM and RF in all classification tasks except dead (Table 3). Highest classification difference was between the ‘deciduous’ type, with CE having a 0.14 increase in F-score compared to RF. CE also outperformed RF and SVM in regression in all forest structure metrics with the biggest improvements in basal area and AGB (Table 4). Post-hoc comparisons of saturation levels for estimated AGB values were modeled using a saturating exponential function [74,75] defined by, 

γ

(
h
)

=

c
0

+

c
1


(
1
−

e


−
3
h

a


)


, to identify the data saturation asymptote (

c
1

) for AGB prediction. This comparison reported Chimera reaching AGB data saturation much later (416.7 Mg/ha) than RF (386.3 Mg/ha) and SVM (245.0 Mg/ha), which agrees with its ability to perform better at estimating AGB (Figure A2).", 3. Results, 3.2. Model Comparison Experiment,3
527,"Although 27,966 FIA plots were available for the CA-NV study area, we removed a large proportion (>50%) of the samples after manual visual inspection, in which non-forest land-use classification defined by FIA did not correspond to the associated land cover in the NAIP image. Though time-consuming and laborious, this exercise was essential to prevent the model from learning incorrect image texture representations of the forest classes and structural attributes measured in situ [21]. The performance of Chimera can mainly be attributed to its access to those 9967 quality data plots. CNNs are the most data-hungry method of machine learning, primarily due to the sheer number of parameters needed to fit the model, which in turn is based on the volume of training data. We also note that given the differences in FIA protocols over time and regions [61], some forest structure response attributes such as canopy cover were measured subject to variability (in situ versus remote sensed image interpretation), which could have downstream effects on the performance of CE (Figure A5). In terms of portability and robustness, it should be mentioned that our tests of CE are exclusively in the CA-NV region. Although a variety of US Western ecotypes, from temperate forests to semi-arid woodlands are represented in our analysis, our approach would not be applicable to make predictions of forest class or structure in rainforest ecotypes nor the hardwood forests of the Eastern US, unless CE were retrained on data from those specific forest types.", 4. Discussion, Caveats Associated with the Training Data,4
528,"We demonstrate the performance of a novel multi-task, multi-input recurrent convolutional neural network called the Chimera model for forest land use classification and forest structure estimation. We summarized the results of three major objectives as follows: (1) performance of the Chimera model was the highest with the full input dataset that included NAIP, Landsat time-series, and ancillary climate and topography data; (2) the Chimera model outperforms SVM and RF models with the same input data for all classification and regression tasks; and (3) ensembling of multiple Chimera models modestly increased predictive performance compared to a single best fit model alone. These results represent, to our knowledge, the first application of a RCNN with multi-input for improving estimations of forest structure.The ability of the Chimera ensemble to distinguish between forested and non-forested land cover images within California and Nevada presents a new approach for generating a time-series of change detection for both afforestation and deforestation based on high-resolution imagery. Since our model requires only freely accessible data, we can feed new acquisitions of NAIP and Landsat scenes through the existing model to generate new predictions. This potential for continuous prediction is progress towards work similar to Wilson et al. [8] who developed a model for imputing forest carbon stock at a nationally continuous scale. Given access to the national USFS FIA dataset, widely considered the “gold standard” of field collected forest metric samples within the entire United States, one would have a large enough sample size to parameterize multiple robust RCNN models focused on a forest of interest. A future iteration of the Chimera ensemble trained on a new subset of USFS FIA encompassing a region outside of California and Nevada could provide state-of-the-art estimates of forest structure in many completely different ecotypes. Additionally, with integration of advanced satellite technology including the GEDI and NISAR missions [90,91], more opportunities to combine LiDAR or radar information with existing NAIP and Landsat data could generate still better estimates of forest structure.Finally, we see this study as just one indication of the promising application of deep learning architectures to ecology and remote sensing. Future work could include multi-task learning applied to land-cover and land-use mapping problems such as monitoring of woody encroachment on wetlands, or measuring forest loss due to wildfire or disease outbreaks. In addition to forest and stand structural characteristics, future research could inform the identification and delineation of key habitat attributes for wildlife [92]. Wall-to-wall forest structural maps can also be used as inputs for fire modeling applications that depend on canopy cover, canopy height, canopy crown bulk density, and crown base height to determine fire behavior [93]. Integration of our model in a “near real-time” wildfire probability model could provide estimates of fire risk and serve as a tool for prioritizing locations for fire prevention treatments [94]. Predictive modeling applications (e.g., coastline vegetation, wetlands, grasslands, or shrublands) often require both classification (e.g., presence/absence, type) and regression (e.g., abundance/cover conditional on presence).We have demonstrated that the Chimera architecture is capable of fusing various types of data (sensor, climate, and geophysical data, both time-varying and fixed) that are now commonplace in many ecological applications, and using the information they provide to improve predictive ability. By taking advantage of distributed cloud computing, future development of a continuously integrated pipeline could extend this model towards automatically updated landscape or global forest metric estimates. RCNN architectures similar to Chimera present an opportunity to combine disparate data types and move towards global-to-local level ecosystem monitoring.", 5. Conclusions and Future Research,None,5
529,"Wetland is one of the important terrestrial ecosystems, providing a variety of ecosystem services globally and regionally [1,2], including regulating hydrological processes, maintaining biodiversity, and regulating the carbon sequestration of wetland vegetation, etc. [3]. The flooded environment of wetland soil plays an important role in maintaining the ecological balance at the basin scale [4]. However, since 1970, the area of wetlands in the world has been drastically reduced [5,6], and about 50% of the wetlands have been eliminated [7], causing serious ecological and social problems [7]. Numerous studies have shown that changes in the hydrothermal conditions caused by the large-scale degradation of wetlands affect the functions of the ecosystems around the wetlands and their sensitivity to climate factors [8,9,10,11].Forest aboveground biomass (AGB) refers to the mass of the aboveground portion of a forest within a given range, which is generally twice as large as the carbon stock, and it is the basis for measuring ecosystem function and structure [12], and plays a vital role in the assessment of global carbon cycle and climate change [13]. Studies have shown that forest vegetation stores nearly 80% of the biomass of the terrestrial ecosystem [14,15], and the carbon flux between forest vegetation and the atmosphere accounts for 90% of the entire terrestrial ecosystem [16]. Therefore, forest AGB is not only an important carbon pool in the global carbon cycle, but also an important indicator for assessing the potential carbon sink. It is worth noting that the forest AGB is very sensitive to hydrothermal conditions. The most obvious feature is that the forest AGB has large regional differences and large inter-annual fluctuations. For example, in the conclusion of Hu et al. (2016) [17], there is a 13.45 Mg ha−1 difference in forest AGB between humid regions (157.69 Mg ha−1) and dry regions (171.41 Mg ha−1).For forest ecosystems in the inland wetland environment, the degradation of inland wetlands affects the reduction or closure of vegetation stomatal conductance, transpiration, and photosynthesis [18], and vegetation productivity by reducing soil available water [19]. On the other hand, the reduction in soil moisture will intensify the forest’s stress on soil moisture [20,21], and then affect the sensitivity of forest AGB to climate factors. Due to the limited adaptability of forest ecosystems, the degradation of inland wetlands is likely to cause the severing of, and long-lasting and irreversible damage to, forest ecosystems. Therefore, how to comprehensively and accurately understand the impact of inland wetlands on forest ecosystems is a general concern in the current carbon cycle research.Accurate monitoring of forest AGB is the basis for in-depth research on forest ecosystems. At the regional scale, the remote sensing estimation method is the only feasible means to achieve large-scale monitoring at different scales, and it is one of the more commonly used methods for forest AGB estimation [22]. Normalized vegetation index (NDVI) is currently the most commonly used method for monitoring AGB of large-scale forests. This index has been widely used in establishing forest biomass models [23] and extracting forest targets [24]. However, the traditional estimation of forest biomass based on the linear relationship method is subject to a series of reasons, such as the limitation of the reflection wavelength of multispectral remote sensing images, and the NDVI value may be saturated in the dense forest estimation [25]. Moreover, in areas with a high proportion of water bodies, the spectral reflectance of remote sensing may also be affected by water body signals, which will increase the uncertainty of NDVI calculations.The construction of machine learning algorithms not only includes linear relationship parameters but also realizes the application of non-linear parameter datasets. It can be said that machine learning algorithms have improved the accuracy of traditional band combinations to a certain extent [26]. The deep neural networks (DNN) algorithm is developed from the deep learning algorithm of the machine learning model. This method deepens the depth of the hidden layer and overcomes the phenomenon that the classification results of a traditional perceptron are insufficient to solve complex problems. In particular, the current DNN not only adds a variety of non-linear activation functions but also adds a regularization term, which optimizes the performance of the deep provincial network. In addition, neural network models with different functions can be supervised according to different actual problems.At the regional or global scale, most researches focus more on the model’s ability to estimate forest biomass, and the research areas are mostly concentrated in tropical regions. There are few studies on the distribution structure of forest AGB on the watershed scale, and the impact of inland wetland degradation on forest AGB is still lacking in a systematic and in-depth understanding. The Tumen River is an international river located at the junction of China, North Korea, and Russia. It is the only water passage from inland China to the Sea of Japan. This area plays an important role in the three river source areas of Northeast China. In addition, the Tumen River Basin has a relatively high forest coverage rate, which is the only horizontal zonal area of vegetation in China with relatively complete natural community fragments and has a relatively unique wetland hydrothermal environment [27]. However, the impact of the substantial reduction in the wetland area in the basin on the forest AGB is still less concerned, and the understanding is relatively scattered. Therefore, it is of great scientific significance to quantitatively analyze the distribution structure of forest AGB in the Tumen River Basin and deeply understand the impact of rivers, swamps, and other inland wetland types on forest AGB.This study used a DNN method to quantify the distribution structure of forest AGB and explores the impact of inland wetland degradation on forest AGB in the Tumen River Basin (Figure 1). This research is expected to improve the understanding of the protection of wetland forest ecosystems at the basin scale and provide an important theoretical basis for the establishment of regional ecosystem models. ", 1. Introduction,None,1.
530,"The Tumen River Basin is located at the junction of China, North Korea, and Russia, and belongs to the mid-temperate continental monsoon zone. The area is dominated by wetland ecosystem, with an area of 903.66 km2 [28], which is an important wetland forest in the forest ecosystem of northeast China. It is also the most characteristic area of forest ecological environment in the Changbai Mountain area (Figure 2). The area is close to the Sea of Japan and is affected by the ocean climate. The climate in this area is mild, the annual temperature difference is small, and the rainfall is sufficient. Therefore, the forest and vegetation coverage in this watershed is relatively high, with a forest coverage rate of 76%.", 2. Materials and Methods, 2.1. Study Site,2
531," 2.2.1. Field DataWhen building the model, we added two related types of training data. Firstly, we collected 180 sample site inventory data with reference to the previous literature. Each data maintained the consistency of the research at the sample site scale, and followed the principle of sample site measurement to ensure that the collected data were not subject to human interference during the collection period. Finally, all field data are AGB of mature forest containing the coordinates of the center point of the sample plot. The distribution of these data samples in the study area is shown in Figure 2.Another type of training data is obtained from the Geoscience Laser Altimeter System (GLAS) instrument on NASA’s Ice, Cloud, and Land Elevation (ICESat) satellite. We selected the data of L3J and L3K campaigns that are consistent with the sample data collection time and used it as additional training data to participate in the construction of the model. When screening the GLAS data, we removed cloud cover and other noise interference, and footprint points with large errors due to terrain factors, and deleted the value of non-forest locations, and finally attained 1714 footprint points that meet the requirements.  2.2.2. Remote Sensing DataWe obtained remote sensing images of Landsat data used for model training in 2015 from the Google Earth engine (accessed on: https://code.earthengine.google.com, accessed 29 July 2020) and in the pre-processing, we selected image data that at the time point with the best vegetation growth in the study area, and modeled the band values shown in Table 1 as five feature vectors in the model training data. 2.2.3. Climate DataHigh-resolution climate data based on the Earth’s land surface (CHELSA) (Accessed on: http://chelsa-climate.org/, accessed 29 July 2020) is used for the climate feature data, and 17 standardized bioclimate variables (Table 2) are calculated as climate factors. In addition to the characteristics of biometeorological variables, we used additional CRU climate data to analyze the climate elements that control the distribution of forest AGB in the study area. The multi-year average of annual average precipitation, annual average precipitation and soil moisture before and after 2015 are used as climate variables, mainly to explore the relationship between forest AGB and precipitation or temperature in the Tumen River Basin. The distribution of temperature and precipitation in the Tumen River Basin is roughly the same as the global climate distribution.  2.2.4. Other Data SourcesTaking into account the influence of terrain factors on the forest AGB, we used the altitude and slope from Space Shuttle Radar Terrain Mission (SRTM, (Available online: https://srtm.csi.cgiar.org/download/, accessed 29 July 2020)) were used to train the forest AGB’s adaptability to the terrain in the model. Meanwhile, we used Landsat data to calculate the normalized difference vegetation index (NDVI) to characterize vegetation coverage. In addition, to illustrate the distribution of AGB of different vegetation types in the Tumen River Basin, we also used ESA CCI land use data to divide the range and location of different tree species.", 2. Materials and Methods, 2.2. Modeling,2
532,"When building the model, we added two related types of training data. Firstly, we collected 180 sample site inventory data with reference to the previous literature. Each data maintained the consistency of the research at the sample site scale, and followed the principle of sample site measurement to ensure that the collected data were not subject to human interference during the collection period. Finally, all field data are AGB of mature forest containing the coordinates of the center point of the sample plot. The distribution of these data samples in the study area is shown in Figure 2.Another type of training data is obtained from the Geoscience Laser Altimeter System (GLAS) instrument on NASA’s Ice, Cloud, and Land Elevation (ICESat) satellite. We selected the data of L3J and L3K campaigns that are consistent with the sample data collection time and used it as additional training data to participate in the construction of the model. When screening the GLAS data, we removed cloud cover and other noise interference, and footprint points with large errors due to terrain factors, and deleted the value of non-forest locations, and finally attained 1714 footprint points that meet the requirements. ", 2. Materials and Methods, 2.2.1. Field Data,2
533,"We obtained remote sensing images of Landsat data used for model training in 2015 from the Google Earth engine (accessed on: https://code.earthengine.google.com, accessed 29 July 2020) and in the pre-processing, we selected image data that at the time point with the best vegetation growth in the study area, and modeled the band values shown in Table 1 as five feature vectors in the model training data.", 2. Materials and Methods, 2.2.2. Remote Sensing Data,2
534,"High-resolution climate data based on the Earth’s land surface (CHELSA) (Accessed on: http://chelsa-climate.org/, accessed 29 July 2020) is used for the climate feature data, and 17 standardized bioclimate variables (Table 2) are calculated as climate factors. In addition to the characteristics of biometeorological variables, we used additional CRU climate data to analyze the climate elements that control the distribution of forest AGB in the study area. The multi-year average of annual average precipitation, annual average precipitation and soil moisture before and after 2015 are used as climate variables, mainly to explore the relationship between forest AGB and precipitation or temperature in the Tumen River Basin. The distribution of temperature and precipitation in the Tumen River Basin is roughly the same as the global climate distribution. ", 2. Materials and Methods, 2.2.3. Climate Data,2
535,"Taking into account the influence of terrain factors on the forest AGB, we used the altitude and slope from Space Shuttle Radar Terrain Mission (SRTM, (Available online: https://srtm.csi.cgiar.org/download/, accessed 29 July 2020)) were used to train the forest AGB’s adaptability to the terrain in the model. Meanwhile, we used Landsat data to calculate the normalized difference vegetation index (NDVI) to characterize vegetation coverage. In addition, to illustrate the distribution of AGB of different vegetation types in the Tumen River Basin, we also used ESA CCI land use data to divide the range and location of different tree species.", 2. Materials and Methods, 2.2.4. Other Data Sources,2
536," 2.3.1. Processing Training DataThis research uses random sampling method to divide the existing forest AGB data, select 80% of the data as the model training data, 10% as the test data, and the rest as the evaluation model verification data to verify the model.  2.3.2. Model Prediction with the DNN AlgorithmUsing the Tensorflow framework developed by Google (Accessed on: https://tensorflow.google.cn/, accessed 29 July 2020), a fully connected DNN model is established under this framework to achieve the purpose of quantifying the AGB of wetland forests. This model is mainly composed of 4 hidden layers and 500 neurons in each layer. Each layer in the network will use the linear rectification unit (ReLU) function of the modified linear unit as the activation function. To avoid the problems of gradient explosion, gradient disappearance and overfitting, this study used the method of assigning weight attenuation (L2 regularization), dropout and early stopping. Finally, the optimal parameters of the model with a learning rate of 0.0002 and a training batch size of 50 are set to predict the forest AGB of the Tumen River Basin (See Table 3 for the specific structure of the model). 2.3.3. Uncertainty Analysis of the ModelIn order to analyze the accuracy of DNN on the results of the forest AGB spatial distribution, we used the Bootstrap method to calculate the uncertainty of the results. The purpose is to eliminate the difference in the results of modeling using repeated sampling training data for 100 times, and the uncertainty fluctuations in the model during each training process, so as to illustrate the spatial distribution of the model’s uncertainty in the AGB prediction.", 2. Materials and Methods, 2.3. AGB Estimation Model,2
537,"This research uses random sampling method to divide the existing forest AGB data, select 80% of the data as the model training data, 10% as the test data, and the rest as the evaluation model verification data to verify the model. ", 2. Materials and Methods, 2.3.1. Processing Training Data,2
538,"Using the Tensorflow framework developed by Google (Accessed on: https://tensorflow.google.cn/, accessed 29 July 2020), a fully connected DNN model is established under this framework to achieve the purpose of quantifying the AGB of wetland forests. This model is mainly composed of 4 hidden layers and 500 neurons in each layer. Each layer in the network will use the linear rectification unit (ReLU) function of the modified linear unit as the activation function. To avoid the problems of gradient explosion, gradient disappearance and overfitting, this study used the method of assigning weight attenuation (L2 regularization), dropout and early stopping. Finally, the optimal parameters of the model with a learning rate of 0.0002 and a training batch size of 50 are set to predict the forest AGB of the Tumen River Basin (See Table 3 for the specific structure of the model).", 2. Materials and Methods, 2.3.2. Model Prediction with the DNN Algorithm,2
539,"In order to analyze the accuracy of DNN on the results of the forest AGB spatial distribution, we used the Bootstrap method to calculate the uncertainty of the results. The purpose is to eliminate the difference in the results of modeling using repeated sampling training data for 100 times, and the uncertainty fluctuations in the model during each training process, so as to illustrate the spatial distribution of the model’s uncertainty in the AGB prediction.", 2. Materials and Methods, 2.3.3. Uncertainty Analysis of the Model,2
540,"In the description of the range of wetlands, Tootchi et al. (2019) [28] constructed global wetland CWT data, which included non-humid areas, groundwater driven wetlands in TCI areas (GDWs-CI (15%)), regular flooding wetlands (RFW), The intersection of RFWs and GDWs and five types of wetlands such as lakes (from HydroLAKES). We intercepted part of the Tumen River Basin for this article’s exploration of wetlands", 2. Materials and Methods, 2.4. Spatial Distribution of Wetland in Tumen River Basin,2
541,"In the sensitivity analysis, we select the 2015 CRU data annual average temperature, annual average precipitation, and soil moisture to calculate the partial correlation with the forest AGB of the Tumen River Basin. Partial correlation analysis can eliminate the impact of multiple factors on the efficiency of AGB. Here we mainly limit the temperature and precipitation (/soil moisture) calculate the correlation of forest AGB to soil moisture (/precipitation) and discuss forest AGB the effect of moisture control.", 2. Materials and Methods, 2.5. The Impact of Inland Wetlands on Forest AGB,2
542," 3.1.1. Relating Forest Canopy Height to AGBDue to the limited quantity of forest field measurement data in our study area, and after the quality screening, it is difficult to effectively carry out the prediction of forest AGB in the study area with the measured data. Therefore, we use GLAS footprint data to expand the measured data and generate widely distributed forest AGB sample data in the whole study area. Firstly, according to the information of forest canopy height (H) and AGB provided by the measured sample points, the unique allometric growth relationship between H and forest AGB in the study area was established, then the functional relationship between the test points and AGBH in the measured forest data was calculated, and finally, the AGB value corresponding to each GLAS point was obtained. The regression relationship of AGB-H was as follows




A
G
B
=
1.56
×

H

1.59






(1)

In Equation (1), the model explains 82% of the variance in AGB field measurements and the standard error is 6.77 Mg ha−1. Based on the verification results, we believe that the relationship between H and AGB established by the model can be used to expand the measured data from GLASs footprint data. 3.1.2. Forest Biomass Mapping in Tumen River BasinIn this study, we used DNN model combined with multi-source remote sensing data to estimate the forest AGB of the Tumen River Basin. The 10-fold cross validation method was used to verify our results. The results are shown in Figure 3. The model finally obtained a higher R2 of 0.78, and a lower RMSE of 4.21 Mg ha−1. The uncertainty is around 4%. According to this verification result, our model has a good ability to capture regional forest AGB and can effectively simulate regional forest AGB.The spatial distribution of AGB in the Tumen River Basin Forest is shown in Figure 4. The regional average AGB value is 103.43 Mg ha−1, and the main distribution range is between 88.73 and 146.18 Mg ha−1 which represents 146.89 ± 0.48 TgC carbon storage. There are obvious differences in AGB between different tree types. The deciduous broad-leaved forest has a higher AGB accumulation value (103.58 Mg ha−1), while deciduous coniferous forest accounts for the least area in the study area, but average AGB (102.62 Mg ha−1) is second only to the deciduous broad-leaved forest. At the same time, the forest AGB in the Tumen River Basin also presents the characteristics of latitude distribution, with a significant increase and then decrease trend distribution as the latitude rises (Figure 4b). Between 42°N and 43°N, the distribution of AGB reaches its peak. In addition, the forest AGB in the study area also showed a clear upward trend with the elevation gradient and reached a peak at 1000 m. Through the uncertainty analysis results of bootstrap, it is found that the uncertainty of the DNN result is distributed in an altitude gradient. With the increase in altitude, the error of DNN’s estimation of forest AGB also increases, and the distribution range is 2 to 16 Mg ha−1, within the interval (p < 0.01). Through the uncertainty calculation of Bootstrap, we evaluated the uncertainty of the final result after transmission in Figure 4d. The results show that the overall uncertainty of forest AGB in the Tumen River Basin is relatively low. However, there is a relatively high error at higher altitudes, which is caused by the data heterogeneity of GLAS footprint points in the high altitude rugged terrain.", 3. Results, 3.1. Effects of Wetlands on Forest AGB,3
543,"Due to the limited quantity of forest field measurement data in our study area, and after the quality screening, it is difficult to effectively carry out the prediction of forest AGB in the study area with the measured data. Therefore, we use GLAS footprint data to expand the measured data and generate widely distributed forest AGB sample data in the whole study area. Firstly, according to the information of forest canopy height (H) and AGB provided by the measured sample points, the unique allometric growth relationship between H and forest AGB in the study area was established, then the functional relationship between the test points and AGBH in the measured forest data was calculated, and finally, the AGB value corresponding to each GLAS point was obtained. The regression relationship of AGB-H was as follows




A
G
B
=
1.56
×

H

1.59






(1)

In Equation (1), the model explains 82% of the variance in AGB field measurements and the standard error is 6.77 Mg ha−1. Based on the verification results, we believe that the relationship between H and AGB established by the model can be used to expand the measured data from GLASs footprint data.", 3. Results, 3.1.1. Relating Forest Canopy Height to AGB,3
544,"In this study, we used DNN model combined with multi-source remote sensing data to estimate the forest AGB of the Tumen River Basin. The 10-fold cross validation method was used to verify our results. The results are shown in Figure 3. The model finally obtained a higher R2 of 0.78, and a lower RMSE of 4.21 Mg ha−1. The uncertainty is around 4%. According to this verification result, our model has a good ability to capture regional forest AGB and can effectively simulate regional forest AGB.The spatial distribution of AGB in the Tumen River Basin Forest is shown in Figure 4. The regional average AGB value is 103.43 Mg ha−1, and the main distribution range is between 88.73 and 146.18 Mg ha−1 which represents 146.89 ± 0.48 TgC carbon storage. There are obvious differences in AGB between different tree types. The deciduous broad-leaved forest has a higher AGB accumulation value (103.58 Mg ha−1), while deciduous coniferous forest accounts for the least area in the study area, but average AGB (102.62 Mg ha−1) is second only to the deciduous broad-leaved forest. At the same time, the forest AGB in the Tumen River Basin also presents the characteristics of latitude distribution, with a significant increase and then decrease trend distribution as the latitude rises (Figure 4b). Between 42°N and 43°N, the distribution of AGB reaches its peak. In addition, the forest AGB in the study area also showed a clear upward trend with the elevation gradient and reached a peak at 1000 m. Through the uncertainty analysis results of bootstrap, it is found that the uncertainty of the DNN result is distributed in an altitude gradient. With the increase in altitude, the error of DNN’s estimation of forest AGB also increases, and the distribution range is 2 to 16 Mg ha−1, within the interval (p < 0.01). Through the uncertainty calculation of Bootstrap, we evaluated the uncertainty of the final result after transmission in Figure 4d. The results show that the overall uncertainty of forest AGB in the Tumen River Basin is relatively low. However, there is a relatively high error at higher altitudes, which is caused by the data heterogeneity of GLAS footprint points in the high altitude rugged terrain.", 3. Results, 3.1.2. Forest Biomass Mapping in Tumen River Basin,3
545," 3.2.1. Control of Forest AGB in Wetland Area of Tumen River Basin by Climatic FactorsTo explore the impact mechanism of climate change on the accumulation of forest AGB in the study area, we have drawn the climate spatial distribution map in Figure 5 to distinguish and analyze the control of temperature and precipitation on the forest AGB in the study area. The temperature range (−5 °C to 2.2 °C) and precipitation range (557.79 to 1077 mm) in the figure are the main impacts on the forest AGB of the Tumen River Basin. It can be seen from the figure that when the annual average temperature is lower than −2 °C, the forest AGB accumulation in the Tumen River Basin is almost unaffected by precipitation; and when the temperature is higher than −2 °C, the precipitation increased, the accumulation of AGB in the forests of the Tumen River Basin decreased slightly, and the variation range was within 1 Mg ha−1. However, when the precipitation is restricted and only the influence of temperature changes on the forest AGB changes in the study area is considered, it can be found that as the temperature rises, the forest AGB in the study area shows a clear increasing trend. It can be seen that in the spatial distribution of forest AGB in the Tumen River Basin, the accumulation of AGB is more sensitive to temperature changes, and when comparing the distribution of this trend on the altitude gradient, it can be seen that when the altitude is near 780 m in the range, temperature has the greatest control effect on forest AGB. 3.2.2. Effects of Wetlands on Forest AGBMost of the current studies show that the accumulation of forest biomass is closely related to precipitation, especially in arid areas, which is almost not controlled by temperature. However, according to our results, the correlation between precipitation and forest AGB in Tumen River area is not significant. Therefore, we further explored the control effect of wetlands on forest AGB accumulation. We take the soil moisture as the moisture content.Under the condition of controlling the effect of annual average temperature on forest AGB, the partial correlation between soil moisture and annual precipitation on forest AGB was calculated. Under the control of temperature and soil moisture, there was a weak negative correlation between precipitation and forest AGB (R = −0.01, p > 0.05). However, in controlling temperature and precipitation, only considering the correlation between soil moisture and forest AGB, we found that soil moisture had a significant positive effect on the accumulation of forest AGB. The results showed that soil moisture had a more significant effect on forest AGB accumulation than precipitation in Tumen River Basin.", 3. Results, 3.2. Effects of Wetlands on Forest AGB Climate Sensitivity,3
546,"To explore the impact mechanism of climate change on the accumulation of forest AGB in the study area, we have drawn the climate spatial distribution map in Figure 5 to distinguish and analyze the control of temperature and precipitation on the forest AGB in the study area. The temperature range (−5 °C to 2.2 °C) and precipitation range (557.79 to 1077 mm) in the figure are the main impacts on the forest AGB of the Tumen River Basin. It can be seen from the figure that when the annual average temperature is lower than −2 °C, the forest AGB accumulation in the Tumen River Basin is almost unaffected by precipitation; and when the temperature is higher than −2 °C, the precipitation increased, the accumulation of AGB in the forests of the Tumen River Basin decreased slightly, and the variation range was within 1 Mg ha−1. However, when the precipitation is restricted and only the influence of temperature changes on the forest AGB changes in the study area is considered, it can be found that as the temperature rises, the forest AGB in the study area shows a clear increasing trend. It can be seen that in the spatial distribution of forest AGB in the Tumen River Basin, the accumulation of AGB is more sensitive to temperature changes, and when comparing the distribution of this trend on the altitude gradient, it can be seen that when the altitude is near 780 m in the range, temperature has the greatest control effect on forest AGB.", 3. Results, 3.2.1. Control of Forest AGB in Wetland Area of Tumen River Basin by Climatic Factors,3
547,"Most of the current studies show that the accumulation of forest biomass is closely related to precipitation, especially in arid areas, which is almost not controlled by temperature. However, according to our results, the correlation between precipitation and forest AGB in Tumen River area is not significant. Therefore, we further explored the control effect of wetlands on forest AGB accumulation. We take the soil moisture as the moisture content.Under the condition of controlling the effect of annual average temperature on forest AGB, the partial correlation between soil moisture and annual precipitation on forest AGB was calculated. Under the control of temperature and soil moisture, there was a weak negative correlation between precipitation and forest AGB (R = −0.01, p > 0.05). However, in controlling temperature and precipitation, only considering the correlation between soil moisture and forest AGB, we found that soil moisture had a significant positive effect on the accumulation of forest AGB. The results showed that soil moisture had a more significant effect on forest AGB accumulation than precipitation in Tumen River Basin.", 3. Results, 3.2.2. Effects of Wetlands on Forest AGB,3
548,"Precisely predicting the vegetation biomass distribution in the wetland area is one of the challenges of biomass exploration. In general, using vegetation indices and empirical regression model methods [29] to estimate AGB usually results in a decrease in prediction performance due to the influence of data noise [30]. In this study, the DL method provided an important role for the accurate assessment of wetland forest AGB. Using the DNN method and combining a large number of predictive variables, such as remote sensing images, climate, and terrain-based data, this study obtained a reliable forest AGB (4.17 ± 0.47 Mg ha−1) distribution in the Tumen River Basin (Table 4). The inter-level structure of the DNN model and the connection function of each component are more capable of explaining abstract regression problems; for example, using the L2 method to limit overfitting has a better performance compared to shallow machine learning models. Therefore, it has a good performance in eliminating the uncertainty of remote sensing data caused by special environmental influences.", 4. Discussion, 4.1. Find a Suitable Method to Map the Biomass Distribution of Tumen River Basin,4
549,"For forest ecosystems, temperature and rainfall and seasonal patterns are important factors affecting forest growth [31]. However, the stress of different environmental factors on forest AGB also means that the complexity of its internal relationship increases. According to our climate-space mapping of the forests in the Tumen River Basin, the increase in precipitation may lead to a decrease in the AGB of the forests in this area. This is contrary to the study proposed by Fang et al. (2005) [32] that NDVI of deciduous broad-leaved forest in northeast China is positively correlated with annual precipitation. The reason for this phenomenon is that there are a large number of wetlands in the Tumen River Basin. Due to the existence of wetlands, the forests in this area are not sensitive to changes in precipitation. Through the analysis of the correlation between wetland and forest AGB, it is also proved that when the impact of wetland on the forest is excluded, precipitation has a weak positive correlation with forest AGB. This result is similar to the findings of Stegen et al. (2011) [33] in the study of tropical forests. In dry tropical and temperate forests, forest biomass increases with the driest season and annual precipitation, but in wet and temperate forests. In humid tropical forests, the impact of this change in precipitation on forest biomass is not clear.In the past few decades, under the background of climate change, Northeast China has shown a trend of increasing temperature and decreasing precipitation [15]. However, according to our results, this trend may lead to an increase in forest AGB in the Tumen River Basin and promote the accumulation of carbon storage in the region. Therefore, under the trend of future climate change, the wetland is an important factor to protect the growth trend of forests from weakening due to the decline in precipitation. Therefore, the protection of wetland ecosystems can not only prevent wetland degradation but also play an important role in promoting forest growth and increasing carbon storage. ", 4. Discussion, 4.2. Wetlands Limit the Impact of Precipitation on Forest AGB,4
550,"The results of correlation analysis between soil water content and forest AGB showed that the impact and feeding effect of wetland on the forest in its adjacent area was incomparable to that of water supply in other areas. Wetland degradation, resulting in the reduction of wetland area and the loss of ecosystem function, will simultaneously change the pattern of forest distribution and lead to the accumulation of forest biomass. Climate and environmental changes caused by wetland loss cannot be ignored [34]. Since the 1990s, the wetland area on the Chinese side of the Tumen River Basin alone has decreased by 19,560 ha, accounting for 40.54% of the total in the 1990s [35], and at the same time, the carbon storage on the forest ground also decreased by 10,000 Mg C between 1990 and 2015 [36].By analyzing the correlation between wetland and forest AGB in the Tumen River Basin, the reduction in its wetland influence range will result in a decrease in the distance between the forest location and the wetland where the minimum AGB reached under the current environment. In this regard, our research is based on the scenario of increasing the scope of wetland influence and inferred the degradation of wetland in the wetland influence zone, that is, the reduction in the area corresponding to the distance from the wetland boundary, and the degree of impact on the forest AGB in the Tumen River Basin. The results are shown in Table 5. When the wetland area decreases by 1 km2 on average, the forest AGB accumulated in the Tumen River Basin will decrease by 0.074 Mg ha−1.Therefore, under the background of achieving carbon neutrality in the country in 2060, maintaining the steady growth of forest carbon storage in the Tumen River Basin requires not only the protection of the forest in this area, but also the strengthening of the protection of the wetland ecosystem in the area to ensure the in the context of climate change, the forests in this area are growing steadily.", 4. Discussion, 4.3. Possible Impacts of Wetland Changes on the Tumen River Basin Forest AGB,4
551,"The forest ecosystem of the Tumen River Basin is unique in its geographical location, and the assessment of its forest AGB is an important part of the ecological environment assessment in both China and North Korea. The DNN model is used to estimate the forest AGB of the Tumen River Basin. The results show that the average AGB of the forest in the Tumen River Basin is 103.43 Mg ha−1, and its spatial distribution follows the law of changing with altitude and altitude. This phenomenon reflects the sensitivity of AGB to climate factors. The analysis results show that the forest ecosystem of the Tumen River Basin is unique in its geographical location, and the assessment of its forest AGB is an important part of the ecological environment assessment in both China and North Korea. The results show that the water restriction effect of wetlands on the forest AGB in the Tumen River Basin is greater than precipitation. Therefore, under the trend of drying in the northeast in the future, protecting the wetland’s water replenishment barrier is an important direction to protect the stable development of forest carbon sinks in the Tumen River Basin under the current carbon neutral background. The results of this study provide a theoretical basis for discovering the link between forests and wetlands and studying the development trend of forest carbon storage.", 5. Conclusions,None,5
552,"Logging, including illegal and selective activities, causes mostly small-scale but spatially widespread disturbances in tropical forests. Illegal logging accounts for ~40% of all logging in tropical forests and up to 72% of all logging in the Brazilian Amazon [1,2]. Despite the large uncertainties, it has been estimated to affect ~12,000 km2 year−1 of forests in the Brazilian Amazon and is responsible for gross carbon losses of ~0.08 Pg C year−1 or ~33% of the Amazon’s annual carbon budget between 1999 and 2002 [3,4]. Besides the direct implications on the carbon cycle, logging also causes ecological impacts, such as the increased mortality of remaining trees, increased fire risk, and losses of floral and faunal biodiversity [3,5,6]. Furthermore, the long-term effects of logging on forest dynamics and turnover remain poorly understood, but likely persist for decades [7].Given the impacts of logging on a forest’s carbon stocks and biodiversity, there is a growing interest in tracking these direct human-induced forest disturbances [8]. This is critical for better understanding the contribution of logging to the carbon budget and ultimately supporting actions for climate change mitigation [4]. However, unlike forest clear-cutting, logging is not easily detected by remote sensing. Compared to clear-cutting, logging causes comparably subtler changes to the canopy, such as opening gaps over logging decks and roads, but most of the canopy damage is due to the direct impacts of tree-falls [3]. Furthermore, the detection challenge increases for low-impact logging (i.e., selective or reduced impact logging), since these activities are carefully planned to minimize environmental impacts, by only extracting targeted individual trees of non-endangered species with high market value.Satellite imagery from the Landsat series (30 m resolution) has been successfully used to map logging disturbances in Amazon forests using mono-temporal, e.g., [3,9], or multi-temporal, e.g., [10], approaches. However, although Landsat satellites provide the longest historical time series (1984-today), the spatial resolution of their instruments is limited with respect to capturing all the small-scale disturbances associated with logging and especially low-impact logging. Alternatively, studies have shown that VHR satellite imagery (≤1 m spatial resolution) is a promising way to map small-scale disturbances from natural mortality and logging by the visual inspection of multi-date imagery [11,12,13]. More recently, Kellner and Hubbell [14] applied an automated method to detect the mortality of canopy tree species Handroanthus guayacan in tropical forests based on synchronous flowering. However, their method only works for tree species with synchronous annual flowering. At this time, we still lack information about the effects of tree size, tree-fall gap opening, and time after the event on the sensitivity of the disturbance detection from the VHR satellite data.Automated disturbance detection using VHR satellite imagery still poses technical challenges, as differences in view-illumination geometries between the pairs of images may cause a mismatch of tree crown geo-location, e.g., [15,16]. Thus, the appearance of artifacts due to canopy shadowing can induce misclassification of disturbance [15], and the high local canopy spectral variability hampers the success of pixel-based change detection approaches [16]. To solve these problems, some studies suggest the application of object-based analyses [15,16] focusing on physically meaningful features rather than pixels. This is often done by the segmentation of images into individual tree crown (ITC) polygon objects, which minimizes the high local spectral variability in the canopy, and reduces the problems of tree crown geo-misallocation. Airborne LiDAR data have also been used to investigate the impacts of selective logging [17,18,19] and natural tree mortality [20] in the Amazon. These studies pointed out that the height difference between a pair of LiDAR data, acquired pre- and post-logging, was strongly related to the aboveground biomass (AGB) change. These approaches enabled the estimation of AGB loss due to logging with fairly low (2–18%) uncertainty, and with precise observation of canopy gaps. Although they achieved a high precision for estimating small-scale disturbance impacts, airborne LiDAR data are not ideal for operational monitoring over large and remote areas because of the high costs associated with data acquisition. Nevertheless, studies suggest that the combination of airborne LiDAR and VHR satellite data could prove useful to quantitatively assess and validate how VHR satellite data can observe individual canopy tree loss, e.g., [11].In this study, we explore the potential of VHR satellite imagery as a means to detect canopy tree loss associated with low-intensity logging in closed-canopy tropical forests. Specifically, we address the following questions: (1) How does logging drive changes in forest canopy height? (2) Can low-intensity logging events be detected by VHR satellite data? (3) Which remote sensing metrics are the most important for tree loss detection? (4) For how long after a disturbance can VHR satellite data still detect it? (5) Is the satellite-based tree loss map consistent across disturbed and undisturbed forests?To answer these questions, we acquired a complete dataset of multi-date (pre- and post-logging) airborne LiDAR and VHR satellite data from WorldView-2 and GeoEye-1 satellites, and a comprehensive field dataset of tree-by-tree georeferenced logged trees at Jamari National Forest in the Brazilian Amazon. This enabled us to evaluate the potential of optical remote sensing to detect tree-by-tree disturbances against a carefully collected airborne LiDAR and ground record of logging. ", 1. Introduction,None,1.
553,"The study area is located in the Jamari National Forest (09°10′S, 63°01′W), next to the BR-364 highway, 90 km from Porto Velho city, capital of the Rondônia state, Brazil (Figure 1). The Jamari Forest covers 2200 km2 of terra firme lowland ombrophilous open forests [21], with tree species of high commercial value. From the total area, 960 km2 (44%) has been allocated for private selective logging concessions since 2008. The forest concessions are administered and managed by the Brazilian Institute of Environment and Renewable Mineral Resources (IBAMA) and the Brazilian Forest Service, respectively. Wood extraction is limited to (i) non-endangered species allowed by IBAMA; (ii) trees with a diameter at breast height (DBH) greater than 50 cm; and (iii) an extraction density of up to 25.8 m3 ha−1. The managed areas are left to recover naturally for 25 years after extraction.This study focuses on an area of 76.6 km2 inside the total managed area, with the availability of images from a pair of VHR satellites (WorldView-2 and GeoEye-1). The area covers four annual production units (UPA): UPA-01 (logged in 2010/2011), UPA-06 (logged in 2016), part of UPA-10 (logged in 2017), and UPA-11 (logged in 2015). Two smaller sections of the study area were analyzed using LiDAR datasets (Figure 1): (A) 1.4 km2 over UPA-06 observed pre- and post-logging by the satellite and LiDAR instruments (analyses of Section 3.1 and Section 3.2), and (B) 1.04 km2 over UPA-01 evaluated by a time series of LiDAR data from 2011 to 2017 (analysis of Section 3.3). The imagery also covers an active legal mining site of Cassiterite ore, located in the western part of the study area. The forests outside of UPAs and away from the mining site are nominally undisturbed.Based on a forest inventory of the UPA-06 conducted by the concessionaire in 2015 (prior to logging), the logged trees include at least 18 different species, with DBH ranging from 50 to 185 cm (mean = 92 cm) and height ranging from 11 to 28 m (mean = 20 m). The region has two well-defined seasons: a wet season from December to May, and a dry season from June to November, with annual precipitation of 2000 mm, varying from 14 mm in the driest month (July) to 318 mm in the wettest (January), as indicated by Tropical Rainfall Measuring Mission (TRMM) data (product TRMM 3B43 v7 at 0.25 deg). Monthly mean temperature ranges from 24 °C in June/July to 27 °C in October, according to the Climatic Research Unit (product v4.01) [22]. The terrain is hilly, with heights ranging from 90 to 158 m above the sea level as measured by the Shuttle Radar Topography Mission v2.1 [23].", 2. Study Area ,None,2
554,"We used airborne LiDAR data and field logged tree coordinates to characterize canopy height changes associated with tree loss events derived from logging. Using this information, we created a tree loss map. We acquired airborne LiDAR data over 1.4 km2 of forests at the UPA-06 during 2015 (pre-logging) and 2017 (post-logging) (Table 1 and area A in Figure 1). The LiDAR point cloud (x, y, z coordinates) was processed into a canopy height model (CHM) following four steps of pre-processing: point classification, generation of a Digital Terrain Model (DTM), height normalization, and extraction of CHM. First, we classified the points into ground or vegetation classes using the lasground, lasheight, and lasclassify functions from LAStools 3.1.1 [24]. Second, to ensure that potential acquisition effects between the two datasets did not interfere with the analysis, we merged their points classified as ground and created a combined DTM with a 1 × 1 m pixel using the TINSurfaceCreate function from FUSION/LDV 3.6 [25]. Third, we normalized the point’s height to height above ground by subtracting the combined DTM height from their values. Finally, we extracted the CHMs considering the highest height of vegetation on each 1 × 1 m pixel using the CanopyModel function from FUSION/LDV. No adjustment for horizontal displacement between the datasets was necessary because tree crowns’ positioning agreed nearly perfectly. Both LiDAR collections had very high point densities (≥12 points m−2), which vary across studies, depending on the platform used for data collection.As already mentioned, we adopted an object-based approach instead of a pixel-based analysis for both LiDAR and VHR analysis. To delineate the ITCs using the LiDAR data, we applied the voronoi-based method (FindTreesCHM and ForestCAS functions) from the rLiDAR R-package [26]. More details on ITC delineation are described in the Supplementary Material S1. The pre-logging LiDAR CHM was used as the input because the tree crowns from logged trees were still intact. To characterize canopy height changes associated with tree loss events and to define a threshold to detect canopy tree loss from logging, we assessed the LiDAR CHM height difference between the acquisitions (ΔCHM = CHMdate2 – CHMdate1) considering 172 ground-mapped logged trees. Tree geolocation was acquired by the forest concessionaire in 2015, prior to the logging activities that occurred in August 2016, using a Garmin 64S handheld global positioning system (GPS) (~10 m precision). We assessed the distribution of most negative height differences in a 30 m radius around logged trees (n = 172) and around non-logged trees areas (n = 146). This radius was chosen to account for (1) tree coordinate displacement due to GPS location error and differences of geo-location between tree trunks and crowns, and (2) displacement between tree coordinates and the areas actually impacted by the tree losses. To ensure that the non-logged tree areas did not overlap with each other nor with areas included within logged trees’ radii, we randomly distributed points across the area at least 60 m away from the logged tree coordinates and from each other. We defined the ΔCHM threshold that maximally separated the distributions of height difference from logged and non-logged areas by fitting a logistic regression model and inspecting the results.Using the ΔCHM threshold, we detected tree losses associated with logging and generated the LiDAR-based tree loss map. To assess how far the detected tree loss events occurred from logged trees, we analyzed the nearest neighbor distances between the two datasets. We also calculated the rate of tree loss occurrence per area and the percentage of canopy change between 2015 and 2017. ", 3. Material and Methods, 3.1. Tree Loss Detection Using LiDAR Data,3
555," 3.2.1. Satellite Data Acquisition and PreprocessingWe acquired VHR satellite data of the study area during 2014 (WorldView-2) and 2017 (GeoEye-1) (Table 1). The intersection of the two images covered an area of 76.6 km2, of which 1.4 km2 overlapped with the LiDAR data of UPA-06 forests (Figure 2). In order to convert the VHR data into surface reflectance, we applied the 6S radiative transfer model [27]. This was conducted using the OpticalCalibration function implemented in the Orfeo Toolbox (OTB) 6.4 [28]. After the correction, we selected only the blue, green, red, and near infrared (NIR) bands, because these bands were available for both GeoEye-1 and WorldView-2 satellites. To resample the pixel size of the multispectral data at the resolution of the panchromatic imagery (0.5 m), we applied the Bayes data fusion method [29] implemented in OTB 6.4. This fusion method is a probabilistic approach that combines the higher spatial resolution from the panchromatic band with the spectral bands. It is considered one of the best methods for preserving the spectral information from VHR satellite images when compared to other traditional fusion methods [29]. In order to match the tree crowns between LiDAR and satellite datasets, we co-registered (i.e., aligned) the VHR satellite data with the LiDAR CHM. Only a translation of a few pixels was necessary to match the datasets. As the pair of images was acquired under different sun-sensor geometry angles and by different sensors (Table 1), to ensure that the signals of VHR satellite images were comparable, we normalized the post-logging image based on the pre-logging image. The normalization was done using the histogram matching method by the histMatch function from the RStoolbox R-package [30]. This method extracts the cumulative distribution functions from both images, adjusting the target histogram as a function of the source histogram. 3.2.2. Selection and Extraction of VHR Satellite MetricsIn addition to the reflectance of the spectral bands, we calculated two widely used vegetation indices to explore forest structural changes: the normalized difference vegetation index (NDVI) [31] and the enhanced vegetation index (EVI) [32]. Since shade is known to be associated with tree mortality, e.g., [33], we also calculated a set of shadow metrics to be used in the modeling. To detect the shadow, we employed a simple thresholding method using the NIR band of the post-logging VHR image. We manually sampled shaded (n = 100) and non-shaded (n = 100) pixels to define a threshold separating the two classes. The threshold was determined considering the first percentile of NIR reflectance (NIR = 0.21) that covered the non-shaded pixels. Hence, all pixels with values below this threshold were classified as shadow. This shadow map was later used to calculate shadow metrics for RF modeling after performing the ITC delineation.Using the NIR band from the pre-logging VHR data, we delineated ITCs with the marker-controlled watershed segmentation (MCWS) method. The vwf and mcws functions from the ForestTools R-package were used [34] (more details in Supplementary Material 1).Based on the LiDAR-based tree loss map, we selected ITC samples representing tree loss and non-tree loss events (n = 200 each) to train the RF model. The tree loss samples were collected randomly from the LiDAR tree loss map. To collect non-tree loss samples, we selected samples at least 5 m away from the LiDAR tree loss detections to minimize potential mismatches of tree crown locations between LiDAR and VHR data. Then, we extracted the VHR satellite data (reflectance of the red, green, blue, and NIR bands; NDVI and EVI; and shadow) from date1 and date2 for each sample.Using the extracted data, we created a total of 18 metrics for RF modeling. Since each ITC contains hundreds of pixels, we first summarized the values inside the ITCs of each of the four reflectance bands and two vegetation indices by calculating the mean and standard deviation (SD); then, we calculated the mean and SD differences (date2 – date1) metrics for each attribute. For the shadow attribute, considering only the values from date2, we calculated six metrics to describe the distribution of shadows inside the tree crowns. The first metric was the shadow fraction, which consisted of the ratio between the area occupied by shadow pixels and the total ITC area. The shadow pixels inside ITC were segmented and the segments were analyzed to create the remaining five metrics: number of segments and maximum, mean, median, and SD of segments’ size. To remove noise, we filtered out segments consisting of only one pixel.  3.2.3. RF ModelRF is a machine-learning algorithm, which consists of an ensemble of decision trees [35]. RF reduces the prediction variance by using a large number of decision trees. We trained RF models using 18 VHR satellite metrics as predictors to classify 400 samples as tree loss or non-tree loss events. This was performed using the randomForest R-package v4.6-12 [36]. Thus, to create the model, we generated 1000 decision trees; each tree was created using a random subset consisting of 2/3 of the samples; and for each node of a tree, only three from the 18 predictors were randomly chosen for that node classification. Since each decision tree has a classification response for a given sample, the ensemble of responses corresponds to a pseudo-probability for classifying that sample as tree loss or non-tree loss. In general, the majority of votes is chosen as the response. However, since our classification problem was binary (presence or absence of tree loss) and our interest was to optimize the precision (inverse of commission error) of the tree loss occurrence class, we used a weighted voting approach towards this class, minimizing commission errors, but increasing omission errors. Finally, we applied the model to predict the class of every ITC and create a satellite-based tree loss map. 3.2.4. Validation of the Satellite-Based Tree Loss MapTo validate the satellite map, we used the LiDAR map as a reference. We intersected both maps and obtained the number of true positives (TP), false positives (FP), and false negatives (FN). TP is defined as the number of ITCs correctly identified by the satellite map, judged by whether they intersected with the ITCs of the LiDAR map; FN is the number of ITCs not identified by the satellite map, but identified by the LiDAR map; and FP is the number of ITCs incorrectly identified by the satellite map, i.e., ITCs which do not occur in the LiDAR map. For the intersections, we used a small buffer of one meter around the tree loss detections to minimize effects of artificial tree crown displacement between satellite and LiDAR datasets. To evaluate the accuracy of the model, we used TP, FP, and FN to calculate two accuracy metrics: precision (P) and recall (R) (Equations (1) and (2)). Precision is the inverse of the commission error and measures how much of the satellite detections coincided with the LiDAR detections. The recall is the inverse of omission error and measures how many ITCs of the LiDAR map were detected by the satellite map.


P = TP/(TP + FP)


(1)



R = TP/(TP + FN)


(2)

We performed additional analyses to explore the model sensitivity to random sampling and tree loss probability cutoff, the spatial dependence of detections between satellite and LiDAR maps, variable importance for modeling, and sensitivity of detections to vertical structure change and tree height. To explore the model sensitivity to sampling, we trained 30 RF models using different random sampling runs. The accuracy metrics (P and R) from the models were aggregated into mean and 95% confidence intervals. To explore the tree loss probability cutoff sensitivity and select a threshold to generate a map, while ensuring that the model predictions had a high precision, we assessed the model performance as a function of the RF tree loss probability ranging from 0.5 to 0.95. As an independent measure of detection capability, we tested if there was significant spatial dependence between tree losses detected by VHR satellite imagery and LiDAR data. For this purpose, we extracted the nearest neighbor distances between the tree loss detections of the two maps, and compared the cumulative distribution of nearest neighbor distances with a completely random (Poisson) point process. We simulated 199 realizations of the random point process using a Monte Carlo approach and created an envelope of complete spatial randomness (CSR) with a 1% significance level. This was done using the envelope and Gcross functions from the spatstat R-package v1.47 [37]. If the observed distribution was located inside the CSR envelope, that would mean that VHR satellite detections occurred independently in space from the LiDAR detections and vice versa.The sensitivity of detection success to vertical structure change and tree height was assessed by exploring the LiDAR CHM pre- and post-logging heights, and ΔCHM over correct VHR satellite detections. Finally, to explore the importance of the different VHR satellite variables for the modeling, we ranked the variables according to the mean decrease accuracy (MDA) metric [35]. Once each node had been determined in a decision tree, this metric was computed by removing a single variable from the pool of variables and assessing the decrease in the model accuracy. The mean and 95% confidence interval of MDA for each variable were computed for the 30 models. The variables with the largest MDA were ranked highest in importance. To further test whether a variable was significantly important in the voting process of the RF, we compared the observed MDA versus a null distribution of MDA. We created this null distribution by running the model 30 times while shuffling the sample responses randomly. This was performed using the rfPermute v2.1.6 R-package [38]. We reported which variables showed MDAs significantly different from the null distribution considering a 5% significance level. ", 3. Material and Methods, 3.2. Tree Loss Detection Using VHR Satellite Data and RF Model,3
556,"We acquired VHR satellite data of the study area during 2014 (WorldView-2) and 2017 (GeoEye-1) (Table 1). The intersection of the two images covered an area of 76.6 km2, of which 1.4 km2 overlapped with the LiDAR data of UPA-06 forests (Figure 2). In order to convert the VHR data into surface reflectance, we applied the 6S radiative transfer model [27]. This was conducted using the OpticalCalibration function implemented in the Orfeo Toolbox (OTB) 6.4 [28]. After the correction, we selected only the blue, green, red, and near infrared (NIR) bands, because these bands were available for both GeoEye-1 and WorldView-2 satellites. To resample the pixel size of the multispectral data at the resolution of the panchromatic imagery (0.5 m), we applied the Bayes data fusion method [29] implemented in OTB 6.4. This fusion method is a probabilistic approach that combines the higher spatial resolution from the panchromatic band with the spectral bands. It is considered one of the best methods for preserving the spectral information from VHR satellite images when compared to other traditional fusion methods [29]. In order to match the tree crowns between LiDAR and satellite datasets, we co-registered (i.e., aligned) the VHR satellite data with the LiDAR CHM. Only a translation of a few pixels was necessary to match the datasets. As the pair of images was acquired under different sun-sensor geometry angles and by different sensors (Table 1), to ensure that the signals of VHR satellite images were comparable, we normalized the post-logging image based on the pre-logging image. The normalization was done using the histogram matching method by the histMatch function from the RStoolbox R-package [30]. This method extracts the cumulative distribution functions from both images, adjusting the target histogram as a function of the source histogram.", 3. Material and Methods, 3.2.1. Satellite Data Acquisition and Preprocessing,3
557,"In addition to the reflectance of the spectral bands, we calculated two widely used vegetation indices to explore forest structural changes: the normalized difference vegetation index (NDVI) [31] and the enhanced vegetation index (EVI) [32]. Since shade is known to be associated with tree mortality, e.g., [33], we also calculated a set of shadow metrics to be used in the modeling. To detect the shadow, we employed a simple thresholding method using the NIR band of the post-logging VHR image. We manually sampled shaded (n = 100) and non-shaded (n = 100) pixels to define a threshold separating the two classes. The threshold was determined considering the first percentile of NIR reflectance (NIR = 0.21) that covered the non-shaded pixels. Hence, all pixels with values below this threshold were classified as shadow. This shadow map was later used to calculate shadow metrics for RF modeling after performing the ITC delineation.Using the NIR band from the pre-logging VHR data, we delineated ITCs with the marker-controlled watershed segmentation (MCWS) method. The vwf and mcws functions from the ForestTools R-package were used [34] (more details in Supplementary Material 1).Based on the LiDAR-based tree loss map, we selected ITC samples representing tree loss and non-tree loss events (n = 200 each) to train the RF model. The tree loss samples were collected randomly from the LiDAR tree loss map. To collect non-tree loss samples, we selected samples at least 5 m away from the LiDAR tree loss detections to minimize potential mismatches of tree crown locations between LiDAR and VHR data. Then, we extracted the VHR satellite data (reflectance of the red, green, blue, and NIR bands; NDVI and EVI; and shadow) from date1 and date2 for each sample.Using the extracted data, we created a total of 18 metrics for RF modeling. Since each ITC contains hundreds of pixels, we first summarized the values inside the ITCs of each of the four reflectance bands and two vegetation indices by calculating the mean and standard deviation (SD); then, we calculated the mean and SD differences (date2 – date1) metrics for each attribute. For the shadow attribute, considering only the values from date2, we calculated six metrics to describe the distribution of shadows inside the tree crowns. The first metric was the shadow fraction, which consisted of the ratio between the area occupied by shadow pixels and the total ITC area. The shadow pixels inside ITC were segmented and the segments were analyzed to create the remaining five metrics: number of segments and maximum, mean, median, and SD of segments’ size. To remove noise, we filtered out segments consisting of only one pixel. ", 3. Material and Methods, 3.2.2. Selection and Extraction of VHR Satellite Metrics,3
558,"RF is a machine-learning algorithm, which consists of an ensemble of decision trees [35]. RF reduces the prediction variance by using a large number of decision trees. We trained RF models using 18 VHR satellite metrics as predictors to classify 400 samples as tree loss or non-tree loss events. This was performed using the randomForest R-package v4.6-12 [36]. Thus, to create the model, we generated 1000 decision trees; each tree was created using a random subset consisting of 2/3 of the samples; and for each node of a tree, only three from the 18 predictors were randomly chosen for that node classification. Since each decision tree has a classification response for a given sample, the ensemble of responses corresponds to a pseudo-probability for classifying that sample as tree loss or non-tree loss. In general, the majority of votes is chosen as the response. However, since our classification problem was binary (presence or absence of tree loss) and our interest was to optimize the precision (inverse of commission error) of the tree loss occurrence class, we used a weighted voting approach towards this class, minimizing commission errors, but increasing omission errors. Finally, we applied the model to predict the class of every ITC and create a satellite-based tree loss map.", 3. Material and Methods, 3.2.3. RF Model,3
559,"To validate the satellite map, we used the LiDAR map as a reference. We intersected both maps and obtained the number of true positives (TP), false positives (FP), and false negatives (FN). TP is defined as the number of ITCs correctly identified by the satellite map, judged by whether they intersected with the ITCs of the LiDAR map; FN is the number of ITCs not identified by the satellite map, but identified by the LiDAR map; and FP is the number of ITCs incorrectly identified by the satellite map, i.e., ITCs which do not occur in the LiDAR map. For the intersections, we used a small buffer of one meter around the tree loss detections to minimize effects of artificial tree crown displacement between satellite and LiDAR datasets. To evaluate the accuracy of the model, we used TP, FP, and FN to calculate two accuracy metrics: precision (P) and recall (R) (Equations (1) and (2)). Precision is the inverse of the commission error and measures how much of the satellite detections coincided with the LiDAR detections. The recall is the inverse of omission error and measures how many ITCs of the LiDAR map were detected by the satellite map.


P = TP/(TP + FP)


(1)



R = TP/(TP + FN)


(2)

We performed additional analyses to explore the model sensitivity to random sampling and tree loss probability cutoff, the spatial dependence of detections between satellite and LiDAR maps, variable importance for modeling, and sensitivity of detections to vertical structure change and tree height. To explore the model sensitivity to sampling, we trained 30 RF models using different random sampling runs. The accuracy metrics (P and R) from the models were aggregated into mean and 95% confidence intervals. To explore the tree loss probability cutoff sensitivity and select a threshold to generate a map, while ensuring that the model predictions had a high precision, we assessed the model performance as a function of the RF tree loss probability ranging from 0.5 to 0.95. As an independent measure of detection capability, we tested if there was significant spatial dependence between tree losses detected by VHR satellite imagery and LiDAR data. For this purpose, we extracted the nearest neighbor distances between the tree loss detections of the two maps, and compared the cumulative distribution of nearest neighbor distances with a completely random (Poisson) point process. We simulated 199 realizations of the random point process using a Monte Carlo approach and created an envelope of complete spatial randomness (CSR) with a 1% significance level. This was done using the envelope and Gcross functions from the spatstat R-package v1.47 [37]. If the observed distribution was located inside the CSR envelope, that would mean that VHR satellite detections occurred independently in space from the LiDAR detections and vice versa.The sensitivity of detection success to vertical structure change and tree height was assessed by exploring the LiDAR CHM pre- and post-logging heights, and ΔCHM over correct VHR satellite detections. Finally, to explore the importance of the different VHR satellite variables for the modeling, we ranked the variables according to the mean decrease accuracy (MDA) metric [35]. Once each node had been determined in a decision tree, this metric was computed by removing a single variable from the pool of variables and assessing the decrease in the model accuracy. The mean and 95% confidence interval of MDA for each variable were computed for the 30 models. The variables with the largest MDA were ranked highest in importance. To further test whether a variable was significantly important in the voting process of the RF, we compared the observed MDA versus a null distribution of MDA. We created this null distribution by running the model 30 times while shuffling the sample responses randomly. This was performed using the rfPermute v2.1.6 R-package [38]. We reported which variables showed MDAs significantly different from the null distribution considering a 5% significance level. ", 3. Material and Methods, 3.2.4. Validation of the Satellite-Based Tree Loss Map,3
560,"Following the assumption that the VHR detection of tree loss events depends on the observation of forest canopy gaps created by the tree-falls, and given that gaps recover over time through new recruitment and recovery of existing trees, we expect a time dependence between the tree loss detection and the time since disturbance. Therefore, we investigated the rate and mechanisms of gap closure over time using a time series of airborne LiDAR observations of a 1.04 km2 forest section collected in 2011, 2013, 2014, 2015, and 2017 over UPA-01 (Table 2 and area B in Figure 1), which was logged during 2010 and 2011. We processed the data to obtain the LiDAR CHM for each date following the same procedures described in Section 3.1. We defined canopy gaps as holes in the forest canopy extending up to 10 m in height above the ground and with at least 5 m2 of contiguous area. Although this height threshold is higher than the classic Brokaw’s gap definition of 2 m height above ground [39], previous studies of gap dynamics with airborne LiDAR in tropical forests showed that gaps extending up to different heights above ground (e.g., 10 to 11 m) were consistent with gaps observed in the field, e.g., [40,41]. Following previous studies, e.g., [42], the minimum gap area was chosen as a small value (5 m2) in order to assess the gap filling variability from smaller to bigger gap sizes. Moreover, the optimal choice of height and minimum area varies across forest types. Hence, the gaps were delineated as follows: (1) all CHM pixels with a height below 10 m were classified as gaps; (2) the pixels defined as gaps were segmented into polygons; (3) polygons were filtered for a minimum area of 5 m2. Since the logging activities in 2010 and 2011 occurred earlier than the first LiDAR acquisition in 2011, we were unable to exactly extract the areas affected exclusively by the selective logging. Thus, to prioritize the observation of logging disturbance rather than gaps caused by natural mortality, we only selected gaps occurring within a 30 m distance from the logged tree’s locations in UPA-01 (n = 215). To estimate the rate of gap closure over time, we calculated each gap’s relative size with respect to its initial size in 2011. We extracted the average gap size change considering all gaps, but also by size classes of up to 25, 25–50, 50–100, 100–500, and larger than 500 m2. We defined gap closure as decreases of gap size over time. This means that the vegetation inside the gap is reaching an average height of 10 m. In addition, we estimated the gap fraction (percentage of area occupied by gaps) for each year and the percentage of gaps that have fully closed.To improve our understanding of the mechanisms of gap filling, we also assessed the percentage of height gains and losses inside gaps and whether the gaps closed by horizontal and/or vertical vegetation regrowth. To separate vertical from horizontal growth, we followed the procedures described in Hunter et al. [40]. First, we estimated a maximum possible tree height growth rate per year, which we defined as the mean plus three standard deviations of the mean height change inside gaps. Then, we applied this threshold to classify pixels inside gaps as horizontal (height change above maximum growth) or vertical growth (height change below maximum growth). Horizontal growth means the ingrowth of trees to the sides instead of actual growth in height. For those pixels classified as vertical growth, we estimated an average growth rate. To estimate the maximum tree height growth and obtain a stable estimate, we only extracted the values from pixels near to the center of the gaps, that is, at least 5 m from the edges. Therefore, the smaller gaps were not included in this estimate.", 3. Material and Methods, 3.3. Assessment of Tree-Fall Gaps Recovery Using LiDAR Data,3
561,"We applied the VHR satellite data and RF model to detect tree loss events for the whole study area. This area is much larger (area = 76.6 km2) than that analyzed in Section 3.2 (1.4 km2). Thus, in order to be able to visualize the spatial distribution of tree loss events, we created a map using the isotropic kernel-smooth density estimator for aggregating the events into cells of 100 × 100 m [43]. We identified areas of greater tree loss occurrence (hotspots) according to the Z-score statistic, the absolute difference between each pixel’s tree loss value, and tree loss mean normalized by the standard deviation and a 5% significance level. To compare our results with an independent source of disturbance mapping, we acquired the global forest cover loss 2000–2017 dataset (available at https://earthenginepartners.appspot.com/science-2013-global-forest). This product, created by Hansen et al. [44] using Landsat data (30 m spatial resolution), has been widely used for forest disturbance monitoring around the world.We assessed and compared the number of tree loss events inside each UPA and the undisturbed forest areas. The undisturbed forests were those outside of UPAs, excluding water bodies and deforestation up to 2017, according to the INPE-PRODES deforestation product [45]. We also excluded areas of cloud cover of the pre-logging image by manually delineating the clouds using a true-color composite. We estimated the canopy turnover time simply as the ratio of the average number of ITCs (canopy tree crowns) to the annualized number of tree losses per unit of area.To explore how much of the variability of satellite tree loss detections is explained by the logged trees recorded in the field dataset, we used the same kernel approach to estimate the density of logged trees inside the managed areas (UPA-01, UPA-06, UPA-10, and UPA-11). We then overlaid the two maps and extracted the pixel-by-pixel density of tree loss events from satellite and field estimates. The relationship between the two variables using linear regression models was then assessed.", 3. Material and Methods, 3.4. Landscape Analysis of Satellite-Based Tree Loss Map,3
562,"We observed LiDAR ΔCHM ranging from −5.6 to −42.2 m, with a mean of −23.5 m, for the ITCs nearby (within 30 m of distance) the 172 logged trees in Jamari National Forest (Figure 3A). For the non-logged areas (n = 146), we noted a distribution of ΔCHM values ranging from −0.3 to −22 m, with a mean of −5.9 m (Figure 3B). This means that, between 2015 and 2017, the largest canopy changes occurred nearby logged trees’ locations. The distributions in Figure 3A,B did not show positive values because we only assessed the most negative height difference in the area’s neighborhood.We obtained a ΔCHM threshold of −10 m, where 96.5% of the logged trees (n = 166/172) were detected and only 16.4% of the non-logged random areas were misattributed (n = 24/146). Using this threshold, 888 tree loss events (634 trees km−2) were detected between 2015 and 2017 (Figure 3C). This corresponded to a canopy change of 6.15% in terms of area. While this detection rate was larger than the number of logged trees of 172 trees (122 trees km−2), it also included trees that were eventually killed during the logging activities and tree losses from natural mortality that occurred during the studied period. This rate was likely also influenced by the average overestimate of the number of trees of about 30% (Supplementary Material 1). Nevertheless, the detected tree loss events occurred predominantly nearby logged trees’ location, with an average nearest neighbor distance of 25.86 m, while only 10% of the tree loss events were located farther than 50 m from the logged trees (see also Figure 3C).", 4. Results, 4.1. Detecting Tree Loss Events Using LiDAR Data ,4
563,"We trained RF models using VHR satellite data to detect tree loss or non-tree loss areas (Figure 4). Overall, we observed that an increase in the cut-off of tree loss occurrence probability (0.5 to 0.95) was associated with an increase in precision (33 to 80%) and a decrease in recall (95 to 23%) (Figure 4A). Given that a useful model requires high precision, we chose a tree loss probability cut-off of 0.85, which resulted in a moderate-to-high precision of 63.9% (95% CI: 62.6%, 65.2%), and a moderate recall of 60.1% (95% CI: 58.7%, 61.4%). Thus, taking the LiDAR map as a reference, on average, 64% of the satellite detections were correct, and more than half (60%) of the total tree losses were detected.We generated a map using the average of the 30 RF models and a tree loss probability cut-off of 0.85 (Figure 4B). This map detected 357 tree loss events (255 trees km−2), of which 74.5% intersected the tree losses detected in the LiDAR map, and 25.5% did not intersect it (commission errors). Part of these errors should represent actual tree losses captured by the VHR satellite data due to its extended observation period in comparison to LiDAR data (Table 1). We detected 50.8% of the tree loss events from the LiDAR map (omission error of 49.2%). The detections corresponded to 2.55% of canopy area change between 2014 and 2017. Even though, in this map, we only detected 51% of the total tree loss events, the satellite detections were predominantly located nearby LiDAR detections, with a mean nearest neighbor distance of 21.2 m (95% CI: 19.8 m, 22.7 m) (Figure 4C). Moreover, the observed distribution of nearest neighbor distances between the two maps (solid line in Figure 4C) lied beyond the upper-part of the 1% significance CSR envelope (p < 0.01), which meant that the satellite detections were not simply randomly distributed, but were clustered with the LiDAR detections (Figure 4C).The accuracy of satellite tree loss detections was sensitive to the magnitude of changes in the vertical structure of the canopy and size (height) of the trees (Figure 5). Tree losses with higher ΔCHMs (−45 to −25 m) were more easily detected (>75% frequency) compared with tree losses with lower ΔCHMs (−25 to −10 m) (45 to 60%) (Figure 5A). Tree losses from the tallest trees (≥45 m) were more successfully detected (>80%) than for other height classes (Figure 5B). However, the high accuracy for the shortest trees (10–15 m) was probably associated with the low average number of samples (n = 1) and does not truly mean a higher accuracy for this height class. Finally, tree losses that created deep gap openings (0 to 5 m height above ground) were the most successfully detected (>80%) (Figure 5C). Variables used in the RF modeling were ranked for importance according to their MDA (Figure 6). The SD of the red band was ranked highest (23% MDA) among all the variables. In general, the SD metrics were ranked higher than the mean metrics, and the most important variables were the SD of the three visible spectrum bands (Red, Green, Blue), followed by the shadow fraction, mean of visible bands, and SD and mean NDVI. Meanwhile, the NIR band and EVI were the least important of the significant variables (p < 0.05). Only the median, max, and number of shadow segments variables did not significantly contribute to the model (p > 0.05). ", 4. Results, 4.2. Detecting Tree Loss Events Using VHR Satellite Data and RF Model,4
564,"We delineated 724 canopy gaps in the 1.04 km2 of forests inside UPA-01 in Jamari National Forest using the LiDAR data of 2011. The detected gaps were predominantly small: 55.3% from 5 to 25 m2, 16.4% from 25 to 50 m2, 8.8% from 50 to 100 m2, 18.5% from 100 to 500 m2, and 1% from 500 to 1300 m2. From 2011 to 2017, the total gap fraction decreased from 4.61 to 1.96%, whereas 63% of the initial gaps completely closed (Figure 7). The average rate of gap filling was 35.4% yr−1 considering all gap sizes and 30% yr−1 when excluding smaller gaps (area < 25 m2). After 1.8 years (2011–2013) and 5.4 years (2011–2017) of recovery, the average gap size consisted of 47% and 13% of their original size, respectively, excluding smaller gaps (area < 25 m2). Therefore, larger gaps were still visible after ~2 years of recovery, but were almost completely closed and invisible after ~5 years.We found that 23.3% of pixels inside gap areas experienced further height loss over time. These were probably caused by delayed mortality of remaining vegetation, natural disturbances, or the decomposition of trees that were killed during logging activities. The majority of pixels (76.7%), however, showed height gain. We estimated a maximum vertical growth rate of 3.9 m yr−1 from 2011 to 2013 considering only the gap centers. Using this threshold to separate horizontal from vertical tree growth inside gaps, we estimated that horizontal ingrowth (height change >3.9 m) corresponded on average to 21.2% of the height gains. The remaining 78.8% of height gains were due to vertical tree growth, with an average growth rate of 1.65 m yr−1 (SD = 0.6). ", 4. Results, 4.3. Tree-Fall Gap Recovery Assessment Using LiDAR Data,4
565,"Using the VHR satellite data and the RF model, we mapped tree losses over a larger area (76.6 km2) of the Jamari National Forest than covered by LiDAR (Figure 8). We found that tree losses were widespread and only a few areas exhibited hotspots of losses up to 7.1 trees ha−1 (red in Figure 8): two at UPA-06 and one at UPA-10. Another area outside of the UPAs, located at undisturbed forests near UPA-06 and UPA-10, showed an unexpected higher frequency of tree loss (5.15 trees ha−1). We observed a greater frequency of tree loss events (1.63 to 4.39 trees ha−1) inside UPAs compared to the frequency of field logged trees (1.28 to 2.21 logged trees ha−1) (Table 3). In addition, tree loss events occurred more frequently (3.08 to 4.39 trees ha−1) in the recently logged areas (UPA-06 and UPA-10) compared to the other UPAs, even though they had the lowest frequency of logged trees in the field (1.28 to 1.38 logged trees ha−1). This was clearly seen in Figure 8, where these two UPAs were the only ones with hotspots. Furthermore, the undisturbed forests exhibited a similar but slightly greater frequency of tree loss (1.8 trees ha−1) as UPA-01 (1.63 trees ha−1), but less than the rest of the UPAs. The most likely explanations for the lower frequency of detections in UPA-01 were that the forest in this area had a long time to recover since logging occurred in 2010/2011, and that the logging process removed the tallest trees at the canopy level. Meanwhile, these trees are those that open the largest gaps when they fall. Based on the tree losses over undisturbed forests during the interval between VHR images (2.72 years), and the average number of ITCs (85 trees ha−1), we inferred a canopy turnover time of 129 years. The global forest cover loss product from Landsat data (30 m resolution) did not show any forest loss over the study area.When we overlaid the kernel density estimates of satellite tree losses and field logged trees of the UPAs, we found that the field logged trees explained part of the satellite tree loss variability for areas that were logged less than one year (R2 = 0.54) and two years (R2 = 0.36) before image acquisition. The same was not verified for areas logged six years before image acquisition (Figure 9). The areas that had been logged up to two years before image acquisition also showed very significant regression slopes (p < 0.001). ", 4. Results, 4.4. Landscape Analysis of Satellite-Based Tree Loss Map,4
566,"Using a unique dataset of multi-date airborne LiDAR and VHR satellite data (pre- and post-logging), and a tree-by-tree field dataset of georeferenced logged trees, we showed that it is possible to use VHR satellite data to detect canopy tree loss associated with logging. Nonetheless, we advise caution regarding the image acquisition frequency, because it can severely affect how well tree loss can be detected, and thus the suitability to use these data for disturbance monitoring. We discuss each of the scientific questions in the paragraphs below.Besides these general insights, our findings showed that logging drove pervasive changes in the canopy vertical structure. The estimated height difference threshold (−10 m) that we used to define tree loss using LiDAR data should represent a general approximation of the minimal logging impacts to the forest structure and could be used in other studies for rough estimates of canopy tree loss. However, we recommend additional tests in other study sites for more precise detection. In a study of forest dynamics in Tapajós National Forest, located in central-east of the Brazilian Amazon, Leitold et al. [20] found a mean height difference of −11.7 m corresponding to natural tree-fall events from single or multiple trees. While this value is similar to our height difference threshold, it is only half of the mean height difference that we found. This could indicate that even though logging conducted at Jamari Forest is considered “low-impact”, these human-disturbances cause more drastic changes to the forest structure than small-scale natural disturbances. Our results show that tree losses associated with logging and other disturbances, most probably natural, can be automatically mapped using VHR satellite imagery and the RF model with an average precision of 64%, while capturing 60% of the events detected by the LiDAR dataset. Even though the accuracy is not optimal, the detected tree losses show a strong spatial correlation with LiDAR detections and logged trees coordinates. Since the model accuracy varied with the model probability cutoff, this parameter must be chosen carefully. It is important to note, however, that our imagery had distinct sun-sensor geometry properties, with a big difference in sun elevation angles between images (~20 degrees), which affected the accuracy. The effects of such differences include the obfuscation of smaller trees by taller trees and potential attribution as a tree loss event. In a scenario where both images have a similar acquisition geometry, we expect an improved detection accuracy. Nevertheless, this result, based on an automatic detection algorithm, advances the visual analysis and manual delineation of tree mortality of Read et al. [11] and Clark et al. [12,13], and opens up new venues for monitoring small-scale disturbances. The sensitivity of our VHR satellite tree loss detection methodology increased with the presence of more pervasive changes to the canopy, such as bigger gap openings and loss of the tallest trees. Because large trees store most of the aboveground biomass in tropical forests [46], these disturbances are likely the most impactful to carbon loss. The accurate detection of these bigger events enables the identification of disturbance hotspots, where multiple small-scale events may be occurring locally and simultaneously. Furthermore, our results confirmed the possibility of detecting some of the tree-falls that do not create gaps following Brokaw’s definition of ≤2 m height above ground [39].Seasonality effects on plant phenology can reduce our ability to extract biophysical information from remote sensing observations in the Amazon, e.g., [47]. Without tree-by-tree phenology field data to support a proper analysis, we are unable to determine the exact impact of seasonality on our detection, but we expect that it may have a minor to moderate impact. Trees that are leafless in one of the two images, or have completely different colors, due to flowering, could indeed be erroneously attributed as a tree loss event. However, if these effects occur roughly at random across the forest, because of the high tree species diversity in tropical forests, they would not prevent the detection of hotspots associated with disturbance. This is because these occur more clustered in space and time. A way to reduce seasonal effects on detection is to fix the multi-year imagery analysis within a fixed period (e.g., dry season). The most important VHR satellite metrics for tree loss detection were the SD of the reflectance of the visible bands and the shadow fraction and amongst those, especially the red band. The fact that these SD metrics were more important than the mean metrics suggests that there were marked increases in spectral variability in tree loss areas due to logging. This variability is associated with shadows cast by nearby trees, and the signal mixture from non-photosynthetically active responses of leaves, branches, and trunks, and possibly exposed soil. For the same reason, the shadow fraction turned out to be one of the most important variables. Other studies have also shown that shadow was related to tree mortality, e.g., [33]. However, although shadow metrics were important in our study, their performance can vary in other study areas and across sensors, depending on the view-illumination geometry during image acquisition.Findings of this study also showed that tree loss detection depends on the time difference between disturbance occurrence and image acquisition, ideally of less than two years. This is explained by the slower in-filling and longer persistence of bigger gaps in the forest, up to five years or more, in comparison to smaller gaps (<25 m2), which close up very rapidly. In either case, the lateral ingrowth was an important process for gap filling, especially for the smaller gaps. These results are corroborated by the findings of Hunter et al. [40], which also show a strong influence of gap size on closure rates; as well as similar, or slightly higher, gap persistence estimates in two Amazonian forests sites: Ducke (8.1 years) and Tapajós (9.1 years). Our estimates of annual tree height gains inside gaps (mean = 1.65 m yr−1, max. = 3.9 m yr−1) were slightly higher than field observations of pioneer species commonly found in tropical forest gaps (e.g., Cecropia spp., mean = 1.2–1.5 m yr−1, max 2–3 m yr−1) [48]. Nevertheless, hotspots were evident in our map in areas with time differences, between disturbance and image acquisition, up to one year. The implication of these findings for small-scale disturbances’ monitoring is that disturbances associated with small gaps will most probably be underestimated unless annual imagery is being used.Our satellite-based map of tree loss disturbances was spatially coherent. It showed a greater density of events in selective logging disturbed forests than in undisturbed forests. However, the rate of tree losses was up to three times greater than the on-the-ground determined logging rate and depended on the time between disturbance and image acquisition. This is probably related to additional damage caused by logging onto the adjacent trees and natural mortality events. In addition, potential explanations for the observed hotspot of tree loss estimates outside the UPAs include: (i) the presence of a road that crosses that exact location—visible in the pre-logging image—which was likely used for timber transportation; (ii) preparation activities (e.g., opening of trails) for exploration of this area in the near future; and (iii) enhanced and/or delayed natural mortality associated with human-disturbances during the opening of the roads. Our estimate of canopy turnover time (129 years) was lower than the estimate of Hunter et al. [40] for canopy trees at two Central-East Amazon sites (300–370 years). This was probably because of our relatively high rate of omission errors (~40%). Nevertheless, we expect that the presented mapping approach using VHR satellite data can also be useful for the detection of hotspots of natural disturbance.As a comparison exercise, we acquired and visualized the global forest cover loss product from Hansen et al. [44] obtained from Landsat data (30 m resolution), and it did not show any forest loss over the study area, even over the managed forests. We believe that this indicates the potential advantages of using VHR imagery for small-scale disturbance detection and monitoring.A caveat regarding the current mapping approach is the requirement of LiDAR data to calibrate the model before extending the VHR satellite estimates into larger areas. However, as shown in this study, LiDAR data acquisition in small areas can be used for this purpose. For example, in our experiment, the LiDAR calibration area covered 1.4 km2 (1 by 1.4 km), while the VHR satellite imagery covered 76.6 km2 of forests. Hence, the satellite imagery area was 55 times bigger than the LiDAR area, and has the potential to cover much larger areas, such as >5000 km2, with a single-pass of either WorldView-2 or GeoEye-1 satellites. In addition, further studies can take advantage of the recent technological advances associated with unmanned aerial vehicles to cover larger areas at reduced costs, with caution to current constraints, e.g., space for taking off, landing, and piloting in dense forest environments. On the other hand, the current mapping approach using an RF model was primarily used as a benchmark to test the VHR imagery potential; other machine learning or statistical approaches, or, perhaps, simpler methods that bypass the calibration step (e.g., thresholding), are possible and should be tested for a more general application over different areas. In the absence of LiDAR data to be used as a reference for model training, other sources of publicly available training data should be considered. For instance, tree loss data at an individual level from forest inventories obtained by the Brazilian Forest Service and/or forest management concessionaires can be useful.Although the study used WorldView-2 and GeoEye-1 satellite imagery for the experiment, the current method is not, by any means, restricted to these spectral data. The mapping approach could be applied with other available VHR satellite data, e.g., Ikonos, QuickBird, WorldView-3, WorldView-4, and Planet satellites, or, indeed, from future satellites to be launched. Moreover, the combined use of multi-sensors should be required to adapt the current method for detecting canopy tree loss and recovery at broader scales. In this context, the advent of the nanosatellite constellations is an alternative to obtain low-cost data at a very high spatial and temporal resolution. Band positioning and bandwidth should be considered in instrument selection for analysis.", 5. Discussion,None,5
567,"Logging activities disturb large areas in Amazon forests every year, affecting flora and fauna diversity, impacting forest structure and carbon balance, and enhancing fire probability. To address the remote sensing challenges of detecting canopy tree loss associated with logging, we explored the use of multi-date VHR satellite imagery (≤1 m resolution) and airborne LiDAR to detect these events. Logging caused pervasive changes in the canopy vertical structure, with a mean of −23.5 m, but applying a simple LiDAR height difference threshold of −10 m was sufficient to map almost all the logged trees. We show that canopy tree losses associated with logging can be detected using VHR satellite imagery and an automated machine-learning method with an average precision of 64%. Events associated with large gap openings or tall trees were most successfully detected. The standard deviation metrics were the most important for the mapping, because they indicate change in spectral variability with the tree losses. The detection was also dependent on the time difference between the disturbance occurrence and the image acquisition, thus annual imagery acquisition is highly recommended. Our study showed the potential of VHR satellite imagery for monitoring the logging in tropical forests and detecting hotspots of natural forest disturbance with a low cost at the regional scale. Future research can build upon our work and improve the accuracy of detection using pairs of images with similar sun-sensor geometry properties, and testing additional satellite-based metrics (e.g., texture) and alternative modeling approaches.", 6. Conclusions,None,6
568,"Soil organic carbon (SOC) is central to soil health as it plays a significant role in soil aggregation, water holding capacity, cation/anion exchangeability, and nutrient availability, which promotes plant growth. SOC can potentially affect both soil ecosystems and crop productivity due to its several critical roles in soil functioning. Globally, the amount of carbon in the upper one meter of soil is about three and two times higher than the amount of carbon found in the biosphere and atmosphere, respectively [1,2,3]. Therefore, the contribution of SOC to the global C cycle by sequestering terrestrial C is of great importance. Changes in SOC pools induced by soil management and land cover changes affect global warming and, in turn, can significantly influence soil physical, chemical, and biological properties [4,5,6]. As SOC is a good indicator of environmental quality [7], high-quality maps of the spatial distribution of SOC can provide base-line data for SOC turnover and sequestration for C management strategies at the province-scale. The spatial variability of SOC at the field to the regional scale is highly related to the soil forming-factors including the climate (precipitation and temperature); organisms (vegetation and human), relief (terrain attributes), parent materials, and time [8].Due to the global importance of SOC, digital soil mapping (DSM) approaches have become more focused on SOC mapping in the last decade [4,9,10,11,12]. DSM describes the spatial variation of SOC by taking the relations between SOC and environmental auxiliary variables into account [13,14,15]. The auxiliary variables correlated with SOC are often obtained from digital elevation models [11,16], remotely sensed data [16,17] and climatic data [18,19]. By using remotely sensed imagery and easy accessibility of climatic and digital elevation model (DEM) data, the application of machine learning (ML) techniques for predicting SOC is significantly increased [11,17,20].Numerous ML algorithms have been applied in DSM for SOC prediction including artificial neural networks (ANNs) [21,22,23,24], genetic programming [25], support vector regression (SVR) [23,25,26], multivariate adaptive regression splines [27,28], Cubist [9,29,30], boosted regression tree [16,31,32], and random forest (RF) [9,16,19,23,32,33,34]. In most cases, these approaches were much more accurate than linear and geostatistical methods due to the higher ability to get a lot more information for unsampled points by investigating nonlinear relationships between SOC and environmental auxiliary variables.Soils, especially SOC contents, which are the result of the actions and interactions of many different processes and factors, vary from place to place with high complexity [35]. Thus, to predict the behaviors and properties of such a complex environment, classical ML may encounter problems [10,12,34,36]. A new approach that has received considerable attention as a sophisticated learning algorithm with substantial learning capability and high performance is deep learning (DL) [37]. Recently, deep neural networks (DNNs) based on DL approaches have been proposed for overcoming the shortages arising from the traditional ANNs [37,38], by adding more complexity (deep) into the conventional models. This provides better learning capabilities to reveal the complexity underlying the data, and thus results in a higher accuracy of the trained model [39]. The hierarchical structure and high learning capacity make DNN models quite flexible and adaptable for a wide variety of highly complex problems such as SOC prediction [11,39,40]. The DNNs have recently been used for the prediction of soil properties [40,41,42] and particularly for SOC prediction [43,44]. Xu et al. [43], for instance, indicated that the DNN method had a high performance for the prediction of SOC with the effective abstraction of complex covariates for learning by using visible and near-infrared soil spectra. DNNs are more complex and need further parametrization but severely depend on the size of the training dataset.To eliminate the multicollinearity of variables and exclude unimportant and redundant auxiliary variables, numerous feature selection techniques have been developed for DSM including. Particle swarm optimization [45], the genetic algorithm (GA) [25,32,46], hybrid GA-artificial neural network [47], parallel GA [48], and the artificial bee colony algorithm [36] are among the notable feature selection techniques. Such variable selection techniques can simplify modeling by lowering the number of input variables and potentially improving the accuracy of soil predictions. There is no universal feature selection method to reduce the number of covariates in the pool presented to an ML algorithm. For instance, Behrens et al. [49] compared the two most common approaches for the selection of covariates, namely supervised and unsupervised, and found that the supervised feature selection approach was superior because the soil classes were predicted more accurately. Taghizadeh-mehrjardi et al. [50] explored the effect of the reduction in dimension of feature space with ant colony optimization (ACO) and correlation-based feature selection (CFS) on the accuracy of prediction of spatial models for each particle size fraction. In this study, we decided to implement the GA, one of the most advanced algorithms for feature selection [46]. GA can manage the datasets with many features and do not need specific knowledge about the problem parallelizing easily in computer clusters [46,51,52].Although many ML algorithms have been developed for the prediction of soil properties, the development of site-specific techniques is necessary for enhancing the quality of thematic soil maps [53]. However, there is no best worldwide predictive algorithm for SOC mapping given that the accuracy level of SOC predictions is highly related to the local geographic attributes of the study area [54], the sampling size [9,55] and the selected auxiliary variates [14,19,56].Mazandaran province, northern Iran, is located on the southern coast of the Caspian Sea. There is a descending precipitation gradient from the west to east across the region, leading to a diversity of soil moisture regime (SMR) and soil temperature regime (STR) classes [57]. Due to the changes in SOC contents in northern Iran caused by the human activities and natural attributes (landslide, flooding, depression) [58,59], the existence of a high-quality SOC prediction map with known uncertainty in the Mazandaran province is crucial. This provides a base-line map for further temporal monitoring of SOC at the province-scale. Despite the known advantages of feature selection, there have been no insights into the important variables for SOC prediction in northern Iran given the different predominant climatic and soil-forming conditions. Therefore, due to the lack of an SOC base-line distribution map in Mazandaran province, the objectives of this research were (1) to determine the important auxiliary variables driving the SOC contents in the province using GA as a popular automatic method for feature selection, (2) to test the performance of six ML algorithms fed with GA-selected auxiliary variables and (3) to predict the spatial distribution of SOC for mapping with associated uncertainty and (4) to compare SOC contents in different geological units, soil classes and land uses in Mazandaran province.", 1. Introduction,None,1.
569,"This research was conducted in Mazandaran province, northern Iran. The region is located at a longitude of 50°31′21′′ E to 53°56′52′′ E and latitude of 36°38′06′′ N to 36°54′59′′ N and covers an area of 2,388,179 ha. It borders the Caspian Sea in the north and the Alborz Mountain range in the south (Figure 1). Most of the province is covered by dense, moderate, and low-density forest with each forest type covering 39%, 4%, and 2% of the total area, respectively. There are several kinds of cultivated lands in the study area. Paddy fields are the most common agricultural land use with about 210,000 ha, and orchards cover about 90,000 ha. Based on the De Martonne climate classification, the western, central, eastern, and mountainous parts of the province have very humid, humid, Mediterranean, and semihumid climates, respectively. The mean annual temperature ranges from 18 °C on the coastal plain to below 8 °C in the highlands. There is a gradient of the decreasing precipitation from the west (around 1400 mm) to the east direction (around 450 mm) leading to the diversity of soil moisture regime (SMR) and soil temperature regime (STR) classes across the province. The xeric SMR class covers the largest area in the province, followed by the udic and aquic classes, while thermic (66%) is the most abundant STR followed by mesic (33%) and cryic (1%) [57]. The variation of elevation ranges from the Caspian Sea coastal areas with elevations <−5 m to more than 3000 m above sea level in the highlands of the Alborz Mountain range. Five USDS soil taxonomy orders including Mollisols, Entisols Inceptisols, Alfisols, and Ultisols were in Mazandaran with a total of 12 suborders. Mollisols are the most dominant soils forming on different landforms with mollic epipedons. Mollisols have four main suborders including the aquolls, rendolls, udolls, and xerolls mostly distinguishing based on soil moisture regime classes except for rendolls that have an epipedon with less than 50 cm thickness overlies on a highly calcareous horizon. Alfisols are characterized by a clay enriched endopedon with two main suborders, i.e., aqualfs and udalfs. Ultisols with a single suborder, i.e., Humults occurring in a very limited area in Mazandaran province with leached soils under native forest vegetation. Entisols with three main suborders, i.e., Orthents, Fluvents, and Aquents are mostly used for paddy cultivation in the study area. Inceptisols in Mazandaran province have a weakly developed B horizon with two main suborders, i.e., Aquept and Xerepts.", 2. Materials and Methods, 2.1. Study Area ,2
570,"The total dataset for SOC mapping is 1879 composite surface soil samples from two main sources (Figure 1). More than half of the data (1055 samples) were derived from five Master of Science (M.Sc.) research projects in the soil science department at Sari Agricultural Sciences and Natural Resources University (SANRU) [60,61,62,63,64]. These samples were collected using a simple random sampling scheme mostly in uncultivated areas. The rest of the dataset comes from soil surveys performed by the Agricultural Research Education and Extension Organization (AREEO) and the Ministry of Jahad-e-Keshvarzi in Sari, Northern Iran. These samples were mostly collected in cultivated areas spread across the province using a grid sampling scheme with a 2000 m grid interval. Each composite soil sample is collected within a 20 m radius surrounding each of the sampling points with at least 10 subsamples (cores). Samples were collected from a depth of 0–20 cm, and their geographical coordinates were recorded with a global positioning system (GPS) device. After air-drying and passing through a 2 mm sieve, the content of SOC was measured by the wet oxidation procedure outlined by the Walkley and Black [65]. Figure 1 shows the spatial distribution of the sampling sites across Mazandaran province.", 2. Materials and Methods, 2.2. Soil Data,2
571,"The full set of 105 predictor variables initially considered is given in Table A1 in the Appendix A. The auxiliary data included variables derived from remotely sensed imagery (60 variables from Landsat 8 and MODerate-resolution Imaging Spectroradiometer, MODIS), terrain attributes (30 variables), climatic data (10 variables), and five categorical data (e.g., soil map and land use map).The high contribution of SOC to soil color can be detected by the spectral signature of remotely sensed data. The 60 environmental auxiliary variables derived from satellite imagery were developed based on the median values of 8 satellite images of the Landsat 8 Operational Land Imager taken from 2012 to 2016 to coincide with the dates of soil sampling. Following radiometric, geometric, and atmospheric corrections digital numbers for the blue (B1), green (B2), red (B3), near-infrared (B4), and shortwave IR-2 bands (B6) were extracted. Several indices were then calculated: the normalized difference vegetation index (NDVI), enhanced vegetation index (EVI), combined spectral response index (COSRI), land surface water index (LSWI), brightness index (BI), and other indices with a spatial resolution of 30 m. The variables derived from MODIS imagery had a spatial resolution of 250 m. These included median values of two spectral reflectance bands: red (645 nm) and near-infrared (858 nm) and the EVI, NDVI, and other indices. The daytime and nighttime land surface temperature with a 1 km resolution were also derived from MODIS data. Overall, 60 auxiliary variables were derived from Landsat 8 and MODIS data.Thirty terrain attributes were derived from a DEM [66]. The DEM was obtained from shuttle radar topography mission terrain (SRTM) data with 30 m grid cells. Terrain attributes, namely slope, aspect, elevation, length and steepness (LS) factor, valley depth, openness, catchments area, catchment slope, plane curvature, topographic wetness index (TWI), channel networks base level (CNBL), distance to channel networks, the multiresolution valley bottom flatness index (MrVBF) and other indices [67], were calculated using SAGA GIS.Climatic factors have high potential to explain large parts of the variation of soil properties in the northern part of Iran, due to the high degree of spatial variability in Mazandaran province. In this study, 10 climatic variables were obtained using WorldClim. WorldClim version 2 [68] contains reliable temperature and precipitation data at a spatial resolution of 1000 m. Categorical predictor variables were derived from five choropleth maps, which were compiled at different cartographic scales, e.g., soil map and land use map [69].Figure 2 shows the spatial distribution of some auxiliary variables related to SOC including precipitation, NDVI, MrVBF, and land use. The precipitation decreases from the north-west to the north-east in the province, especially in shoreline areas (Figure 2). The southern parts of the province have lower precipitation compared with the northern region where the Caspian Sea shoreline is located. The NDVI values range from −0.5 to more than 0.8, indicating a high diversity of vegetation cover spread across the province that has a potentially significant effect on SOC content due to large differences in the number of falling leaves and plant residues. The MrVBF shows that flat valley bottoms where sediments and outflows accumulate leading to higher clay and SOC contents [34,67]. All environmental variables which did not conform with SOC grid resolution of 30 × 30 m were resampled to a 30 m spatial resolution using either the nearest neighbor or bilinear resampling methods.", 2. Materials and Methods, 2.3. Auxiliary Variables,2
572,"Instead of taking all 105 environmental auxiliary variables into consideration for a predictive ML algorithm, the feature selection method reduces the number and collinearity of the auxiliary variables. The most informative auxiliary variables should be inserted into the algorithms with the aim of high accuracy of the ML algorithms for SOC prediction [9,16,25]. The selection of the significant environment auxiliary variables is a preprocessing step for ML algorithms to remove redundant and irrelevant variables. For this study, one of the most advanced algorithms for feature selection, namely the genetic algorithm (GA), was used to select the most appropriate auxiliary data to be fed as inputs to the ML algorithms [16]. GA is able to select those auxiliary data that are not only essential but improve performance as well. Moreover, GA can manage the nonlinear relationships between SOC and auxiliary data [70].By mimicking natural biological evolution, the GA which is a heuristic search algorithm provides the best value for a function [51]. A GA feature selection process starts with an initial random population consisting of individuals. The individuals, representing subsets of auxiliary data, are encoded as binary in which 1 represents if the feature is selected and 0 otherwise [71]. Then three primary operations including selection, crossover, mutation repeat until a stopping criterion is reached. The selection operations were for selecting the two fittest individuals for reproduction (i.e., the solutions providing the lowest root mean squared error, RMSE). The crossover recombines two individuals to create new ones which may be better. The mutation operator introduces alteration in a small number of individuals. The process of selection, crossover, and mutation continues until a termination condition is satisfied [48,52]. Importantly, for each generation, it is necessary to assign a fitness value to each individual in the population so that the RMSE values are calculated by fitting the random forest model [46,48,52].In this study, the GA procedure was performed with 10-fold cross-validation and 100 iterations to select the smallest number of auxiliary variables important for SOC modeling using the caret package in R [72]. The population size, crossover, and mutation rates used were 50, 0.6, and 0.001, respectively, as outlined by Welikala et al. [52].", 2. Materials and Methods, 2.4. Selection of Auxiliary Variables Using Genetic Algorithms (GA),2
573,"In this study, six ML algorithms including support vector machines (SVM), artificial neural networks (ANNs), regression tree (Cubist), random forest (RF), extreme gradient boosting (XGBoost), and deep neural networks (DNN) were chosen. Each algorithm can discover complex relationships between SOC content and auxiliary covariables. Table 1 summarizes the hyperparameters of the six ML algorithms used in this study. A brief description of the ML techniques used in this study follows. 2.5.1. Support Vector Machines (SVMs)Initially, SVMs were developed as a methodology for resolving problems of classification into two attributes using a threshold value. Connected with the earlier development of SVMs as a classification method, the regressive type of support vector machines was proposed. This caused the spread of the philosophy of support vectors machines being used to solve regression problems. The algorithm was formulated as a linear method and then it was generalized to (1) the presence of noise in the data using slack variables following the soft-margin philosophy, and (2) a nonlinear model through the conversion of the input space into a larger dimension, as done for classification [73]. Hence, SVM is used for classification and regression processes with a set of connected supervised learning algorithms and they have an excellent ability to be universal predictors of any multivariate function to any specified degree of accuracy [20]. In this study, the SVM algorithm was employed by improving the range of its components (C: 0.01–100; σ: 0.01–100) based on the input data (Table 1). 2.5.2. Artificial Neural NetworksArtificial neural networks (ANNs) stand out among the different types of models because they are calculative techniques with mathematical models simulated from the human’s brain neural function [74]. ANNs as vigorous data-modeling tools attain knowledge by way of experience. They are able to detect patterns and draw results, therefore they can be used for data prediction with correlation, such as soil properties. The ability for handling and modeling multiple outputs simultaneously is a primary benefit of ANN techniques [75]. The development of an ANN model mainly consists of three main stages: the generation of data for the training/testing of the model, the selection of the optimal configuration, and the validation of the model on an independent data set. Additionally, ANNs are interconnected by structures called perceptrons and consist of input, output, and hidden layers that transform the input into something that the output layer can utilize [76]. ANN models allow one to attribute lower weight to samples that deviate from a standard, since ANNs can identify patterns in data distribution, which is not observed in linear and nonlinear regression [77]. As a result, ANN models can lead to a higher accuracy than linear and nonlinear regression [78]. The present neural networks of this study were made based on a learning rate of 0.001–0.05 and the number of hidden layer neurons was 2–10 (Table 1). The sigmoid function is the activation function in the nnet package [79] for the MLP with one hidden layer which we used in this study. 2.5.3. Regression Tree (Cubist)Cubist is an ML estimating tool that is similar in approach to regression trees [80]. However, unlike classification and regression tree models, linear models are often well structured rather than having end values [81]. Additionally, the Cubist and other regression tree algorithms have a clear difference, that is the linear regression model is fitted to the leaf nodes of the trees in the Cubist [82]. Overall, the Cubist approach makes multivariate models that are made of sets of rules, and the prediction model will be chosen based on the rules [83]. In this research, the ptoposed regression tree models are based on Cubist regression models [84]. Cubist models were improved by defining the number of model trees, and nearest neighbors using the data set shown in Table 1. 2.5.4. Random Forest (RF)The random forest (RF) consists of a series of binary rule-based decisions that define relationships between input and its dependent variables. It comprises a large number of individual tree algorithms trained from bootstrap samples of the data [85]. The single prediction will be made by accumulating the results of all trees. One of the main benefits of random forests is that they can precisely explain the compound connections between the independent variables and the dependent variables. So when composite environmental systems and ecological supplementary variables are introduced, RF can be helpful [86]. Two important parameters in RF algorithms are the number of trees (Ntree) and the number of variables (Mtry) which are available for selection in each split [87]. These two main parameters (Mtry and Ntree) were adjusted for the best result. The range of values used is shown in Table 1. 2.5.5. Extreme Gradient Boosting (XGBoost)The algorithm for extreme gradient boosting (XGBoost) was proposed by Chen and Guestrin [88]. It is an algorithm for improving the performance for gradient boosting machines and especially for regression trees and K classification methods [89]. By the supplemental training strategies, the “boosting” as a basic idea of this method extends a “strong” learner from a set of “weak” learners. The XGBoost technique is supposed to improve calculation but also reduce over-estimation events. The XGBoost simplifies the objective functions and improves the calculation speed to an optimum by allowing the combination of estimative and adjustment terms. In addition, in the XGBoost approach, during the training step, simultaneous computations will be done automatically for the functions [89]. More information can be obtained about the XGBoost algorithm from the work of [88]. Table 1 shows the XGBoost algorithm parameters used to do this research including the type of algorithm, the depth of trees, the minimum sum of weights of all observations, the number of variables provided to a tree, the number of samples provided to a tree, and the learning rate. 2.5.6. Deep Neural Networks (DNN)The performance of conventional DNN as an estimation algorithm for remote sensing applications has been extensively explored during the past few years [90]. DNN has been reported as a reliable and efficient approximation function for delivering insight into the relationship (whether a linear or a nonlinear relationship) between input and output variables [91]. DNN has shown promising results in a wide and diverse range of applications from digital signal processing and control systems to hazard susceptibility mapping [92,93]. Figure 3 illustrates the architecture of a conventional DNN. The networks are configured by passing several layers for learning the probability of the outputs.In this study, conventional DNN is a feedforward learning network where there is no looping back from the output layer to input. In this case, the DNN produces a map of virtual neurons and random weights. The inputs and weights will be multiplied and would deliver outputs within the range of 0 and 1. The algorithm would adjust the weights to accurately identify a particular learning pattern to fully process the data. The DNN includes L hidden layers, the input layer (vector X), and the output layer (vector Y). As recently formulated by Wang et al. [94], the estimation of Y can be presented as follows.






z

1

=

σ
1


(



W

1


X

+

b
1


)





(1)







z

2

=

σ
2


(



W

2



z

1

+

b
2


)

,
 


z

L

=

σ
L


(



W

L



z


L
−
1


+

b
L


)

,
 

Y

=


W


L
+
1




z

L

+

b
L

,
 
θ
=



{



W

i

,



 
b


i


}



i
=
1


L
+
1






(2)


where 


b
i


 and 


σ
i


 are the bias and the activation function of the ith layer. Here, 



W

i


 represents the weights. In Equation (2), the 

L
+
1

 represents the output layer. Therefore, Y can be presented as follows.





Y

=
N
N

(


X

;
θ

)





(3)

Eventually, through calculating the mean square error (MSE) of output and input values, loss function L can be estimated as follows.




M
S

E

D
a
t
a


=
L

(
θ
)

=

1
N



∑


i
=
1

N




|

N
N

(



X

i

;
θ

)

−


Y

i


|


2





(4)


where N represents the sequence of data. Here, the GA is used to minimize the 

L

(
θ
)


 function for the training. A trained DNN is further used for the estimation of the new variables. The predictive ability of neural networks is possible by learning large amounts of data. Generally, input data create the training datasets, and similar output data will be entered into a neural network algorithm. This algorithm can detect the basic rules in the data entered and compose an interior model that is suitable to estimate the new input data using several training repetitions during the process. The model can be computed by the interactions and connections between neurons, whereas any physical or clear mathematical relationships cannot be supplied [90]. The neural network structure can affect the precision of the predictive models. Each latent layer of the DNN algorithm consists of some calculative neurons that are interconnected to the next calculative neurons in the adjoining latent layers. To finalize the DNN model, the neurons of each latent layer measure the calculative neuron outputs of the prior layer, and after the computation procedure of the activation function, the outputs are generated for the subsequent layer [42].Table 1 shows the specifications used for DNN, which are hidden layers, size, network weight initialization, learning rate, dropout regularization. In this study, for the DNN method, the H2O package [92] with the rectifier function as a nonlinear transformation was used for DNNs in this study [95]. It is worth mentioning that adhering to a balanced ratio of training and testing is of utmost importance in modeling with machine learning [96]. Several methods in a wide range of applications are introduced to identify the correct balance for testing [97]. Nevertheless, the evaluation metrics have been shown to be reliable measures to maintain a sufficient number of elements for a training dataset in soil research [37,38,39,40]. It is often observed that by decreasing the amount of training data, the error increases, which accurately indicates the worth of data for models. The amount of training data, in this study, is optimally tuned to ensure the lowest errors. The total dataset is divided into 10 datasets that are sequentially used for training and testing. The DNN is calibrated 10 times to assure each data point was used as validation at least once.", 2. Materials and Methods, 2.5. Machine Learning Techniques,2
574,"Initially, SVMs were developed as a methodology for resolving problems of classification into two attributes using a threshold value. Connected with the earlier development of SVMs as a classification method, the regressive type of support vector machines was proposed. This caused the spread of the philosophy of support vectors machines being used to solve regression problems. The algorithm was formulated as a linear method and then it was generalized to (1) the presence of noise in the data using slack variables following the soft-margin philosophy, and (2) a nonlinear model through the conversion of the input space into a larger dimension, as done for classification [73]. Hence, SVM is used for classification and regression processes with a set of connected supervised learning algorithms and they have an excellent ability to be universal predictors of any multivariate function to any specified degree of accuracy [20]. In this study, the SVM algorithm was employed by improving the range of its components (C: 0.01–100; σ: 0.01–100) based on the input data (Table 1).", 2. Materials and Methods, 2.5.1. Support Vector Machines (SVMs),2
575,"Artificial neural networks (ANNs) stand out among the different types of models because they are calculative techniques with mathematical models simulated from the human’s brain neural function [74]. ANNs as vigorous data-modeling tools attain knowledge by way of experience. They are able to detect patterns and draw results, therefore they can be used for data prediction with correlation, such as soil properties. The ability for handling and modeling multiple outputs simultaneously is a primary benefit of ANN techniques [75]. The development of an ANN model mainly consists of three main stages: the generation of data for the training/testing of the model, the selection of the optimal configuration, and the validation of the model on an independent data set. Additionally, ANNs are interconnected by structures called perceptrons and consist of input, output, and hidden layers that transform the input into something that the output layer can utilize [76]. ANN models allow one to attribute lower weight to samples that deviate from a standard, since ANNs can identify patterns in data distribution, which is not observed in linear and nonlinear regression [77]. As a result, ANN models can lead to a higher accuracy than linear and nonlinear regression [78]. The present neural networks of this study were made based on a learning rate of 0.001–0.05 and the number of hidden layer neurons was 2–10 (Table 1). The sigmoid function is the activation function in the nnet package [79] for the MLP with one hidden layer which we used in this study.", 2. Materials and Methods, 2.5.2. Artificial Neural Networks,2
576,"Cubist is an ML estimating tool that is similar in approach to regression trees [80]. However, unlike classification and regression tree models, linear models are often well structured rather than having end values [81]. Additionally, the Cubist and other regression tree algorithms have a clear difference, that is the linear regression model is fitted to the leaf nodes of the trees in the Cubist [82]. Overall, the Cubist approach makes multivariate models that are made of sets of rules, and the prediction model will be chosen based on the rules [83]. In this research, the ptoposed regression tree models are based on Cubist regression models [84]. Cubist models were improved by defining the number of model trees, and nearest neighbors using the data set shown in Table 1.", 2. Materials and Methods, 2.5.3. Regression Tree (Cubist),2
577,"The random forest (RF) consists of a series of binary rule-based decisions that define relationships between input and its dependent variables. It comprises a large number of individual tree algorithms trained from bootstrap samples of the data [85]. The single prediction will be made by accumulating the results of all trees. One of the main benefits of random forests is that they can precisely explain the compound connections between the independent variables and the dependent variables. So when composite environmental systems and ecological supplementary variables are introduced, RF can be helpful [86]. Two important parameters in RF algorithms are the number of trees (Ntree) and the number of variables (Mtry) which are available for selection in each split [87]. These two main parameters (Mtry and Ntree) were adjusted for the best result. The range of values used is shown in Table 1.", 2. Materials and Methods, 2.5.4. Random Forest (RF),2
578,"The algorithm for extreme gradient boosting (XGBoost) was proposed by Chen and Guestrin [88]. It is an algorithm for improving the performance for gradient boosting machines and especially for regression trees and K classification methods [89]. By the supplemental training strategies, the “boosting” as a basic idea of this method extends a “strong” learner from a set of “weak” learners. The XGBoost technique is supposed to improve calculation but also reduce over-estimation events. The XGBoost simplifies the objective functions and improves the calculation speed to an optimum by allowing the combination of estimative and adjustment terms. In addition, in the XGBoost approach, during the training step, simultaneous computations will be done automatically for the functions [89]. More information can be obtained about the XGBoost algorithm from the work of [88]. Table 1 shows the XGBoost algorithm parameters used to do this research including the type of algorithm, the depth of trees, the minimum sum of weights of all observations, the number of variables provided to a tree, the number of samples provided to a tree, and the learning rate.", 2. Materials and Methods, 2.5.5. Extreme Gradient Boosting (XGBoost),2
579,"The performance of conventional DNN as an estimation algorithm for remote sensing applications has been extensively explored during the past few years [90]. DNN has been reported as a reliable and efficient approximation function for delivering insight into the relationship (whether a linear or a nonlinear relationship) between input and output variables [91]. DNN has shown promising results in a wide and diverse range of applications from digital signal processing and control systems to hazard susceptibility mapping [92,93]. Figure 3 illustrates the architecture of a conventional DNN. The networks are configured by passing several layers for learning the probability of the outputs.In this study, conventional DNN is a feedforward learning network where there is no looping back from the output layer to input. In this case, the DNN produces a map of virtual neurons and random weights. The inputs and weights will be multiplied and would deliver outputs within the range of 0 and 1. The algorithm would adjust the weights to accurately identify a particular learning pattern to fully process the data. The DNN includes L hidden layers, the input layer (vector X), and the output layer (vector Y). As recently formulated by Wang et al. [94], the estimation of Y can be presented as follows.






z

1

=

σ
1


(



W

1


X

+

b
1


)





(1)







z

2

=

σ
2


(



W

2



z

1

+

b
2


)

,
 


z

L

=

σ
L


(



W

L



z


L
−
1


+

b
L


)

,
 

Y

=


W


L
+
1




z

L

+

b
L

,
 
θ
=



{



W

i

,



 
b


i


}



i
=
1


L
+
1






(2)


where 


b
i


 and 


σ
i


 are the bias and the activation function of the ith layer. Here, 



W

i


 represents the weights. In Equation (2), the 

L
+
1

 represents the output layer. Therefore, Y can be presented as follows.





Y

=
N
N

(


X

;
θ

)





(3)

Eventually, through calculating the mean square error (MSE) of output and input values, loss function L can be estimated as follows.




M
S

E

D
a
t
a


=
L

(
θ
)

=

1
N



∑


i
=
1

N




|

N
N

(



X

i

;
θ

)

−


Y

i


|


2





(4)


where N represents the sequence of data. Here, the GA is used to minimize the 

L

(
θ
)


 function for the training. A trained DNN is further used for the estimation of the new variables. The predictive ability of neural networks is possible by learning large amounts of data. Generally, input data create the training datasets, and similar output data will be entered into a neural network algorithm. This algorithm can detect the basic rules in the data entered and compose an interior model that is suitable to estimate the new input data using several training repetitions during the process. The model can be computed by the interactions and connections between neurons, whereas any physical or clear mathematical relationships cannot be supplied [90]. The neural network structure can affect the precision of the predictive models. Each latent layer of the DNN algorithm consists of some calculative neurons that are interconnected to the next calculative neurons in the adjoining latent layers. To finalize the DNN model, the neurons of each latent layer measure the calculative neuron outputs of the prior layer, and after the computation procedure of the activation function, the outputs are generated for the subsequent layer [42].Table 1 shows the specifications used for DNN, which are hidden layers, size, network weight initialization, learning rate, dropout regularization. In this study, for the DNN method, the H2O package [92] with the rectifier function as a nonlinear transformation was used for DNNs in this study [95]. It is worth mentioning that adhering to a balanced ratio of training and testing is of utmost importance in modeling with machine learning [96]. Several methods in a wide range of applications are introduced to identify the correct balance for testing [97]. Nevertheless, the evaluation metrics have been shown to be reliable measures to maintain a sufficient number of elements for a training dataset in soil research [37,38,39,40]. It is often observed that by decreasing the amount of training data, the error increases, which accurately indicates the worth of data for models. The amount of training data, in this study, is optimally tuned to ensure the lowest errors. The total dataset is divided into 10 datasets that are sequentially used for training and testing. The DNN is calibrated 10 times to assure each data point was used as validation at least once.", 2. Materials and Methods, 2.5.6. Deep Neural Networks (DNN),2
580,"Ten-fold cross-validation was implemented for testing the performances of six ML prediction algorithms for estimating the SOC contents in Mazandaran province. In this regard, the total dataset was split into 10 datasets that were sequentially used as training and testing datasets for a given prediction algorithm. Each prediction model is calibrated 10 times, guaranteeing each data point was used as validation at least once. Then, the 10 prediction errors can be obtained for each prediction algorithm. The four evaluation criteria used in this study are the coefficient of determination (R2) [98], Lin’s concordance correlation coefficient (CCC) [99], mean absolute error (MAE) [100] and root mean squared error (RMSE) [100] with following formulas:




R
2

=
1
−

(





∑


i
=
1

n




(

O
i
−
p

)


2





∑


i
=
1

n




(

O
i
−

O
′


)


2




)





(5)





C
C
C
=


2
 
r
 

σ
o


σ
p




σ
o
2

+

σ
p
2

+



[


O
′

−

Ρ
′


]


2







(6)





M
A
E
=

1
n



∑


i
=
1

n


|

P
i
−
O
i

|





(7)





R
M
S
E
=



1
n



∑


i
=
1

n




(

P
i
−
O
i

)


2







(8)


where, n is the number of samples, Oi and Pi are observed and predicted SOC contents, respectively. O′ and P′ are the means for the observed and predicted SOC contents, respectively. Furthermore, σo and σp are the variances of observed and predicted values. Four criteria of the validation datasets in 10-fold validation in each prediction algorithm were averaged and used for selecting the best performing prediction algorithms. The prediction algorithm with the lowest MAE and RMSE, and highest R2 and CCC values are determined as the best for SOC prediction.", 2. Materials and Methods, 2.6. Evaluation of Algorithm Performance,2
581,"The spatially explicit quantification of the uncertainty of SOC prediction is analyzed in this study. The SOC maps generated by each model were used to calculate the mean and standard deviation (SD) of the SOC for each pixel in 10-fold realization [101]. It was assumed that six ML models follow the normal distribution for each raster cell. The confidence interval (CI) was calculated with the mean as ±1.64 SD for a given 90% CI. The upper and lower limit of the 90% CI were mapped. The mean of the SOC contents in each pixel and the 90% CI was calculated by retrieving the 5th and 95th percentiles of prediction. Finally, three maps of the SOC were produced for the best performing model: the mean prediction, lower CI (5%), and higher CI (95%).", 2. Materials and Methods, 2.7. Uncertainty Assessment,2
582,"Table 2 shows the summary statistics for topsoil SOC for the 1879 sampling sites. SOC contents ranged from 0.02% to 11.48% with a mean and standard deviation of 2.19% and 1.27%, respectively. The lower SOC contents correspond to highly degraded lands where the surface soil is eroded and the maximum SOC contents were observed in dense forestlands. The coefficient of variation of 58.23% demonstrates the high variability of SOC contents within the study area. The values of skewness (2.33) and kurtosis (8.2) indicate that the SOC data is highly skewed and in turn, violates assumptions of normality. SOC data were anchored at 1.00 and then, transformed by the natural logarithm to make the distribution less skewed. The skewness and kurtosis values of the log-transformed SOC values were 0.59 and 1.50, respectively, and the Kolmogorov–Smirnov test showed that the distribution of these log-transformed values was not significantly different from normal. Further analysis was performed on the log-transformed data; and the predicted SOC values were back-transformed to the original scale.", 3. Results and Discussions, 3.1. Summary Statistics,3
583,"In this study, the GA procedure with 10-fold cross-validation and 100 iterations (i.e., GA was executed 1000 times) was used to select the minimum number of important auxiliary variables for SOC modeling. The results of GA for 1000 generations are presented in Figure 4. The average of the internal out-of-bag RMSE estimates as well as the average of the external performance estimates calculated. Based on these results, the generation associated with the best external RMSE estimate was 0.86. The GA selected 35 predictors out of 105 environmental variables, as the most relevant driving factors for SOC mapping in Mazandaran province (Table 3). These variables comprised 13 terrain attributes, 18 remotely sensed variables, two climatic variables, and two categorical data layers. The resolution and origins of the 35 predictors are given in Table 3. Getting more information about the contribution of each variable to SOC variability is of great importance. Therefore, the significance of each environmental auxiliary variable was analyzed using a sensitivity analysis and was represented as an attribute percentage. Figure 5 indicates the order of the relative importance of the selected predictors on SOC spatial variability using the procedure outlined by [45].As can be seen in Figure 5, precipitation is the most crucial feature (14.9%) driving the spatial variability of SOC contents in Mazandaran province followed by the NDVI (12.5%), MODIS day temperature (10.6%), MrVBF (8.7%), land use (8.2%), valley depth (7.2%), and MODIS night temperature, respectively. In Mazandaran province, as previously thought, the precipitation significantly affects SOC contents by enhancing vegetation coverage and the rate of organic matter inputs. Together precipitation and temperature (MAT) explain 18.9% of the variation in SOC contents demonstrating the high dependencies of SOC contents in the province-scale to the climatic variables. Lamichhane et al. [14] reviewed several studies and pointed out that climate is the most influential factor for the variation of SOC at large extents. The high precipitation is mostly combined with lower temperatures and slower SOC decomposition rates at higher altitudes [102,103]. Falahatkar et al. [104] reported that the most important auxiliary predictors for SOC stocks for surface soil in Guilan province, northern Iran are land use, NDWI, silt, clay, and elevation. Along with our findings, the surface temperature data derived from remotely sensed data (Landsat) was found to be influential for improving SOC prediction [66].The NDVI is the second most important feature explaining SOC variability, indicating that the SOC contents were highly influenced by vegetation variation. SOC content was highly dependent on the natural vegetation cover intensity, and the plant residue left after plant harvesting [4,36,105]. Due to the dependency of SOC on vegetation cover, NDVI has frequently been used as a predictor for mapping SOC in several studies [16,25,33,106]. Additionally, NDVI has more importance to SOC contents compared to other remotely sensed vegetation indices like EVI. Although the EVI performs better than the NDVI in many applications, our results indicated that NDVI is more important for explaining SOC contents compared to EVI. It might be related to the topographic conditions as Matsushita et al. [107] reported that EVI is more sensitive to topographic conditions than is the NDVI. Meanwhile, the green band of Landsat-8 (B2) showed a higher contribution to SOC than B3 and B4.The high contribution of the MrVBF (8.7%) to SOC variability in this study could be attributed to the deposition of fine organic-enriched particles and sediment [58] from the highlands in the lower valleys with flat and low-lying areas. Land use data is considered as the fifth important variable for SOC variation. Land use effects on SOC variation is related to the land-use conversion in the last two decades in Mazandaran province that have led to the exposure of soils and the rapid decomposition of SOC [58].The TWI only contributed 3% SOC contents showing that SOC tends to accumulate in wetter, low-lying areas in Mazandaran province. Taghizadeh-Mehrjardi et al. [25] demonstrated that the wetness index is the most important terrain variable for the prediction of SOC in subsoils (>30 cm depth). Plan curvature (Plan.Curv), soil map, slope, aspect, channel networks base level (CHNL.BASE), LS factor and other variables ranked in Figure 4 made only a small contribution to SOC spatial variability at the province-scale used in this study but still need to be considered as input variables for SOC modeling by ML techniques.", 3. Results and Discussions, 3.2. Selected Auxiliary Data,3
584,"The average MAE, RMSE, R2, and CCC for SOC prediction by 10-fold cross-validation are shown in Table 4. The proposed ML models showed different abilities to predict SOC contents at unsampled locations at the province-scale. This could be related to the various mathematical functions of each algorithm [2]. The mean R2 values indicate that the SVM, ANN, Cubist, RF, and XGB models deliver 53%, 55%, 57%, 58%, and 57% of SOC variability, respectively. However, the DNN model outperforms other models by delivering 65% of the SOC variability. In all ML models, the RMSE values are reported more significant than the MAE, indicating that there is a contribution of the errors in SOC predictions [108]. The DNN algorithm showed the lowest mean MAE value (0.59%) of the six studied ML algorithms. The SVM algorithm had the highest error with mean RMSE values of 0.87% compared with other ML models, meanwhile, the DNN outperformed with the lowest mean RMSE value (0.75%). ANN, Cubist, RF, and XGB showed a similar ability to predict SOC in Mazandaran province. Based on the performance criteria used, SVM was always a weaker ML algorithm than the other algorithms, while DNN was the most consistently robust algorithm.One of the main advantages of DNN is that the step of feature extraction was performed by the DNN model itself [10]. Our results confirm previous research on the performance of DNN in soil modeling. For instance, a recent research study introduces the DNN as an effective and robust modeling method to capture the complex nonlinearity between auxiliary variables and soil moisture [40] and SOC prediction [11,42]. DNN models by using the multiple hidden layers of the neural network improve the SOC prediction. Padarian et al. [11] reported that using deep learning models for digital soil mapping offers a simple and effective framework for future soil mapping. The DNN algorithm needs a large number of parameters to be fitted so that it performs well with a large dataset like the one used in this study. Importantly, the sample size is a critical issue for training in the DNN [41].underestimated. The CCC statistic quantified the level of agreement between predicted and measured SOC values according to the 1:1 line. It is based on CCC values (Table 4). The The lower performance of other ML algorithms except for the DNN could be related to taking a large number of auxiliary variables into account and the original data having multiple-scales of variation, as well as different sources and sampling times, all of which increase the uncertainty.The 1:1 scatterplots of actual vs. predicted SOC using the six ML algorithms are shown in Figure 6. It is now much easier to understand the prediction efficiency of the DNN algorithm as most predictions follow the 1:1 line with the exception of large observed SOC contents, which were slightly DNN algorithms with a 0.83 value were superior and the SVM (CCC = 0.76) was inferior.As the deep learning method is sensitive to the size of the training dataset, DNN apparently yielded the best result in this study due to the large data for training. Using a deep convolutional neural network trained with a smaller dataset was not effective for the prediction of soil properties by spectral data [41].The DNN algorithm has a more flexible structure and is explicitly able to extract more information from the environmental auxiliary variables and the SOC content and this is consistent with the results of [11,42]. Therefore, we could recommend the DNN algorithm as the best ML algorithm for the prediction of SOC content with reliable uncertainty in Mazandaran province. The DNN model in this study was successfully trained with a large number of covariates due to its more flexible neural structure and in turn was able to effectively combine with multiscale properties. This algorithm uses the data imputation for taking the missing values into account thereby the better model performance could be achievable especially for subsurface DSM [11].The observed mean value of R2 and RMSE in the DNN algorithm can be compared to the other studies at the regional scale [109,110,111]. Wang et al. [16] only achieved an R2 mean value of 48% of the total spatial SOC variability using the RF algorithm in semiarid pastures of eastern Australia.", 3. Results and Discussions, 3.3. Machine Learning Performances,3
585,"The numbers and percentages of SOC contents that fall within the 90% CI are shown in Table 5. The uncertainty analysis also showed to some extent the same trend to the ability of the ML algorithms to predict SOC. The DNN had the maximum percentage of observations (~88%) that fell within the defined CI. The spatial prediction of mean SOC content with a 5% lower confidence limit and 95% upper confidence limit values in Mazandaran province produced by the DNN algorithm are shown in Figure 7. It is clear that the combined influence of selected auxiliary variables controls the SOC contents. It is evident that the SOC contents tend to be higher in a strip from the west (more than 3%) to the east (lower than 1%) in the middle of the Mazandaran province. The precipitation gradient and NDVI index, which were the most highly correlated variables, were greatly responsible for SOC variations. The SOC content coincided in a systematic way with increasing the precipitation gradient, NDVI, and MrVBF indices (Figure 2). It was clear from the predicted SOC map that the amounts were higher in the area with high NDVI values ranging from 0.71 to 0.81 (the central part of the study area). The higher rainfall favors higher net primary production of plant residues and explains the higher SOC contents in the middle portion of the province. There is some uncertainty in the predicted map that may be related to the high variability in SOC data, low precision of predictors, inherently poor relationships between SOC and auxiliary variables, and errors in modeling [112]. Considering the multiple scales of auxiliary variables and the good resolution of soil erosion/deposition data, such data can potentially [32] reduce the spatial prediction uncertainty in future studies.The SOC contents change over time, thus the predicted map can be used as a base-line to indicate temporal changes. Together with the estimation of uncertainty, the prepared maps are more reliable and could be useful for future SOC inventories and province-scale accounting and carbon balance studies.", 3. Results and Discussions, 3.4. Spatial Prediction of SOC with Uncertainty Estimates,3
586,"The mean comparison of the SOC contents within different soil orders and suborders is shown in Table 6. The Ultisols and Mollisols with mean SOC contents of 4.04% and 3.20%, respectively, had higher surface SOC compared with other soils. Most Ultisols and Mollisols were found in the dense forest in Mazandaran province showing the higher C inputs into the soils. The high precipitation with a relatively low MAT in the center of the Mazandaran province leads to higher SOC accumulation at the soil surface and in turn higher clay content in a Bt horizon [6,113] and the deeper Bk horizon [6,113,114]. Entisols had the highest SOC variability (CV = 40.66%) followed by the Inceptisols (33.94%), Alfisols (CV = 33.64%), and Mollisols (30.55%). The SOC under Mumults had the highest SOC with the lowest SOC variability (CV = 15.63) whereas Fluvents had significantly the lowest SOC due to the higher SOC decomposition caused by the exposure (tillage) and loss of SOC by erosion.The mean SOC contents spread across the Mazandaran province differed in soils under different soil SMR and STR classes as shown in Figure 8. The SOC mean value was the highest in the udic SMR class with mean values of 3.85% followed by the aquic (2.45%) and xeric (2.10%), respectively. The high precipitation for soils with the udic SMR class [57] led to the high aboveground biomass production inputs. The greater SOC contents in soils having the aquic SMR class compared to the xeric SMR could be related to anaerobic (reducing) conditions decreasing the rates of organic matter decomposition [115].The soils having mesic STR classes have high SOC content with a mean value of 2.75%, which was significantly higher than the thermic (2.20%) and cryic (1.25%) STR classes, respectively (Figure 8). Soils in the thermic STR class with higher MAT in low-lying areas had lower SOC contents compared with mesic STR classes reflecting a negative effect of MAT on SOC contents in Mazandaran province due to the high SOC decomposition rate. The small area of the province with a cryic STR class has low vegetation cover in high-altitude lands accompanied by unsuitable temperature conditions for plant growth leading to low inputs of plant residues and biomass. Overall, SOC has been increased with precipitation and decreased with temperature associated with a given altitude in the study area. Moreover, soils formed on younger geological formation have lower SOC contents. The mean SOC contents in soils under the Cenozoic geological era (2.35%) had significantly lower SOC contents compared with soils under Mesozoic (3.12%), Paleozoic (3.35%) and Proterozoic (3.29%) eras, respectively. The higher observed SOC developed on the older geological formations could be attributed to the increased time for SOC to develop and aboveground carbon inputs by the dense vegetation cover inducing the SOC accumulation.", 3. Results and Discussions, 3.5. SOC Contents in Soil Classes and Geological Eras,3
587,"The soils formed on mountainous landforms had the highest SOC (3.11%) values with forest land use, while there was little difference in SOC contents for the other landforms except for the soils developed on alluvial fans that had significantly the lowest SOC contents (1.57%) with high coarse fractions (soil particles greater than 2 mm) (Figure 9). The alluvial fans with unstable landforms, have a high susceptibility to erosion and have little water holding capacity providing the lowest aboveground biomass production in the study area. The high degrees of stability in mountain landforms especially in the summit areas [6] showed more developed soils including the Ultisols, Mollisols, and Alfisols. These are closer to the steady-state conditions relative to the younger landforms (Fluvents) leading to greater humification and SOC accumulation on mountain landforms that are currently covered by dense forest. On more geomorphically dynamic/unstable landforms, organic layers can be removed from the developing surface inducing the SOC losses through erosion [115].The disturbed soils in croplands and orchards had significantly lower SOC compared with forests and rangelands except for poor rangelands. Soils in residential, dry farming, poor rangelands, and seashore areas had SOC mean values of 2.08%, 1.78%, 1.71%, and 0.75%, respectively. Unsurprisingly, the dense forestlands have significantly the highest SOC content with mean values of 3.77% (Figure 9) followed by the semidense forestlands (2.90%), low dense forestlands (2.50%), good rangelands (2.57%), and moderate rangelands (2.03%), respectively. Emadi et al. [58] reported that the cultivation of virgin forest and pasturelands in Mazandaran province led to about 35 and 30% reduction of SOC content, respectively. The conversion of forest and rangelands into the croplands induces SOC oxidation whereby the topsoil SOC decreases.", 3. Results and Discussions, 3.6. SOC Contents in Landform Units and Land Uses,3
588,"The objective of this study was to determine a reliable algorithm for predicting the SOC contents in Mazandaran province through consideration of six different ML algorithms and using 105 environmental auxiliary variables derived from terrain attributes, remote sensing, and climatic data. Thirty-five auxiliary predictors were selected by the GA method. Precipitation, NDVI, MODIS day temperature, MrVBF, and land use were the most important predictors. The results show that the DNN algorithm outperformed other ML algorithms in terms of the power of the prediction uncertainty at the province scale demonstrating that DNN is suitable for use as a robust estimator for SOC mapping in Mazandaran province. The SOC was lower in soils under late geological age (Cenozoic era), while it is accumulated in more developed Ultisols and Mollisols with virgin forest and rangelands in udic SMR classes spread across the middle strip of Mazandaran province. The mesic STR class has significantly higher SOC with high vegetation cover and biomass and probably with a lower C decomposition rate. The predicted SOC map could be used as a base-line for further studies and projects related to the C sequestration development both locally in soils of the Mazandaran province and globally at the worldwide scale. Although the DNN algorithm was found to be the best algorithm to map SOC contents more accurately than other studied ML algorithms, the search for optimized spatial interpolation algorithms is still in its early stages in this province. Moreover, further investigation should be conducted to test the potential of other combination algorithms in this province and test the reliability of DNN reliability for other regions in Iran with different climate and agro-ecological structures.", 4. Conclusions,None,4
589,"Forest soil is an important component of forest ecosystems and one of the largest organic carbon pools in terrestrial ecosystems. It plays an irreplaceable role in regulating global carbon balance and slowing down the rise of atmospheric CO2 concentration [1,2]. Dixon et al. [3] estimated the global forest soil carbon pool is 787 PgC based on literature review, accounting for 73% of the total global soil carbon. Soil structure is complex, its spatial distribution is uneven, and its spatial variability is large [4]. At present, the estimation of forest soil organic carbon (SOC) stocks has a large uncertainty, which contributes to an estimation error of annual carbon emissions from forest soils to the atmosphere (10 PgC) larger than the total industrial emissions (5.3 PgC) [5]. Therefore, a detailed investigation of forest SOC stocks shall help better quantify the global carbon balance.The interaction of natural and human factors is the main cause of spatial variability of soil properties [6,7], including climate, topography, parent material, time, biology, and land use. Because soil properties are affected by many environmental factors, it is difficult to predict soil properties accurately and efficiently at the regional scale [8]. As an efficient and low-cost method, digital soil mapping (DSM) technology is able to accurately describe the spatial variability of soil attributes in a region by using a limited amount of sampling data and environmental variables [9]. In order to accurately predict the SOC stocks in a region and analyze its key environmental factors, scholars have carried out a lot of researches [10,11,12]. In fact, the direct relationship between soil properties and environmental factors is non-linear and complex [13,14]. Therefore, machine learning algorithms which can effectively avoid this kind of problem are widely used in DSM mapping [11,15]. For example, on Barro Colorado Island, Panama, Grimm et al. [15] used a random forest model to simulate SOC stocks in 0–10 cm, 10–20 cm, 20–30 cm, and 30–50 cm layers, respectively. Giasson et al. [16] applied a multiple logistic regression model to predict the occurrence of soil types in southern Brazil. Dorji et al. [17] selected regression kriging and equal-area spline profile function to predict the SOC stocks at depths 0–5, 5–15, 15–30, 30–60, and 60–100 cm in montane ecosystems, Eastern Himalayas. In Denmark, Adhikari et al. [18] used regression kriging and 12 environmental variables to simulate the spatial distribution of SOC stocks at five soil layers. Were et al. [19] compared the performance of support vector regression, artificial neural network, and random forest models in predicting and mapping SOC stocks in the Eastern Mau Forest Reserve, Kenya.Different from the DSM technology mentioned above, the boosted regression trees (BRT) model is a relatively new model based on tree development [20], which is rarely used in the study of temporal and spatial changes of SOC stocks, especially in forest areas. Compared with the single tree model, the BRT model has higher performance and efficiency [20]. In many previous studies, the BRT model is a reliable prediction model for soil properties [11]. The BRT model is the final prediction model generated by many simple tree models [21]. In this process, the model improves its performance through iteration and enhancement technology to reduce its fitting errors [19]. The BRT model can deal with imperfect data, such as outliers, missing values, and data interaction [21,22]. Thus, the BRT model is widely used in many fields, such as remote sensing [23], ecology [24], environmental science, epidemiology [25], fisheries science [26], and soil science [19,22]. However, the BRT model is rarely selected for the study of temporal and spatial changes of forest organic carbon stocks at regional scales.In this study, the BRT model was used to estimate the temporal and spatial changes of SOC stocks in forest topsoil in Liaoning Province, China. The specific research objectives are to: (1) map the spatial distribution of soil organic carbon stocks from 1990 to 2015; (2) quantify the role of different environmental factors in the distribution of forest surface soil organic carbon; and (3) identify the spatiotemporal change pattern of SOC stocks during 25 years (1990–2015).", 1. Introduction,None,1.
590,"Liaoning Province is located between 118°53′~125°46′E and 38°43′~43°26′N (Figure 1). Its land and sea areas are 145,900 km2 and 152,200 km2, respectively. Its elevation is higher in the East and west of Liaoning Province, but lower in the middle region. Mountainous and hilly areas are divided into east and west sides. The average elevations of mountainous areas in Eastern and Western Liaoning are 800 m and 500 m, respectively, and the elevation of the central Liaoning Province is 200 m. It has temperate continental monsoon climate, with hot and rainy seasons, and four distinct seasons. Its annual average temperature ranges from 7 to 11 °C, with the highest temperature above 30 °C above zero and the lowest temperature below 30 °C below zero. Its annual precipitation is 400–1100 mm. According to the second national land use classification system issued by the State Council of China in 2007, the forest area in the study area is divided into woodland, shrub woodland, sparse woodland, and other woodland. By the end of 2016, there were 63,440 km2 of forestry land in Liaoning Province, including 46,410 km2 of forest land (including 14,150 km2 of economic forest), accounting for 73.1% of forestry land; 569 km2 of sparse forest land, accounting for 0.9%; 2,275 km2 of shrub forest area, accounting for 3.6%; 14 190 km2 of other forest land, accounting for 22.4%; and 31.8% of forest cover in the study area. Corresponding to the classification system of soil system in China [27], the main soil types of forest land in the study area are Primosols (36.7%) and Cambisols (33.4%), followed by Argosols (25.6%), Spodosols (4.1%), and Isohumosols (0.2%).", 2. Materials and Methods, 2.1. Study Area,2
591," 2.2.1. Soil Survey Data for 1990The data of forest land soil properties in 1990 were obtained from the second National Soil Survey database of Liaoning Province [22]. A total of 367 forest soil data covering different soil types and parent material types were obtained. The database contains environmental information such as climate, topography, and parent material at sampling sites. In addition, this study focused only on the spatial variability of forest soil organic carbon (SOC) stocks in topsoil (0–30 cm), because we only extracted topsoil soil property data. For some sampling sites with missing soil bulk density (y), we used a Peod-transfer function (PTFs) and SOC content to estimate the BD. Specific formulas are as follows:



y
=
1.52
−
0.08
∗


S
O
C


 
(

R
2

 
=
 
0.74
,
 
p
 
<
 
0.001
)




(1)

 2.2.2. Soil Sampling in 2015A total of 539 topsoil (0–30 cm) samples were collected, covering the forest topsoil of the whole province in 2015. The forest area is about 63,440 km2, accounting for 59.5% of the total land area of the Liaoning Province. Therefore, it was difficult to collect soil samples in situ or in large quantities on the basis of sampling in 1990, especially in the rugged terrain with dense forest roads in the northeastern part of the study area. In order to accurately predict the surface SOC stocks in those regions, we applied a purposeful sampling method [28] to design a sampling strategy. Firstly, we selected the main environmental factors affecting the spatial variability of forest SOC stocks (mean annual temperature (MAT), mean annual precipitation (MAP), elevation, slope gradient, topographic wetness index (TWI), normalized difference vegetation index (NDVI)) and clustered the forest areas in the study area by using the fuzzy C-means clustering method [29]. Finally, 51 clustering landscape units were generated, and 10–12 sampling sites were collected in each unit. Longitudinal and latitudinal information was recorded by a hand-held GPS in each sampling point. The dead branches and leaves were removed from each sample point and 1 kg of mixed soil samples was collected. In the Center for Analysis and Testing, Shenyang Agricultural University, Shenyang, China, the samples were grinded and screened and the SOC content was finally determined using a C/N analyzer (Vario Max, Elementar Amerivas Ins., Germany). In addition, at each sampling site, soil samples were sampled with 100 cm3 of undisturbed soil cores in the central part of the 0–30 cm soil layer and placed in an oven at 105 ℃ for 48 h to determine bulk density. 2.2.3. Environmental VariablesIn this study, nine variables (elevation, slope gradient, TWI, MAP, MAT, B3, B4, B5, and NDVI) in three categories (Table 1) were selected as environmental variables to predict SOC stocks in those regions. Because these variables are collected from different departments with different precision, we use ArcGIS 10.2 software to resample them to grid data with 90 m spatial resolution. In addition, in order to facilitate modeling and analysis, we transformed the collected soil data and environmental variables into a unified projection coordinate system (Gauss Kruger).Terrain-related variables are traditionally one of the widely used environmental variables in DSM. In this research, the digital elevation model (DEM) was downloaded from Geospatial Data Cloud site, Computer Network Information Center, Chinese Academy of Sciences [30]. ArcGIS 10.2 software was used to produce elevation and slope gradient, and then SAGA GIS software was used to obtain TWI. TWI generated by SAGA GIS can better reflect the details of the region and is more suitable for the analysis of this type of forest in the region.MAT and MAP are the main climatic variables, obtained from the Meteorological Data Service Center of China [30]. Based on the observation data, historical data, and other auxiliary data, the spatial distribution map of MAT and MAP needs to be made by using the climate data spatial interpolation Anusplin software [31] to predict the spatial distribution of MAT and MAP.Remote sensing data covering from July to September in 1990 and 2015 (United States Geological Survey, USGS, 2017) were selected for modeling. Firstly, we used a polynomial geometric accuracy correction method to correct the image, and then applied an ENVI software to splice and cut the image. Finally, we selected Landsat TM band 3 (B3), Landsat TM band 4 (B4), and Landsat TM band 5 (B5) representing vegetation growth, cover, and biomass for modeling. In addition, the NDVI was calculated by using B3 and B4. The specific formulas are as follows:



N
D
V
I
=
 

(

B
4

 
−
 

B
3

)

/

(

B
4

 
+
 

B
3

)





(2)

", 2. Materials and Methods, 2.2. Data Sources,2
592,"The data of forest land soil properties in 1990 were obtained from the second National Soil Survey database of Liaoning Province [22]. A total of 367 forest soil data covering different soil types and parent material types were obtained. The database contains environmental information such as climate, topography, and parent material at sampling sites. In addition, this study focused only on the spatial variability of forest soil organic carbon (SOC) stocks in topsoil (0–30 cm), because we only extracted topsoil soil property data. For some sampling sites with missing soil bulk density (y), we used a Peod-transfer function (PTFs) and SOC content to estimate the BD. Specific formulas are as follows:



y
=
1.52
−
0.08
∗


S
O
C


 
(

R
2

 
=
 
0.74
,
 
p
 
<
 
0.001
)




(1)

", 2. Materials and Methods, 2.2.1. Soil Survey Data for 1990,2
593,"A total of 539 topsoil (0–30 cm) samples were collected, covering the forest topsoil of the whole province in 2015. The forest area is about 63,440 km2, accounting for 59.5% of the total land area of the Liaoning Province. Therefore, it was difficult to collect soil samples in situ or in large quantities on the basis of sampling in 1990, especially in the rugged terrain with dense forest roads in the northeastern part of the study area. In order to accurately predict the surface SOC stocks in those regions, we applied a purposeful sampling method [28] to design a sampling strategy. Firstly, we selected the main environmental factors affecting the spatial variability of forest SOC stocks (mean annual temperature (MAT), mean annual precipitation (MAP), elevation, slope gradient, topographic wetness index (TWI), normalized difference vegetation index (NDVI)) and clustered the forest areas in the study area by using the fuzzy C-means clustering method [29]. Finally, 51 clustering landscape units were generated, and 10–12 sampling sites were collected in each unit. Longitudinal and latitudinal information was recorded by a hand-held GPS in each sampling point. The dead branches and leaves were removed from each sample point and 1 kg of mixed soil samples was collected. In the Center for Analysis and Testing, Shenyang Agricultural University, Shenyang, China, the samples were grinded and screened and the SOC content was finally determined using a C/N analyzer (Vario Max, Elementar Amerivas Ins., Germany). In addition, at each sampling site, soil samples were sampled with 100 cm3 of undisturbed soil cores in the central part of the 0–30 cm soil layer and placed in an oven at 105 ℃ for 48 h to determine bulk density.", 2. Materials and Methods, 2.2.2. Soil Sampling in 2015,2
594,"In this study, nine variables (elevation, slope gradient, TWI, MAP, MAT, B3, B4, B5, and NDVI) in three categories (Table 1) were selected as environmental variables to predict SOC stocks in those regions. Because these variables are collected from different departments with different precision, we use ArcGIS 10.2 software to resample them to grid data with 90 m spatial resolution. In addition, in order to facilitate modeling and analysis, we transformed the collected soil data and environmental variables into a unified projection coordinate system (Gauss Kruger).Terrain-related variables are traditionally one of the widely used environmental variables in DSM. In this research, the digital elevation model (DEM) was downloaded from Geospatial Data Cloud site, Computer Network Information Center, Chinese Academy of Sciences [30]. ArcGIS 10.2 software was used to produce elevation and slope gradient, and then SAGA GIS software was used to obtain TWI. TWI generated by SAGA GIS can better reflect the details of the region and is more suitable for the analysis of this type of forest in the region.MAT and MAP are the main climatic variables, obtained from the Meteorological Data Service Center of China [30]. Based on the observation data, historical data, and other auxiliary data, the spatial distribution map of MAT and MAP needs to be made by using the climate data spatial interpolation Anusplin software [31] to predict the spatial distribution of MAT and MAP.Remote sensing data covering from July to September in 1990 and 2015 (United States Geological Survey, USGS, 2017) were selected for modeling. Firstly, we used a polynomial geometric accuracy correction method to correct the image, and then applied an ENVI software to splice and cut the image. Finally, we selected Landsat TM band 3 (B3), Landsat TM band 4 (B4), and Landsat TM band 5 (B5) representing vegetation growth, cover, and biomass for modeling. In addition, the NDVI was calculated by using B3 and B4. The specific formulas are as follows:



N
D
V
I
=
 

(

B
4

 
−
 

B
3

)

/

(

B
4

 
+
 

B
3

)





(2)

", 2. Materials and Methods, 2.2.3. Environmental Variables,2
595,"Figure 2 summarized the descriptive statistics of SOC stocks and different environmental variables at sampling sits in 1990 and 2015. In 1990, SOC stocks ranged from 0.53 kg m−2 to 16.13 kg m−2, with an average of 9.1 kg m−2. The average SOC stocks in 2015 were 9.44 kg m−2. In 1990 and 2015, the skewness coefficients of SOC stocks were 0.89 and 1.21, respectively. The dataset presented a generalized skewness distribution. Logarithmic transformation of SOC stocks was carried out in two periods to make it conform to normal distribution.Table 2 listed the correlation coefficients between SOC stocks and selected environmental variables over the periods in 1990 and 2015. Elevation, slope gradient, TWI, and MAP were positively correlated with SOC stocks in both periods. Correspondingly, SOC stocks were negatively correlated with MAT, B4, B5, and NDVI in both periods. In addition, there might be multiple collinearities between terrain variables and remote sensing image variables (Table 2). If this study used traditional statistical methods to predict SOC stocks, it might not be accurate. Therefore, the classical machine-learning algorithm-boosted regression trees (BRT) model was introduced to predict the spatial distribution of SOC stocks in this study.", 2. Materials and Methods, 2.3. Descriptive Statistics,2
596,"In order to characterize the relationship between SOC stocks and all predictors, the BRT model developed by Friedman et al. [32] was used in this study. The BRT model is composed of two technologies: boosting and regression tree [19]. Boosting technology is an improvement based on the random gradient of decision tree [11]. It uses all samples at a time and changes the weight of samples at each round of training [20]. The goal of the next round of training is to find a function to fit the residuals of the previous round. It stops when the residual is small enough or reaches the maximum number of iterations set [23]. The BRT model can flexibly deal with soil environmental problems in complex landscape areas, and effectively avoid non-linearity and interaction [11]. Compared with the traditional regression model, the BRT model exhibits better prediction performance, especially in the spatial simulation of soil properties, which has been widely used in spatial prediction research [11,19,20]. In this study, we used the “dismo” package developed by Elith et al. [21] to construct the model in R language environment [33].In the BRT model, four parameters (learning rate (LR), tree complexity (TC), bag fraction (BF), and tree number (NT)) need to be set by users [26]. LR represents the contribution of each tree in the model to the final fitting model [11]. TC is a direct predictor of tree depth and maximum interaction level [20]. BF represents the proportion of data used in each model [19]. NT is determined by LR and TC [23]. We test different combinations of these parameters by 10-fold cross-validation technology for obtaining the best prediction performance of the BRT model. Finally, we set LR, TC, BF, and NT to 0.0025, 9, 0.65, and 1200 in 2015, respectively. In 1990, LR, TC, BF, and NT were set to 0.0025, 9, 0.60, and 1000, respectively.The BRT model was iterated 100 times, and the average standard deviation of 100 prediction results was calculated, which was used as an uncertain index to evaluate the prediction performance of SOC stocks.In addition, we also calculated the relative importance (RI) of each environmental variable in simulating the spatial distribution of SOC stocks during the two periods. The RI of variables was measured based on the number of times a variable is selected for modeling, and weighted by the square improvement of each segmentation and mean value of all trees. Finally, the average RI of 100 iterations of each variable in BRT model is converted to a percentage value.", 2. Materials and Methods, 2.4. Boosted Regression Trees Model,2
597,"In this research, we applied 10-fold cross-validation technology to test the prediction performance of the BRT model. Mean absolute prediction error (MAE), root mean square error (RMSE), coefficient of determination (R2), and Lin’s concordance correlation coefficient (LCCC) [34] were calculated using this technology in R software:



M
A
E
=

1
n



∑

i
=
1

n



|


p
i

−

o
i


|







(3)





R
M
S
E
=



1
n



∑

i
=
1

n





(


p
i

−

o
i


)


2









(4)






R
2

=




∑

i
=
1

n





(


p
i

−



o
¯


i


)


2







∑

i
=
1

n





(


p
i

−



o
¯


i


)


2









(5)





L
U
C
C
=


2
r

∂
p


∂
o




∂
p
2

+

∂
o
2

+



(


p
¯

+

o
¯


)


2







(6)


where pi, oi, 

p
¯

, 

o
¯

, 


∂
p


, and 


∂
o


 represent the predicted value, the measured value, the average value of the predicted, the average value of the measured, the variance of predicted value, and the variance of predicted and measured values at the sampling point i, respectively; n denotes the number of sampling points; and r is Pearson correlation coefficient.", 2. Materials and Methods, 2.5. Prediction Accuracy,2
598,"Ten-fold cross-validation technology was selected to verify the spatial prediction performance of the BRT model for SOC stocks during the two periods (1990 and 2015). The results showed that the BRT model presented higher R2 and LUCC, and lower Mae and MRSE in both time periods (Table 3). Although there might be differences in sampling methods, experimental methods, and prediction models, our prediction accuracy was not inferior to that of previous studies. The average coefficient of variation (CV) of the 100 iteration maps predicted by the model for the two periods was shown in Figure 3. The average CVs in 1990 and 2015 were 7.3 and 13.2 kg m−2, respectively.", 3. Results, 3.1. Model Performance and Uncertainty,3
599,"During the two research periods, the selected environmental variables showed different RI in predicting SOC stocks. MAP and NDVI were important environmental variables affecting SOC stocks in both periods. In 1990, the main factors affecting SOC stocks were remote-sensing-related variable, followed by climatic and topographic factors (Figure 4a). Correspondingly, the order of impacts was biological, topographic, and climatic factors in 2015 (Figure 4b).", 3. Results, 3.2. Importance of Environmental Covariates,3
600,"The BRT model was run 100 times to obtain the spatial distribution map of the average SOC stock in 1990 and 2015, respectively (Figure 5). From 1990 to 2015, the forest SOC stocks of Liaoning Province in Northeast China showed an upward trend (Figure 6a). The average SOC stocks increased from 5.66 kg m−2 in 1990 to 6.61 kg m−2 in 2015, an increase of 0.95 kg m−2. A total of 83.7% of the study area increased SOC stocks, mainly in the eastern and western mountainous areas of Liaoning Province. In the past 25 years, the decline of forest SOC stocks was mainly concentrated in the central plain, accounting for 3.4% of the total area of the study area (Figure 6b).", 3. Results, 3.3. Spatial Prediction of SOC Stocks,3
601,"In 1990 and 2015, the forest SOC stocks showed an increasing trend in the northeast and southwest regions of the Liaoning Province, and a decreasing trend in the central region of the Liaoning Province. The areas with high SOC stocks were mostly concentrated in the eastern and western areas where forest resources were abundant. However, in the central plain areas where human activities interfered greatly, the SOC stocks tended to decrease. In 1990, we found that there was a high correlation between regional SOC stocks and vegetation variables, especially NDVI, which was confirmed by previous studies [22,35,36,37]. In Seoul Forest Park, Seoul, Republic of Korea, Bae et al. [37] found that the SOC stock in topsoil in 2013 was about three times that in 2003. By comparing the two periods of NDVI, it was found that the history of land use, the expansion of plant area, and the growth of plants are the main reasons for the increase of topsoil SOC stocks in the past 10 years. Except for vegetation-related variables, SOC stocks also showed a close relationship with topographic variables, especially elevation variables, in 2015. Recent studies have pointed out that topographic variables, especially elevation variables, could be used as key environmental variables to effectively predict SOC stocks [11,22,36,37,38,39,40]. Tsui et al. [41] considered the effects of soil grade, vegetation type, and elevation on SOC stocks in subtropical wet volcanic ash in Yangmingshan National Park, Taipei City, Taiwan Province, China. In complex terrains, climate, vegetation type, and soil mineralogy change along elevation gradient [29]. Their results showed that elevation was a simple and effective prediction of SOC stocks. Different elevation gradients could form different hydrothermal conditions, which could affect the activity of microorganisms in soil and indirectly affect the accumulation and loss of organic matter, thus affecting the change of SOC stocks in the region.We found that 3.4% of the whole study area showed a downward trend, mainly distributed in the plains of central Liaoning Province, and this part of the area was the main commodity grain producing area. The soil in this part of the area was strongly disturbed by human activities, and the land use pattern changed rapidly, which caused the decrease of organic carbon storage in the forest surface soil. Qi et al. [30] considered the topsoil SOC stocks in the same area. They believed that reclamation and other human activities were the main factors causing the decrease of SOC stocks in this area, which was confirmed in the studies of Bae and Ryu [37]. In most areas of the region, the forest SOC stocks showed an increasing trend, especially in the northeastern mountainous areas. The main reason is that this part of the region has been covered by forests and is seldom disturbed by man-made destruction, because the SOC stocks in this area showed an increasing trend, while the increase of SOC stocks in southwestern China can be attributed to the national policy of returning farmland to forests, leading to the increase of SOC stocks in this area. Wang et al. [22] used a BRT model and 9 environmental variables to simulate the spatial variations of SOC stocks in the forest-dominated area of Wafangdian, Liaoning Province, Northeast China. It was found that the increase of SOC stocks could be attributed to the implementation of the policy of returning farmland to forest and grass for many years in this area.", 4. Discussion, 4.1. Estimates of SOC Stocks,4
602,"In both periods, vegetation-related variables were the most important influencing factors (Figure 4). This finding is consistent with the previous research conclusion. Bae and Ryu [37] considered that vegetation-related variables were closely related to the spatial distribution of SOC stocks. Vegetation is the main source of soil organic matter and controls the amount of organic matter entering the soil [36]. Among all the vegetation variables, NDVI and B3, representing the biomass and productivity of vegetation, respectively, were the most effective environmental variables to predict the main SOC stocks [42]. Our results showed that remote sensing and other related environmental variables play an important role in mapping regional forest topsoil SOC stocks. To some extent, B4 and B5 reflect the land use situation in those regions, while the SOC stocks under different land use patterns were significantly different. These results were consistent with the previous findings of Zhang et al. [43]. Bhunia et al. [44] used B3, B4, B5, and NDVI of Landsant 5 satellite to simulate the spatial variation of SOC stocks in India. Using remote sensing data has significantly improved the prediction of SOC stocks in this study.The terrain determines the distribution of light, heat, and water, affecting the distribution of land vegetation types and the migration and transformation of SOC [18,22]. Different land-use and land-cover types and their changes also affect the input and accumulation capacity of SOC [17,37,38]. In addition, the spatial variability of soil properties and topographic variables all affect SOC changes [11]. In this study, we found that the RI of terrain-related variables in 2015 was higher than that in 1990 (Figure 4). Our results show that terrain variables were the main environmental factors and played an important role in the spatial variation of SOC stocks during these two periods. Elevation referred to the vertical distance of a place on the ground or a geographical object above or below sea level [20,45]. In mountainous vertical zones, with increasing elevation, the temperature gradually decreases, so the SOC density was vulnerable to this vertical zonality [45,46,47]. In addition, slope gradient could significantly affect soil erosion, vegetation cover, and other factors, affecting SOC stocks. Liu et al. [45] discussed the effects of elevation and slope gradient on SOC stocks by fitting a linear equation. The results showed that elevation and slope gradient had significant effects. SOC stocks increased with the increase of elevation, but were negatively correlated with elevation at a certain height. The larger slope gradient tended to have higher SOC stocks. Tan et al. [46] studied the relationship between SOC stocks and natural factors in the topsoil of Ohio, Great Lakes, USA. It was found that the SOC stocks were closely related to the elevation in the forest cover area. Ramarson et al. [48] considered the influencing factors of SOC stocks in 1590 hectares of Madagascar Island. They concluded that elevation was the most influential factor when using a BRT model to simulate SOC stocks. In addition, the slope gradient and TWI were also the dominant topographic variables affecting the spatial variability of SOC stocks. The existence of slope gradient will affect the distribution of vegetation and soil layers. Especially in some low hilly and gentle slope areas, the increase of slope gradient led to thinning of soil layer and strong disturbance of human activities, which easily results in the loss of SOC [49]. However, when the slope gradient increased to a certain extent, which limited human activities and did not easily affect the accumulation of SOC, the impact of slope gradient on SOC was positively correlated [50]. TWI was a quantitative description of runoff length and confluence area. It was an effective index to measure soil water content. TWI and soil moisture change synergistically. Soil moisture was also very high in areas with large TWI. Huang et al. [50] and Raduła et al. [49] considered that the relationship between TWI and soil moisture was linear, and the spatial change of TWI was proportional to the spatial change of soil moisture. Therefore, it was feasible to use TWI to reflect the level of soil moisture. In previous studies, it was found that SOC also had a significant positive correlation with soil moisture [45,46,49,50]. They pointed out that the increase of SOC could promote aggregate formation, improve soil structure, and consequently increase soil water retention capacity, and reduce the loss of surface soil water due to evaporation or infiltration into the lower layer [49,50]. Therefore, TWI can be used as an effective factor to predict SOC stocks.Climate variables were the key environmental variables affecting SOC stocks [11,20]. Previous studies [18,22,30,46,48] had revealed that climate-related variables were closely related to SOC stocks, especially on the regional scale [18], and MAP and MAT were considered to be the main climate variables controlling the spatial variability of SOC stocks. The correlation between MAP and SOC stocks decreased with the decrease of spatial scale, while the correlation between MAP and SOC stocks was not obvious with the change of spatial scale, and there was a strong regional difference [42]. SOC stocks were mainly affected by the combined effect of MAP and MAT [51]. In this study, the explanatory ability of climate variables to the variation of SOC stocks was about 20% during two periods, and the explanatory ability gradually decreased with the decrease of scale. With the increase of MAP, the annual output of organic matter increases correspondingly, so the organic carbon quality entering the soil also increases [52]. In addition, the RI of climate variables was offset to some extent by related environmental factors such as topography [42]. For instance, areas with different elevations have different hydrothermal conditions, affecting SOC stocks in mountainous areas.", 4. Discussion, 4.2. Controls of SOC Stocks,4
603,"The results showed that, although the BRT model had excellent prediction performance in predicting SOC stocks during the 1990 and 2015 periods, there were still some uncertainties in this study. First, while the soil data were obtained from the historical dataset of the Second National Soil Survey Database of Liaoning Province in 1990, the whole dataset come from different departments, which might have sampling errors or experimental errors. Second, because some bulk density data were missing in 1990, we used a Pedo-transfer function (PTFs) (Formula 1) to predict the missing bulk density. Nevertheless, the soil was not homogeneous in those regions and the distribution estimates of land cover types might have also been biased. Finally, this study was limited to the estimation of SOC stocks in the topsoil (0–30 cm), which would have underestimated the total SOC in this area. Especially in the forest covered areas, the SOC stocks are usually stored at deeper layers in the forest soils.", 4. Discussion, 4.3. Uncertainty in Current Research,4
604,"We used a BRT model to simulate the spatial distribution of forest topsoil (0–30 cm) SOC stocks in Liaoning Province, China, and determined their key environmental variables. We found that, in the past 25 years, the average value of SOC stocks has increased from 5.66 kg m−2 to 6.61 kg m-2 in this region. Surprisingly, the SOC stocks showed a decreasing trend in the central plain area of the study area, accounting for 3.4% of the total area. It was also found that NDVI and MAP were two key environmental variables that affect the spatial distribution of SOC stocks in the two periods. Overall, this study provided a more accurate prediction of regional SOC, which shall help ecological restoration, forest protection, and environmental management in the forest areas of the region.", 5. Conclusions,None,5
605,"On the world’s land surface, forests cover about 4200 million hectares, and the carbon stock of forests accounts for about 45% of the world’s terrestrial carbon reserves [1]. Aboveground biomass is an important component of forest ecosystems and accounts for a large proportion of forest carbon stock; thus, quantifying forest aboveground biomass is important for forest managers [2].Diameter at breast height (DBH) and aboveground biomass (AGB) are two important measurements of individual trees, widely used in yield estimations and forest growth [3]. Tree DBH is an easy measuring factor with high accuracy—all DBH data are measured. However, AGB is difficult to measure and has less accuracy than ground-observed DBH—only limited tree biomass can be measured in the sample [4]. Consequently, in the past few decades, many studies have proposed numerous equations to estimate aboveground biomass [5,6,7,8,9,10]. Developing an AGB model according to ground-based DBH has been widely applied in forest investigation and yield modeling. It is important to note that DBH measurement in large-scale forest inventory is still time-consuming and costly.LIDAR is a range detection system, which obtains the forest point cloud by LIDAR sensors. The LIDAR system has been used to measure the forest vegetation structure and has been applied to measure forest variables since the mid-1980s [11]. These variables, including tree height, stem volume, crown projection area, diameter at breast height, and other variables, are significantly connected to the forest biomass [3,11,12]. Using these LIDAR variables, individual tree DBH and aboveground biomass can be estimated by developing DBH and AGB models, respectively [3,12,13]. With some studies also using LIDAR data to predict timber volume and discern age class, LIDAR data have been widely used in forestry over the past two decades. The application of LIDAR technology has reduced the cost of forest management and provided a good opportunity for large-scale forest inventory [11,12].The Bayesian method is used to integrate prior information about unknown parameters with the sample information; then, the posterior information is obtained according to the Bayes formula and the method of unknown parameters is further inferred according to the posterior information. Many studies have already used the Bayesian method to develop DBH and AGB models and have compared the Bayesian model with the classical model [14,15,16,17]. Zapata-Cuartas et al. [14] presented a comparison of aboveground biomass estimation in different sample sizes using the Bayesian method and the classical method. They obtained a result that the bias in the classical method was always bigger than that in the Bayesian approach.Although LIDAR technology and Bayesian methods are used separately in individual DBH and AGB modeling [6,13,14,15,17,18,19,20,21], few studies have combined the two methods to estimate DBH and aboveground biomass. Tenneson [22] presented a combination of the Bayesian method and LIDAR to model LIDAR-derived forest inventory, combining the advantages of both DBH and AGB prediction; they used Bayesian model averaging (BMA), while we are using the hierarchical Bayesian method [23,24]. In this study, we used the hierarchical Bayesian method to choose the best DBH and AGB model to predict DBH and aboveground biomass on the basis of LIDAR point cloud data, integrating the advantages of the Bayesian approach and LIDAR data to reduce costs compared with conventional measurements [13,14]. Further, compared with the classical prediction method, using the Bayesian method can improve the accuracy to a certain degree.", 1. Introduction,None,1.
606,"The study area from which data were taken is located at the Xishui forest farm of Su’nan Yuguzu Autonomous County, China (38°290–38°350N, 100°120–100°200E) and lies within the temperate alpine cold semi-humid and semi-arid zone. The altitude is in the 2550 to 3680 m range, with a mean value of 2993 m in this area. This area is occupied by mountainous forests and steppes, and one of the main functions of these forests is to protect the water resources in the Dayekou Basin of the Qilian Mountains. Grass and natural mature secondary pure forests dominate the sunny and shady slopes, respectively. The dominant tree species in the forest in this area is Picea crassifolia Kom.We established a single permanent sample plot (PSP) of 100 m × 100 m along the hillside and divided it into sixteen subplots of 25 m × 25 m. DBH, tree height (H), crown base height, and crown diameters in two perpendicular directions of all standing trees were measured in each subplot. We used a differential global positioning system unit to measure the corners and centers of the PSP in each subplot, and a total station to measure the positions of individual trees.Airborne LIDAR data were acquired using a Lite Mapper 5600 system on 23 June 2008. The mean flight speed was 230 km h−1 and the mean flight height was 3699 m above sea level. The point elevation varied from 2725 to 3193 m, and the LIDAR point density was 4.34 points m−2. We can obtain individual LIDAR tree heights and crown projection areas on the basis of the airborne LIDAR point cloud from a canopy height model (CHM), and the CHM was derived as the difference between the digital surface model (DSM) and the digital elevation model (DEM) of the study area. The digital surface model grid, which contained elevation information including all ground objects, was interpolated from raw LIDAR point cloud data by a maximum height interpolation method and by filling null cells. For obtaining the absolute vegetation heights, we must remove the influence of the terrain. Thus, we obtained the digital elevation model from the ground-classified LIDAR point cloud data using a progressive morphological filter and, in this study, with a grid cell size of 0.5 m [3]. We also eliminated the noise using a Gaussian smoothing filter to obtain a more accurate crown projection area [3]. We used the local maxima algorithm to find the individual tree crown tops, and used the region growing method to obtain the tree crown boundary, the crown projection area was calculated according to the determined tree crown boundary. The details of the algorithms can be found in Fu et al. [3]. A total of 402 individual P. crassifolia tree crowns in the 16 subplots nested in the PSP were delineated; the individual tree LIDAR crown projection area and field measurement data were matched by individual tree locations measured by total station—Fu et al. [3] has drawn a figure to explain this. The biomasses of each component (stem, branch, foliage, and fruit) of the 402 P. crassifolia trees were estimated using the empirical allometric models developed by Wang et al. [25] using the field-measured individual DBH and tree height H. The total tree AGB was obtained by summing the component biomass values. For more information about the study sites and data collection, please see Fu et al. [3].", 2. Materials and Methods, 2.1. Study Area and Data,2
607,"In order to compare the LIDAR AGB estimation by the Bayesian method and the classical method in different sample sizes, five samples (Samples 1–4) of different sizes were randomly selected from the population. The independent variables in the population, including LIDAR crown projection area (CPA), LIDAR tree height (LH), ground-measured DBH, and the ground-estimated AGB, were assessed. Sample 1 randomly sampled 10% of the population, and Samples 2–4 randomly sampled 25%, 50%, and 75% of the population, respectively. The statistics of sample sizes 1–4 are presented in (Table 1), and we also put the statistics of the full dataset into this table.", 2. Materials and Methods, 2.2. Random Sampling,2
608,"In this paper, four frequently used candidate model forms [3] and another three models [26,27,28] were used to develop LIDAR DBH estimation models by regarding the LIDAR-derived tree height and the crown projection area as the predictor variables. These models are listed as follows: 



D
B
H
=

β
1

+

β
2

L
H
+

β
3

C
P
A
+

ε

D
B
H


 
(
Linear
)




I.1





D
B
H
=

β
1


[

1
−
e
x
p
(
−

β
2

L
H
−

β
3

C
P
A

)

]
+

ε

D
B
H


 
(
Richards
)




I.2





D
B
H
=

β
1

/

[

1
+

β
2

e
x
p
(
−

β
3

L
H
−

β
4

C
P
A

)

]
+

ε

D
B
H


 
(
Logistic
)




I.3





D
B
H
=

β
1

e
x
p
(
−
β


2

L
H
−

β
3

C
P
A
)
+

ε

D
B
H


 
(
Exponential
)




I.4





D
B
H
=
−


β
1


−
1


ln
[
1
−

(



60


−
1



(

L
H
−
1.3

)


)

1
/

β
2




]

+

ε

D
B
H


 
(
Richards
)




I.5





D
B
H
=
[
−


β
1


−
1


ln


(
1
−


60


−
1


(
L
H
−
1.3
)
]


1
/

β
2



+

ε

D
B
H


 
(
[
27
]
)




I.6





D
B
H
=

β
1




(
L
H
−
1.3
)



β
2



e
x
p
(

β
3

C
P
A
)

+

ε

D
B
H


 
(
[
28
]
)




I.7


where β1–β4 are parameters of the models, LH is the LIDAR tree height, CPA is the LIDAR crown projection area, and εDBH is the error term.On the basis of the best DBH model, five commonly used AGB model forms were applied to estimate the aboveground biomass. They are listed as follows: 



A
G
B
=

α
1

D
B

H


α
2



+

ε

A
G
B






II.1





A
G
B
=

α
1

D
B

H


α
2



L

H


α
3



+

ε

A
G
B






II.2





A
G
B
=

α
1

D
B

H


α
2



C
P

A


α
3



+

ε

A
G
B






II.3





A
G
B
=

α
1

L

H


α
2



C
P

A


α
3



+

ε

A
G
B






II.4





A
G
B
=

α
1

D
B

H


α
2



L

H


α
3



C
P

A


α
4



+

ε

A
G
B






II.5


where α1–α3 are model parameters, DBH is the LIDAR estimated DBH, and εAGB is the error term.", 2. Materials and Methods, 2.3. DBH and AGB Models,2
609,"Bayesian estimation is used to combine new evidence and prior distributions with the Bayesian theorem to get a new probability. Zhang et al. [16,29] presented the Bayesian rules in detail. Let y = (y1, y2, y3, …) represent a vector of data and θ = (θ1, θ2, θ3, …) be a vector of parameters to be estimated. Bayes’ expression is




p

(

y
,
θ

)

=
p

(

y

|
θ


)

p

(
θ
)

=
p
(
θ

|

y
)
p

(
y
)









where p(θ) is the prior distribution for the parameters, which can be obtained by the classical method; and p(θ|y) is the posterior distribution of the Bayesian frameworks.An important feature of the Bayesian method is that the parameter will be given a prior distribution before sampling. The choice of prior distribution is critical for the Bayesian method [25]. Non-informative priors with large or infinite variance that reflect prior “ignorance” are generally chosen [29,30,31]. Alternatively, if prior information is available from external knowledge (reported parameters from the literature), the information can be used to construct a prior distribution. Zhang et al. [32] used the parameter estimates of height growth models from classical method as the prior information for the Bayesian method, consistent with Zhang et al. [32]. Here, we used the parameters of NLME estimation as the prior distribution for the Bayesian estimation.", 2. Materials and Methods, 2.4. Bayesian Method,2
610,"The best DBH and AGB model was chosen from the value of the deviance information criterion (DIC) [16], when pooling the data: 



D
I
C
=

D
¯

+
N






where 


D
¯

=

E
θ

{
−
2

log
 

[
p
(
y

|

θ
)
]
}



 represents the posterior mean of the deviance; and 

N
=

D
¯

+
2

log
 

[
p
(
y

|


θ
¯

)
]



 is the effective number of parameters in the model and represents the complexity of the model. A smaller value of DIC for a model indicates a better fit to the data [31].In addition, the stationarity test in Heidelberger–Welch Diagnostics [33,34] was regarded as a criterion to test if the model converged in our study. The stationary process is a random process in statistics, and its unconditional joint probability distribution does not change with time. Thus, the mean value and variance do not change with time either [35].The determination coefficient (R2) and mean absolute deviation (MAD) were used to compare the Bayesian method with the classical method. Higher R2 and smaller MAD values indicate a better model fit to the data. They are calculated by





R
2

=


∑
(
y
−

y
^


)
2



∑


(
y
−

y
¯

)

2



,









M
A
D
=
∑

|

y
−

y
^


|

/
n
,






where y is the observed AGB, 

y
^

 is the LIDAR predicted DBH or AGB, 

y
¯

 is the mean value of the observed AGB, and n is the number of samples.This study developed several candidate DBH models and selected the best model. On the basis of the best DBH model, DBH predictions were introduced to the five candidate AGB models as one of the independent variables. Both the DBH and the AGB models were developed through the hierarchical Bayesian approach. In addition, five different random sample sizes were used for comparing the Bayesian method with the classical method.Considering the random effects of plot, we added a random effect parameter to β1 in DBH models and to α1 in AGB models using hierarchical Bayesian and classical methods (nonlinear mixed effects model, NLME). The Bayesian and NLME models were constructed by using SAS procedures MCMC and MODEL, respectively [36]. For the Bayesian estimation, a burn-in period of 10,000 steps and 100,000 iterations was used to estimate parameters. The thinning parameter was set to 5 to reduce the correlation between neighboring iterations.", 2. Materials and Methods, 2.5. Model Evaluation,2
611,"In this study, deviance information criterion (DIC) statistics and the stationarity test were used to evaluate the Bayesian DBH and AGB models. As shown in Table 2, all the DBH models other than model I.5 passed the stationarity test (Table 2). Model I.3 had the smallest DIC value, followed by I.4, I.7, I.2, I.1, and I.6. Thus, model I.3 was selected as the best model to predict DBH used as an independent variable for modeling AGB.The parameter estimations of model I.3 for different sample sizes are listed in Table 3. In all sample sizes, the standard deviations of all the parameters estimated by the Bayesian method were smaller than those estimated by the classical method, meaning that the parameters estimated by the Bayesian method were more stable than those estimated by the classical method. Simultaneously, we can see from Table 3 that in Bayesian estimation, the range of parameters at sample size 39 was between −0.036 and 49.34, while it was between 0.066 and 111.3 at full data. The ranges of parameter estimates for small sample size were significantly narrower than those of the full data, which confirms that for a small sample size, the Bayesian method shows higher efficiency.In terms of the fitting statistics, AGB models II.1, II.3, and II.4 passed the stationarity test (Table 4), however, the other two models failed. Among the three models, II.1, II.3, and II.4, the DIC in II.3 (4754.906) was much smaller than those in the other two models. Therefore, model II.3 was selected as the best model to predict AGB. The parameter estimations of model II.3 are listed in Table 5. The standard deviation of parameter estimations by Bayesian method in all sample sizes are smaller than classical method.", 3. Results, 3.1. Model Selection,3
612,"Figure 1 shows the correlations and residuals of AGB using the Bayesian method and the classical method when pooling the data. Both these plots show that the two methods performed well when modeling AGB. Also, the two plots from the two methods are very similar. However, as sample size decreased, the two methodologies produced large differences in R2 and MAD. For example, when pooling the data, the R2 of the Bayesian method was 0.5867, which was 2.587% larger than that of the classical method (0.5719). However, for a sample size of 39, the R2 of the Bayesian method was 11.238% larger than that of the classical method (Table 6). Similarly, although the MAD value from the Bayesian method was slightly smaller (2.172%) than that from the classical method using the whole data set, it was much smaller (16.62%) than that from the classical method for a sample size of 39 (Table 6).In addition, we found that parameter estimation through the Bayesian method was more stable than that through the classical method when using different sample sizes. For the parameter α1, the parameter range was 0.027–0.281 for the Bayesian method and 0.007–0.167 for the classical method. In particular, when the sample size was 39, the estimate changed largely compared with that for the pooled data set using the classical method, which could also be seen in parameters α2 and α3 (Figure 2). In addition, we found that the classical approach always produced estimates in a wider range than the Bayesian approach (Figure 2).", 3. Results, 3.2. Comparing the Hierarchical Bayesian and NLME Methods,3
613,"In this study, an individual tree DBH and AGB model was selected from seven DBH models and five AGB models using the Bayesian method on the basis of airborne LIDAR data. When selecting a model, we ensured that all models were compared at the same level and that the random effects of the parameters were considered in the same position. The criteria of model selection were the value of DIC and the results of the parameter stationarity test. When selecting the AGB model, the independent variable DBH was the LIDAR estimated DBH, which ensured that the selected AGB model took the correlation between DBH and AGB into account.LIDAR has the ability to measure the forest structure, and it is a useful tool for obtaining canopy information [11]. This study used LIDAR to obtain the image data of our study area, then acquired individual tree information, including individual tree height and crown projection area, for model development. For aboveground biomass estimation, many studies have used LIDAR data. Næsset et al. [12] used LIDAR data for estimating the timber volume of forest stands. They obtained the LIDAR canopy height and canopy cover density for timber volume estimation, and they found that LIDAR data produced equal results to aerial photointerpretation, though different sites had large differences when estimating timber volume. Holmgren et al. [11] studied how to use LIDAR-derived data in regressive models for estimating the mean tree height and stem volume; the R2 of mean tree height linear regression functions was between 0.89 and 0.91 and that for average stem volumes was between 0.82 and 0.9 when using the LIDAR mean tree height and LIDAR crown coverage area as variables. LIDAR is widely used in biomass prediction.The study of forest biomass by the Bayesian method has been relatively less frequent than by the classical method. When the Bayesian method is compared to the classical method, an important difference is that the Bayesian method treats the parameters as random variables, while the classical method treats the parameters as fixed values; that is, the classical method treats the probability as the stable value of the frequency of a large number of repeated trials of events. Zapata-Cuartas et al. [14] used the existing biomass equation reported in the literature as the prior distribution, assuming that the information can be useful to probability distributions, and validated the larger R2 in the Bayesian method. This study used a different approach to the prior distribution—we used the parameters estimated by NLME for the prior distribution and obtained the same results.We compared the classical method and the Bayesian method in estimating DBH and AGB; the results show that parameter estimation using the Bayesian method had higher stability than that using the classical method, and the R2 of the Bayesian method was higher than that of the classical method. Zianis et al. [17] also compared the two methods—they obtained a contrary result that the classical method was superior to the Bayesian method [17], but they did not compare the two methods on different sample sizes. In order to show that the Bayesian method is more accurate in estimating AGB for different sample sizes, we randomly sampled from the complete data set (Table 6). The data showed that the Bayesian method was more efficient than the classical method for different sizes of samples, which is the same as the result for the full data set. Zapata-Cuartas et al. [14] compared these two methods in the same way, and their results showed that for small sample sizes, the Bayesian method outperforms classical methods of least-square regression. Huang et al. [37] used the same method and showed that when the sample size is less than 50, we should use the Bayesian method to estimate aboveground biomass. Yao et al. [38] also presented a comparison of the Bayesian and classical methods—they found a more stable parameter value when using the Bayesian method. Thus, using the Bayesian method to estimate the aboveground biomass from small sample sizes is a good direction in biomass estimation. If classical methods are applied, especially with a small sample size, violation of statistical assumptions of error can lead to biased point estimates [20,39]. In addition, in this study, we have not taken into account the error propagation, thus a join model is perhaps a good method, and further studies are needed to solve the join model under the Bayesian framework for reducing the model uncertainties.This study developed LIDAR DBH and LIDAR AGB models using the Bayesian method based on airborne LIDAR data. Previous studies have used the classical method to develop models and applied the classical method to airborne LIDAR data [9,10]. Fu et al. [1] developed a system to predict individual tree diameter and aboveground biomass using the classical method and compared two other widely used model structures (the classical method to estimate AGB depending on DBH and the classical method to estimate AGB not depending on DBH). The current article compared the classical method to the hierarchical Bayesian method, and the results of this study showed that the Bayesian method has higher R2 and smaller MAD than the classical method for all sample sizes; thus, the Bayesian method was better than the classical method in estimating LIDAR DBH and LIDAR AGB for Picea crassifolia Kom. in northwestern China.Overall, this study combined the advantages of the Bayesian method and airborne LIDAR data; that is, airborne LIDAR data are easier to obtain than conventional aboveground measurements, and the Bayesian method was proven to have greater accuracy than the classical method. In addition, the present study also provides a reference for modeling with a small sample size.", 4. Discussion and Conclusions,None,4
614,"Our ability to estimate aboveground forest biomass from remote sensing observations has advanced substantially over the past decade, largely due to the increased availability of direct three-dimensional (3-D) measurements of vegetation structure provided by light detection and ranging (Lidar; [1]) and interferometric synthetic aperture radar (InSAR; [2]). Although approaches to forest biomass estimation based on remotely sensed structure have yet to be fully developed and validated (cf. [3]), they are already greatly expanding our knowledge of the amount and spatial distribution of carbon stored in terrestrial ecosystems, particularly in tropical forests (e.g., [4,5,6]), where large areas have never been inventoried on the ground [7]. Lidar remote sensing, calibrated with field measurements and combined with wall-to-wall observations from InSAR and/or passive optical systems, represents a promising alternative to more traditional approaches to biomass mapping (e.g., [8,9]) and is expected to play a key role in forest monitoring systems being developed in the context of climate change mitigation efforts such as REDD (Reducing Emissions from Deforestation and Forest Degradation), and to improve our understanding of the global carbon balance [10,11,12,13].The typical approach to producing spatially explicit estimates of biomass from 3-D remote sensing is characterized by two primary steps. First, field estimates of aboveground biomass density are obtained from sample plot data together with published allometric equations, which allow the estimation of tree-level biomass from more easily measured quantities such as diameter, height, and wood density [14,15,16]. Second, the plot-level estimates of biomass are related to co-located remote sensing estimates of structure (e.g., mean canopy height) using a statistical model. The model is then applied together with remote sensing data to predict biomass in locations where ground measurements are not available [17,18,19,20,21]. When the 3-D measurements are spatially discontinuous, as is usually the case with Lidar, the resulting biomass predictions can be further integrated with radar and/or passive optical imagery (typically using machine learning algorithms) to produce wall-to-wall maps of biomass or carbon [5,6], although often with poorer resolution and unknown accuracy.One of the main limitations of this scaling approach, as noted by [22], is that biomass is never measured directly (i.e., quantified by harvesting and weighing the leaves, branches, and stems of trees). Because direct measurements are laborious, time-consuming, and ultimately destructive (e.g., [23]), the remotely sensed structure is calibrated against allometrically estimated biomass (a function of diameter and sometimes height and wood density) and the final product is, in essence, “an estimate of an estimate” of biomass.Despite significant advances in the development of allometric equations for tropical forest trees over the past decade [15,16], the allometrically-derived biomass is subject to a number of sources of error, including: (i) uncertainty in the estimation of the parameters of the allometric equation as a result of sampling error (e.g., resulting from a relatively small number of trees being harvested or bias against the harvest of trees with a “typical” form), natural variability in tree structure (i.e., trees of the same diameter, height, and wood density can display a range of biomass values), and measurement errors on the harvested trees; (ii) uncertainty associated with the choice of a particular equation or application of a given equation beyond the site(s) and/or species for which it was developed (uncertainty driven primarily by biogeographic variation in allometric relations due to soil fertility and climate); and (iii) measurement errors in the diameter, height, and wood density of the trees that the allometric equation is being applied to [22,24,25]. Combined, these sources of uncertainty have been estimated to represent approximately 50%–80% of the estimated biomass at the tree level, and over 20% at the plot scale [24,26].Because remote sensing algorithms for prediction of forest biomass are typically calibrated with allometrically estimated biomass (see [27] for an exception), they incorporate all of the sources of uncertainty described above, in addition to those associated with the remote sensing observations. As a result, while the precision (degree of reproducibility) of remote sensing estimates of biomass can be easily assessed, their accuracy is rarely known. Although precision may be all that is needed for the relative tracking of changes in carbon stocks for REDD-like initiatives, accuracy is ultimately critical for determining the absolute amount of carbon stored in forests, as required for global carbon budgets and climate change science [22].While the accuracy of remote sensing-based estimates of biomass cannot be truly determined without whole-plot harvests, it can nevertheless be optimized. When calibrating remotely sensed structure to allometrically estimated biomass, it is reasonable to expect that the uncertainty in the estimated biomass will vary from plot to plot as a function of differences in, for example, tree size distribution and species composition. If these plot-level uncertainties can be estimated precisely relative to one another, the prediction accuracy of the statistical model relating biomass to remotely sensed structure can be significantly improved by giving sample plots with smaller standard deviations more weight in the parameter estimation. In practice, this can be accomplished, for example, using the method of weighted least squares (WLS), where each plot is weighted inversely by its own variance [28,29]. Although considered a standard statistical technique for dealing with nonconstant variance when responses are estimates, WLS is almost never used in the current context, in part because the uncertainty in the field biomass is rarely quantified (see [30] for an exception).In this study, we use field plot data collected at the Tapajós National Forest, Brazil, to gain a better understanding of the uncertainty associated with plot-level biomass estimates obtained specifically for calibration of remote sensing measurements in tropical forests. In addition to accounting for sources of error that would be normally expected in conventional biomass estimates (e.g., measurement and allometric errors; [24,31,32,33,34]), we examine two sources of uncertainty that are specific to the calibration process and should be taken into account in most remote sensing studies: (1) the error resulting from spatial disagreement between field and remote sensing samples (co-location error); and (2) the error introduced when accounting for temporal differences in data acquisition.", 1. Introduction,None,1.
615,"The Tapajós National Forest is located along highway BR-163, approximately 50 km south of the city of Santarém, Pará, in the central Brazilian Amazon (Figure 1). The climate is tropical monsoon (Köppen Am), with a mean annual temperature of 25.1 °C and annual precipitation of 1909 mm, with a 5-month dry season (<100 mm month−1) between July and November [35]. The vegetation is dense, upland, tropical moist forest. Common genera among 193 tree species sampled in this study include Psychotria (Rubiaceae), Protium (Burseraceae), Otoba (Myristicaceae), Eschweilera (Lecythidaceae), Pouteria (Sapotaceae), and Rinorea (Violaceae) in primary forests, and Cecropia (Urticaceae), Banara (Salicaceae), and Inga (Fabaceae) in secondary forests. The soils are nutrient-poor oxisols and ultisols, with low pH, organic matter, and cation exchange capacity, and a high concentration of aluminum oxides [36]. Our sample sites were situated on a relatively flat plateau, with the elevation ranging from approximately 80 to 180 m.", 2. Materials and Methods, 2.1. Study Site,2
616,"Field data were collected in September 2010 in 30 0.25-ha plots (50 m × 50 m) intended for calibration of Lidar data acquired by the Geoscience Laser Altimeter System (GLAS; [19]). Of the 30 plots, 8 were primary forest (PF), 8 were primary forest subject to reduced-impact selective logging (PFL) between 1999 and 2003 (~3.5 trees harvested per hectare during this period; [37]), and 14 were secondary forest (SF) with different age and disturbance histories. Plots were centered on GLAS footprints selected along two sensor acquisition tracks, spanning a wide range in vertical structure and aboveground biomass (Figure 1). Individual footprint centers were located on the ground using a total station and the Differential Global Positioning System (DGPS).Field biometric measurements included diameter at breast height (D) measured with a diameter tape at 1.3 m and recorded to the nearest 0.1 cm; height to the base of the live crown (HC) and total height (HT), estimated visually by experienced members of the field crew to the nearest 0.5 m; and crown depth (CD), calculated as the difference between HT and HC. Measurements were taken for each living tree ≥5 cm in diameter in early successional stands and ≥10 cm in all other stands. For a 12.5 m × 50 m subplot extending along the major axis of the GLAS footprint, we also measured crown radius (CR) in two orthogonal directions by projecting the edge of the crown to the ground and recording its horizontal distance to the trunk to the nearest 0.1 m using a tape measure. All trees were identified as to their species or genus (when species was uncertain) level and assigned a wood density value (ρ, oven-dry weight over green volume) derived from the literature [38,39].To estimate measurement errors associated with the inventory, we conducted a blind remeasurement of 2–4 trees selected at random in each plot, resulting in a total resampling effort of 3%. For a portion of the trees that were remeasured (and additional trees selected in open areas), heights were also obtained with a laser rangefinder using the tangent method [40]. We used these observations to develop a regression model relating precise laser-measured heights to less precise, however more readily obtained, visually estimated heights (cf. [37]). This model, described in detail in [19], was applied to calibrate all visually estimated heights.", 2. Materials and Methods, 2.2. Field Data,2
617,"The oven-dry aboveground mass of each live tree (M) was estimated from its diameter, total height, and wood density using an established allometric equation for tropical moist forests ([15]; Table 1). Exceptions were made for Cecropia spp. and palms, which differ significantly from other species in wood density and allometry [15,41] and had their biomass estimated with specific equations, as indicated in Table 1. We selected Chave’s equation as the basis of our estimate because it was developed using a large number of harvested trees (1350) covering a wide range in diameter (5–156 cm), and because it included information on tree height and wood density, which greatly improves the accuracy of biomass estimates [15,16]. In addition, approximately 43% of the trees used in the fit were harvested in the Brazilian Amazon, and 11% in the state of Pará, in sites having climatic and edaphic conditions comparable to ours. Nevertheless, we also estimated M in this study using two additional, widely used equations ([14,42]; Table 1), to obtain a measure of allometric uncertainty as described in Section 2.4.2.The aboveground biomass density (AGB, Mg·ha−1) at the plot level was calculated by adding the masses of all inventoried trees in the plot and dividing by the plot area (i.e., 0.25 ha). In plots where the minimum diameter was 10 cm, we corrected for the AGB in the 5–10 cm class by: (i) fitting a negative exponential function to the diameter distribution of the plot [33,43]






N
i

=
k
 

e

−
a

d
i








(1)


where Ni was the number of trees per hectare in the ith diameter class with midpoint di, and k and a were model parameters estimated by nonlinear least squares; (ii) estimating the number of trees per hectare in the 5–10 cm class; and (iii) multiplying the resulting number by the biomass of a tree with diameter of 7.5 cm (midpoint) and wood density equal to the plot mean. To avoid errors due to the estimation of a mean height for the 5–10 cm class, we used an alternative equation based on diameter and wood density only ([15]; Table 1). Because the GLAS Lidar data were acquired in 2007, three years prior to our field measurements, we applied the site-specific, stand-level growth model [44]








A
G

B
t

=
0.397
 

B
t

 

H

T
O

P
t



 
,
 
w
i
t
h







B
t

=
21.057
 



(

1
−

e

−
0.109
 
t



)



1.894









H

T
O

P
t



=
23.067
 



(

1
−

e

−
0.074
 
t



)



0.946










(2)


to all SF plots to correct for the AGB change between observation epochs, where AGBt is the plot biomass (Mg·ha−1), estimated with the equation of [45] (Table 1); Bt is the basal area (m2·ha−1); 



H

T
O

P
t





 is the top height (m), defined as the mean total height of the tallest 20% of the trees; and t is the stand age (years since stand initiation). Because this growth model is based on a biomass equation that is different from the ones used in this study, we calculated the biomass change as a proportion of the plot biomass. This was done by: (i) inverting the first line of Equation (2) to estimate the plot age in years in 2010 (t2010) from its measured biomass (AGB2010); (ii) estimating the plot biomass at the time of the GLAS acquisition (AGB2007), making t = t2010 − 3; and (iii) calculating the ratio (AGB2010 − AGB2007)/AGB2010. For primary forests, we assumed no biomass change in the 3-year period. This is supported by [44], who found that biomass tends to increase rapidly in early stand development at Tapajós, reaching near-asymptote as early as 40–50 years after clear-cutting (Figure 2).", 2. Materials and Methods, 2.3. Biomass Estimation,2
618," 2.4.1. Individual Tree MeasurementsMeasurement errors in D, HC, HT, CD, and CR were described in terms of total error, systematic error (bias), and random error. The total error for each attribute was quantified with the root mean square deviation (RMSD)





RMSD
=



1
n



∑


i
=
1

n



e
i

2



 
,


 
with
 
e

i

=
m

1
i

−
m

2
i






(3)


where n is the number of pairs of repeated measurements for the attribute, and ei is the measurement difference for the ith pair, with m1i and m2i representing the original measurement and remeasurement, respectively. The systematic and random errors were quantified, respectively, as the mean and sample standard deviation (SD) of the measurement differences ei




Mean
=

1
n



∑


i
=
1

n


e
i






(4)






SD
=



1

n
−
1




∑


i
=
1

n




(


e
i

−
Mean

)


2








(5)

We also calculated all of the above in relative terms, expressing ei as a fraction of the average of the two measurements. For the wood density values, the standard deviation was either taken or estimated from the supplementary material provided by [39].To test the hypothesis of no systematic difference between the first and second measurements of a given attribute, we used either a paired t-test or the alternative Wilcoxon signed-rank test, depending on the assessment of distributional assumptions and the presence of outliers [29]. To determine whether measurement variation increased with the magnitude of the measurement, we: (i) divided the measurements for a given attribute into four classes with an equal number of samples; (ii) regressed the SD calculated for each size class on the average value of the measurement for that class; and (iii) tested whether the slope was significantly different from zero. Finally, we tested if measurement differences varied with forest type by including forest type as a factor in the regression of the absolute measurement difference on the magnitude of the measurement—i.e., incorporating different intercepts and slopes for SF, PFL and PF—and testing for the equality of the coefficients using the extra-sum-of-squares F-test [29]. 2.4.2. BiomassMeasurement errors in diameter (σD), height (σH), and wood density (σρ) were propagated to the biomass estimate by expanding the allometric equations in Table 1 to a Taylor series and retaining only first-order terms. For a model like MT2 (Table 1), of the form M = aDkHρ, with ρ uncorrelated with both D and H, we expressed the uncertainty in the mass of a tree (σM) in terms of measurement errors as [24]









σ
M

=



[


σ
D
2




(



∂
M


∂
D



)


2

+

σ
H
2




(



∂
M


∂
H



)


2

+

σ
ρ
2




(



∂
M


∂
ρ



)


2

+
2

σ

DH

2


(



∂
M


∂
D



)


(



∂
M


∂
H



)


]



1
/
2








=
M



(


k
2




σ
D
2




D
2



+



σ
H
2




H
2



+



σ
ρ
2




ρ
2



+
2
k



σ

DH

2



D
H



)



1
/
2










(6)


where the terms in parentheses in the upper equation are the partial derivatives of M with respect to each of the dendrometric quantities, D, H, and ρ; and σDH is the covariance between D and H.We accounted for two sources of allometric uncertainty: (i) the uncertainty related to the model residuals, σA, estimated as [24,48]






σ
A

=



[


e


(

2


σ
^

2

+
2
ln
M

)



−


e



(



σ
^

2

+
2
ln
M

)




]



1
/
2


=



(


e



σ
^

2



−
1

)



1
/
2


〈
M
〉





(7)


where 


σ
^


 is the standard error of the regression on log-transformed data (see Table 1), and 


M
=
M
×
exp

(



σ
^

2

/
2

)



 is an unbiased estimate of the back-transformed biomass prediction M; and (ii) the uncertainty involved in the selection of the allometric equation, σS, estimated by calculating the mass of each tree with three independent equations (MT2, MA1, and MA2 in Table 1) and obtaining the standard deviation of the resulting values. The quantification of a third source of allometric uncertainty, the uncertainty in the determination of the model parameters as a result of sampling error (e.g., [26]), would require access to the destructive harvest data used in the development of the allometric equations and was not considered in this study.Spatial disagreement between the field plots and the GLAS footprints introduced additional uncertainty in the biomass estimates. This co-location error, σC, was introduced because of positional errors associated with both data sets [49,50], and because the size, shape, and orientation of the field and the GLAS samples did not exactly coincide (Figure 3). We took a Monte Carlo approach, based on binomial statistics [20], to estimate the difference in biomass between what was measured in each 50 m × 50 m field plot and what was actually present in the area covered by the GLAS footprint (Figure 3). The binomial-statistical approach constructs an ensemble of possible tree masses (M) based on those measured in the field. The method of ensemble-member construction is to assume that the set of Ms actually measured for each tree are the only values allowable for all ensemble members. For a single area, in just the FUI (field) area of Figure 3 for example, say there were 100 trees. There are 100 tree mass “bins”—bins labeled by the mass of the actually-measured tree—and the only way that another statistical ensemble member can be realized is by changing the population number of trees in each bin according to the binomial distribution, which means the probability of populating a single mass bin of mass B with x trees is






P
B


(

x
|

n
p


)

=

(






n
p






x




)


p
x




(

1
−
p

)




n
p

−
x







(8)


where p is the probability of finding a single tree in the mass bin, p = 1/np, and np is the total number of trees in the plot, 100 in this example. On average, each mass bin B will be populated with 1 tree, (np × p = 1), a result of binomial statistics, and the total average mass of the plot will be exactly what was measured in the field (the mass of the sum of the 100 bin labels). The fundamental assumption of binomial statistics is that each outcome—the number of trees in each bin—is independent of all other outcomes. That is, for example, if we measured one tree at 500 kg and one at 1000 kg, the probability of finding one tree in a tree mass bin of 500 kg is the same as finding one in a mass bin of 1000 kg.Figure 3 shows 3 areas relevant to considering area mismatch. The field measurements were taken with the rectangular boundaries shown, and the GLAS measurements were taken within the ellipse. “F” signifies the part of the field measurement area not in common with GLAS, and, similarly, “G” refers to the part of the GLAS measurement area not in common with the field. “I” refers to the area in common between field and GLAS, and for that area, the field-GLAS mismatch is zero. It is the difference in biomasses of areas F∪I and G∪I in Figure 3 that is of interest in assessing the area “mismatch”, where F∪I is the zone measured in the field and G∪I is the zone observed by GLAS. Probabilities as in Equation (8) for the same mass bins as in the field are constructed. That is, it is assumed that the spectrum of tree masses is the same for all areas of Figure 3. In order to construct a probability for one of the zones, np in Equation (8) must be replaced by nz, the number of total trees in the zone. This total number is assumed to be in proportion to area. We therefore took the probability of x trees in bin B of zone z to be






P
B


(

x
|

n
z

,
p

)

=

(






n
z






x




)


p
x




(

1
−
p

)




n
z

−
x







(9)


Monte Carlo values of xi were generated for the ith bin of zone z with the probability distribution of Equation (9). Total zone z biomasses (Bz) were generated by summing over all N bins (the number of trees measured in the field) for each throw:






B
z

=


∑


i
=
0

N


x
i


B
i






(10)

The difference 



(


B

G
∪
I


/


Area


G
∪
I



)

−

(


B

F
∪
I


/


Area


F
∪
I



)



 was calculated for each Monte Carlo throw. This procedure was repeated automatically 104 times and the standard deviation of the biomass differences was taken as the co-location error.In addition to the error sources discussed above, we included in our error budget the uncertainty associated with the corrections based on Equations (1) and (2), described in Section 2.3. The error of estimating biomass for the 5–10 cm diameter class, σ5–10, was assumed to be the same as for the 10–15 cm class, where all trees were actually measured and the error could be determined. This assumption was tested and verified on plots where the minimum diameter was 5 cm. The uncertainty associated with the application of the growth model, σG, was estimated by propagating the uncertainties in the parameters of Equation (2) to the determination of the biomass change, in a framework similar to Equation (6).Errors σM, σA, and σS were calculated at the tree level and added in quadrature to obtain plot-level estimates on a per-hectare basis. These errors were in turn combined in quadrature with σC, σ5–10, and σG, calculated directly at the plot level, to obtain an estimate of the overall uncertainty under the assumption of additivity and statistical independence.", 2. Materials and Methods, 2.4. Error Analysis,2
619,"Measurement errors in D, HC, HT, CD, and CR were described in terms of total error, systematic error (bias), and random error. The total error for each attribute was quantified with the root mean square deviation (RMSD)





RMSD
=



1
n



∑


i
=
1

n



e
i

2



 
,


 
with
 
e

i

=
m

1
i

−
m

2
i






(3)


where n is the number of pairs of repeated measurements for the attribute, and ei is the measurement difference for the ith pair, with m1i and m2i representing the original measurement and remeasurement, respectively. The systematic and random errors were quantified, respectively, as the mean and sample standard deviation (SD) of the measurement differences ei




Mean
=

1
n



∑


i
=
1

n


e
i






(4)






SD
=



1

n
−
1




∑


i
=
1

n




(


e
i

−
Mean

)


2








(5)

We also calculated all of the above in relative terms, expressing ei as a fraction of the average of the two measurements. For the wood density values, the standard deviation was either taken or estimated from the supplementary material provided by [39].To test the hypothesis of no systematic difference between the first and second measurements of a given attribute, we used either a paired t-test or the alternative Wilcoxon signed-rank test, depending on the assessment of distributional assumptions and the presence of outliers [29]. To determine whether measurement variation increased with the magnitude of the measurement, we: (i) divided the measurements for a given attribute into four classes with an equal number of samples; (ii) regressed the SD calculated for each size class on the average value of the measurement for that class; and (iii) tested whether the slope was significantly different from zero. Finally, we tested if measurement differences varied with forest type by including forest type as a factor in the regression of the absolute measurement difference on the magnitude of the measurement—i.e., incorporating different intercepts and slopes for SF, PFL and PF—and testing for the equality of the coefficients using the extra-sum-of-squares F-test [29].", 2. Materials and Methods, 2.4.1. Individual Tree Measurements,2
620,"Measurement errors in diameter (σD), height (σH), and wood density (σρ) were propagated to the biomass estimate by expanding the allometric equations in Table 1 to a Taylor series and retaining only first-order terms. For a model like MT2 (Table 1), of the form M = aDkHρ, with ρ uncorrelated with both D and H, we expressed the uncertainty in the mass of a tree (σM) in terms of measurement errors as [24]









σ
M

=



[


σ
D
2




(



∂
M


∂
D



)


2

+

σ
H
2




(



∂
M


∂
H



)


2

+

σ
ρ
2




(



∂
M


∂
ρ



)


2

+
2

σ

DH

2


(



∂
M


∂
D



)


(



∂
M


∂
H



)


]



1
/
2








=
M



(


k
2




σ
D
2




D
2



+



σ
H
2




H
2



+



σ
ρ
2




ρ
2



+
2
k



σ

DH

2



D
H



)



1
/
2










(6)


where the terms in parentheses in the upper equation are the partial derivatives of M with respect to each of the dendrometric quantities, D, H, and ρ; and σDH is the covariance between D and H.We accounted for two sources of allometric uncertainty: (i) the uncertainty related to the model residuals, σA, estimated as [24,48]






σ
A

=



[


e


(

2


σ
^

2

+
2
ln
M

)



−


e



(



σ
^

2

+
2
ln
M

)




]



1
/
2


=



(


e



σ
^

2



−
1

)



1
/
2


〈
M
〉





(7)


where 


σ
^


 is the standard error of the regression on log-transformed data (see Table 1), and 


M
=
M
×
exp

(



σ
^

2

/
2

)



 is an unbiased estimate of the back-transformed biomass prediction M; and (ii) the uncertainty involved in the selection of the allometric equation, σS, estimated by calculating the mass of each tree with three independent equations (MT2, MA1, and MA2 in Table 1) and obtaining the standard deviation of the resulting values. The quantification of a third source of allometric uncertainty, the uncertainty in the determination of the model parameters as a result of sampling error (e.g., [26]), would require access to the destructive harvest data used in the development of the allometric equations and was not considered in this study.Spatial disagreement between the field plots and the GLAS footprints introduced additional uncertainty in the biomass estimates. This co-location error, σC, was introduced because of positional errors associated with both data sets [49,50], and because the size, shape, and orientation of the field and the GLAS samples did not exactly coincide (Figure 3). We took a Monte Carlo approach, based on binomial statistics [20], to estimate the difference in biomass between what was measured in each 50 m × 50 m field plot and what was actually present in the area covered by the GLAS footprint (Figure 3). The binomial-statistical approach constructs an ensemble of possible tree masses (M) based on those measured in the field. The method of ensemble-member construction is to assume that the set of Ms actually measured for each tree are the only values allowable for all ensemble members. For a single area, in just the FUI (field) area of Figure 3 for example, say there were 100 trees. There are 100 tree mass “bins”—bins labeled by the mass of the actually-measured tree—and the only way that another statistical ensemble member can be realized is by changing the population number of trees in each bin according to the binomial distribution, which means the probability of populating a single mass bin of mass B with x trees is






P
B


(

x
|

n
p


)

=

(






n
p






x




)


p
x




(

1
−
p

)




n
p

−
x







(8)


where p is the probability of finding a single tree in the mass bin, p = 1/np, and np is the total number of trees in the plot, 100 in this example. On average, each mass bin B will be populated with 1 tree, (np × p = 1), a result of binomial statistics, and the total average mass of the plot will be exactly what was measured in the field (the mass of the sum of the 100 bin labels). The fundamental assumption of binomial statistics is that each outcome—the number of trees in each bin—is independent of all other outcomes. That is, for example, if we measured one tree at 500 kg and one at 1000 kg, the probability of finding one tree in a tree mass bin of 500 kg is the same as finding one in a mass bin of 1000 kg.Figure 3 shows 3 areas relevant to considering area mismatch. The field measurements were taken with the rectangular boundaries shown, and the GLAS measurements were taken within the ellipse. “F” signifies the part of the field measurement area not in common with GLAS, and, similarly, “G” refers to the part of the GLAS measurement area not in common with the field. “I” refers to the area in common between field and GLAS, and for that area, the field-GLAS mismatch is zero. It is the difference in biomasses of areas F∪I and G∪I in Figure 3 that is of interest in assessing the area “mismatch”, where F∪I is the zone measured in the field and G∪I is the zone observed by GLAS. Probabilities as in Equation (8) for the same mass bins as in the field are constructed. That is, it is assumed that the spectrum of tree masses is the same for all areas of Figure 3. In order to construct a probability for one of the zones, np in Equation (8) must be replaced by nz, the number of total trees in the zone. This total number is assumed to be in proportion to area. We therefore took the probability of x trees in bin B of zone z to be






P
B


(

x
|

n
z

,
p

)

=

(






n
z






x




)


p
x




(

1
−
p

)




n
z

−
x







(9)


Monte Carlo values of xi were generated for the ith bin of zone z with the probability distribution of Equation (9). Total zone z biomasses (Bz) were generated by summing over all N bins (the number of trees measured in the field) for each throw:






B
z

=


∑


i
=
0

N


x
i


B
i






(10)

The difference 



(


B

G
∪
I


/


Area


G
∪
I



)

−

(


B

F
∪
I


/


Area


F
∪
I



)



 was calculated for each Monte Carlo throw. This procedure was repeated automatically 104 times and the standard deviation of the biomass differences was taken as the co-location error.In addition to the error sources discussed above, we included in our error budget the uncertainty associated with the corrections based on Equations (1) and (2), described in Section 2.3. The error of estimating biomass for the 5–10 cm diameter class, σ5–10, was assumed to be the same as for the 10–15 cm class, where all trees were actually measured and the error could be determined. This assumption was tested and verified on plots where the minimum diameter was 5 cm. The uncertainty associated with the application of the growth model, σG, was estimated by propagating the uncertainties in the parameters of Equation (2) to the determination of the biomass change, in a framework similar to Equation (6).Errors σM, σA, and σS were calculated at the tree level and added in quadrature to obtain plot-level estimates on a per-hectare basis. These errors were in turn combined in quadrature with σC, σ5–10, and σG, calculated directly at the plot level, to obtain an estimate of the overall uncertainty under the assumption of additivity and statistical independence.", 2. Materials and Methods, 2.4.2. Biomass,2
621,"Uncertainties resulting from differences in repeated measurements of D, HC, HT, CD, and CR are summarized in Table 2. D was the most precisely measured quantity, with a RMSD of less than 2%. Repeated measurements of height were typically within 1 m of each other (RMSD = 15%–18%), with approximately half of the HC, and a quarter of the HT observations showing identical repeated measurements. CD and CR measurements showed considerably less agreement (RMSD of 31 and 26%, respectively). However, with the exception of D, there was no evidence of a systematic difference between first and second measurements (Table 2 and Figure 4). For D, the data suggested that the second measurement produced values that were lower to a statistically significant degree when compared to the first measurement, although the estimated median difference of less than 0.1 cm has no practical significance.Measurement variation increased significantly with the magnitude of the measurement across all attributes (Figure 4). The estimated rates of increase in the standard deviation of the measurement differences were 4, 10, 7, 18, and 26% for D, HC, HT, CD, and CR, respectively. When differences were expressed as a percentage of the measurement, HC and CR showed no significant trend. The relative differences in D also increased with D (at a rate of 0.04% cm−1), although the evidence was only suggestive, and the differences in HT and CD actually decreased with the magnitude of the measurements, at rates of 0.4% m−1 and 1.9% m−1, respectively. There was no evidence that absolute differences between repeated measurements (both the mean and the rate of change) varied with forest type, after accounting for differences in the magnitude of the measurements.In terms of wood density, about 90% of the inventoried trees showed a coefficient of variation (CV) of less than 20%. The CV was 15% on average (median of 14%), but ranged from 0 to as high as 64%, depending on the method used to assign the wood density value (e.g., species-vs. genus-level database estimates).", 3. Results, 3.1. Tree Measurement Errors,3
622,"Plot-level aboveground biomass ranged from 1.9 to 130.1 Mg·ha−1 in secondary forests, and from 162.6 to 423.6 Mg·ha−1 in primary forests, with no apparent difference between PF and PFL plots. The overall mean was 174.8 ± 134 (SD) Mg·ha−1, and the median was 172.8 Mg·ha−1. These results are summarized by forest type in Table 3, along with a number of other stand characteristics.Figure 5 shows the average stem density (bars) and tree height (circles) per diameter class for all secondary (dark gray) and primary (light gray) forest plots. The solid lines show the fit of Equation (1) to the average diameter distributions, and the dashed lines show the fit of a similar exponential decay model to the tree height data. The diameter distributions followed an inverted J-shaped curve typical of tropical forests, with the ratio of the number of trees in successive diameter classes roughly constant (~1.9 for SF and 1.7 for PF/PFL). Secondary forests showed considerably fewer (and generally shorter) trees than primary forests at any given diameter class, except for the smallest classes (<20 cm). Primary forests showed fairly balanced diameter distributions (both PF and PFL stands), while secondary forests contained virtually no trees above 60 cm diameter.The estimated frequency of trees 5–10 cm diameter with Equation (1) averaged 475 ha−1 for mid-successional forests and 234 ha−1 for primary forests, representing 0.8 to 20% of the total plot biomass. As shown in Figure 6, these results are consistent with those of stands where trees 5–10 cm diameter were actually measured in the field. For young secondary forests, Figure 6 suggests that the contribution of trees in this class is a linear function of the stand biomass, decreasing rapidly from about 70 to 15% as biomass increases from near 0 to 50 Mg·ha−1. For stands with biomass greater than 50 Mg·ha−1, the contribution of trees 5–10 cm diameter declines exponentially from an initial value of 12%, leveling off at about 1.4% after ~280 Mg·ha−1.The estimated biomass change for the three-year period between field and GLAS measurements ranged from 7% in the oldest SF stand (~27 years) to 97% in the youngest stand (~4 years). As suggested by Figure 2, biomass accumulation rates varied nonlinearly with stand age (from a low of 0.6 to a maximum of 6.6 Mg·ha−1·yr−1), with the highest rates observed for stands 10 to 14 years old.", 3. Results, 3.2. Field Biomass,3
623,"The contribution of the different error sources to the overall uncertainty in the field biomass is summarized in Table 4 and detailed below. Figure 7 explores the calculated sensitivity of our binomial approach in Equation (8), showing the dependence of the co-location error on the spatial overlap between field and GLAS samples. The gray and black lines represent the average co-location error for secondary and primary forests, respectively, when the overlap is artificially changed from 0% to 100%. When the overlap is zero, the binomial model yields an average co-location error of 29% of the estimated biomass for SF plots and an error of 42% for PF plots. These errors decrease slowly (and almost linearly) as the overlap increases from 0 to about 60% overlap, and then converge rapidly to zero as the overlap approaches 100%. On average, overlaps ≥ 75% are needed in primary forests to attain co-location errors not exceeding 20%. In secondary forests, this same level of co-location error can be achieved with overlaps ≥ 50%. The estimated overlap between GLAS and our field plots ranged between 50 and 91%, except for one secondary stand where the overlap was zero—the plot missed the GLAS footprint by about 26 m. The resulting co-location errors (σC) were typically 13%–26% and dominated the overall uncertainty in both mid-successional and primary stands (Table 4).Uncertainties in diameter (~2%), height (~15%), and wood density (~14%) resulted in a median error of 25% in the mass of individual trees. Nonetheless, this error dropped to only about 6% when scaled to the plot level (σM, Table 4). In secondary forests, the alternative allometric equations of Brown [14] and Chambers [42] (MA1 and MA2, Table 1) overestimated the Chave-based plot biomass by an average of 29 and 54%, respectively. In primary forests, the Brown equation showed no systematic bias, whereas the Chambers equation resulted in slight underestimates in high-biomass stands (~11%). The errors associated with the choice of the allometry (σS) were typically 5%–11%, similar to the errors related to the model residuals (σA). The individual contributions of measurement and allometric errors to the final uncertainty were generally below 15%, and slightly lower in secondary forests than in primary forests (Table 4).To gain a better understanding of the uncertainty associated with allometric methods, we also compared our reference biomass estimates obtained with the Chave equation MT2 (Table 1) using field-measured D and HT, and taxon-specific ρ derived from the literature, with four alternative estimates produced with the Chave equations, but making small changes in the input data to illustrate the variability that can be expected when common, suboptimal field data sets are used: Use of the Chave equation MT2 with a regional average wood density of 0.667 g·cm−3 [39], as opposed to taxon-specific densities, resulted in overestimation of biomass values by about 23% in secondary forests and no bias in primary forests. When MT2 was applied using taxon-specific wood densities, but heights derived from a regional height-diameter relationship [52], the plot-level biomass was 11% lower on average due to a negative bias in height of 2.6 m. Use of the Chave equation without the height term (MA3, Table 1) resulted in plot-level biomass ~20% higher, regardless of the successional status. When this equation was applied using the regional average wood density of 0.667 g·cm−3, the discrepancies in secondary forests were higher still (48%). We should note that the biomass of cecropias and palms, estimated by the specific equations MT1, MP1, and MP2 (Table 1), was held constant across all comparisons. Although this introduced some dependence across biomass estimates, these species typically accounted for only about 3% of the total plot biomass.In primary forests, where the minimum measured diameter was 10 cm, the error of estimating biomass for the 5–10 cm diameter class (σ5–10) contributed less than 1% to the total variance and could safely be neglected. However, this error was about seven times larger in mid-successional forests, being comparable to other sources in magnitude (Table 4). In secondary forests, the projection of biomass values backward in time three years induced errors (σG) of the order of 7%–19%. This term dominated the uncertainties in early successional stands, accounting for about half of the total variance on average, and represented the second largest component in mid-successional stands (Table 4). The dependence of σG on the temporal difference between field and remote sensing acquisitions is illustrated in Figure 8 for SF plots of different ages. As expected, σG increases significantly with the time gap in data acquisition. The increase is faster for younger forests, which display higher values of σG than older forests at any given temporal interval (the greater the relative change in biomass, the greater the uncertainty in the model estimate).The overall uncertainty in the field biomass was typically 25% (for both secondary and primary forests), but ranged from 16% to 53%. Measurement (σM), allometric (both σA and σS), and co-location (σC) errors increased significantly with plot biomass, at rates of 8, 10, 11, and 22%, respectively (Figure 9). The error of estimating biomass for the 5–10 cm diameter class (not shown in the figure) increased significantly with biomass in secondary forests (at a rate of 10%), but showed no trend in old-growth forests. The growth model error showed no linear trend with biomass, but was a straight-line function of the biomass accumulation rate, increasing by about 0.7 Mg·ha−1 for each unit increase in the growth rate. As a result of the above trends, the overall uncertainty also increased with biomass, at a combined rate of 28%. However, there was no evidence that the mean errors or rates of error increase differed among forest types, after accounting for differences in biomass.", 3. Results, 3.3. Biomass Error,3
624,"Tree diameter measurements are not difficult to obtain, involve limited subjectivity, and can usually be made with a high degree of precision (e.g., [53,54,55,56]). The small variation in diameter measurements observed in this study (RMSD = 0.8 cm or 1.8%) is consistent with previous findings and likely resulted from divergences in tape placement, with repeated measurements taken at slightly different tree heights or angles. Other potential sources of variation include mistakes reading the tape, recording error, and data entry error, all of which are difficult to detect if the resulting values are not particularly unusual.Despite the obvious subjectivity associated with ocular height estimates (both HC and HT), they were surprisingly precise, with a combined RMSD of only 2 m [19]. For comparison, Kitahara et al. [56] reported nearly the same level of precision (1.8 m) for repeated height measurements made with a modern ultrasonic hypsometer (Haglöf Vertex) in less dense temperate forests with relatively lower structural complexity. In a recent study also conducted at Tapajós, Hunter et al. [57] obtained a precision of 4.7 m for heights obtained with a clinometer and a measuring tape, keeping angles below 50° and correcting for slope to minimize measurement error. Factors contributing to variation in our height measurements include difficulty in determining the location of the treetop due to occlusion by surrounding vegetation, and disparity in the perception of where the base of the crown is located.Variation was considerably higher for crown measurements. Crown depth, calculated as the difference between HT and HC, was very similar in absolute precision to the ocular height estimates. However, while a RMSD of 2 m typically represents a relatively small percentage of a tree height, it corresponds to a large fraction of a typical crown depth measurement (6 m on average for the trees sampled in this study). The precision of crown radius measurements was better than 1 m, but represented ~26% in relative terms. These measurements required some level of personal judgment and were affected by visibility restrictions in ways similar to the height estimates. In addition, crown spread was typically 25%–45% of the tree height and the resulting high levels of crown overlap among trees made it often challenging to identify the correct branches for the measurement. We note that the horizontal position of the crown edge is somewhat difficult to determine from directly below and suggest that the precision of crown radius measurements would likely be improved by sighting the edges along a clinometer held at a 90-degree angle. In terms of height measurements (and the derived crown depth), uncertainties may be reduced with the aid of a telescoping height measuring pole. Although not necessarily practical, the pole could be used to obtain direct height measurements for small trees (up to 10–15 m), and serve as a height reference for the ocular estimation of taller trees.Not surprisingly, measurements of the attributes in Table 2 were more precise for small trees than for large trees (most sources of measurement variation become more pronounced as tree size increases). Although measurement variation generally increased with the dimension of the measurement, the magnitude of this effect differed substantially among attributes, with stem diameter showing the lowest rate of increase, followed by height, and crown dimensions. For tree height, Hunter et al. [57] observed an eightfold increase in measurement variation (from 1.1 to 8.2 m) after dividing the data into four diameter classes with an equal number of trees. This contrasts sharply with the less than twofold increase observed in this study (from 1.8 to 2.9 m), indicating that the precision of the ocular height estimates was not only high, but also displayed a relatively low, yet statistically significant, dependence on tree height.Because precision is not constant across the range of diameters and heights, it is important to account for this variation when propagating measurement errors to determine the uncertainty in biomass. The standard deviation of the differences between repeated measurements, calculated by quartiles of the ranked set of measurements, is provided in Table A1 for reference.While measurement uncertainty was generally not negligible, with precision clearly declining with increasing tree size, we found no systematic errors. In addition, we found no differences in precision (or rates of decline in precision with increasing tree size) between primary and secondary forests, after accounting for tree size. This suggests that measurement precision was fairly robust to changes in measurement conditions (induced by changes in stem density, species composition, leaf area index, etc.), with divergences in overall precision being largely attributable to differences in tree size distribution (see Figure 5). We stress that the results presented here refer strictly to reproducibility of measurements, and that no reference is made to the agreement of those measurements with the true, unknown values (i.e., accuracy).", 4. Discussion, 4.1. Precision of Individual Tree Measurements,4
625,"Our results show that co-location error, defined in this study as the uncertainty in the biomass estimate resulting from the spatial disagreement between field and Lidar samples (i.e., field plots including trees not captured by GLAS and/or excluding trees that were actually captured), accounts for a substantial portion of the total error. In agreement with our findings for stands at La Selva Biological Station, Costa Rica [20], co-location error dominated the overall uncertainty in the field biomass, except in early-successional forests where the application of the growth model resulted in larger errors on average (Table 4). The results illustrated in Figure 7 are consistent with the expectation of lower co-location error with increasing Lidar/field overlap, as well as lower errors for secondary forests compared to primary forests, given their lower species diversity and more homogeneous canopy structure (cf. Figure 5). We should note that the binomial approach in (8) assumes that the tree size-frequency distribution of each individual zone depicted in Figure 3 (i.e., F, I, and G) is similar to that observed for the full 50 m × 50 m field plot (F ∪ I). This explains the relatively low maximum values of co-location error in Figure 7 when the overlap is zero. We should also note that although the binomial approach is presented here using GLAS as an example, it depends exclusively on the field data and on the amount of overlap between the field and the remote sensing samples, and thus could be applied regardless of the remote sensing data type.In a previous study in a tropical rainforest in Hawaii, Asner et al. [49] found that misalignment of Lidar and field data introduced errors in biomass estimates of only 0–10 Mg·ha−1 (0%–3.5% of the median biomass). While differences in floristic composition, vegetation structure, and plot size make direct comparisons between studies difficult, differences in methodology most likely account for much of the observed discrepancy. In their study, Asner et al. estimated the co-location error by varying the location and size of the Lidar “plots” by small amounts (10%); regressing the Lidar metrics obtained for each new location/size against the (fixed) field-measured biomass; and determining the variation in the biomass predictions resulting from variation in the Lidar metrics. This is conceptually different from the approach used in this study, where the field-based estimate of biomass was varied instead. This distinction is important because inclusion/exclusion of trees in the calibration plots (particularly big trees) can cause large changes in the field estimate of biomass that may not be proportionally reflected in the vertical structure captured by the Lidar (and in turn, in the Lidar estimate of biomass). As shown by [58], even relatively small changes in field-based estimates of biomass in tropical forests (as a result of accounting for portions of trees that fall outside the plot boundary) can have a significant impact on the relationship with Lidar metrics, accounting for as much as 55% of the error associated with Lidar-biomass models.In comparison to the co-location error, measurement and allometric errors were relatively small. Uncertainties in height and wood density values were large relative to the uncertainty in diameter and contributed the bulk of the uncertainty in biomass due to measurement variation. This measurement error was fairly large at the tree level, but decreased significantly at the plot scale because measurement variation was unbiased (Table 2) and tree-level errors were added in quadrature to produce realistic plot-level estimates.The overestimation of the reference, Chave-based biomass in secondary forests by the equations of Brown [14] and Chambers [42] (MA1 and MA2, Table 1) was largely explained by the omission of wood density information in the models. These alternative mixed-species equations were derived from primary forest trees, which tend to have much denser wood than the secondary forest trees to which they were applied (cf. Table 3 and [41]). When we corrected MA1 and MA2 by including a dependence on wood density as in [24], the overestimation of the reference biomass in secondary forests decreased by a factor of 3 and 2, respectively. From our tests with the Chave equations with and without height, we would expect these differences to decrease by an additional ~20% if MA1 and MA2 also included a dependence on tree height, and if tree allometry is somewhat conserved across moist tropical sites as indicated by [16]. Thus, most of the variation captured by σS was apparently due to the use of allometric equations, which differed with respect to the inclusion of height and wood density information.As with the measurement error, allometric errors were assumed to be uncorrelated and decreased significantly (by a factor of 3–4) when scaled to the plot level. While this assumption seems reasonable for σA (cf. [24,25,26,32]) given the random nature of the regression errors (assumed to be normally distributed with mean zero), one could argue that the error due to the choice of the allometric equation (σS) is systematic and unlikely to be independent (trees with similar diameter, for example, can have nearly the same σS). One way of testing if the sum in quadrature is appropriate is to calculate σS directly at the plot level by taking the standard deviation of the plot-level biomass estimates obtained with the alternative equations. This resulted in a median error of 13% for our 30 plots, which is only slightly higher than that obtained by adding tree-level errors in quadrature (Table 4). The error for primary forests alone was virtually the same (9%), confirming the tendency of individual tree errors to offset each other when combined to generate plot-level estimates. We note that [33] observed the same level of error (10%) when estimating the biomass density (trees ≥ 15 cm diameter) of an area of 392 ha at Tapajós using four alternative equations (one of which is MA1). A similar error (13%) was also reported by [24] for estimates obtained with eight different equations in a 50 ha plot in Panama, after correcting for variation in wood density.The estimation of biomass for the modeled diameter class of 5–10 cm made a negligible contribution to the final uncertainty in primary forests, but represented a significant source of error in mid-successional forests. This is not surprising when one considers the rapid decrease in the contribution of trees 5–10 cm diameter to biomass with increasing biomass, as observed in Figure 6. Because in young secondary forests (<50 Mg·ha−1) trees 5–10 cm diameter can account for as much as 70% of the aboveground biomass, modeling the stem frequency of this class with Equation (1) and estimating biomass for the modeled class has the potential to introduce large errors. For these young forests, we recommend that trees 5–10 cm diameter be directly measured (or tallied) in the field.The biomass accumulation rates of secondary forests estimated with the site-specific growth model of Neeff & Santos [44] agreed well with rates from a long-term study of SF regrowth in the central Amazon [59], as well as with a more general estimate for tropical moist forests based on data from a number of sites [60]. However, the error associated with this model dominated the overall uncertainty in the biomass of the youngest stands and represented the second largest contribution in older secondary forests. In (2), stand biomass is defined as the product of basal area and top height (the two state variables that are explicitly modeled), and most of its uncertainty results from the relatively poor fit of the basal area model (Figure 2). Although site-specific, the model is based on growth rates inferred from a chronosequence, which may differ substantially from actual growth rates due to stand differences in land-use history (e.g., old agricultural fields vs. abandoned pastures) [59]. This probably explains most of the variability observed by Neeff & Santos [44] in basal area for a given age, and the relatively large uncertainty associated with the model parameters.The estimated biomass change of over 30% per year for the youngest secondary forests emphasizes the importance of accounting for temporal differences between field and remote sensing data. Here, we assumed no biomass change for primary forests, but these changes have been determined to be small at Tapajós (~1% per year) relative to the average biomass [35,61,62]. We would expect the resulting errors to be negligible, unless some disturbance occurred between observation epochs (e.g., logging, fire, windstorms, etc.). This is generally detectable in the field and/or in remote sensing data [63], and neither data source revealed the occurrence of a significant disturbance event during the period of this study.The overall uncertainty in the plot-level biomass observed in this study (typically 20%–34%) was similar in relative size to that observed by Treuhaft et al. [20] for a tropical wet forest in Costa Rica (26%–31%) where measurement, allometric, and co-location errors were also considered. It is also in line with the total plot-level error observed by Chave et al. [24] (~23%–27%, as calculated from their Table 3) and Chen et al. [26] (20%), although different methods were used for the assessment of uncertainty. Recent estimates of biomass from Lidar [19] and InSAR [21] observations for the plots used in this study showed RMS errors about the field-estimated biomass of 20%–35%. The uncertainty in the field biomass can therefore represent a dominant term in the overall error budget for biomass maps derived from remote sensing, and should be taken into account in calibration and validation efforts.Because co-location and temporal errors have the potential to account for a large fraction of the total variance (~70% on average for the plots in this study, but as much as 94% in individual plots), they emerge as obvious targets for reducing uncertainty in studies relating tropical forest biomass to remotely sensed data. Temporal errors can be minimized by conducting field campaigns as close as possible in time to the remote sensing data acquisition. In cases where this is not possible (e.g., when using historical data), our results underscore the importance of selecting an appropriate growth model to account for biomass change in secondary forests, and of quantifying the uncertainty associated with this model. Reducing co-location errors requires not only the acquisition of high-precision differential GPS measurements for plot location (often complemented with topographic surveying in closed-canopy forests), but also that field and remote sensing samples agree as much as possible in size, shape, and orientation. A simple statistical approach such as the one presented in Section 2.4.2 can be used to account for errors due to partial overlap.Finally, we note that although measurement and allometric errors were relatively unimportant when considered alone, combined they accounted for roughly 30% of the total variance on average (as much as 64% in individual plots) and should not be ignored. Steps can be taken to reduce uncertainties in height and wood density measurements, as well as in allometric equations. However, reducing co-location and temporal errors may be a more cost-effective solution for reducing the overall uncertainty when resources are limited. For instance, the total error in Table 4 would drop by nearly half if co-location and temporal errors were zero, but only by about 20% if we disregard measurement and allometric errors instead.", 4. Discussion, 4.2. Biomass Estimation and Its Error,4
626,"The objective of this study was to use field plot data collected in the central Amazon to gain a better understanding of the uncertainty associated with plot-level biomass estimates obtained specifically for calibration of remote sensing measurements in tropical forests (see [19] for details on the calibration performed using the plots of this study). We found that the overall uncertainty in the field biomass was typically 25% for both secondary and primary forests, but ranged from 16% to 53%. Co-location and temporal errors accounted for a large fraction of the total variance (>65%) when compared to sources of error that are commonly assessed in conventional biomass estimates, emerging as important targets for reducing uncertainty in studies relating tropical forest biomass to remotely sensed data. Although measurement and allometric errors were relatively unimportant when considered alone, combined they accounted for roughly 30% of the total variance on average and should not be ignored. Our results suggest that a thorough understanding of the sources of error associated with plot-level biomass estimates in tropical forests is critical to determine confidence in remote sensing estimates of carbon stocks and fluxes, and to develop strategies for reducing the overall uncertainty of remote sensing approaches.", 5. Conclusions,None,5
627,"Since China’s reform, rapid urban development has brought great benefits to its economy and society, and now China is the most industrialized country and the second largest economy in the world. However, despite these achievements, China’s rapid development has also brought many social and environmental problems. With continuous development and urbanization, China’s total urban area has increased along with pollution emissions from industrial activities, motor vehicles, and other human activities [1]. Atmospheric pollutants have led to various social and environmental issues, including those associated with acid rain, ozone layer depletion, human health, as well as economic, and aesthetic impacts associated with ground level air pollution [2,3,4]. Research has shown that air pollution has a significant impact on public health [5,6]. In recent years, issues with China’s air pollution have raised considerable concern among government officials, experts, scholars, and the general public, driving the need for further research on the subject. Pope (2000) found that long-term repeated exposure to fine particulate pollution, resulted in significant reduction in average life expectancy in highly polluted environments [7]. Chai et al. (2018) found that high PM2.5 concentrations were associated with an increase in the daily outpatient visits for respiratory diseases [8]. Additionally, Landrigan et al. (2019) attributed the deaths of 940,000 children worldwide to air pollution in 2016 [9]. It can be seen that the air pollution problem brought about by urbanization is an urgent problem to be solved.Many studies have shown that there is a significant relationship between LUCC and air quality. Different cities and land-use types have different effects on air quality [10,11]. Land-use can directly and indirectly affect both natural surface coverage and urban air quality. Implementation of forests and water area in urban areas can significantly improve local urban air quality [12,13]. On the contrary, land-use types, such as built-up land, can be associated with higher levels emissions of air pollution [3,14]. The idea that built-up land types have a significant impact on air quality has been proposed in the past [15,16], and has since been supported by several studies [17,18]. Zahari et al. (2016) explored the relationship between built-up land and air quality in Malaysia, and the results showed that air quality can be manipulated or reduced through proper land use planning [19]. Zou et al. (2016) conducted research at Changsha, Zhuzhou, and Xiangtan and concluded that optimizing urban LUCC can effectively improve air quality [20]. Additional studies have shown that urbanization changes the land use structure, and the increase of built-up land will lead to the strengthening of regional activities, such as living discharges caused by population intensive, transportation, etc., and these activities will directly or indirectly deteriorating air quality [21,22]; Burley et al. (2008) and Loures et al. (2016) also indicated that people pay more attention in post-industrial landscape redevelopment and public participation in urban planning process [23,24]. Land use strategies should be given heavier emphasis when formulating policies to reduce air pollution [25].The studies mentioned above show that the LUCC has a strong correlation with the change in air quality. However, most of the previous studies only focused on the impacts of land use on air pollutants in urban built-up areas, and their study areas had complex and diverse social and economic structure [26,27,28]. This makes it difficult to differentiate impact factors. Wuyishan City is the only city named after by scenic spot (Wuyi Mountain) in China, which is famous all over the world. Its economy relies heavily on tourism, agriculture, as well as under-forest economic crops. Although socioeconomic factors are also considered to be a primary source of air pollution [29,30], the research geostatistical yearbook found that the socioeconomic factors for the research area were relatively stable during the study period and, therefore, these are not listed as impact factors in this study. In summary, this paper focuses on select LUCC that are closely related to changes in air quality [31,32]. In Wuyishan, secondary industry had remained stable, so the social, economic, industrial, and transportation factors had lower impacts on air pollution than other cities, and the research sites were representative. It is beneficial to study the correlation between LUCC and air pollutants. Therefore, we choose Wuyishan City as the study area to analyze the correlation between LUCC and air pollutants, in hopes to guide the planning and development of the city. This study aims to (i) study the transformation characteristics of the five types of land use (built-up land, forests, cultivated land, water area, and bare land) within the Wuyishan City from 2014 to 2017; (ii) analyze the annual, seasonal, and weekly variation characteristics of air pollutants concentration; and (iii) investigate the relationship between LUCC and air pollutants.", 1. Introduction,None,1.
628,"Wuyishan City is located in the northwestern part of Fujian Province, at the junction with Jiangxi Province, and is characterized as mid-subtropical climate (Figure 1). The geographical coordinates are 117°37′22″ E~118°19′44″ E and 27°27′31″ N~28°04′49″ N. The city has a total area of 2813 km2, and a total population of 234,400 (2010). The economy of Wuyishan City has grown steadily, its annual production was valued at $2.211 billion USD in 2016. Among the production value, the primary industry declined, the secondary industry continued to accelerate, and the tertiary industry developed steadily. They accounted for 16.30%, 40.52%, and 43.17%, respectively. The annual gross domestic product (GDP) was $24.180 million USD. In December 1999, it was approved by the United Nations Educational, Scientific, and Cultural Organization (UNESCO) to be included in the World Heritage List, making it one of four Chinese sites to be included in this title and one of the 23 “double heritage” of world culture and nature locations.", 2. Materials and Methods, 2.1. Overview of Wuyishan City,2
629," 2.2.1. Remote Sensing Image Source and ProcessingRemote sensing images used for this study were selected from the National Geographic Data Cloud (http://www.gscloud.cn) (February 2014; February 2015; February 2016; and 31 March 2017). In order to minimize the extraneous variability, images were selected from the same (or as close as possible) season, period, and time. Subtle differences in image reflection characteristics caused by eliminating solar height and phenology were unavoidable [33]. Once selected, images were interpreted and analyzed using ENVI 5.3 software (Exelis Visual Information Solutions Inc, United States).According to the Classification of Land Use Status (GB/T21010-2007), the utilization and characteristics of land resources and the characteristics of remote sensing images in Wuyishan City were combined. The land area was divided into 5 land uses types: forests, cultivated land, water area, built-up land and bare land. To perform image interpretation and analysis, a supervised classification methodology was adopted through the usage of ENVI5.3 software, for image interpretation of the remote sensing images of Wuyishan City from 2014 to 2017. The supervised classification of Wuyishan City from 2014 to 2017 was performed through the following four steps:the Radiometric Calibration tool of ENVI 5.3 was used to calibrate the image;the FLAASH Atmospheric Correction was used to perform image atmospheric correction;the FLAASH tool was used for parameter correction; and“Likelihood Classification” and “Maximum Likelihood” tools were used to supervise the classification methodology.After interpretation, remote sensing image processing was carried out through the following 4 steps:Plot verification was performed using Google Earth;Field survey were conducted on plots with poor resolution;ENVI CLASSICLE software was used for secondary visual interpretation; andthe “Confusion Matrix Using Ground Truth ROIs” tool was used for accuracy verification using a supervised inspection of approximately 2% of the total land area on the remote sensing image [34,35]. 2.2.2. Air Pollutants Concentration ChangeAir pollutant data from 2014 to 2017 was obtained from the Wuyishan monitoring station of the National Atmospheric Environment of Fujian Province (http://hbt.fujian.gov.cn/). Air pollution parameters obtained included concentrations of SO2, NO2, CO, PM10, O3, PM2.5, black carbon, as well as atmospheric visibility. The annual, seasonal and weekly mean concentration of the air pollutants were calculated using Excel 2013.The Air Quality Index (AQI) was additionally calculated using Equation (1), as follows:



AQI
=



I

h
i
g
h


−

I

l
o
w





C

h
i
g
h


−

C

l
o
w





(

C
−

C

l
o
w



)

+

I

l
o
w






(1)


where AQI refers to the air quality index; C refers to the instantaneous pollutant concentration; Clow refers to the concentration limit ≤ C; Chigh refers to the concentration limit ≥ C; Ilow refers to the index limit corresponding to Clow; and Ihigh refers to the index limit corresponding to Chigh.Following the methodology set out by the “Environmental Air Quality Standard–GB 3095-2012”, air quality was divided into five levels based on the AQI: 0–50, 51–100, 101–200, 201–300, and 300–500, represented as levels I, II, III, IV, and V, respectively, on the national air quality standards GB/3095–2012. Following the methodology of previous studies, the correlation between air pollutants concentration data and LUCC was analyzed by SPSS 19.0 software to understand the relationship between pollutants and LUCC [36,37]. 2.2.3. Correlation between LUCC and Air PollutantsCorrelations between LUCC and concentrations of SO2, NO2, CO, PM10, O3, PM2.5, and black carbon, as well as atmospheric visibility were quantified based on the Pearson correlation coefficient (Equation (2)):




ρ

x
,
y


=



σ

x
y





σ
x


σ
y







(2)


where ρx,y represent the covariance between the two variables, σx represent the standard deviation of land use type, and σy represent the standard deviation of pollutants. The Pearson correlation coefficient was used to measure the degree of correlation between the two variables. A correlation value of 1 indicated that the variables were significant positively correlated, a value of −1 indicated a significant negative correlation between the variables, and a value of 0 indicated no significant relationship between the variables [38].", 2. Materials and Methods, 2.2. Data Sources and Research Methods,2
630,"Remote sensing images used for this study were selected from the National Geographic Data Cloud (http://www.gscloud.cn) (February 2014; February 2015; February 2016; and 31 March 2017). In order to minimize the extraneous variability, images were selected from the same (or as close as possible) season, period, and time. Subtle differences in image reflection characteristics caused by eliminating solar height and phenology were unavoidable [33]. Once selected, images were interpreted and analyzed using ENVI 5.3 software (Exelis Visual Information Solutions Inc, United States).According to the Classification of Land Use Status (GB/T21010-2007), the utilization and characteristics of land resources and the characteristics of remote sensing images in Wuyishan City were combined. The land area was divided into 5 land uses types: forests, cultivated land, water area, built-up land and bare land. To perform image interpretation and analysis, a supervised classification methodology was adopted through the usage of ENVI5.3 software, for image interpretation of the remote sensing images of Wuyishan City from 2014 to 2017. The supervised classification of Wuyishan City from 2014 to 2017 was performed through the following four steps:the Radiometric Calibration tool of ENVI 5.3 was used to calibrate the image;the FLAASH Atmospheric Correction was used to perform image atmospheric correction;the FLAASH tool was used for parameter correction; and“Likelihood Classification” and “Maximum Likelihood” tools were used to supervise the classification methodology.After interpretation, remote sensing image processing was carried out through the following 4 steps:Plot verification was performed using Google Earth;Field survey were conducted on plots with poor resolution;ENVI CLASSICLE software was used for secondary visual interpretation; andthe “Confusion Matrix Using Ground Truth ROIs” tool was used for accuracy verification using a supervised inspection of approximately 2% of the total land area on the remote sensing image [34,35].", 2. Materials and Methods, 2.2.1. Remote Sensing Image Source and Processing,2
631,"Air pollutant data from 2014 to 2017 was obtained from the Wuyishan monitoring station of the National Atmospheric Environment of Fujian Province (http://hbt.fujian.gov.cn/). Air pollution parameters obtained included concentrations of SO2, NO2, CO, PM10, O3, PM2.5, black carbon, as well as atmospheric visibility. The annual, seasonal and weekly mean concentration of the air pollutants were calculated using Excel 2013.The Air Quality Index (AQI) was additionally calculated using Equation (1), as follows:



AQI
=



I

h
i
g
h


−

I

l
o
w





C

h
i
g
h


−

C

l
o
w





(

C
−

C

l
o
w



)

+

I

l
o
w






(1)


where AQI refers to the air quality index; C refers to the instantaneous pollutant concentration; Clow refers to the concentration limit ≤ C; Chigh refers to the concentration limit ≥ C; Ilow refers to the index limit corresponding to Clow; and Ihigh refers to the index limit corresponding to Chigh.Following the methodology set out by the “Environmental Air Quality Standard–GB 3095-2012”, air quality was divided into five levels based on the AQI: 0–50, 51–100, 101–200, 201–300, and 300–500, represented as levels I, II, III, IV, and V, respectively, on the national air quality standards GB/3095–2012. Following the methodology of previous studies, the correlation between air pollutants concentration data and LUCC was analyzed by SPSS 19.0 software to understand the relationship between pollutants and LUCC [36,37].", 2. Materials and Methods, 2.2.2. Air Pollutants Concentration Change,2
632,"Correlations between LUCC and concentrations of SO2, NO2, CO, PM10, O3, PM2.5, and black carbon, as well as atmospheric visibility were quantified based on the Pearson correlation coefficient (Equation (2)):




ρ

x
,
y


=



σ

x
y





σ
x


σ
y







(2)


where ρx,y represent the covariance between the two variables, σx represent the standard deviation of land use type, and σy represent the standard deviation of pollutants. The Pearson correlation coefficient was used to measure the degree of correlation between the two variables. A correlation value of 1 indicated that the variables were significant positively correlated, a value of −1 indicated a significant negative correlation between the variables, and a value of 0 indicated no significant relationship between the variables [38].", 2. Materials and Methods, 2.2.3. Correlation between LUCC and Air Pollutants,2
633,"The classification results for the 2014 and 2017 periods are shown in Figure 2. The LUCC transfer matrix is presented in Table 1. From 2014–2017, forestry and water area land area increased, and cultivated land, bare land, and built-up land area decreased. Cultivated land area decreased considerably over this time period from 242.512 km2 to 226.833 km2 at a rate of 6.47% from 2014 to 2017. The characteristics of two-way changes in transfer are outstanding. The forest area change rate was the lowest at 1.79% from 2014 to 2017; however, due to its large base, this accounted for a total area change of 44.438 km2. Over the study period, the water area was increased by 2.861 km2 in total with a change rate of 15.89%. Built-up land area changed with a total decrease in area of 5.822 km2, and a rate of change of 16.03%. The newly built-up land area mainly transferred from cultivated land and bare land and was mostly concentrated on existing towns. Bare land had the highest rate of change at 72.61% with a total area reduction 25.77 km2. The decrease in Bare land area could mainly be attributed to the conversion into agricultural and forestry.", 3. Results, 3.1. LUCC in Wuyishan City,3
634,"In 2014, a total of 324 days had an AQI of level I, and 50 days had an AQI level of II (Table 2). In 2015, the number of days with an AQI level I was increased to 339 days. In 2016, the number of days with an AQI level I was highest from 2014–2017, reached 356 days. In 2017, the number of days with an AQI level I was 345 days, whereas the number of AQI level II days was only 16 (Table 2). Table 2 also indicates that in 2017, a pollution event took place over a total of four days where the AQI reached level III. The specific data and variation characteristics are shown in Table 2. Overall, the data showed that Wuyishan City has great air quality, and there were no serious pollution problems. The results also showed that the air quality in 2016 and 2017 was better than 2014 and 2015. As shown in Figure 3, the concentration of various pollutants in 2014 and 2015 was higher than that in 2016 and 2017. The concentration of SO2, PM10 and NO2 differs greatly, and the concentration of CO and O3 are similar. In addition, the visibility level in 2014 was lower than 2017, further indicating that the air quality of Wuyishan City had increased from 2014 to 2017 (Figure 3).Figure 3 and Table 3 showed that average concentrations of most air pollutants were higher in 2014. Air pollutants concentration value were similar in 2016 and 2017. The air pollutants concentration showed a gradual decline from 2014 to 2017. Therefore, the visibility was higher in 2017 than 2014. We also found that the air quality in spring and winter was lower than summer and autumn. In 2017, the concentration of air pollutants in summer, autumn and winter were lower than those in 2014, and visibility levels were higher than those in 2014 (Table 3). The results show that concentrations of all air pollutants were higher in 2014 than in 2017. From 2014 to 2017, NO2, CO, O3, PM10, PM2.5, and black carbon decreased in autumn and visibility increased in summer (Table 3). This indicates that, the overall air quality was higher in 2017 than 2014.", 3. Results, 3.2. Concentration of Air Pollutants,3
635,"The Pearson correlations between LUCC and air pollutant concentration from 2014–2017 was displayed in Table 4. The results show that concentrations of SO2, CO, O3, and black carbon were all positively correlated with the cultivated land. Similarly, concentrations of SO2, CO, and black carbon were negatively correlated with forestry. PM10 and PM2.5 were negatively correlated with the water area. There were no correlations between air pollutant concentrations and built-up land or bare land. Atmospheric visibility was found to be positively correlated with forestry area, and negatively correlated with cultivated land. These indicated that visibility similarly improved with the increase in forestry area (Table 4).", 3. Results, 3.3. Relationship between LUCC and Air Pollutants,3
636,"The interpretation and analysis of LUCC in Wuyishan City showed that built-up land was relatively stable between 2014 and 2017. This could be attributed to afforestation and restrictions on urban development. Over this period, significant land conversion into forests occurred, resulting in an increase of forest coverage [39]. This effect is likely in response to current policy which focused on restoring cultivated land to forests in China [40,41,42]. Fan et al. (2019) further confirmed that the forested areas in the Nanping City has increased, while the area of cultivated land has decreased from 2010 to 2015 [43]. In order to meet the need of the tourism and tea industry in Wuyishan City, most of bare land had turn into forests (78.10%) and cultivated land (12.72%). The study of Wuyishan tourism by Chen et al. (2017) are consistent with our findings, residents in Wuyishan appeared supportive of the conservation of natural resources and local culture [44]. Wu et al. (2016) revealed that LUCC and urban expansion were highly correlated with economic development, population growth, technical progress, policy elements, and other similar factors [45]. From the perspective of LUCC, forest and cultivated land were the largest land use type in Wuyishan, which relates to the economic structure of Wuyishan. This finding was consistent with Yang et al. (2011), whereby tourism has continued to develop, and the tea industry has remained stable in Wuyishan [46]. However, in Northeast China, in order to meet the needs of economic development, population growth, and industrialization, many cities have relied on continuous expansion which is leads to the increased built-up of land area [47,48,49]. The increasing demand for built-up areas caused the disappearance of a large amount of cultivated land and forests surrounding the cities [50]. During 2014 and 2017, the change in water area was relatively stable, mainly due to increased investment in water conservation, environmental protection of water ecology, and energy conservation in China [46].", 4. Discussion, 4.1. The LUCC between 2014 and 2017,4
637,"The results indicate that the overall air quality showed great condition in Wuyishan, more than 88.77% of the days in one year reached the level I. This is mainly related to the key development of forestry-related industries in Wuyishan City. This result was consistent with the study by Francisco et al. (2009) on the effects of urban forest on spatial heterogeneity and air pollution in Santiago de Chile, and found that air quality improvement was mainly related to vegetation [51]. Our study found that there were similar changes among air pollutants. Allen’s (1990) research corroborates our results, indicated that there was a potential synergy between air pollutants [52]. The overall air quality and atmospheric visibility were better in 2017 than 2014 mainly due to the increased of forest area. This finding was verified by Irga et al. (2015), which found that air samples taken from sites with less greenspaces frequently had higher concentrations of all fractions of aerosolized particulates than sites with high proximal greenspaces, which had lower particulates [53]. In the spring of 2017, the concentrations of SO2, PM10 and PM2.5 were higher than that in the spring of 2014. The slight pollution phenomenon appeared in Wuyishan City, which may be related to the release of fireworks and firecrackers during the Spring Festival. Studies have shown that the fireworks and firecrackers could release a large amount of SO2 and fine dust, which leads to an increased in the concentrations of SO2, PM10, PM2.5 [51,54]. This pollution phenomenon seems to be consistent with this idea since the increase in pollutants was only observed in spring, and pollutant concentrations were lower in all other seasons in 2017.", 4. Discussion, 4.2. Change Characteristics of Air Pollutants in 2014–2017,4
638,"Our research found that SO2, CO, O3, and black carbon concentration were positively correlated with cultivated land. In contrary, there was a significant negative correlation between SO2, CO, black carbon and the increase of forested areas (Table 4). This indicates that an increase in cultivated land areas would reduce air quality, and the increase in forested areas would improve air quality by affecting the air pollutants. This finding was consistent with Huang et al. (2018), which examined the effects of urban land expansion on air pollution in China, and found that urban land expansion influenced air pollution, with a significant relationship to the concentration of air pollutants [55]. Zhang et al. (2015) found that visibility was significantly affected by the variation of PMs concentrations [56], and many studies have also shown that forests can effectively reduce the concentration of PMs [15,29]. Therefore, the increase in the forest can effectively improve visibility, which was consistent with the results of this research. It also indicated that the atmospheric environment quality of Wuyishan City has been further improved. The variation of air pollutants in Wuyishan City is related to various factors, including city area expansion, industrial activities, population, meteorological factors, policies, urban forest, and so on. As forest coverage increases, it can absorb more pollutants and improve air quality [57]. Rodriguez et al. (2016) investigated the relationship between local air pollution and urban structure with an emphasis on urban fragmentation, and their findings support the hypothesis that urban structure has a significant impact on air pollutant concentration [58]. These existing observations were also supported by our findings [59,60,61]. Due to the conversion of cultivated land into forests in Wuyishan City, average carbon sequestration and oxygen release value has significantly increased, which reduces the concentration of air pollutants [62]. This is consistent with previous research indicating that a decrease in built-up land, and an increase in forests and green area, led to a lower concentration of NO2 and PM2.5 [58,63,64]. Our research results showed that the correlation between bare land and air pollutants is poor. The reason may be due to bare land mainly turned into cultivated land and forestr, and our research found that cultivated land is positively correlated with many air pollutants [55], while forestry land is negatively correlated with many air pollutants [59], which leads to the insignificant correlation between bare land and air pollutants. Built-up land and air pollutants also showed no significant. Our research found that the change in built-up land during the study period was less obvious and remained at a relatively stable condition, which may be the main reason for the inconspicuous results of our correlation test.", 4. Discussion, 4.3. Relationships between LUCC and Air Pollutants in the Reference Period,4
639,"China’s rapid economic development has resulted in many environmental problems. In order to protect and repair these environmental problems, the Chinese government has integrated the construction of ecological civilization into the overall layout of the socialist cause with Chinese characteristics. For example, in 2014 the Ministry of Land and Resources of China issued the “Regulations on the Use of Land for Saving and Intensive Use” policy, which restricted the supply of new built-up land in 16 megacities undergoing urban construction and development. This shows that China is beginning to prioritize the protection of ecology and environment in urban development. As stated in 4.3, the restrictions on the supply of built-up land can effectively avoid further deterioration of the environment. The findings of this study suggest that more attention should be paid to the construction of urban green spaces and urban forests. Future development processes should consider the importance of the protection of forest and water area. Additionally, the relationship between built-up land, cultivated land, bare land, forest and water area should be rationally planned. The results of this study indicate that regulators and city planners should limit disorderly expansion, consider ecological protection, and adhere to the urban planning model of sustainable development. In order to establish a healthy and sustainable development in Wuyishan City. We propose to combine the strong environmental regulation policy, improve market competition mechanism, and make long-term strategic planning of green development. This research found that LUCC has an impact on air quality, and the increase in forests can effectively improve the air environment of the city.", 4. Discussion, 4.4. Application: Policy Recommendation,4
640,"This paper analyzed the relationship between urban LUCC and air quality in the city of Wuyishan. The results showed that from 2014 to 2017, built-up land keep stability, and cultivated land and bare land area decreased, while forest and water area increased. The air quality measured in 2017 was better than in 2014. The relationship between LUCC and air pollutant concentrations revealed that the cultivated lands were significantly positively correlated with SO2, CO, O3, and black carbon concentration, while forested areas were significantly negatively correlated with SO2, CO, and black carbon. Furthermore, the change in build-up land during the study period was less obvious and remained at a relatively stable condition, which may be the main reason for the inconspicuous results of our correlation test.The results of this study indicate that changes in land uses may have direct or indirect impacts on the air quality. This research explains the correlation between LUCC and air pollutants concentration in Wuyishan City. It provides a references for regional development planning and can better improve urban planning and construction by comparing the relationship between LUCC and air pollutants for different urbanization levels in the future. In order to improve the urban air environment and enable people to live in a healthier environment, the actions of afforestation should continue to be maintained. There were also some shortcomings of this study. For example, in this study, only 5 types of land use types were classified. For future research, it is necessary to refine the classification of land types in order to guide the city’s construction direction more comprehensively and accurately. The investigation of the slight pollution phenomenon in Wuyishan City in 2017 can only help make a preliminary judgment; the time span of the study can be extended appropriately if needed. Additionally, it will continue to be strengthened in future researches.", 5. Conclusions,None,5
